pygame 1.9.6
Hello from the pygame community. https://www.pygame.org/contribute.html
Loading chipmunk for Linux (64bit) [/usr/local/lib/python3.5/dist-packages/pymunk/libchipmunk.so]
Starting test with params: {'nn_layers': [64, 64, 64]}
Namespace(draw_screen=False, env_config='configs/env.config', policy='multi_human_rl', policy_config='configs/policy.config', test=False, train_config='configs/train.config', weights=None)
Gym environment created.
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.5435547    |
| ent_coef_loss           | -2.0474677   |
| entropy                 | 2.6189935    |
| episodes                | 4            |
| fps                     | 146          |
| mean 100 episode reward | -0.1         |
| n_updates               | 1220         |
| policy_loss             | -5.432762    |
| qf1_loss                | 0.0041970694 |
| qf2_loss                | 0.0025909154 |
| time_elapsed            | 8            |
| total timesteps         | 1320         |
| value_loss              | 0.0170949    |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.22553082   |
| ent_coef_loss           | -4.972507    |
| entropy                 | 2.5918932    |
| episodes                | 8            |
| fps                     | 144          |
| mean 100 episode reward | -0.1         |
| n_updates               | 2980         |
| policy_loss             | -8.493529    |
| qf1_loss                | 0.006931858  |
| qf2_loss                | 0.0075816647 |
| time_elapsed            | 21           |
| total timesteps         | 3080         |
| value_loss              | 0.025726605  |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0005      |
| ent_coef                | 0.09392594  |
| ent_coef_loss           | -7.5939326  |
| entropy                 | 2.5080338   |
| episodes                | 12          |
| fps                     | 142         |
| mean 100 episode reward | -0.1        |
| n_updates               | 4740        |
| policy_loss             | -8.82379    |
| qf1_loss                | 0.020317579 |
| qf2_loss                | 0.02132786  |
| time_elapsed            | 33          |
| total timesteps         | 4840        |
| value_loss              | 0.07889493  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0005      |
| ent_coef                | 0.039453186 |
| ent_coef_loss           | -10.291363  |
| entropy                 | 2.7405481   |
| episodes                | 16          |
| fps                     | 142         |
| mean 100 episode reward | -0.1        |
| n_updates               | 6500        |
| policy_loss             | -8.548777   |
| qf1_loss                | 0.004713271 |
| qf2_loss                | 0.006656021 |
| time_elapsed            | 46          |
| total timesteps         | 6600        |
| value_loss              | 0.008737893 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0005      |
| ent_coef                | 0.017861608 |
| ent_coef_loss           | -7.3171043  |
| entropy                 | 2.2449262   |
| episodes                | 20          |
| fps                     | 142         |
| mean 100 episode reward | -0.1        |
| n_updates               | 8260        |
| policy_loss             | -7.9705925  |
| qf1_loss                | 0.46129474  |
| qf2_loss                | 0.48265985  |
| time_elapsed            | 58          |
| total timesteps         | 8360        |
| value_loss              | 0.007990355 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.011143901  |
| ent_coef_loss           | -1.5239134   |
| entropy                 | 1.09018      |
| episodes                | 24           |
| fps                     | 142          |
| mean 100 episode reward | -0.2         |
| n_updates               | 10020        |
| policy_loss             | -7.361762    |
| qf1_loss                | 0.009359064  |
| qf2_loss                | 0.007901647  |
| time_elapsed            | 71           |
| total timesteps         | 10120        |
| value_loss              | 0.0056055035 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0074536055 |
| ent_coef_loss           | 3.8938482    |
| entropy                 | 1.4427376    |
| episodes                | 28           |
| fps                     | 142          |
| mean 100 episode reward | -0.2         |
| n_updates               | 11780        |
| policy_loss             | -6.7588882   |
| qf1_loss                | 0.006237128  |
| qf2_loss                | 0.0047628474 |
| time_elapsed            | 83           |
| total timesteps         | 11880        |
| value_loss              | 0.005517234  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0061797863 |
| ent_coef_loss           | -4.6382523   |
| entropy                 | 1.039737     |
| episodes                | 32           |
| fps                     | 141          |
| mean 100 episode reward | -0.2         |
| n_updates               | 13540        |
| policy_loss             | -6.0956516   |
| qf1_loss                | 0.002227766  |
| qf2_loss                | 0.0022510532 |
| time_elapsed            | 96           |
| total timesteps         | 13640        |
| value_loss              | 0.006620812  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.005164387  |
| ent_coef_loss           | 2.1340647    |
| entropy                 | 0.54336524   |
| episodes                | 36           |
| fps                     | 141          |
| mean 100 episode reward | -0.1         |
| n_updates               | 15300        |
| policy_loss             | -5.5706196   |
| qf1_loss                | 0.23094657   |
| qf2_loss                | 0.2348917    |
| time_elapsed            | 108          |
| total timesteps         | 15400        |
| value_loss              | 0.0075176065 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0036832315 |
| ent_coef_loss           | -0.3335357   |
| entropy                 | -0.41380113  |
| episodes                | 40           |
| fps                     | 141          |
| mean 100 episode reward | -0.1         |
| n_updates               | 17060        |
| policy_loss             | -5.011347    |
| qf1_loss                | 0.0015966643 |
| qf2_loss                | 0.0023241166 |
| time_elapsed            | 121          |
| total timesteps         | 17160        |
| value_loss              | 0.0015326142 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0043412796 |
| ent_coef_loss           | 1.1701561    |
| entropy                 | 1.1726664    |
| episodes                | 44           |
| fps                     | 141          |
| mean 100 episode reward | -0.1         |
| n_updates               | 18820        |
| policy_loss             | -4.6520643   |
| qf1_loss                | 0.0023414777 |
| qf2_loss                | 0.0034459368 |
| time_elapsed            | 133          |
| total timesteps         | 18920        |
| value_loss              | 0.004636294  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0034819478 |
| ent_coef_loss           | -2.6394186   |
| entropy                 | -0.74658084  |
| episodes                | 48           |
| fps                     | 141          |
| mean 100 episode reward | -0.2         |
| n_updates               | 20580        |
| policy_loss             | -4.1405973   |
| qf1_loss                | 0.0018998873 |
| qf2_loss                | 0.0015740157 |
| time_elapsed            | 146          |
| total timesteps         | 20680        |
| value_loss              | 0.0045561325 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.002995514  |
| ent_coef_loss           | -6.3384256   |
| entropy                 | 0.68384385   |
| episodes                | 52           |
| fps                     | 141          |
| mean 100 episode reward | -0.1         |
| n_updates               | 22340        |
| policy_loss             | -3.7896214   |
| qf1_loss                | 0.0020597521 |
| qf2_loss                | 0.0021795284 |
| time_elapsed            | 158          |
| total timesteps         | 22440        |
| value_loss              | 0.008047891  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.002208265   |
| ent_coef_loss           | -2.3642921    |
| entropy                 | 0.45857525    |
| episodes                | 56            |
| fps                     | 141           |
| mean 100 episode reward | -0.1          |
| n_updates               | 24100         |
| policy_loss             | -3.2933073    |
| qf1_loss                | 0.00035802624 |
| qf2_loss                | 0.00026441162 |
| time_elapsed            | 171           |
| total timesteps         | 24200         |
| value_loss              | 0.00054639566 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0017705351  |
| ent_coef_loss           | -6.0185814    |
| entropy                 | -0.2375076    |
| episodes                | 60            |
| fps                     | 141           |
| mean 100 episode reward | -0.2          |
| n_updates               | 25641         |
| policy_loss             | -3.0530791    |
| qf1_loss                | 0.00027571223 |
| qf2_loss                | 0.00034818414 |
| time_elapsed            | 182           |
| total timesteps         | 25741         |
| value_loss              | 0.00063838    |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0022656862  |
| ent_coef_loss           | 2.2360244     |
| entropy                 | 0.5222195     |
| episodes                | 64            |
| fps                     | 141           |
| mean 100 episode reward | -0.3          |
| n_updates               | 27401         |
| policy_loss             | -2.79944      |
| qf1_loss                | 0.0006369268  |
| qf2_loss                | 0.00042189838 |
| time_elapsed            | 194           |
| total timesteps         | 27501         |
| value_loss              | 0.002917034   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0016693812  |
| ent_coef_loss           | -2.397186     |
| entropy                 | 0.2848263     |
| episodes                | 68            |
| fps                     | 141           |
| mean 100 episode reward | -0.3          |
| n_updates               | 28823         |
| policy_loss             | -2.568326     |
| qf1_loss                | 0.00030908512 |
| qf2_loss                | 0.00029455387 |
| time_elapsed            | 204           |
| total timesteps         | 28923         |
| value_loss              | 0.00021067598 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013196405  |
| ent_coef_loss           | 1.6109414     |
| entropy                 | 0.03172736    |
| episodes                | 72            |
| fps                     | 141           |
| mean 100 episode reward | -0.4          |
| n_updates               | 30308         |
| policy_loss             | -2.3430283    |
| qf1_loss                | 0.00018767867 |
| qf2_loss                | 0.00014057412 |
| time_elapsed            | 215           |
| total timesteps         | 30408         |
| value_loss              | 0.00041557237 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011413569  |
| ent_coef_loss           | 1.8456416     |
| entropy                 | 0.12034812    |
| episodes                | 76            |
| fps                     | 141           |
| mean 100 episode reward | -0.4          |
| n_updates               | 31787         |
| policy_loss             | -2.1825423    |
| qf1_loss                | 0.0002793631  |
| qf2_loss                | 0.00019639448 |
| time_elapsed            | 225           |
| total timesteps         | 31887         |
| value_loss              | 0.00017626435 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010202698  |
| ent_coef_loss           | -0.5819311    |
| entropy                 | -0.62157476   |
| episodes                | 80            |
| fps                     | 141           |
| mean 100 episode reward | -0.5          |
| n_updates               | 32685         |
| policy_loss             | -2.0434604    |
| qf1_loss                | 0.00035211036 |
| qf2_loss                | 0.00062796986 |
| time_elapsed            | 232           |
| total timesteps         | 32785         |
| value_loss              | 0.0038691934  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009153488  |
| ent_coef_loss           | 9.797649      |
| entropy                 | 0.17793101    |
| episodes                | 84            |
| fps                     | 141           |
| mean 100 episode reward | -0.5          |
| n_updates               | 33874         |
| policy_loss             | -1.9279389    |
| qf1_loss                | 0.00021073595 |
| qf2_loss                | 0.00018656175 |
| time_elapsed            | 240           |
| total timesteps         | 33974         |
| value_loss              | 0.0004026139  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00083378796 |
| ent_coef_loss           | -5.174773     |
| entropy                 | 0.17658272    |
| episodes                | 88            |
| fps                     | 141           |
| mean 100 episode reward | -0.5          |
| n_updates               | 35634         |
| policy_loss             | -1.7633891    |
| qf1_loss                | 0.00014353331 |
| qf2_loss                | 0.00014455902 |
| time_elapsed            | 252           |
| total timesteps         | 35734         |
| value_loss              | 0.00016669671 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007410653  |
| ent_coef_loss           | -3.3890893    |
| entropy                 | -0.5957417    |
| episodes                | 92            |
| fps                     | 141           |
| mean 100 episode reward | -0.5          |
| n_updates               | 37394         |
| policy_loss             | -1.5813317    |
| qf1_loss                | 0.00012403502 |
| qf2_loss                | 0.00016351389 |
| time_elapsed            | 265           |
| total timesteps         | 37494         |
| value_loss              | 0.00023461356 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007612406  |
| ent_coef_loss           | -1.6455848    |
| entropy                 | -0.024889179  |
| episodes                | 96            |
| fps                     | 141           |
| mean 100 episode reward | -0.6          |
| n_updates               | 38981         |
| policy_loss             | -1.4369881    |
| qf1_loss                | 0.00023460877 |
| qf2_loss                | 0.00015443814 |
| time_elapsed            | 276           |
| total timesteps         | 39081         |
| value_loss              | 0.00026900467 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00059979886 |
| ent_coef_loss           | 14.0174265    |
| entropy                 | 0.21204096    |
| episodes                | 100           |
| fps                     | 141           |
| mean 100 episode reward | -0.5          |
| n_updates               | 40624         |
| policy_loss             | -1.3109365    |
| qf1_loss                | 0.00014476763 |
| qf2_loss                | 0.00011044871 |
| time_elapsed            | 288           |
| total timesteps         | 40724         |
| value_loss              | 7.692969e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00069910346 |
| ent_coef_loss           | 0.64129174    |
| entropy                 | -0.07919474   |
| episodes                | 104           |
| fps                     | 141           |
| mean 100 episode reward | -0.6          |
| n_updates               | 42384         |
| policy_loss             | -1.1880536    |
| qf1_loss                | 9.207706e-05  |
| qf2_loss                | 0.00011875773 |
| time_elapsed            | 300           |
| total timesteps         | 42484         |
| value_loss              | 6.097553e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000873756   |
| ent_coef_loss           | -0.98877347   |
| entropy                 | 0.20045134    |
| episodes                | 108           |
| fps                     | 141           |
| mean 100 episode reward | -0.7          |
| n_updates               | 43839         |
| policy_loss             | -1.0882852    |
| qf1_loss                | 5.9612357e-05 |
| qf2_loss                | 9.733868e-05  |
| time_elapsed            | 311           |
| total timesteps         | 43939         |
| value_loss              | 6.231718e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00071194256 |
| ent_coef_loss           | 1.7819021     |
| entropy                 | -0.18270579   |
| episodes                | 112           |
| fps                     | 141           |
| mean 100 episode reward | -0.7          |
| n_updates               | 45572         |
| policy_loss             | -0.9977617    |
| qf1_loss                | 9.838026e-05  |
| qf2_loss                | 5.7266734e-05 |
| time_elapsed            | 323           |
| total timesteps         | 45672         |
| value_loss              | 0.0002606877  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0005173884 |
| ent_coef_loss           | -0.30949464  |
| entropy                 | -0.7898568   |
| episodes                | 116          |
| fps                     | 141          |
| mean 100 episode reward | -0.9         |
| n_updates               | 47218        |
| policy_loss             | -0.881843    |
| qf1_loss                | 0.00904399   |
| qf2_loss                | 0.009130654  |
| time_elapsed            | 334          |
| total timesteps         | 47318        |
| value_loss              | 6.546734e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00047739776 |
| ent_coef_loss           | 5.2963343     |
| entropy                 | -0.5055134    |
| episodes                | 120           |
| fps                     | 141           |
| mean 100 episode reward | -1            |
| n_updates               | 48978         |
| policy_loss             | -0.808408     |
| qf1_loss                | 4.53021e-05   |
| qf2_loss                | 4.8048212e-05 |
| time_elapsed            | 347           |
| total timesteps         | 49078         |
| value_loss              | 5.7351208e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0005689607  |
| ent_coef_loss           | 4.341472      |
| entropy                 | 0.09296095    |
| episodes                | 124           |
| fps                     | 141           |
| mean 100 episode reward | -1            |
| n_updates               | 50205         |
| policy_loss             | -0.72927517   |
| qf1_loss                | 8.335516e-05  |
| qf2_loss                | 5.8711255e-05 |
| time_elapsed            | 356           |
| total timesteps         | 50305         |
| value_loss              | 4.168531e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0004840639  |
| ent_coef_loss           | -2.7841284    |
| entropy                 | -0.043315627  |
| episodes                | 128           |
| fps                     | 141           |
| mean 100 episode reward | -1            |
| n_updates               | 51965         |
| policy_loss             | -0.6669402    |
| qf1_loss                | 0.00016458167 |
| qf2_loss                | 0.00016328564 |
| time_elapsed            | 368           |
| total timesteps         | 52065         |
| value_loss              | 3.989496e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0005479414  |
| ent_coef_loss           | -1.2607735    |
| entropy                 | 0.30665392    |
| episodes                | 132           |
| fps                     | 141           |
| mean 100 episode reward | -1            |
| n_updates               | 53415         |
| policy_loss             | -0.5942266    |
| qf1_loss                | 1.9069168e-05 |
| qf2_loss                | 2.5034064e-05 |
| time_elapsed            | 378           |
| total timesteps         | 53515         |
| value_loss              | 2.8988808e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0004860813  |
| ent_coef_loss           | 0.3411976     |
| entropy                 | 0.33740756    |
| episodes                | 136           |
| fps                     | 141           |
| mean 100 episode reward | -1.1          |
| n_updates               | 54537         |
| policy_loss             | -0.54899246   |
| qf1_loss                | 3.175977e-05  |
| qf2_loss                | 8.8015266e-05 |
| time_elapsed            | 386           |
| total timesteps         | 54637         |
| value_loss              | 5.8620128e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00047437247 |
| ent_coef_loss           | 0.15657336    |
| entropy                 | 0.37872422    |
| episodes                | 140           |
| fps                     | 141           |
| mean 100 episode reward | -1.2          |
| n_updates               | 55463         |
| policy_loss             | -0.5063952    |
| qf1_loss                | 3.4225155e-05 |
| qf2_loss                | 3.2114884e-05 |
| time_elapsed            | 393           |
| total timesteps         | 55563         |
| value_loss              | 9.234515e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00043206874 |
| ent_coef_loss           | 1.2434633     |
| entropy                 | 0.20980337    |
| episodes                | 144           |
| fps                     | 141           |
| mean 100 episode reward | -1.2          |
| n_updates               | 57014         |
| policy_loss             | -0.43687305   |
| qf1_loss                | 0.0020683298  |
| qf2_loss                | 0.0020717585  |
| time_elapsed            | 404           |
| total timesteps         | 57114         |
| value_loss              | 4.304301e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00046876317 |
| ent_coef_loss           | 0.36947906    |
| entropy                 | 0.21221156    |
| episodes                | 148           |
| fps                     | 141           |
| mean 100 episode reward | -1.2          |
| n_updates               | 58351         |
| policy_loss             | -0.3882231    |
| qf1_loss                | 2.7061276e-05 |
| qf2_loss                | 2.321197e-05  |
| time_elapsed            | 413           |
| total timesteps         | 58451         |
| value_loss              | 8.840953e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00051144115 |
| ent_coef_loss           | 7.9290447     |
| entropy                 | 0.56267476    |
| episodes                | 152           |
| fps                     | 141           |
| mean 100 episode reward | -1.2          |
| n_updates               | 60111         |
| policy_loss             | -0.36886215   |
| qf1_loss                | 0.0016262215  |
| qf2_loss                | 0.0016174386  |
| time_elapsed            | 426           |
| total timesteps         | 60211         |
| value_loss              | 5.3605938e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00045258505 |
| ent_coef_loss           | 3.8310666     |
| entropy                 | 0.25134963    |
| episodes                | 156           |
| fps                     | 141           |
| mean 100 episode reward | -1.2          |
| n_updates               | 61621         |
| policy_loss             | -0.3041839    |
| qf1_loss                | 3.832894e-05  |
| qf2_loss                | 6.578924e-05  |
| time_elapsed            | 437           |
| total timesteps         | 61721         |
| value_loss              | 7.602794e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00057918427 |
| ent_coef_loss           | 1.592679      |
| entropy                 | 0.5678213     |
| episodes                | 160           |
| fps                     | 141           |
| mean 100 episode reward | -1.1          |
| n_updates               | 63111         |
| policy_loss             | -0.3023563    |
| qf1_loss                | 0.0008775837  |
| qf2_loss                | 0.0008361137  |
| time_elapsed            | 447           |
| total timesteps         | 63211         |
| value_loss              | 0.00012643053 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00053669565 |
| ent_coef_loss           | 2.480598      |
| entropy                 | 0.5094811     |
| episodes                | 164           |
| fps                     | 141           |
| mean 100 episode reward | -1.1          |
| n_updates               | 64632         |
| policy_loss             | -0.26261035   |
| qf1_loss                | 0.0005734646  |
| qf2_loss                | 0.00064240344 |
| time_elapsed            | 458           |
| total timesteps         | 64732         |
| value_loss              | 0.00010832297 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006202474  |
| ent_coef_loss           | 4.0220346     |
| entropy                 | 0.94775665    |
| episodes                | 168           |
| fps                     | 141           |
| mean 100 episode reward | -1            |
| n_updates               | 65942         |
| policy_loss             | -0.21176064   |
| qf1_loss                | 0.0005103348  |
| qf2_loss                | 0.0007051693  |
| time_elapsed            | 467           |
| total timesteps         | 66042         |
| value_loss              | 0.00044051846 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0006727593 |
| ent_coef_loss           | 2.2831018    |
| entropy                 | 0.59216726   |
| episodes                | 172          |
| fps                     | 141          |
| mean 100 episode reward | -1           |
| n_updates               | 67490        |
| policy_loss             | -0.19483176  |
| qf1_loss                | 7.471729e-05 |
| qf2_loss                | 6.282695e-05 |
| time_elapsed            | 478          |
| total timesteps         | 67590        |
| value_loss              | 8.557225e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006906935  |
| ent_coef_loss           | -0.63817227   |
| entropy                 | 0.72677237    |
| episodes                | 176           |
| fps                     | 141           |
| mean 100 episode reward | -0.9          |
| n_updates               | 68849         |
| policy_loss             | -0.18447256   |
| qf1_loss                | 6.746678e-05  |
| qf2_loss                | 0.00010633514 |
| time_elapsed            | 488           |
| total timesteps         | 68949         |
| value_loss              | 0.0001036721  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0005720276  |
| ent_coef_loss           | 3.6187947     |
| entropy                 | 0.6744694     |
| episodes                | 180           |
| fps                     | 141           |
| mean 100 episode reward | -0.9          |
| n_updates               | 70609         |
| policy_loss             | -0.14701049   |
| qf1_loss                | 0.00014647169 |
| qf2_loss                | 0.0012713296  |
| time_elapsed            | 500           |
| total timesteps         | 70709         |
| value_loss              | 6.572214e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0005582958  |
| ent_coef_loss           | 2.4980762     |
| entropy                 | 0.36469635    |
| episodes                | 184           |
| fps                     | 141           |
| mean 100 episode reward | -0.8          |
| n_updates               | 71759         |
| policy_loss             | -0.16880572   |
| qf1_loss                | 3.838814e-05  |
| qf2_loss                | 5.5308035e-05 |
| time_elapsed            | 509           |
| total timesteps         | 71859         |
| value_loss              | 9.3412615e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0005685053  |
| ent_coef_loss           | -0.4263372    |
| entropy                 | 0.22385693    |
| episodes                | 188           |
| fps                     | 141           |
| mean 100 episode reward | -0.8          |
| n_updates               | 72951         |
| policy_loss             | -0.16708586   |
| qf1_loss                | 0.00018790366 |
| qf2_loss                | 0.00025001742 |
| time_elapsed            | 517           |
| total timesteps         | 73051         |
| value_loss              | 7.7339995e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0005678129 |
| ent_coef_loss           | 3.9311025    |
| entropy                 | 0.048516028  |
| episodes                | 192          |
| fps                     | 141          |
| mean 100 episode reward | -0.8         |
| n_updates               | 74520        |
| policy_loss             | -0.14330742  |
| qf1_loss                | 0.0010407369 |
| qf2_loss                | 0.0011839299 |
| time_elapsed            | 528          |
| total timesteps         | 74620        |
| value_loss              | 0.0017315104 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0005504644  |
| ent_coef_loss           | -2.9422936    |
| entropy                 | 0.23187298    |
| episodes                | 196           |
| fps                     | 141           |
| mean 100 episode reward | -0.7          |
| n_updates               | 76047         |
| policy_loss             | -0.17690483   |
| qf1_loss                | 3.7135844e-05 |
| qf2_loss                | 5.0249957e-05 |
| time_elapsed            | 539           |
| total timesteps         | 76147         |
| value_loss              | 7.2529234e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006558988  |
| ent_coef_loss           | 0.6414468     |
| entropy                 | 0.22541979    |
| episodes                | 200           |
| fps                     | 141           |
| mean 100 episode reward | -0.7          |
| n_updates               | 77759         |
| policy_loss             | -0.15319405   |
| qf1_loss                | 0.0015651241  |
| qf2_loss                | 0.00067587674 |
| time_elapsed            | 551           |
| total timesteps         | 77859         |
| value_loss              | 0.0005772612  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00061257684 |
| ent_coef_loss           | 1.3479593     |
| entropy                 | 0.1621559     |
| episodes                | 204           |
| fps                     | 141           |
| mean 100 episode reward | -0.6          |
| n_updates               | 79259         |
| policy_loss             | -0.14951886   |
| qf1_loss                | 5.4493434e-05 |
| qf2_loss                | 8.7639135e-05 |
| time_elapsed            | 562           |
| total timesteps         | 79359         |
| value_loss              | 4.008489e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00058425654 |
| ent_coef_loss           | -0.38524455   |
| entropy                 | 0.0018409863  |
| episodes                | 208           |
| fps                     | 141           |
| mean 100 episode reward | -0.5          |
| n_updates               | 80669         |
| policy_loss             | -0.116310455  |
| qf1_loss                | 3.9847044e-05 |
| qf2_loss                | 3.6584126e-05 |
| time_elapsed            | 572           |
| total timesteps         | 80769         |
| value_loss              | 4.6575842e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006589776  |
| ent_coef_loss           | -2.9290369    |
| entropy                 | -0.1080724    |
| episodes                | 212           |
| fps                     | 141           |
| mean 100 episode reward | -0.5          |
| n_updates               | 81932         |
| policy_loss             | -0.17807688   |
| qf1_loss                | 2.8421218e-05 |
| qf2_loss                | 2.4760155e-05 |
| time_elapsed            | 581           |
| total timesteps         | 82032         |
| value_loss              | 4.7418464e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007454647  |
| ent_coef_loss           | -2.1863918    |
| entropy                 | -0.1329227    |
| episodes                | 216           |
| fps                     | 141           |
| mean 100 episode reward | -0.3          |
| n_updates               | 83461         |
| policy_loss             | -0.12697843   |
| qf1_loss                | 0.0014121236  |
| qf2_loss                | 0.0016082252  |
| time_elapsed            | 592           |
| total timesteps         | 83561         |
| value_loss              | 0.00055835384 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00074096955 |
| ent_coef_loss           | 5.003182      |
| entropy                 | -0.033976648  |
| episodes                | 220           |
| fps                     | 141           |
| mean 100 episode reward | -0.2          |
| n_updates               | 84340         |
| policy_loss             | -0.15518048   |
| qf1_loss                | 0.008340758   |
| qf2_loss                | 0.008842213   |
| time_elapsed            | 598           |
| total timesteps         | 84440         |
| value_loss              | 0.00015358196 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007846204  |
| ent_coef_loss           | 1.2483306     |
| entropy                 | 0.5869878     |
| episodes                | 224           |
| fps                     | 141           |
| mean 100 episode reward | -0.1          |
| n_updates               | 85604         |
| policy_loss             | -0.14675872   |
| qf1_loss                | 3.8465787e-05 |
| qf2_loss                | 3.5989353e-05 |
| time_elapsed            | 607           |
| total timesteps         | 85704         |
| value_loss              | 5.88795e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00083123543 |
| ent_coef_loss           | 0.40773797    |
| entropy                 | 0.42030972    |
| episodes                | 228           |
| fps                     | 141           |
| mean 100 episode reward | -0            |
| n_updates               | 86670         |
| policy_loss             | -0.1730771    |
| qf1_loss                | 0.0029437453  |
| qf2_loss                | 0.0029192907  |
| time_elapsed            | 615           |
| total timesteps         | 86770         |
| value_loss              | 7.688438e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00080442225 |
| ent_coef_loss           | 0.25286224    |
| entropy                 | 0.6037959     |
| episodes                | 232           |
| fps                     | 141           |
| mean 100 episode reward | 0             |
| n_updates               | 87732         |
| policy_loss             | -0.19470583   |
| qf1_loss                | 5.0548373e-05 |
| qf2_loss                | 4.6907026e-05 |
| time_elapsed            | 622           |
| total timesteps         | 87832         |
| value_loss              | 5.54945e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007253802  |
| ent_coef_loss           | -1.8214892    |
| entropy                 | 0.3174296     |
| episodes                | 236           |
| fps                     | 141           |
| mean 100 episode reward | 0.1           |
| n_updates               | 89282         |
| policy_loss             | -0.20372194   |
| qf1_loss                | 0.00012709506 |
| qf2_loss                | 8.397709e-05  |
| time_elapsed            | 633           |
| total timesteps         | 89382         |
| value_loss              | 8.205678e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00066901965 |
| ent_coef_loss           | 1.183017      |
| entropy                 | -0.06415038   |
| episodes                | 240           |
| fps                     | 141           |
| mean 100 episode reward | 0.2           |
| n_updates               | 90335         |
| policy_loss             | -0.18933308   |
| qf1_loss                | 6.4589054e-05 |
| qf2_loss                | 7.026986e-05  |
| time_elapsed            | 641           |
| total timesteps         | 90435         |
| value_loss              | 0.00018019852 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007376656  |
| ent_coef_loss           | -3.7828717    |
| entropy                 | 0.14638674    |
| episodes                | 244           |
| fps                     | 141           |
| mean 100 episode reward | 0.2           |
| n_updates               | 91738         |
| policy_loss             | -0.17917922   |
| qf1_loss                | 0.000315464   |
| qf2_loss                | 0.0005118474  |
| time_elapsed            | 651           |
| total timesteps         | 91838         |
| value_loss              | 0.00010941042 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008383959  |
| ent_coef_loss           | 3.2245243     |
| entropy                 | 0.47317415    |
| episodes                | 248           |
| fps                     | 141           |
| mean 100 episode reward | 0.2           |
| n_updates               | 93316         |
| policy_loss             | -0.19650543   |
| qf1_loss                | 6.849387e-05  |
| qf2_loss                | 7.752879e-05  |
| time_elapsed            | 662           |
| total timesteps         | 93416         |
| value_loss              | 0.00013659167 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007429111  |
| ent_coef_loss           | -0.27226365   |
| entropy                 | 0.81434816    |
| episodes                | 252           |
| fps                     | 141           |
| mean 100 episode reward | 0.2           |
| n_updates               | 94546         |
| policy_loss             | -0.19204536   |
| qf1_loss                | 4.6669233e-05 |
| qf2_loss                | 5.3090786e-05 |
| time_elapsed            | 671           |
| total timesteps         | 94646         |
| value_loss              | 3.0661093e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00076037867 |
| ent_coef_loss           | 1.6453205     |
| entropy                 | 0.2439985     |
| episodes                | 256           |
| fps                     | 141           |
| mean 100 episode reward | 0.2           |
| n_updates               | 95488         |
| policy_loss             | -0.15626656   |
| qf1_loss                | 0.00065459893 |
| qf2_loss                | 0.0005747772  |
| time_elapsed            | 677           |
| total timesteps         | 95588         |
| value_loss              | 0.00010493284 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009385318  |
| ent_coef_loss           | 0.9390638     |
| entropy                 | 0.66917646    |
| episodes                | 260           |
| fps                     | 141           |
| mean 100 episode reward | 0.3           |
| n_updates               | 96789         |
| policy_loss             | -0.2164841    |
| qf1_loss                | 0.00028519772 |
| qf2_loss                | 0.00031460833 |
| time_elapsed            | 687           |
| total timesteps         | 96889         |
| value_loss              | 0.0003501803  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009444033  |
| ent_coef_loss           | -0.2656451    |
| entropy                 | 0.6834185     |
| episodes                | 264           |
| fps                     | 141           |
| mean 100 episode reward | 0.3           |
| n_updates               | 97738         |
| policy_loss             | -0.19750935   |
| qf1_loss                | 0.0014503971  |
| qf2_loss                | 0.00070069724 |
| time_elapsed            | 693           |
| total timesteps         | 97838         |
| value_loss              | 9.487814e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00080220593 |
| ent_coef_loss           | 3.0880027     |
| entropy                 | 0.34421796    |
| episodes                | 268           |
| fps                     | 141           |
| mean 100 episode reward | 0.3           |
| n_updates               | 98948         |
| policy_loss             | -0.22744498   |
| qf1_loss                | 6.957708e-05  |
| qf2_loss                | 0.00086540985 |
| time_elapsed            | 702           |
| total timesteps         | 99048         |
| value_loss              | 0.00048417316 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0008150277   |
| ent_coef_loss           | 1.6784052      |
| entropy                 | 0.6219388      |
| episodes                | 272            |
| fps                     | 141            |
| mean 100 episode reward | 0.3            |
| n_updates               | 100160         |
| policy_loss             | -0.21855596    |
| qf1_loss                | 0.000102253405 |
| qf2_loss                | 9.0205474e-05  |
| time_elapsed            | 710            |
| total timesteps         | 100260         |
| value_loss              | 0.00014221849  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008047618  |
| ent_coef_loss           | -0.4955436    |
| entropy                 | 0.8337984     |
| episodes                | 276           |
| fps                     | 141           |
| mean 100 episode reward | 0.3           |
| n_updates               | 101471        |
| policy_loss             | -0.23199329   |
| qf1_loss                | 0.00037014775 |
| qf2_loss                | 0.0004107814  |
| time_elapsed            | 720           |
| total timesteps         | 101571        |
| value_loss              | 0.00011976892 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008891423  |
| ent_coef_loss           | -1.8246558    |
| entropy                 | 0.94239306    |
| episodes                | 280           |
| fps                     | 141           |
| mean 100 episode reward | 0.4           |
| n_updates               | 102304        |
| policy_loss             | -0.23156562   |
| qf1_loss                | 6.0097955e-05 |
| qf2_loss                | 5.4424196e-05 |
| time_elapsed            | 726           |
| total timesteps         | 102404        |
| value_loss              | 4.2872838e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00079636707 |
| ent_coef_loss           | 1.1996024     |
| entropy                 | 0.398151      |
| episodes                | 284           |
| fps                     | 141           |
| mean 100 episode reward | 0.4           |
| n_updates               | 103436        |
| policy_loss             | -0.23684964   |
| qf1_loss                | 9.873745e-05  |
| qf2_loss                | 6.931053e-05  |
| time_elapsed            | 734           |
| total timesteps         | 103536        |
| value_loss              | 0.00012063171 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008957481  |
| ent_coef_loss           | -0.4401632    |
| entropy                 | 0.6292901     |
| episodes                | 288           |
| fps                     | 141           |
| mean 100 episode reward | 0.4           |
| n_updates               | 104325        |
| policy_loss             | -0.2614876    |
| qf1_loss                | 5.1890056e-05 |
| qf2_loss                | 5.7271936e-05 |
| time_elapsed            | 740           |
| total timesteps         | 104425        |
| value_loss              | 8.400674e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000943271   |
| ent_coef_loss           | 1.0417463     |
| entropy                 | 0.8849344     |
| episodes                | 292           |
| fps                     | 141           |
| mean 100 episode reward | 0.4           |
| n_updates               | 105293        |
| policy_loss             | -0.29235318   |
| qf1_loss                | 6.84937e-05   |
| qf2_loss                | 4.232735e-05  |
| time_elapsed            | 747           |
| total timesteps         | 105393        |
| value_loss              | 5.4994794e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007610417  |
| ent_coef_loss           | -2.7717285    |
| entropy                 | 0.64934474    |
| episodes                | 296           |
| fps                     | 141           |
| mean 100 episode reward | 0.5           |
| n_updates               | 106259        |
| policy_loss             | -0.25602412   |
| qf1_loss                | 6.380577e-05  |
| qf2_loss                | 4.6671485e-05 |
| time_elapsed            | 754           |
| total timesteps         | 106359        |
| value_loss              | 0.00016923429 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0008154467 |
| ent_coef_loss           | -0.24946284  |
| entropy                 | 0.31895047   |
| episodes                | 300          |
| fps                     | 141          |
| mean 100 episode reward | 0.5          |
| n_updates               | 107068       |
| policy_loss             | -0.29855937  |
| qf1_loss                | 0.0035397585 |
| qf2_loss                | 0.0035778696 |
| time_elapsed            | 759          |
| total timesteps         | 107168       |
| value_loss              | 9.265235e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008065943  |
| ent_coef_loss           | 4.049377      |
| entropy                 | 0.80941975    |
| episodes                | 304           |
| fps                     | 141           |
| mean 100 episode reward | 0.5           |
| n_updates               | 108371        |
| policy_loss             | -0.36658362   |
| qf1_loss                | 8.706375e-05  |
| qf2_loss                | 5.234123e-05  |
| time_elapsed            | 769           |
| total timesteps         | 108471        |
| value_loss              | 5.8225025e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000769381   |
| ent_coef_loss           | -2.2527783    |
| entropy                 | 0.57537544    |
| episodes                | 308           |
| fps                     | 141           |
| mean 100 episode reward | 0.5           |
| n_updates               | 109377        |
| policy_loss             | -0.33490682   |
| qf1_loss                | 0.0011744489  |
| qf2_loss                | 0.0012031714  |
| time_elapsed            | 776           |
| total timesteps         | 109477        |
| value_loss              | 0.00013057326 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008416817  |
| ent_coef_loss           | 0.6020812     |
| entropy                 | 0.707047      |
| episodes                | 312           |
| fps                     | 141           |
| mean 100 episode reward | 0.5           |
| n_updates               | 110342        |
| policy_loss             | -0.28877997   |
| qf1_loss                | 9.8339195e-05 |
| qf2_loss                | 4.975784e-05  |
| time_elapsed            | 783           |
| total timesteps         | 110442        |
| value_loss              | 5.416123e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092818297 |
| ent_coef_loss           | 0.051105052   |
| entropy                 | 0.8906542     |
| episodes                | 316           |
| fps                     | 141           |
| mean 100 episode reward | 0.6           |
| n_updates               | 111450        |
| policy_loss             | -0.31289178   |
| qf1_loss                | 0.00014008302 |
| qf2_loss                | 0.00016213124 |
| time_elapsed            | 790           |
| total timesteps         | 111550        |
| value_loss              | 6.298917e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093241315 |
| ent_coef_loss           | -0.3263328    |
| entropy                 | 0.6707299     |
| episodes                | 320           |
| fps                     | 141           |
| mean 100 episode reward | 0.5           |
| n_updates               | 112520        |
| policy_loss             | -0.39539582   |
| qf1_loss                | 4.1550556e-05 |
| qf2_loss                | 5.060673e-05  |
| time_elapsed            | 798           |
| total timesteps         | 112620        |
| value_loss              | 7.015957e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090702454 |
| ent_coef_loss           | -3.8120375    |
| entropy                 | 0.8320565     |
| episodes                | 324           |
| fps                     | 141           |
| mean 100 episode reward | 0.6           |
| n_updates               | 113424        |
| policy_loss             | -0.35642093   |
| qf1_loss                | 6.614569e-05  |
| qf2_loss                | 5.46935e-05   |
| time_elapsed            | 804           |
| total timesteps         | 113524        |
| value_loss              | 6.640468e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000970891   |
| ent_coef_loss           | -0.33012128   |
| entropy                 | 0.71921444    |
| episodes                | 328           |
| fps                     | 141           |
| mean 100 episode reward | 0.6           |
| n_updates               | 114669        |
| policy_loss             | -0.35664406   |
| qf1_loss                | 0.00010166773 |
| qf2_loss                | 0.0003768555  |
| time_elapsed            | 813           |
| total timesteps         | 114769        |
| value_loss              | 0.00013446031 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092806126 |
| ent_coef_loss           | -0.10919109   |
| entropy                 | 0.69214576    |
| episodes                | 332           |
| fps                     | 141           |
| mean 100 episode reward | 0.6           |
| n_updates               | 115720        |
| policy_loss             | -0.40254325   |
| qf1_loss                | 0.00010351952 |
| qf2_loss                | 8.0243306e-05 |
| time_elapsed            | 821           |
| total timesteps         | 115820        |
| value_loss              | 0.00011700907 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0008558842 |
| ent_coef_loss           | 1.0340756    |
| entropy                 | 0.76675516   |
| episodes                | 336          |
| fps                     | 141          |
| mean 100 episode reward | 0.6          |
| n_updates               | 116597       |
| policy_loss             | -0.34346664  |
| qf1_loss                | 8.761396e-05 |
| qf2_loss                | 8.029473e-05 |
| time_elapsed            | 827          |
| total timesteps         | 116697       |
| value_loss              | 8.129659e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008029472  |
| ent_coef_loss           | 1.5823581     |
| entropy                 | 0.4743479     |
| episodes                | 340           |
| fps                     | 141           |
| mean 100 episode reward | 0.6           |
| n_updates               | 117628        |
| policy_loss             | -0.347571     |
| qf1_loss                | 5.4261687e-05 |
| qf2_loss                | 5.435913e-05  |
| time_elapsed            | 834           |
| total timesteps         | 117728        |
| value_loss              | 7.4417316e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008565542  |
| ent_coef_loss           | -2.594687     |
| entropy                 | 0.5932581     |
| episodes                | 344           |
| fps                     | 141           |
| mean 100 episode reward | 0.6           |
| n_updates               | 118628        |
| policy_loss             | -0.34146088   |
| qf1_loss                | 0.00014789547 |
| qf2_loss                | 0.00010842574 |
| time_elapsed            | 841           |
| total timesteps         | 118728        |
| value_loss              | 0.00019191804 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008866532  |
| ent_coef_loss           | 0.3719495     |
| entropy                 | 0.7732165     |
| episodes                | 348           |
| fps                     | 141           |
| mean 100 episode reward | 0.7           |
| n_updates               | 119531        |
| policy_loss             | -0.27539027   |
| qf1_loss                | 8.934654e-05  |
| qf2_loss                | 0.0002448462  |
| time_elapsed            | 848           |
| total timesteps         | 119631        |
| value_loss              | 0.00011690724 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087030476 |
| ent_coef_loss           | -0.23273045   |
| entropy                 | 0.7342947     |
| episodes                | 352           |
| fps                     | 141           |
| mean 100 episode reward | 0.7           |
| n_updates               | 120513        |
| policy_loss             | -0.28580427   |
| qf1_loss                | 0.0001885478  |
| qf2_loss                | 0.00028802454 |
| time_elapsed            | 855           |
| total timesteps         | 120613        |
| value_loss              | 0.00026536692 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085279543 |
| ent_coef_loss           | 2.6883194     |
| entropy                 | 0.62516487    |
| episodes                | 356           |
| fps                     | 141           |
| mean 100 episode reward | 0.7           |
| n_updates               | 121312        |
| policy_loss             | -0.37296662   |
| qf1_loss                | 9.5822885e-05 |
| qf2_loss                | 8.947952e-05  |
| time_elapsed            | 860           |
| total timesteps         | 121412        |
| value_loss              | 0.000199479   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094708655 |
| ent_coef_loss           | 2.144728      |
| entropy                 | 0.7925067     |
| episodes                | 360           |
| fps                     | 141           |
| mean 100 episode reward | 0.7           |
| n_updates               | 122153        |
| policy_loss             | -0.36202997   |
| qf1_loss                | 6.868088e-05  |
| qf2_loss                | 7.452705e-05  |
| time_elapsed            | 866           |
| total timesteps         | 122253        |
| value_loss              | 5.1050985e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00082053884 |
| ent_coef_loss           | 0.15191257    |
| entropy                 | 0.69713104    |
| episodes                | 364           |
| fps                     | 141           |
| mean 100 episode reward | 0.7           |
| n_updates               | 122903        |
| policy_loss             | -0.35583094   |
| qf1_loss                | 0.00046869437 |
| qf2_loss                | 0.00026399974 |
| time_elapsed            | 872           |
| total timesteps         | 123003        |
| value_loss              | 0.0006845216  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008902491  |
| ent_coef_loss           | 5.4585447     |
| entropy                 | 0.5412466     |
| episodes                | 368           |
| fps                     | 141           |
| mean 100 episode reward | 0.7           |
| n_updates               | 123654        |
| policy_loss             | -0.309719     |
| qf1_loss                | 0.00019873772 |
| qf2_loss                | 0.00012424274 |
| time_elapsed            | 877           |
| total timesteps         | 123754        |
| value_loss              | 0.00012946359 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009725539   |
| ent_coef_loss           | 0.15321308     |
| entropy                 | 1.1676458      |
| episodes                | 372            |
| fps                     | 141            |
| mean 100 episode reward | 0.7            |
| n_updates               | 124384         |
| policy_loss             | -0.34921065    |
| qf1_loss                | 4.5195447e-05  |
| qf2_loss                | 4.2548665e-05  |
| time_elapsed            | 882            |
| total timesteps         | 124484         |
| value_loss              | 0.000114222494 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009631963  |
| ent_coef_loss           | -0.6840998    |
| entropy                 | 0.93398196    |
| episodes                | 376           |
| fps                     | 141           |
| mean 100 episode reward | 0.7           |
| n_updates               | 125159        |
| policy_loss             | -0.40772343   |
| qf1_loss                | 0.0015930962  |
| qf2_loss                | 0.0017908891  |
| time_elapsed            | 888           |
| total timesteps         | 125259        |
| value_loss              | 0.00017216927 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092694367 |
| ent_coef_loss           | -2.7371454    |
| entropy                 | 0.9827868     |
| episodes                | 380           |
| fps                     | 141           |
| mean 100 episode reward | 0.7           |
| n_updates               | 125918        |
| policy_loss             | -0.35955924   |
| qf1_loss                | 0.0001502437  |
| qf2_loss                | 0.00020540511 |
| time_elapsed            | 893           |
| total timesteps         | 126018        |
| value_loss              | 0.0003000021  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093907124 |
| ent_coef_loss           | 2.8974762     |
| entropy                 | 1.0546389     |
| episodes                | 384           |
| fps                     | 141           |
| mean 100 episode reward | 0.7           |
| n_updates               | 126727        |
| policy_loss             | -0.43456542   |
| qf1_loss                | 0.00023125744 |
| qf2_loss                | 0.0003040363  |
| time_elapsed            | 899           |
| total timesteps         | 126827        |
| value_loss              | 8.500126e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010762183  |
| ent_coef_loss           | 1.539546      |
| entropy                 | 1.108706      |
| episodes                | 388           |
| fps                     | 141           |
| mean 100 episode reward | 0.8           |
| n_updates               | 127591        |
| policy_loss             | -0.36693114   |
| qf1_loss                | 6.6902e-05    |
| qf2_loss                | 5.54593e-05   |
| time_elapsed            | 905           |
| total timesteps         | 127691        |
| value_loss              | 5.1558214e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010013011  |
| ent_coef_loss           | -0.6955972    |
| entropy                 | 0.90478086    |
| episodes                | 392           |
| fps                     | 141           |
| mean 100 episode reward | 0.8           |
| n_updates               | 128534        |
| policy_loss             | -0.3794703    |
| qf1_loss                | 0.00016495275 |
| qf2_loss                | 5.506967e-05  |
| time_elapsed            | 912           |
| total timesteps         | 128634        |
| value_loss              | 9.924968e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009620097  |
| ent_coef_loss           | 2.8118312     |
| entropy                 | 0.8715602     |
| episodes                | 396           |
| fps                     | 141           |
| mean 100 episode reward | 0.8           |
| n_updates               | 129357        |
| policy_loss             | -0.41894      |
| qf1_loss                | 0.0006001091  |
| qf2_loss                | 0.00074439915 |
| time_elapsed            | 917           |
| total timesteps         | 129457        |
| value_loss              | 0.0003859785  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010399052  |
| ent_coef_loss           | -0.09633875   |
| entropy                 | 1.09637       |
| episodes                | 400           |
| fps                     | 141           |
| mean 100 episode reward | 0.8           |
| n_updates               | 130217        |
| policy_loss             | -0.37441295   |
| qf1_loss                | 7.688574e-05  |
| qf2_loss                | 8.622685e-05  |
| time_elapsed            | 923           |
| total timesteps         | 130317        |
| value_loss              | 0.00011259745 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011267377  |
| ent_coef_loss           | -2.781622     |
| entropy                 | 1.192775      |
| episodes                | 404           |
| fps                     | 141           |
| mean 100 episode reward | 0.8           |
| n_updates               | 131041        |
| policy_loss             | -0.4083045    |
| qf1_loss                | 3.2773794e-05 |
| qf2_loss                | 3.644918e-05  |
| time_elapsed            | 929           |
| total timesteps         | 131141        |
| value_loss              | 6.181817e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0011619561   |
| ent_coef_loss           | -0.42789865    |
| entropy                 | 1.3455783      |
| episodes                | 408            |
| fps                     | 141            |
| mean 100 episode reward | 0.8            |
| n_updates               | 131924         |
| policy_loss             | -0.3736786     |
| qf1_loss                | 0.000104000224 |
| qf2_loss                | 9.202371e-05   |
| time_elapsed            | 936            |
| total timesteps         | 132024         |
| value_loss              | 0.00011863614  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012654247  |
| ent_coef_loss           | -0.2666018    |
| entropy                 | 1.2883211     |
| episodes                | 412           |
| fps                     | 141           |
| mean 100 episode reward | 0.8           |
| n_updates               | 132603        |
| policy_loss             | -0.3691184    |
| qf1_loss                | 0.00049695524 |
| qf2_loss                | 0.0006776012  |
| time_elapsed            | 941           |
| total timesteps         | 132703        |
| value_loss              | 0.00021877085 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012566911  |
| ent_coef_loss           | -2.0411303    |
| entropy                 | 1.4657484     |
| episodes                | 416           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 133304        |
| policy_loss             | -0.38678083   |
| qf1_loss                | 6.133163e-05  |
| qf2_loss                | 5.205139e-05  |
| time_elapsed            | 946           |
| total timesteps         | 133404        |
| value_loss              | 0.00012402439 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0010690083   |
| ent_coef_loss           | 4.4588633      |
| entropy                 | 1.41729        |
| episodes                | 420            |
| fps                     | 141            |
| mean 100 episode reward | 0.8            |
| n_updates               | 134093         |
| policy_loss             | -0.4509495     |
| qf1_loss                | 9.4708375e-05  |
| qf2_loss                | 0.000120130455 |
| time_elapsed            | 951            |
| total timesteps         | 134193         |
| value_loss              | 0.00014518115  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011147845  |
| ent_coef_loss           | -0.56169343   |
| entropy                 | 1.2634497     |
| episodes                | 424           |
| fps                     | 141           |
| mean 100 episode reward | 0.8           |
| n_updates               | 134814        |
| policy_loss             | -0.38795984   |
| qf1_loss                | 6.4464875e-05 |
| qf2_loss                | 9.644822e-05  |
| time_elapsed            | 956           |
| total timesteps         | 134914        |
| value_loss              | 5.738267e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011677478  |
| ent_coef_loss           | 1.2604396     |
| entropy                 | 1.3001213     |
| episodes                | 428           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 135528        |
| policy_loss             | -0.40220702   |
| qf1_loss                | 0.00054136134 |
| qf2_loss                | 0.0006636864  |
| time_elapsed            | 961           |
| total timesteps         | 135628        |
| value_loss              | 5.656102e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011516439  |
| ent_coef_loss           | -2.02703      |
| entropy                 | 1.2790463     |
| episodes                | 432           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 136310        |
| policy_loss             | -0.44577464   |
| qf1_loss                | 0.0002926826  |
| qf2_loss                | 0.0003811547  |
| time_elapsed            | 967           |
| total timesteps         | 136410        |
| value_loss              | 0.00013773449 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010940074  |
| ent_coef_loss           | -1.1764122    |
| entropy                 | 1.133031      |
| episodes                | 436           |
| fps                     | 141           |
| mean 100 episode reward | 0.9           |
| n_updates               | 137034        |
| policy_loss             | -0.41939723   |
| qf1_loss                | 0.0003392148  |
| qf2_loss                | 0.00025998603 |
| time_elapsed            | 972           |
| total timesteps         | 137134        |
| value_loss              | 5.0423994e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.001115095    |
| ent_coef_loss           | -0.17579323    |
| entropy                 | 1.1289493      |
| episodes                | 440            |
| fps                     | 141            |
| mean 100 episode reward | 0.9            |
| n_updates               | 137836         |
| policy_loss             | -0.4319679     |
| qf1_loss                | 9.6714815e-05  |
| qf2_loss                | 0.000111878035 |
| time_elapsed            | 978            |
| total timesteps         | 137936         |
| value_loss              | 7.2466166e-05  |
--------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0010398929   |
| ent_coef_loss           | -0.9894712     |
| entropy                 | 1.2512444      |
| episodes                | 444            |
| fps                     | 141            |
| mean 100 episode reward | 0.9            |
| n_updates               | 138575         |
| policy_loss             | -0.41299897    |
| qf1_loss                | 0.000113104965 |
| qf2_loss                | 0.00018425388  |
| time_elapsed            | 983            |
| total timesteps         | 138675         |
| value_loss              | 4.560045e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010800875  |
| ent_coef_loss           | 1.3164742     |
| entropy                 | 1.1208076     |
| episodes                | 448           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 139537        |
| policy_loss             | -0.4162538    |
| qf1_loss                | 0.00024426845 |
| qf2_loss                | 0.0002806132  |
| time_elapsed            | 990           |
| total timesteps         | 139637        |
| value_loss              | 5.032611e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010635055  |
| ent_coef_loss           | -0.22271693   |
| entropy                 | 1.1444895     |
| episodes                | 452           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 140233        |
| policy_loss             | -0.4157338    |
| qf1_loss                | 5.7253787e-05 |
| qf2_loss                | 6.505301e-05  |
| time_elapsed            | 995           |
| total timesteps         | 140333        |
| value_loss              | 0.00023813463 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010545196  |
| ent_coef_loss           | -1.3866011    |
| entropy                 | 1.0381002     |
| episodes                | 456           |
| fps                     | 141           |
| mean 100 episode reward | 0.8           |
| n_updates               | 140929        |
| policy_loss             | -0.4522618    |
| qf1_loss                | 0.00010744681 |
| qf2_loss                | 0.00016936843 |
| time_elapsed            | 1000          |
| total timesteps         | 141029        |
| value_loss              | 0.0002596407  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010701292  |
| ent_coef_loss           | -2.23016      |
| entropy                 | 1.1180518     |
| episodes                | 460           |
| fps                     | 141           |
| mean 100 episode reward | 0.8           |
| n_updates               | 141578        |
| policy_loss             | -0.43006536   |
| qf1_loss                | 4.301694e-05  |
| qf2_loss                | 6.911583e-05  |
| time_elapsed            | 1004          |
| total timesteps         | 141678        |
| value_loss              | 0.00010195852 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011712012  |
| ent_coef_loss           | -1.1385353    |
| entropy                 | 1.140141      |
| episodes                | 464           |
| fps                     | 141           |
| mean 100 episode reward | 0.8           |
| n_updates               | 142608        |
| policy_loss             | -0.44323087   |
| qf1_loss                | 6.0203376e-05 |
| qf2_loss                | 4.1903397e-05 |
| time_elapsed            | 1012          |
| total timesteps         | 142708        |
| value_loss              | 0.00010386722 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010899007  |
| ent_coef_loss           | -3.1753266    |
| entropy                 | 1.2318043     |
| episodes                | 468           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 143274        |
| policy_loss             | -0.44892558   |
| qf1_loss                | 4.0604806e-05 |
| qf2_loss                | 4.1951127e-05 |
| time_elapsed            | 1016          |
| total timesteps         | 143374        |
| value_loss              | 4.623379e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010777949  |
| ent_coef_loss           | -0.26867956   |
| entropy                 | 1.1087269     |
| episodes                | 472           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 143952        |
| policy_loss             | -0.44887805   |
| qf1_loss                | 0.00014104038 |
| qf2_loss                | 8.568115e-05  |
| time_elapsed            | 1021          |
| total timesteps         | 144052        |
| value_loss              | 0.00010587211 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010577037  |
| ent_coef_loss           | -1.5805995    |
| entropy                 | 1.1796786     |
| episodes                | 476           |
| fps                     | 141           |
| mean 100 episode reward | 0.8           |
| n_updates               | 144636        |
| policy_loss             | -0.44990128   |
| qf1_loss                | 0.00011841419 |
| qf2_loss                | 0.00022147302 |
| time_elapsed            | 1026          |
| total timesteps         | 144736        |
| value_loss              | 7.612615e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010621499  |
| ent_coef_loss           | 1.5165157     |
| entropy                 | 1.1466448     |
| episodes                | 480           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 145353        |
| policy_loss             | -0.4408856    |
| qf1_loss                | 0.00013289691 |
| qf2_loss                | 7.616244e-05  |
| time_elapsed            | 1031          |
| total timesteps         | 145453        |
| value_loss              | 9.581895e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010557859  |
| ent_coef_loss           | 1.8056984     |
| entropy                 | 1.1247556     |
| episodes                | 484           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 146174        |
| policy_loss             | -0.4915867    |
| qf1_loss                | 0.00034754528 |
| qf2_loss                | 0.00032922384 |
| time_elapsed            | 1037          |
| total timesteps         | 146274        |
| value_loss              | 5.3330165e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010267325 |
| ent_coef_loss           | -1.4892861   |
| entropy                 | 1.095576     |
| episodes                | 488          |
| fps                     | 141          |
| mean 100 episode reward | 0.8          |
| n_updates               | 146828       |
| policy_loss             | -0.4702862   |
| qf1_loss                | 6.243373e-05 |
| qf2_loss                | 4.14274e-05  |
| time_elapsed            | 1042         |
| total timesteps         | 146928       |
| value_loss              | 8.682422e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010097888  |
| ent_coef_loss           | -1.0118247    |
| entropy                 | 1.0878246     |
| episodes                | 492           |
| fps                     | 141           |
| mean 100 episode reward | 0.8           |
| n_updates               | 147509        |
| policy_loss             | -0.49711567   |
| qf1_loss                | 3.1322656e-05 |
| qf2_loss                | 2.6442145e-05 |
| time_elapsed            | 1046          |
| total timesteps         | 147609        |
| value_loss              | 4.8007878e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010276709  |
| ent_coef_loss           | -0.27408946   |
| entropy                 | 1.1441703     |
| episodes                | 496           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 148197        |
| policy_loss             | -0.5431491    |
| qf1_loss                | 7.4816664e-05 |
| qf2_loss                | 9.012071e-05  |
| time_elapsed            | 1051          |
| total timesteps         | 148297        |
| value_loss              | 9.644315e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010215832  |
| ent_coef_loss           | 1.1210575     |
| entropy                 | 1.1797013     |
| episodes                | 500           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 148872        |
| policy_loss             | -0.46378762   |
| qf1_loss                | 2.8709801e-05 |
| qf2_loss                | 4.4522265e-05 |
| time_elapsed            | 1056          |
| total timesteps         | 148972        |
| value_loss              | 0.00012509071 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009826915  |
| ent_coef_loss           | 0.37799895    |
| entropy                 | 1.2394567     |
| episodes                | 504           |
| fps                     | 141           |
| mean 100 episode reward | 0.8           |
| n_updates               | 149521        |
| policy_loss             | -0.51996756   |
| qf1_loss                | 0.00019713756 |
| qf2_loss                | 0.00021528352 |
| time_elapsed            | 1061          |
| total timesteps         | 149621        |
| value_loss              | 6.4078624e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009313045  |
| ent_coef_loss           | -0.99693656   |
| entropy                 | 1.2963948     |
| episodes                | 508           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 150206        |
| policy_loss             | -0.48969862   |
| qf1_loss                | 3.7078054e-05 |
| qf2_loss                | 2.110243e-05  |
| time_elapsed            | 1066          |
| total timesteps         | 150306        |
| value_loss              | 3.599037e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009578476  |
| ent_coef_loss           | -1.3485761    |
| entropy                 | 1.1478469     |
| episodes                | 512           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 150909        |
| policy_loss             | -0.49844277   |
| qf1_loss                | 2.9614075e-05 |
| qf2_loss                | 3.529304e-05  |
| time_elapsed            | 1071          |
| total timesteps         | 151009        |
| value_loss              | 0.00011794839 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00079981494 |
| ent_coef_loss           | 0.27871192    |
| entropy                 | 0.84521824    |
| episodes                | 516           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 151822        |
| policy_loss             | -0.52225757   |
| qf1_loss                | 5.5984823e-05 |
| qf2_loss                | 7.395509e-05  |
| time_elapsed            | 1077          |
| total timesteps         | 151922        |
| value_loss              | 0.00014545782 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0009284933 |
| ent_coef_loss           | -2.4234142   |
| entropy                 | 1.0765853    |
| episodes                | 520          |
| fps                     | 140          |
| mean 100 episode reward | 0.8          |
| n_updates               | 152515       |
| policy_loss             | -0.54527974  |
| qf1_loss                | 5.296546e-05 |
| qf2_loss                | 6.887694e-05 |
| time_elapsed            | 1082         |
| total timesteps         | 152615       |
| value_loss              | 5.676475e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009329148  |
| ent_coef_loss           | -1.1093338    |
| entropy                 | 1.1332979     |
| episodes                | 524           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 153294        |
| policy_loss             | -0.5526035    |
| qf1_loss                | 0.00018191389 |
| qf2_loss                | 0.00011787987 |
| time_elapsed            | 1087          |
| total timesteps         | 153394        |
| value_loss              | 2.9948973e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009761365  |
| ent_coef_loss           | 1.1199069     |
| entropy                 | 1.2552221     |
| episodes                | 528           |
| fps                     | 141           |
| mean 100 episode reward | 0.7           |
| n_updates               | 154055        |
| policy_loss             | -0.53416014   |
| qf1_loss                | 2.5311698e-05 |
| qf2_loss                | 3.7087426e-05 |
| time_elapsed            | 1093          |
| total timesteps         | 154155        |
| value_loss              | 5.123998e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009377749  |
| ent_coef_loss           | 1.3020914     |
| entropy                 | 1.353525      |
| episodes                | 532           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 154702        |
| policy_loss             | -0.48975873   |
| qf1_loss                | 2.0783065e-05 |
| qf2_loss                | 2.1483893e-05 |
| time_elapsed            | 1097          |
| total timesteps         | 154802        |
| value_loss              | 3.8101316e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096199    |
| ent_coef_loss           | 1.9525386     |
| entropy                 | 1.2603182     |
| episodes                | 536           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 155413        |
| policy_loss             | -0.5360929    |
| qf1_loss                | 4.246309e-05  |
| qf2_loss                | 3.0569085e-05 |
| time_elapsed            | 1102          |
| total timesteps         | 155513        |
| value_loss              | 2.6807898e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010738756  |
| ent_coef_loss           | -1.3661048    |
| entropy                 | 1.2785175     |
| episodes                | 540           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 156182        |
| policy_loss             | -0.52654463   |
| qf1_loss                | 2.7104921e-05 |
| qf2_loss                | 2.56153e-05   |
| time_elapsed            | 1108          |
| total timesteps         | 156282        |
| value_loss              | 5.321591e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010619411 |
| ent_coef_loss           | 0.56424063   |
| entropy                 | 1.3858712    |
| episodes                | 544          |
| fps                     | 140          |
| mean 100 episode reward | 0.8          |
| n_updates               | 156868       |
| policy_loss             | -0.49354708  |
| qf1_loss                | 6.565823e-05 |
| qf2_loss                | 4.571872e-05 |
| time_elapsed            | 1113         |
| total timesteps         | 156968       |
| value_loss              | 8.414223e-05 |
------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0010191      |
| ent_coef_loss           | 4.166589       |
| entropy                 | 1.3788791      |
| episodes                | 548            |
| fps                     | 140            |
| mean 100 episode reward | 0.8            |
| n_updates               | 157613         |
| policy_loss             | -0.45600232    |
| qf1_loss                | 0.00014149587  |
| qf2_loss                | 0.000109970446 |
| time_elapsed            | 1118           |
| total timesteps         | 157713         |
| value_loss              | 3.40279e-05    |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010360096  |
| ent_coef_loss           | 3.8454332     |
| entropy                 | 1.362824      |
| episodes                | 552           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 158331        |
| policy_loss             | -0.51459527   |
| qf1_loss                | 6.383432e-05  |
| qf2_loss                | 7.626076e-05  |
| time_elapsed            | 1123          |
| total timesteps         | 158431        |
| value_loss              | 0.00011105541 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000964824   |
| ent_coef_loss           | 1.0334522     |
| entropy                 | 1.2562392     |
| episodes                | 556           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 159070        |
| policy_loss             | -0.5509944    |
| qf1_loss                | 5.1907507e-05 |
| qf2_loss                | 9.858355e-05  |
| time_elapsed            | 1128          |
| total timesteps         | 159170        |
| value_loss              | 7.6360935e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097639253 |
| ent_coef_loss           | 1.924827      |
| entropy                 | 1.1167831     |
| episodes                | 560           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 159711        |
| policy_loss             | -0.51190007   |
| qf1_loss                | 5.046432e-05  |
| qf2_loss                | 6.183766e-05  |
| time_elapsed            | 1133          |
| total timesteps         | 159811        |
| value_loss              | 8.2350605e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010018207  |
| ent_coef_loss           | 1.5053241     |
| entropy                 | 1.2683108     |
| episodes                | 564           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 160362        |
| policy_loss             | -0.51658165   |
| qf1_loss                | 3.241544e-05  |
| qf2_loss                | 2.9295405e-05 |
| time_elapsed            | 1138          |
| total timesteps         | 160462        |
| value_loss              | 0.00011237062 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010734481  |
| ent_coef_loss           | -1.4951441    |
| entropy                 | 1.2131865     |
| episodes                | 568           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 161268        |
| policy_loss             | -0.50613004   |
| qf1_loss                | 9.825261e-05  |
| qf2_loss                | 9.656751e-05  |
| time_elapsed            | 1144          |
| total timesteps         | 161368        |
| value_loss              | 6.0826846e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010428743  |
| ent_coef_loss           | -1.600832     |
| entropy                 | 1.2405634     |
| episodes                | 572           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 161976        |
| policy_loss             | -0.48411328   |
| qf1_loss                | 0.00019160728 |
| qf2_loss                | 0.00016398696 |
| time_elapsed            | 1149          |
| total timesteps         | 162076        |
| value_loss              | 0.00021252548 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009950758  |
| ent_coef_loss           | 1.6872172     |
| entropy                 | 1.2992291     |
| episodes                | 576           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 162705        |
| policy_loss             | -0.4413055    |
| qf1_loss                | 5.0639836e-05 |
| qf2_loss                | 3.9416067e-05 |
| time_elapsed            | 1154          |
| total timesteps         | 162805        |
| value_loss              | 7.4348696e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009882204  |
| ent_coef_loss           | 0.56755996    |
| entropy                 | 1.2654668     |
| episodes                | 580           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 163588        |
| policy_loss             | -0.51848215   |
| qf1_loss                | 8.6999615e-05 |
| qf2_loss                | 0.00010508621 |
| time_elapsed            | 1161          |
| total timesteps         | 163688        |
| value_loss              | 6.925724e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009636428  |
| ent_coef_loss           | 3.8284407     |
| entropy                 | 1.2420543     |
| episodes                | 584           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 164269        |
| policy_loss             | -0.51367426   |
| qf1_loss                | 0.00012920951 |
| qf2_loss                | 0.00014964568 |
| time_elapsed            | 1165          |
| total timesteps         | 164369        |
| value_loss              | 5.0894552e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009253366  |
| ent_coef_loss           | 0.38510257    |
| entropy                 | 1.1882932     |
| episodes                | 588           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 164932        |
| policy_loss             | -0.5246953    |
| qf1_loss                | 3.6593083e-05 |
| qf2_loss                | 3.588504e-05  |
| time_elapsed            | 1170          |
| total timesteps         | 165032        |
| value_loss              | 3.103967e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010006916  |
| ent_coef_loss           | 0.07326481    |
| entropy                 | 1.1829917     |
| episodes                | 592           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 165696        |
| policy_loss             | -0.51488507   |
| qf1_loss                | 3.2030614e-05 |
| qf2_loss                | 4.5591114e-05 |
| time_elapsed            | 1176          |
| total timesteps         | 165796        |
| value_loss              | 8.6521235e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010539846  |
| ent_coef_loss           | -0.52028906   |
| entropy                 | 1.2384958     |
| episodes                | 596           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 166571        |
| policy_loss             | -0.49538082   |
| qf1_loss                | 6.76558e-05   |
| qf2_loss                | 6.533273e-05  |
| time_elapsed            | 1182          |
| total timesteps         | 166671        |
| value_loss              | 0.00014434359 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010880652  |
| ent_coef_loss           | -0.1459918    |
| entropy                 | 1.1506529     |
| episodes                | 600           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 167243        |
| policy_loss             | -0.4938528    |
| qf1_loss                | 6.7563975e-05 |
| qf2_loss                | 0.00010580172 |
| time_elapsed            | 1186          |
| total timesteps         | 167343        |
| value_loss              | 6.4737294e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010831944  |
| ent_coef_loss           | 0.017359376   |
| entropy                 | 1.1553428     |
| episodes                | 604           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 167892        |
| policy_loss             | -0.5496936    |
| qf1_loss                | 2.3753288e-05 |
| qf2_loss                | 1.9357914e-05 |
| time_elapsed            | 1191          |
| total timesteps         | 167992        |
| value_loss              | 5.048106e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010180848  |
| ent_coef_loss           | -2.0116453    |
| entropy                 | 1.1277633     |
| episodes                | 608           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 168568        |
| policy_loss             | -0.5218923    |
| qf1_loss                | 0.00018550293 |
| qf2_loss                | 9.421428e-05  |
| time_elapsed            | 1196          |
| total timesteps         | 168668        |
| value_loss              | 0.00014586796 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010468691 |
| ent_coef_loss           | 1.1172915    |
| entropy                 | 1.2755759    |
| episodes                | 612          |
| fps                     | 140          |
| mean 100 episode reward | 0.8          |
| n_updates               | 169208       |
| policy_loss             | -0.5717584   |
| qf1_loss                | 6.889757e-05 |
| qf2_loss                | 2.569707e-05 |
| time_elapsed            | 1201         |
| total timesteps         | 169308       |
| value_loss              | 9.458806e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097572093 |
| ent_coef_loss           | -0.12587115   |
| entropy                 | 1.1465256     |
| episodes                | 616           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 169948        |
| policy_loss             | -0.5967002    |
| qf1_loss                | 6.988807e-05  |
| qf2_loss                | 5.4030315e-05 |
| time_elapsed            | 1206          |
| total timesteps         | 170048        |
| value_loss              | 3.48733e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009565025  |
| ent_coef_loss           | -1.0765332    |
| entropy                 | 1.2867485     |
| episodes                | 620           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 170698        |
| policy_loss             | -0.63893783   |
| qf1_loss                | 2.7587801e-05 |
| qf2_loss                | 1.7452885e-05 |
| time_elapsed            | 1211          |
| total timesteps         | 170798        |
| value_loss              | 3.651133e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009999064  |
| ent_coef_loss           | 1.4453807     |
| entropy                 | 1.3333187     |
| episodes                | 624           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 171627        |
| policy_loss             | -0.5646409    |
| qf1_loss                | 2.399261e-05  |
| qf2_loss                | 2.64217e-05   |
| time_elapsed            | 1218          |
| total timesteps         | 171727        |
| value_loss              | 3.6215206e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097209355 |
| ent_coef_loss           | -1.5762126    |
| entropy                 | 1.3914346     |
| episodes                | 628           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 172356        |
| policy_loss             | -0.55284315   |
| qf1_loss                | 2.681878e-05  |
| qf2_loss                | 1.9826493e-05 |
| time_elapsed            | 1223          |
| total timesteps         | 172456        |
| value_loss              | 2.813276e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094816246 |
| ent_coef_loss           | 0.17595363    |
| entropy                 | 1.1835966     |
| episodes                | 632           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 173076        |
| policy_loss             | -0.5930916    |
| qf1_loss                | 3.177237e-05  |
| qf2_loss                | 2.9227538e-05 |
| time_elapsed            | 1228          |
| total timesteps         | 173176        |
| value_loss              | 5.2554227e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009354597  |
| ent_coef_loss           | -0.6144884    |
| entropy                 | 1.279984      |
| episodes                | 636           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 173826        |
| policy_loss             | -0.5369113    |
| qf1_loss                | 2.8275346e-05 |
| qf2_loss                | 2.0723792e-05 |
| time_elapsed            | 1234          |
| total timesteps         | 173926        |
| value_loss              | 3.235871e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009896682  |
| ent_coef_loss           | 1.6857011     |
| entropy                 | 1.1980765     |
| episodes                | 640           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 174517        |
| policy_loss             | -0.53979963   |
| qf1_loss                | 0.00015848497 |
| qf2_loss                | 0.0001664359  |
| time_elapsed            | 1238          |
| total timesteps         | 174617        |
| value_loss              | 2.6947648e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009938505  |
| ent_coef_loss           | 1.7277533     |
| entropy                 | 1.3140678     |
| episodes                | 644           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 175260        |
| policy_loss             | -0.5177151    |
| qf1_loss                | 3.093846e-05  |
| qf2_loss                | 2.5497695e-05 |
| time_elapsed            | 1244          |
| total timesteps         | 175360        |
| value_loss              | 4.5230085e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009578554   |
| ent_coef_loss           | 3.668589       |
| entropy                 | 1.1863886      |
| episodes                | 648            |
| fps                     | 140            |
| mean 100 episode reward | 0.9            |
| n_updates               | 175988         |
| policy_loss             | -0.55204916    |
| qf1_loss                | 4.6898265e-05  |
| qf2_loss                | 0.000115196446 |
| time_elapsed            | 1249           |
| total timesteps         | 176088         |
| value_loss              | 7.674503e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009265755  |
| ent_coef_loss           | 0.08991301    |
| entropy                 | 1.292094      |
| episodes                | 652           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 176849        |
| policy_loss             | -0.5778545    |
| qf1_loss                | 0.00013394849 |
| qf2_loss                | 0.00013956647 |
| time_elapsed            | 1255          |
| total timesteps         | 176949        |
| value_loss              | 7.7916426e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009249519  |
| ent_coef_loss           | -0.15122643   |
| entropy                 | 1.1890982     |
| episodes                | 656           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 177569        |
| policy_loss             | -0.51955706   |
| qf1_loss                | 4.8451337e-05 |
| qf2_loss                | 5.788071e-05  |
| time_elapsed            | 1260          |
| total timesteps         | 177669        |
| value_loss              | 2.9801595e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009359331  |
| ent_coef_loss           | 0.5995972     |
| entropy                 | 1.3945187     |
| episodes                | 660           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 178451        |
| policy_loss             | -0.56839573   |
| qf1_loss                | 0.00025809885 |
| qf2_loss                | 0.00010558182 |
| time_elapsed            | 1266          |
| total timesteps         | 178551        |
| value_loss              | 6.250858e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000865094   |
| ent_coef_loss           | -4.990532     |
| entropy                 | 1.2394899     |
| episodes                | 664           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 179462        |
| policy_loss             | -0.56113374   |
| qf1_loss                | 1.4225431e-05 |
| qf2_loss                | 2.641804e-05  |
| time_elapsed            | 1274          |
| total timesteps         | 179562        |
| value_loss              | 3.747189e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089745776 |
| ent_coef_loss           | -1.3028984    |
| entropy                 | 1.1316686     |
| episodes                | 668           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 180316        |
| policy_loss             | -0.5440667    |
| qf1_loss                | 2.2836211e-05 |
| qf2_loss                | 4.925332e-05  |
| time_elapsed            | 1280          |
| total timesteps         | 180416        |
| value_loss              | 0.00039055088 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091547193 |
| ent_coef_loss           | 0.9258425     |
| entropy                 | 1.185889      |
| episodes                | 672           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 181130        |
| policy_loss             | -0.5807074    |
| qf1_loss                | 3.2100823e-05 |
| qf2_loss                | 2.1135507e-05 |
| time_elapsed            | 1285          |
| total timesteps         | 181230        |
| value_loss              | 5.1801428e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009666074  |
| ent_coef_loss           | 0.1743845     |
| entropy                 | 1.2307241     |
| episodes                | 676           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 181975        |
| policy_loss             | -0.5969845    |
| qf1_loss                | 4.5861307e-05 |
| qf2_loss                | 3.0621097e-05 |
| time_elapsed            | 1291          |
| total timesteps         | 182075        |
| value_loss              | 2.5521043e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008959971  |
| ent_coef_loss           | -0.15214086   |
| entropy                 | 1.1994574     |
| episodes                | 680           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 182910        |
| policy_loss             | -0.5152539    |
| qf1_loss                | 2.1896249e-05 |
| qf2_loss                | 3.2080734e-05 |
| time_elapsed            | 1298          |
| total timesteps         | 183010        |
| value_loss              | 3.1249772e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008661916  |
| ent_coef_loss           | -2.395384     |
| entropy                 | 1.297432      |
| episodes                | 684           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 183588        |
| policy_loss             | -0.5655402    |
| qf1_loss                | 2.7244412e-05 |
| qf2_loss                | 2.6796799e-05 |
| time_elapsed            | 1303          |
| total timesteps         | 183688        |
| value_loss              | 4.1490428e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008432774  |
| ent_coef_loss           | -3.3501482    |
| entropy                 | 1.2962135     |
| episodes                | 688           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 184322        |
| policy_loss             | -0.61297846   |
| qf1_loss                | 5.831302e-05  |
| qf2_loss                | 5.0060265e-05 |
| time_elapsed            | 1308          |
| total timesteps         | 184422        |
| value_loss              | 0.00014871974 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.000796342    |
| ent_coef_loss           | -1.4310148     |
| entropy                 | 1.1884462      |
| episodes                | 692            |
| fps                     | 140            |
| mean 100 episode reward | 0.9            |
| n_updates               | 185023         |
| policy_loss             | -0.5632031     |
| qf1_loss                | 1.48891695e-05 |
| qf2_loss                | 1.9303669e-05  |
| time_elapsed            | 1313           |
| total timesteps         | 185123         |
| value_loss              | 3.2448086e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008099335  |
| ent_coef_loss           | 1.6394215     |
| entropy                 | 1.4261464     |
| episodes                | 696           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 185947        |
| policy_loss             | -0.6279875    |
| qf1_loss                | 2.9485913e-05 |
| qf2_loss                | 1.5792626e-05 |
| time_elapsed            | 1320          |
| total timesteps         | 186047        |
| value_loss              | 2.707242e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008332673  |
| ent_coef_loss           | -0.39783043   |
| entropy                 | 1.3316978     |
| episodes                | 700           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 186588        |
| policy_loss             | -0.5799496    |
| qf1_loss                | 1.4234324e-05 |
| qf2_loss                | 1.9179373e-05 |
| time_elapsed            | 1324          |
| total timesteps         | 186688        |
| value_loss              | 2.8794038e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009130402  |
| ent_coef_loss           | -1.92245      |
| entropy                 | 1.3674972     |
| episodes                | 704           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 187291        |
| policy_loss             | -0.59371954   |
| qf1_loss                | 3.8899594e-05 |
| qf2_loss                | 3.7546783e-05 |
| time_elapsed            | 1329          |
| total timesteps         | 187391        |
| value_loss              | 9.226179e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085519435 |
| ent_coef_loss           | 3.4332366     |
| entropy                 | 1.2807153     |
| episodes                | 708           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 188084        |
| policy_loss             | -0.59348595   |
| qf1_loss                | 1.1634937e-05 |
| qf2_loss                | 2.038182e-05  |
| time_elapsed            | 1335          |
| total timesteps         | 188184        |
| value_loss              | 2.594971e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007507259  |
| ent_coef_loss           | -2.288244     |
| entropy                 | 1.2948421     |
| episodes                | 712           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 188998        |
| policy_loss             | -0.5493969    |
| qf1_loss                | 7.2894225e-05 |
| qf2_loss                | 7.0459006e-05 |
| time_elapsed            | 1341          |
| total timesteps         | 189098        |
| value_loss              | 5.198039e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007817471  |
| ent_coef_loss           | 1.4497004     |
| entropy                 | 1.2103131     |
| episodes                | 716           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 189590        |
| policy_loss             | -0.6020142    |
| qf1_loss                | 7.333564e-05  |
| qf2_loss                | 6.657754e-05  |
| time_elapsed            | 1345          |
| total timesteps         | 189690        |
| value_loss              | 5.6010846e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007608084  |
| ent_coef_loss           | 0.57706994    |
| entropy                 | 1.2555488     |
| episodes                | 720           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 190324        |
| policy_loss             | -0.52182555   |
| qf1_loss                | 2.9477027e-05 |
| qf2_loss                | 4.1005038e-05 |
| time_elapsed            | 1351          |
| total timesteps         | 190424        |
| value_loss              | 3.5257635e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008340381  |
| ent_coef_loss           | 1.200232      |
| entropy                 | 1.4117818     |
| episodes                | 724           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 190975        |
| policy_loss             | -0.5767342    |
| qf1_loss                | 2.4392033e-05 |
| qf2_loss                | 4.0340998e-05 |
| time_elapsed            | 1355          |
| total timesteps         | 191075        |
| value_loss              | 3.1200194e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00084529753 |
| ent_coef_loss           | 2.5710258     |
| entropy                 | 1.5361325     |
| episodes                | 728           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 191697        |
| policy_loss             | -0.5648087    |
| qf1_loss                | 8.620078e-06  |
| qf2_loss                | 1.9912237e-05 |
| time_elapsed            | 1360          |
| total timesteps         | 191797        |
| value_loss              | 3.9321603e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089437125 |
| ent_coef_loss           | -0.75356835   |
| entropy                 | 1.4247241     |
| episodes                | 732           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 192607        |
| policy_loss             | -0.601568     |
| qf1_loss                | 2.6367568e-05 |
| qf2_loss                | 2.5172314e-05 |
| time_elapsed            | 1367          |
| total timesteps         | 192707        |
| value_loss              | 3.713988e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008091298  |
| ent_coef_loss           | -1.2926264    |
| entropy                 | 1.2586231     |
| episodes                | 736           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 193259        |
| policy_loss             | -0.5531591    |
| qf1_loss                | 7.142925e-05  |
| qf2_loss                | 5.9252972e-05 |
| time_elapsed            | 1371          |
| total timesteps         | 193359        |
| value_loss              | 7.589909e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007831656  |
| ent_coef_loss           | -1.2828289    |
| entropy                 | 1.4101013     |
| episodes                | 740           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 194025        |
| policy_loss             | -0.59200644   |
| qf1_loss                | 2.9365321e-05 |
| qf2_loss                | 2.7127155e-05 |
| time_elapsed            | 1377          |
| total timesteps         | 194125        |
| value_loss              | 3.428632e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000769096   |
| ent_coef_loss           | -0.34350544   |
| entropy                 | 1.4549822     |
| episodes                | 744           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 194709        |
| policy_loss             | -0.57109857   |
| qf1_loss                | 3.8044236e-05 |
| qf2_loss                | 5.1414576e-05 |
| time_elapsed            | 1382          |
| total timesteps         | 194809        |
| value_loss              | 7.8362486e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007637785  |
| ent_coef_loss           | 3.4738927     |
| entropy                 | 1.195404      |
| episodes                | 748           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 195459        |
| policy_loss             | -0.59309137   |
| qf1_loss                | 4.590116e-05  |
| qf2_loss                | 2.5871515e-05 |
| time_elapsed            | 1387          |
| total timesteps         | 195559        |
| value_loss              | 5.1915835e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0008332371   |
| ent_coef_loss           | 0.44090688     |
| entropy                 | 1.4149946      |
| episodes                | 752            |
| fps                     | 140            |
| mean 100 episode reward | 0.8            |
| n_updates               | 196470         |
| policy_loss             | -0.5366075     |
| qf1_loss                | 0.000104320075 |
| qf2_loss                | 4.4411438e-05  |
| time_elapsed            | 1394           |
| total timesteps         | 196570         |
| value_loss              | 4.244713e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008415416  |
| ent_coef_loss           | 2.6305277     |
| entropy                 | 1.290431      |
| episodes                | 756           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 197175        |
| policy_loss             | -0.5388414    |
| qf1_loss                | 3.482029e-05  |
| qf2_loss                | 3.3354765e-05 |
| time_elapsed            | 1399          |
| total timesteps         | 197275        |
| value_loss              | 4.897396e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008445687  |
| ent_coef_loss           | -1.0980508    |
| entropy                 | 1.3269091     |
| episodes                | 760           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 198108        |
| policy_loss             | -0.5426877    |
| qf1_loss                | 6.289587e-05  |
| qf2_loss                | 5.4242944e-05 |
| time_elapsed            | 1406          |
| total timesteps         | 198208        |
| value_loss              | 0.00019233019 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008992295  |
| ent_coef_loss           | 0.7655585     |
| entropy                 | 1.4026169     |
| episodes                | 764           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 198797        |
| policy_loss             | -0.58740723   |
| qf1_loss                | 8.027538e-05  |
| qf2_loss                | 4.9733622e-05 |
| time_elapsed            | 1411          |
| total timesteps         | 198897        |
| value_loss              | 0.00018258562 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008815791  |
| ent_coef_loss           | -0.16335607   |
| entropy                 | 1.4297467     |
| episodes                | 768           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 199539        |
| policy_loss             | -0.5776823    |
| qf1_loss                | 0.00012339446 |
| qf2_loss                | 0.00015044793 |
| time_elapsed            | 1416          |
| total timesteps         | 199639        |
| value_loss              | 5.8939066e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008578855  |
| ent_coef_loss           | 0.38056538    |
| entropy                 | 1.3651841     |
| episodes                | 772           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 200216        |
| policy_loss             | -0.60622704   |
| qf1_loss                | 3.4350163e-05 |
| qf2_loss                | 2.6127858e-05 |
| time_elapsed            | 1421          |
| total timesteps         | 200316        |
| value_loss              | 2.5475445e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008726772  |
| ent_coef_loss           | 0.28465444    |
| entropy                 | 1.2164756     |
| episodes                | 776           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 200898        |
| policy_loss             | -0.59082365   |
| qf1_loss                | 0.00013491401 |
| qf2_loss                | 0.00014440081 |
| time_elapsed            | 1426          |
| total timesteps         | 200998        |
| value_loss              | 5.698718e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087643747 |
| ent_coef_loss           | 1.2255238     |
| entropy                 | 1.3498365     |
| episodes                | 780           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 201548        |
| policy_loss             | -0.59218127   |
| qf1_loss                | 3.0469324e-05 |
| qf2_loss                | 2.5810732e-05 |
| time_elapsed            | 1430          |
| total timesteps         | 201648        |
| value_loss              | 3.0538522e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009238482  |
| ent_coef_loss           | 2.7348175     |
| entropy                 | 1.3187388     |
| episodes                | 784           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 202545        |
| policy_loss             | -0.5723736    |
| qf1_loss                | 2.6352369e-05 |
| qf2_loss                | 2.0273155e-05 |
| time_elapsed            | 1438          |
| total timesteps         | 202645        |
| value_loss              | 4.3104952e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009208425  |
| ent_coef_loss           | -3.2334516    |
| entropy                 | 1.3991764     |
| episodes                | 788           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 203254        |
| policy_loss             | -0.54680026   |
| qf1_loss                | 2.7285048e-05 |
| qf2_loss                | 1.6073383e-05 |
| time_elapsed            | 1443          |
| total timesteps         | 203354        |
| value_loss              | 3.0713854e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095628    |
| ent_coef_loss           | 0.029822946   |
| entropy                 | 1.4660454     |
| episodes                | 792           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 203928        |
| policy_loss             | -0.55142605   |
| qf1_loss                | 2.663198e-05  |
| qf2_loss                | 4.5093133e-05 |
| time_elapsed            | 1447          |
| total timesteps         | 204028        |
| value_loss              | 3.8414895e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009861516  |
| ent_coef_loss           | -0.51866746   |
| entropy                 | 1.3839004     |
| episodes                | 796           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 204559        |
| policy_loss             | -0.593044     |
| qf1_loss                | 3.529839e-05  |
| qf2_loss                | 2.7271806e-05 |
| time_elapsed            | 1452          |
| total timesteps         | 204659        |
| value_loss              | 0.00015872729 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091703475 |
| ent_coef_loss           | -0.95055264   |
| entropy                 | 1.4424577     |
| episodes                | 800           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 205267        |
| policy_loss             | -0.57570183   |
| qf1_loss                | 9.572319e-05  |
| qf2_loss                | 4.851068e-05  |
| time_elapsed            | 1457          |
| total timesteps         | 205367        |
| value_loss              | 0.00016969486 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008763752  |
| ent_coef_loss           | 0.016910553   |
| entropy                 | 1.4488966     |
| episodes                | 804           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 206206        |
| policy_loss             | -0.5538775    |
| qf1_loss                | 1.9844738e-05 |
| qf2_loss                | 2.0253052e-05 |
| time_elapsed            | 1463          |
| total timesteps         | 206306        |
| value_loss              | 2.5599755e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097221084 |
| ent_coef_loss           | -2.4228892    |
| entropy                 | 1.5440371     |
| episodes                | 808           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 206849        |
| policy_loss             | -0.5689249    |
| qf1_loss                | 2.7119457e-05 |
| qf2_loss                | 1.2460456e-05 |
| time_elapsed            | 1468          |
| total timesteps         | 206949        |
| value_loss              | 2.4567798e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0009499215 |
| ent_coef_loss           | -1.0095942   |
| entropy                 | 1.2793198    |
| episodes                | 812          |
| fps                     | 140          |
| mean 100 episode reward | 0.8          |
| n_updates               | 207530       |
| policy_loss             | -0.5270257   |
| qf1_loss                | 7.528283e-05 |
| qf2_loss                | 7.24997e-05  |
| time_elapsed            | 1473         |
| total timesteps         | 207630       |
| value_loss              | 2.403313e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009951717  |
| ent_coef_loss           | 1.1132224     |
| entropy                 | 1.4370418     |
| episodes                | 816           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 208231        |
| policy_loss             | -0.53949183   |
| qf1_loss                | 1.8037412e-05 |
| qf2_loss                | 2.4466503e-05 |
| time_elapsed            | 1478          |
| total timesteps         | 208331        |
| value_loss              | 5.9344613e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009712679  |
| ent_coef_loss           | 2.9921598     |
| entropy                 | 1.4140472     |
| episodes                | 820           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 208924        |
| policy_loss             | -0.5649991    |
| qf1_loss                | 2.3702594e-05 |
| qf2_loss                | 2.242285e-05  |
| time_elapsed            | 1483          |
| total timesteps         | 209024        |
| value_loss              | 6.485248e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094351254 |
| ent_coef_loss           | 1.4465027     |
| entropy                 | 1.2826036     |
| episodes                | 824           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 209627        |
| policy_loss             | -0.5696049    |
| qf1_loss                | 3.4697e-05    |
| qf2_loss                | 1.7469994e-05 |
| time_elapsed            | 1488          |
| total timesteps         | 209727        |
| value_loss              | 2.0068856e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00094144884  |
| ent_coef_loss           | 0.32131404     |
| entropy                 | 1.4974802      |
| episodes                | 828            |
| fps                     | 140            |
| mean 100 episode reward | 0.8            |
| n_updates               | 210304         |
| policy_loss             | -0.5485512     |
| qf1_loss                | 4.3949512e-05  |
| qf2_loss                | 4.8023398e-05  |
| time_elapsed            | 1493           |
| total timesteps         | 210404         |
| value_loss              | 0.000106641106 |
--------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0009382276 |
| ent_coef_loss           | -1.2309992   |
| entropy                 | 1.5575583    |
| episodes                | 832          |
| fps                     | 140          |
| mean 100 episode reward | 0.9          |
| n_updates               | 210957       |
| policy_loss             | -0.58327836  |
| qf1_loss                | 2.803959e-05 |
| qf2_loss                | 2.672151e-05 |
| time_elapsed            | 1497         |
| total timesteps         | 211057       |
| value_loss              | 1.957627e-05 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0009265053 |
| ent_coef_loss           | 1.3673606    |
| entropy                 | 1.4115458    |
| episodes                | 836          |
| fps                     | 140          |
| mean 100 episode reward | 0.9          |
| n_updates               | 211621       |
| policy_loss             | -0.5689943   |
| qf1_loss                | 7.663401e-05 |
| qf2_loss                | 5.457855e-05 |
| time_elapsed            | 1502         |
| total timesteps         | 211721       |
| value_loss              | 4.899834e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092355045 |
| ent_coef_loss           | -3.0956879    |
| entropy                 | 1.4100516     |
| episodes                | 840           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 212318        |
| policy_loss             | -0.5645102    |
| qf1_loss                | 5.8651458e-05 |
| qf2_loss                | 4.891881e-05  |
| time_elapsed            | 1507          |
| total timesteps         | 212418        |
| value_loss              | 4.77615e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089827593 |
| ent_coef_loss           | 2.0252268     |
| entropy                 | 1.4232751     |
| episodes                | 844           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 213039        |
| policy_loss             | -0.5409275    |
| qf1_loss                | 1.7260463e-05 |
| qf2_loss                | 2.7548114e-05 |
| time_elapsed            | 1512          |
| total timesteps         | 213139        |
| value_loss              | 3.363052e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009389535  |
| ent_coef_loss           | -1.2965853    |
| entropy                 | 1.4730079     |
| episodes                | 848           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 213703        |
| policy_loss             | -0.5764767    |
| qf1_loss                | 1.8010147e-05 |
| qf2_loss                | 1.9546063e-05 |
| time_elapsed            | 1517          |
| total timesteps         | 213803        |
| value_loss              | 2.3088538e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008897522  |
| ent_coef_loss           | 2.0095816     |
| entropy                 | 1.5895798     |
| episodes                | 852           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 214401        |
| policy_loss             | -0.6075516    |
| qf1_loss                | 4.6130568e-05 |
| qf2_loss                | 6.171568e-05  |
| time_elapsed            | 1522          |
| total timesteps         | 214501        |
| value_loss              | 8.93017e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009438482  |
| ent_coef_loss           | 2.5662708     |
| entropy                 | 1.527601      |
| episodes                | 856           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 215091        |
| policy_loss             | -0.5856787    |
| qf1_loss                | 2.3232122e-05 |
| qf2_loss                | 8.573361e-06  |
| time_elapsed            | 1527          |
| total timesteps         | 215191        |
| value_loss              | 7.233188e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000911925   |
| ent_coef_loss           | -0.43081257   |
| entropy                 | 1.5733316     |
| episodes                | 860           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 215747        |
| policy_loss             | -0.61299396   |
| qf1_loss                | 5.901198e-05  |
| qf2_loss                | 3.3670764e-05 |
| time_elapsed            | 1531          |
| total timesteps         | 215847        |
| value_loss              | 0.00016050672 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092555635 |
| ent_coef_loss           | 0.11996053    |
| entropy                 | 1.5440555     |
| episodes                | 864           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 216437        |
| policy_loss             | -0.51463765   |
| qf1_loss                | 4.361357e-05  |
| qf2_loss                | 2.2412289e-05 |
| time_elapsed            | 1536          |
| total timesteps         | 216537        |
| value_loss              | 3.9670747e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00088241266 |
| ent_coef_loss           | -0.02135849   |
| entropy                 | 1.3423511     |
| episodes                | 868           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 217126        |
| policy_loss             | -0.5974164    |
| qf1_loss                | 7.554574e-05  |
| qf2_loss                | 0.00010341031 |
| time_elapsed            | 1541          |
| total timesteps         | 217226        |
| value_loss              | 0.0002507933  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008747307  |
| ent_coef_loss           | -2.1569204    |
| entropy                 | 1.4259866     |
| episodes                | 872           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 217852        |
| policy_loss             | -0.56937313   |
| qf1_loss                | 5.7046942e-05 |
| qf2_loss                | 5.722136e-05  |
| time_elapsed            | 1546          |
| total timesteps         | 217952        |
| value_loss              | 5.4904325e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008437057  |
| ent_coef_loss           | -1.1429614    |
| entropy                 | 1.4004486     |
| episodes                | 876           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 218570        |
| policy_loss             | -0.5681088    |
| qf1_loss                | 2.9369807e-05 |
| qf2_loss                | 2.3812714e-05 |
| time_elapsed            | 1551          |
| total timesteps         | 218670        |
| value_loss              | 3.8518083e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009486979  |
| ent_coef_loss           | -2.2172542    |
| entropy                 | 1.40821       |
| episodes                | 880           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 219236        |
| policy_loss             | -0.5694647    |
| qf1_loss                | 2.3884735e-05 |
| qf2_loss                | 4.1248946e-05 |
| time_elapsed            | 1556          |
| total timesteps         | 219336        |
| value_loss              | 7.3232324e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009589805  |
| ent_coef_loss           | -0.1802378    |
| entropy                 | 1.5903722     |
| episodes                | 884           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 219928        |
| policy_loss             | -0.57673234   |
| qf1_loss                | 4.150221e-05  |
| qf2_loss                | 3.1408992e-05 |
| time_elapsed            | 1561          |
| total timesteps         | 220028        |
| value_loss              | 4.3995784e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009284583  |
| ent_coef_loss           | 0.7963302     |
| entropy                 | 1.5426023     |
| episodes                | 888           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 220696        |
| policy_loss             | -0.5140834    |
| qf1_loss                | 2.6012138e-05 |
| qf2_loss                | 2.2295742e-05 |
| time_elapsed            | 1566          |
| total timesteps         | 220796        |
| value_loss              | 4.5485813e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091518124 |
| ent_coef_loss           | -0.9503164    |
| entropy                 | 1.4183488     |
| episodes                | 892           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 221350        |
| policy_loss             | -0.58165437   |
| qf1_loss                | 2.964686e-05  |
| qf2_loss                | 2.4894289e-05 |
| time_elapsed            | 1571          |
| total timesteps         | 221450        |
| value_loss              | 4.1317828e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0009582647 |
| ent_coef_loss           | 1.0427601    |
| entropy                 | 1.5663168    |
| episodes                | 896          |
| fps                     | 140          |
| mean 100 episode reward | 0.8          |
| n_updates               | 222103       |
| policy_loss             | -0.5255374   |
| qf1_loss                | 8.010936e-05 |
| qf2_loss                | 7.121279e-05 |
| time_elapsed            | 1576         |
| total timesteps         | 222203       |
| value_loss              | 0.0002006646 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009384208  |
| ent_coef_loss           | -0.5886582    |
| entropy                 | 1.3394433     |
| episodes                | 900           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 222777        |
| policy_loss             | -0.55532485   |
| qf1_loss                | 2.2954711e-05 |
| qf2_loss                | 2.0904758e-05 |
| time_elapsed            | 1581          |
| total timesteps         | 222877        |
| value_loss              | 3.1963416e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009018781  |
| ent_coef_loss           | 0.5035063     |
| entropy                 | 1.4129548     |
| episodes                | 904           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 223457        |
| policy_loss             | -0.5387795    |
| qf1_loss                | 2.8626124e-05 |
| qf2_loss                | 3.053346e-05  |
| time_elapsed            | 1586          |
| total timesteps         | 223557        |
| value_loss              | 5.0811483e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00088783866 |
| ent_coef_loss           | -2.4309304    |
| entropy                 | 1.4290941     |
| episodes                | 908           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 224414        |
| policy_loss             | -0.511704     |
| qf1_loss                | 4.159532e-05  |
| qf2_loss                | 4.490652e-05  |
| time_elapsed            | 1593          |
| total timesteps         | 224514        |
| value_loss              | 0.00014902886 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008971279  |
| ent_coef_loss           | 0.6064611     |
| entropy                 | 1.3899243     |
| episodes                | 912           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 225070        |
| policy_loss             | -0.54159796   |
| qf1_loss                | 3.2894583e-05 |
| qf2_loss                | 2.5438612e-05 |
| time_elapsed            | 1597          |
| total timesteps         | 225170        |
| value_loss              | 3.6143392e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0008869226   |
| ent_coef_loss           | 1.5971453      |
| entropy                 | 1.31246        |
| episodes                | 916            |
| fps                     | 140            |
| mean 100 episode reward | 0.8            |
| n_updates               | 225772         |
| policy_loss             | -0.56886315    |
| qf1_loss                | 4.9283524e-05  |
| qf2_loss                | 5.8977996e-05  |
| time_elapsed            | 1602           |
| total timesteps         | 225872         |
| value_loss              | 0.000103199025 |
--------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0009487382 |
| ent_coef_loss           | -2.349296    |
| entropy                 | 1.2011003    |
| episodes                | 920          |
| fps                     | 140          |
| mean 100 episode reward | 0.8          |
| n_updates               | 226462       |
| policy_loss             | -0.49556363  |
| qf1_loss                | 3.956347e-05 |
| qf2_loss                | 3.527205e-05 |
| time_elapsed            | 1607         |
| total timesteps         | 226562       |
| value_loss              | 6.219218e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091344997 |
| ent_coef_loss           | 4.721891      |
| entropy                 | 1.5025632     |
| episodes                | 924           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 227097        |
| policy_loss             | -0.56814367   |
| qf1_loss                | 2.4271332e-05 |
| qf2_loss                | 2.103262e-05  |
| time_elapsed            | 1612          |
| total timesteps         | 227197        |
| value_loss              | 4.096706e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085303496 |
| ent_coef_loss           | -0.066209435  |
| entropy                 | 1.3196669     |
| episodes                | 928           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 227748        |
| policy_loss             | -0.6004772    |
| qf1_loss                | 4.9838192e-05 |
| qf2_loss                | 4.1096748e-05 |
| time_elapsed            | 1616          |
| total timesteps         | 227848        |
| value_loss              | 0.00017732654 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008598804  |
| ent_coef_loss           | -0.9395985    |
| entropy                 | 1.2000706     |
| episodes                | 932           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 228563        |
| policy_loss             | -0.53756267   |
| qf1_loss                | 2.393523e-05  |
| qf2_loss                | 2.5709713e-05 |
| time_elapsed            | 1622          |
| total timesteps         | 228663        |
| value_loss              | 1.2984461e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008724604  |
| ent_coef_loss           | -1.0397476    |
| entropy                 | 1.3404648     |
| episodes                | 936           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 229299        |
| policy_loss             | -0.51541954   |
| qf1_loss                | 7.9116566e-05 |
| qf2_loss                | 7.29617e-05   |
| time_elapsed            | 1627          |
| total timesteps         | 229399        |
| value_loss              | 0.00016673161 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090357324 |
| ent_coef_loss           | 2.0467744     |
| entropy                 | 1.4096134     |
| episodes                | 940           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 229997        |
| policy_loss             | -0.5238949    |
| qf1_loss                | 2.6287787e-05 |
| qf2_loss                | 3.4267534e-05 |
| time_elapsed            | 1632          |
| total timesteps         | 230097        |
| value_loss              | 4.476917e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093036355 |
| ent_coef_loss           | -0.003950715  |
| entropy                 | 1.3340201     |
| episodes                | 944           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 230689        |
| policy_loss             | -0.5312838    |
| qf1_loss                | 4.3461194e-05 |
| qf2_loss                | 2.8577195e-05 |
| time_elapsed            | 1637          |
| total timesteps         | 230789        |
| value_loss              | 3.6393478e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089356175 |
| ent_coef_loss           | 1.0704321     |
| entropy                 | 1.2467175     |
| episodes                | 948           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 231371        |
| policy_loss             | -0.54364216   |
| qf1_loss                | 4.1749754e-05 |
| qf2_loss                | 1.7677015e-05 |
| time_elapsed            | 1642          |
| total timesteps         | 231471        |
| value_loss              | 1.643903e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095377397 |
| ent_coef_loss           | 0.32351857    |
| entropy                 | 1.3645046     |
| episodes                | 952           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 232175        |
| policy_loss             | -0.55484545   |
| qf1_loss                | 4.964266e-05  |
| qf2_loss                | 3.503508e-05  |
| time_elapsed            | 1648          |
| total timesteps         | 232275        |
| value_loss              | 1.6093556e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000953708   |
| ent_coef_loss           | -1.2767173    |
| entropy                 | 1.4313383     |
| episodes                | 956           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 232834        |
| policy_loss             | -0.5496961    |
| qf1_loss                | 1.3261908e-05 |
| qf2_loss                | 2.5524107e-05 |
| time_elapsed            | 1653          |
| total timesteps         | 232934        |
| value_loss              | 2.5678126e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089343946 |
| ent_coef_loss           | 1.2743869     |
| entropy                 | 1.2361484     |
| episodes                | 960           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 233489        |
| policy_loss             | -0.5531554    |
| qf1_loss                | 6.6969915e-05 |
| qf2_loss                | 3.95985e-05   |
| time_elapsed            | 1657          |
| total timesteps         | 233589        |
| value_loss              | 4.490446e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000877816   |
| ent_coef_loss           | -0.48984778   |
| entropy                 | 1.2481248     |
| episodes                | 964           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 234193        |
| policy_loss             | -0.5290352    |
| qf1_loss                | 3.1005926e-05 |
| qf2_loss                | 2.328547e-05  |
| time_elapsed            | 1662          |
| total timesteps         | 234293        |
| value_loss              | 3.2897275e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007287744  |
| ent_coef_loss           | -0.81235355   |
| entropy                 | 1.1137809     |
| episodes                | 968           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 235175        |
| policy_loss             | -0.5636971    |
| qf1_loss                | 6.8546906e-05 |
| qf2_loss                | 8.5609056e-05 |
| time_elapsed            | 1669          |
| total timesteps         | 235275        |
| value_loss              | 4.4457964e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00077007175 |
| ent_coef_loss           | -0.013516307  |
| entropy                 | 1.2989109     |
| episodes                | 972           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 235835        |
| policy_loss             | -0.58195984   |
| qf1_loss                | 2.0904987e-05 |
| qf2_loss                | 1.9464847e-05 |
| time_elapsed            | 1674          |
| total timesteps         | 235935        |
| value_loss              | 3.6669764e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094988523 |
| ent_coef_loss           | -0.32225206   |
| entropy                 | 1.2792702     |
| episodes                | 976           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 236639        |
| policy_loss             | -0.52663505   |
| qf1_loss                | 3.4076627e-05 |
| qf2_loss                | 8.289979e-05  |
| time_elapsed            | 1680          |
| total timesteps         | 236739        |
| value_loss              | 0.0004142063  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092748436 |
| ent_coef_loss           | -0.06216204   |
| entropy                 | 1.3009255     |
| episodes                | 980           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 237361        |
| policy_loss             | -0.5213362    |
| qf1_loss                | 2.876006e-05  |
| qf2_loss                | 3.264928e-05  |
| time_elapsed            | 1685          |
| total timesteps         | 237461        |
| value_loss              | 2.6472597e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0009615488 |
| ent_coef_loss           | 1.4295996    |
| entropy                 | 1.4514699    |
| episodes                | 984          |
| fps                     | 140          |
| mean 100 episode reward | 0.8          |
| n_updates               | 238326       |
| policy_loss             | -0.5592729   |
| qf1_loss                | 4.931104e-05 |
| qf2_loss                | 8.170289e-05 |
| time_elapsed            | 1692         |
| total timesteps         | 238426       |
| value_loss              | 6.110348e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096804794 |
| ent_coef_loss           | 0.73106384    |
| entropy                 | 1.357988      |
| episodes                | 988           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 239029        |
| policy_loss             | -0.5232458    |
| qf1_loss                | 1.594966e-05  |
| qf2_loss                | 1.9876332e-05 |
| time_elapsed            | 1697          |
| total timesteps         | 239129        |
| value_loss              | 3.9678118e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008916005  |
| ent_coef_loss           | 3.2244735     |
| entropy                 | 1.4115922     |
| episodes                | 992           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 239709        |
| policy_loss             | -0.57548213   |
| qf1_loss                | 5.2410993e-05 |
| qf2_loss                | 9.16699e-05   |
| time_elapsed            | 1701          |
| total timesteps         | 239809        |
| value_loss              | 2.5603158e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090522453 |
| ent_coef_loss           | 1.308866      |
| entropy                 | 1.3439276     |
| episodes                | 996           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 240460        |
| policy_loss             | -0.54258764   |
| qf1_loss                | 4.0014653e-05 |
| qf2_loss                | 3.664656e-05  |
| time_elapsed            | 1707          |
| total timesteps         | 240560        |
| value_loss              | 8.730538e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092281    |
| ent_coef_loss           | 0.11301777    |
| entropy                 | 1.5093676     |
| episodes                | 1000          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 241153        |
| policy_loss             | -0.5834759    |
| qf1_loss                | 3.5267738e-05 |
| qf2_loss                | 4.8192174e-05 |
| time_elapsed            | 1712          |
| total timesteps         | 241253        |
| value_loss              | 3.145592e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000875995   |
| ent_coef_loss           | 1.996902      |
| entropy                 | 1.4188884     |
| episodes                | 1004          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 241811        |
| policy_loss             | -0.47847348   |
| qf1_loss                | 6.6166336e-05 |
| qf2_loss                | 5.2774063e-05 |
| time_elapsed            | 1716          |
| total timesteps         | 241911        |
| value_loss              | 4.062002e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096506183 |
| ent_coef_loss           | 3.2352488     |
| entropy                 | 1.4028201     |
| episodes                | 1008          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 242475        |
| policy_loss             | -0.46628052   |
| qf1_loss                | 6.070468e-05  |
| qf2_loss                | 6.632427e-05  |
| time_elapsed            | 1721          |
| total timesteps         | 242575        |
| value_loss              | 4.8615482e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009405981  |
| ent_coef_loss           | 1.3146284     |
| entropy                 | 1.3783011     |
| episodes                | 1012          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 243201        |
| policy_loss             | -0.54467046   |
| qf1_loss                | 2.1750497e-05 |
| qf2_loss                | 2.4242612e-05 |
| time_elapsed            | 1726          |
| total timesteps         | 243301        |
| value_loss              | 2.4458255e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000930301   |
| ent_coef_loss           | 0.30591425    |
| entropy                 | 1.2296853     |
| episodes                | 1016          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 243913        |
| policy_loss             | -0.5506521    |
| qf1_loss                | 7.123401e-05  |
| qf2_loss                | 2.6408594e-05 |
| time_elapsed            | 1731          |
| total timesteps         | 244013        |
| value_loss              | 5.491284e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096062355 |
| ent_coef_loss           | -1.2491177    |
| entropy                 | 1.3945105     |
| episodes                | 1020          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 244601        |
| policy_loss             | -0.51793814   |
| qf1_loss                | 2.296779e-05  |
| qf2_loss                | 2.3942523e-05 |
| time_elapsed            | 1736          |
| total timesteps         | 244701        |
| value_loss              | 6.817713e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008759265  |
| ent_coef_loss           | -1.311167     |
| entropy                 | 1.3086934     |
| episodes                | 1024          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 245434        |
| policy_loss             | -0.5634699    |
| qf1_loss                | 2.8238599e-05 |
| qf2_loss                | 3.5825586e-05 |
| time_elapsed            | 1742          |
| total timesteps         | 245534        |
| value_loss              | 5.453243e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090000895 |
| ent_coef_loss           | -1.0222862    |
| entropy                 | 1.4595376     |
| episodes                | 1028          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 246214        |
| policy_loss             | -0.56143296   |
| qf1_loss                | 1.4552915e-05 |
| qf2_loss                | 1.0825177e-05 |
| time_elapsed            | 1748          |
| total timesteps         | 246314        |
| value_loss              | 1.8694576e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090125605 |
| ent_coef_loss           | 1.6937202     |
| entropy                 | 1.567388      |
| episodes                | 1032          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 246928        |
| policy_loss             | -0.5445037    |
| qf1_loss                | 9.945826e-06  |
| qf2_loss                | 1.4583429e-05 |
| time_elapsed            | 1753          |
| total timesteps         | 247028        |
| value_loss              | 2.1063828e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097530696 |
| ent_coef_loss           | -1.7550521    |
| entropy                 | 1.4705253     |
| episodes                | 1036          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 247618        |
| policy_loss             | -0.5142045    |
| qf1_loss                | 1.5647938e-05 |
| qf2_loss                | 1.6905171e-05 |
| time_elapsed            | 1758          |
| total timesteps         | 247718        |
| value_loss              | 2.923877e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009279652  |
| ent_coef_loss           | 0.5547859     |
| entropy                 | 1.4407802     |
| episodes                | 1040          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 248278        |
| policy_loss             | -0.5006838    |
| qf1_loss                | 5.9878246e-05 |
| qf2_loss                | 8.069603e-05  |
| time_elapsed            | 1762          |
| total timesteps         | 248378        |
| value_loss              | 0.00010028186 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009347226  |
| ent_coef_loss           | -1.0315242    |
| entropy                 | 1.5098541     |
| episodes                | 1044          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 248924        |
| policy_loss             | -0.59164625   |
| qf1_loss                | 1.6377271e-05 |
| qf2_loss                | 2.3252767e-05 |
| time_elapsed            | 1767          |
| total timesteps         | 249024        |
| value_loss              | 1.4480749e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009314173   |
| ent_coef_loss           | 0.2993704      |
| entropy                 | 1.3649638      |
| episodes                | 1048           |
| fps                     | 140            |
| mean 100 episode reward | 0.8            |
| n_updates               | 249641         |
| policy_loss             | -0.5125599     |
| qf1_loss                | 6.262594e-05   |
| qf2_loss                | 2.2825934e-05  |
| time_elapsed            | 1772           |
| total timesteps         | 249741         |
| value_loss              | 0.000109290966 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009407681  |
| ent_coef_loss           | -1.7034314    |
| entropy                 | 1.2698846     |
| episodes                | 1052          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 250305        |
| policy_loss             | -0.504691     |
| qf1_loss                | 0.00010673111 |
| qf2_loss                | 5.015755e-05  |
| time_elapsed            | 1777          |
| total timesteps         | 250405        |
| value_loss              | 4.9123875e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092780596 |
| ent_coef_loss           | -3.1070676    |
| entropy                 | 1.5230912     |
| episodes                | 1056          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 251042        |
| policy_loss             | -0.6004966    |
| qf1_loss                | 1.8669807e-05 |
| qf2_loss                | 1.3299774e-05 |
| time_elapsed            | 1782          |
| total timesteps         | 251142        |
| value_loss              | 3.2372496e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090438535 |
| ent_coef_loss           | -1.747303     |
| entropy                 | 1.512497      |
| episodes                | 1060          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 251676        |
| policy_loss             | -0.5381366    |
| qf1_loss                | 3.4916906e-05 |
| qf2_loss                | 1.4535877e-05 |
| time_elapsed            | 1786          |
| total timesteps         | 251776        |
| value_loss              | 5.0767077e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096384087 |
| ent_coef_loss           | -1.9496729    |
| entropy                 | 1.4928434     |
| episodes                | 1064          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 252369        |
| policy_loss             | -0.55730724   |
| qf1_loss                | 1.847828e-05  |
| qf2_loss                | 2.2061547e-05 |
| time_elapsed            | 1791          |
| total timesteps         | 252469        |
| value_loss              | 2.7114645e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000793495   |
| ent_coef_loss           | 3.1946316     |
| entropy                 | 1.4730386     |
| episodes                | 1068          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 253055        |
| policy_loss             | -0.56977904   |
| qf1_loss                | 1.3540835e-05 |
| qf2_loss                | 4.6255987e-05 |
| time_elapsed            | 1796          |
| total timesteps         | 253155        |
| value_loss              | 4.6414752e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085121184 |
| ent_coef_loss           | 0.04746309    |
| entropy                 | 1.6774889     |
| episodes                | 1072          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 253766        |
| policy_loss             | -0.5860777    |
| qf1_loss                | 1.8279192e-05 |
| qf2_loss                | 3.6929803e-05 |
| time_elapsed            | 1801          |
| total timesteps         | 253866        |
| value_loss              | 7.310751e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009108103  |
| ent_coef_loss           | -1.9710822    |
| entropy                 | 1.5310571     |
| episodes                | 1076          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 254457        |
| policy_loss             | -0.5563747    |
| qf1_loss                | 2.5215812e-05 |
| qf2_loss                | 2.1788035e-05 |
| time_elapsed            | 1806          |
| total timesteps         | 254557        |
| value_loss              | 3.8572132e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008877366  |
| ent_coef_loss           | 0.8154627     |
| entropy                 | 1.504563      |
| episodes                | 1080          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 255214        |
| policy_loss             | -0.54804194   |
| qf1_loss                | 2.511943e-05  |
| qf2_loss                | 1.8523147e-05 |
| time_elapsed            | 1812          |
| total timesteps         | 255314        |
| value_loss              | 3.3480093e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.000887038  |
| ent_coef_loss           | 2.2966943    |
| entropy                 | 1.5802538    |
| episodes                | 1084         |
| fps                     | 140          |
| mean 100 episode reward | 0.9          |
| n_updates               | 255891       |
| policy_loss             | -0.52098167  |
| qf1_loss                | 8.988824e-05 |
| qf2_loss                | 9.32806e-05  |
| time_elapsed            | 1816         |
| total timesteps         | 255991       |
| value_loss              | 9.763647e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009065675  |
| ent_coef_loss           | -0.13385868   |
| entropy                 | 1.5021988     |
| episodes                | 1088          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 256577        |
| policy_loss             | -0.5247154    |
| qf1_loss                | 2.9665376e-05 |
| qf2_loss                | 1.6227117e-05 |
| time_elapsed            | 1821          |
| total timesteps         | 256677        |
| value_loss              | 3.736113e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009402389  |
| ent_coef_loss           | 0.90592074    |
| entropy                 | 1.3887757     |
| episodes                | 1092          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 257268        |
| policy_loss             | -0.52477205   |
| qf1_loss                | 2.930051e-05  |
| qf2_loss                | 2.630186e-05  |
| time_elapsed            | 1826          |
| total timesteps         | 257368        |
| value_loss              | 3.2423464e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009493373  |
| ent_coef_loss           | 4.3296375     |
| entropy                 | 1.482266      |
| episodes                | 1096          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 258227        |
| policy_loss             | -0.5423498    |
| qf1_loss                | 3.122795e-05  |
| qf2_loss                | 1.9679472e-05 |
| time_elapsed            | 1833          |
| total timesteps         | 258327        |
| value_loss              | 8.214303e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009692105  |
| ent_coef_loss           | -2.956088     |
| entropy                 | 1.4596719     |
| episodes                | 1100          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 258927        |
| policy_loss             | -0.577636     |
| qf1_loss                | 2.2424932e-05 |
| qf2_loss                | 1.2736442e-05 |
| time_elapsed            | 1838          |
| total timesteps         | 259027        |
| value_loss              | 1.3996158e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009529757  |
| ent_coef_loss           | 2.620882      |
| entropy                 | 1.409204      |
| episodes                | 1104          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 259665        |
| policy_loss             | -0.4872148    |
| qf1_loss                | 2.5816902e-05 |
| qf2_loss                | 1.1598564e-05 |
| time_elapsed            | 1843          |
| total timesteps         | 259765        |
| value_loss              | 5.8685073e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008700189  |
| ent_coef_loss           | -0.32411033   |
| entropy                 | 1.3614922     |
| episodes                | 1108          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 260320        |
| policy_loss             | -0.56786996   |
| qf1_loss                | 1.6102644e-05 |
| qf2_loss                | 7.315931e-06  |
| time_elapsed            | 1848          |
| total timesteps         | 260420        |
| value_loss              | 2.753369e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008896397  |
| ent_coef_loss           | -1.2060544    |
| entropy                 | 1.3727443     |
| episodes                | 1112          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 260965        |
| policy_loss             | -0.57780534   |
| qf1_loss                | 3.2291206e-05 |
| qf2_loss                | 1.6790686e-05 |
| time_elapsed            | 1852          |
| total timesteps         | 261065        |
| value_loss              | 7.22142e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009236205  |
| ent_coef_loss           | -2.1789343    |
| entropy                 | 1.5398681     |
| episodes                | 1116          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 261692        |
| policy_loss             | -0.55626523   |
| qf1_loss                | 7.0001304e-05 |
| qf2_loss                | 4.297201e-05  |
| time_elapsed            | 1858          |
| total timesteps         | 261792        |
| value_loss              | 0.00014126934 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00093540124  |
| ent_coef_loss           | 1.2905531      |
| entropy                 | 1.5918174      |
| episodes                | 1120           |
| fps                     | 140            |
| mean 100 episode reward | 0.8            |
| n_updates               | 262374         |
| policy_loss             | -0.5781697     |
| qf1_loss                | 1.0022233e-05  |
| qf2_loss                | 1.39955955e-05 |
| time_elapsed            | 1862           |
| total timesteps         | 262474         |
| value_loss              | 1.3381517e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009181864  |
| ent_coef_loss           | -2.0155106    |
| entropy                 | 1.5511929     |
| episodes                | 1124          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 263094        |
| policy_loss             | -0.56016815   |
| qf1_loss                | 0.0017956207  |
| qf2_loss                | 0.0018190005  |
| time_elapsed            | 1868          |
| total timesteps         | 263194        |
| value_loss              | 1.9898165e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00084949785 |
| ent_coef_loss           | 0.41552043    |
| entropy                 | 1.4815496     |
| episodes                | 1128          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 263760        |
| policy_loss             | -0.5960437    |
| qf1_loss                | 2.7128084e-05 |
| qf2_loss                | 1.6230828e-05 |
| time_elapsed            | 1872          |
| total timesteps         | 263860        |
| value_loss              | 2.6965528e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008956054  |
| ent_coef_loss           | 0.3412245     |
| entropy                 | 1.3765823     |
| episodes                | 1132          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 264415        |
| policy_loss             | -0.6281463    |
| qf1_loss                | 1.3983072e-05 |
| qf2_loss                | 1.451639e-05  |
| time_elapsed            | 1877          |
| total timesteps         | 264515        |
| value_loss              | 1.6082062e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089191727 |
| ent_coef_loss           | 0.8928149     |
| entropy                 | 1.5675254     |
| episodes                | 1136          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 265071        |
| policy_loss             | -0.5328132    |
| qf1_loss                | 2.1538483e-05 |
| qf2_loss                | 2.0578565e-05 |
| time_elapsed            | 1882          |
| total timesteps         | 265171        |
| value_loss              | 2.8758226e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094622077 |
| ent_coef_loss           | -2.1090255    |
| entropy                 | 1.5225526     |
| episodes                | 1140          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 265714        |
| policy_loss             | -0.5357429    |
| qf1_loss                | 2.5285004e-05 |
| qf2_loss                | 1.5328422e-05 |
| time_elapsed            | 1886          |
| total timesteps         | 265814        |
| value_loss              | 1.9011546e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009138408  |
| ent_coef_loss           | 0.33407968    |
| entropy                 | 1.4245863     |
| episodes                | 1144          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 266387        |
| policy_loss             | -0.58254033   |
| qf1_loss                | 2.0274605e-05 |
| qf2_loss                | 1.1641948e-05 |
| time_elapsed            | 1891          |
| total timesteps         | 266487        |
| value_loss              | 2.371325e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095049915 |
| ent_coef_loss           | -1.0532122    |
| entropy                 | 1.5080764     |
| episodes                | 1148          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 267053        |
| policy_loss             | -0.5700131    |
| qf1_loss                | 1.8343751e-05 |
| qf2_loss                | 2.4906709e-05 |
| time_elapsed            | 1896          |
| total timesteps         | 267153        |
| value_loss              | 1.3404996e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092748966 |
| ent_coef_loss           | 0.16550279    |
| entropy                 | 1.5163829     |
| episodes                | 1152          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 267728        |
| policy_loss             | -0.5798632    |
| qf1_loss                | 1.602653e-05  |
| qf2_loss                | 1.3303477e-05 |
| time_elapsed            | 1901          |
| total timesteps         | 267828        |
| value_loss              | 3.8036564e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000985695   |
| ent_coef_loss           | 0.70341843    |
| entropy                 | 1.5129688     |
| episodes                | 1156          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 268427        |
| policy_loss             | -0.5292709    |
| qf1_loss                | 6.909417e-05  |
| qf2_loss                | 6.619135e-05  |
| time_elapsed            | 1906          |
| total timesteps         | 268527        |
| value_loss              | 3.1611326e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093942194 |
| ent_coef_loss           | -0.31296715   |
| entropy                 | 1.4080769     |
| episodes                | 1160          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 269067        |
| policy_loss             | -0.53179365   |
| qf1_loss                | 1.562731e-05  |
| qf2_loss                | 1.537826e-05  |
| time_elapsed            | 1910          |
| total timesteps         | 269167        |
| value_loss              | 3.0121644e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095981493 |
| ent_coef_loss           | -0.04882717   |
| entropy                 | 1.4746342     |
| episodes                | 1164          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 269744        |
| policy_loss             | -0.5776149    |
| qf1_loss                | 1.3653174e-05 |
| qf2_loss                | 1.946867e-05  |
| time_elapsed            | 1915          |
| total timesteps         | 269844        |
| value_loss              | 4.1711068e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010051414  |
| ent_coef_loss           | -1.1932843    |
| entropy                 | 1.5844806     |
| episodes                | 1168          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 270421        |
| policy_loss             | -0.58709633   |
| qf1_loss                | 4.237819e-05  |
| qf2_loss                | 1.3978197e-05 |
| time_elapsed            | 1920          |
| total timesteps         | 270521        |
| value_loss              | 2.790715e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010243793  |
| ent_coef_loss           | 3.7900615     |
| entropy                 | 1.5561863     |
| episodes                | 1172          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 271221        |
| policy_loss             | -0.53954136   |
| qf1_loss                | 0.00016873777 |
| qf2_loss                | 0.00026518948 |
| time_elapsed            | 1925          |
| total timesteps         | 271321        |
| value_loss              | 6.827312e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009896223  |
| ent_coef_loss           | 2.289715      |
| entropy                 | 1.6343174     |
| episodes                | 1176          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 272141        |
| policy_loss             | -0.591384     |
| qf1_loss                | 2.1187447e-05 |
| qf2_loss                | 1.9211708e-05 |
| time_elapsed            | 1932          |
| total timesteps         | 272241        |
| value_loss              | 2.2952801e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010130625  |
| ent_coef_loss           | -2.712947     |
| entropy                 | 1.5275811     |
| episodes                | 1180          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 272806        |
| policy_loss             | -0.605574     |
| qf1_loss                | 5.069941e-05  |
| qf2_loss                | 2.0119955e-05 |
| time_elapsed            | 1937          |
| total timesteps         | 272906        |
| value_loss              | 6.664566e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009888685  |
| ent_coef_loss           | 1.990648      |
| entropy                 | 1.5982448     |
| episodes                | 1184          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 273517        |
| policy_loss             | -0.5531179    |
| qf1_loss                | 4.2844065e-05 |
| qf2_loss                | 3.2869466e-05 |
| time_elapsed            | 1942          |
| total timesteps         | 273617        |
| value_loss              | 9.943998e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0010433941   |
| ent_coef_loss           | 2.581758       |
| entropy                 | 1.589015       |
| episodes                | 1188           |
| fps                     | 140            |
| mean 100 episode reward | 0.8            |
| n_updates               | 274148         |
| policy_loss             | -0.5226449     |
| qf1_loss                | 2.2701272e-05  |
| qf2_loss                | 1.26665645e-05 |
| time_elapsed            | 1946           |
| total timesteps         | 274248         |
| value_loss              | 4.7118443e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009671561  |
| ent_coef_loss           | 2.1641512     |
| entropy                 | 1.5463115     |
| episodes                | 1192          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 275010        |
| policy_loss             | -0.53613484   |
| qf1_loss                | 2.2122136e-05 |
| qf2_loss                | 1.7054126e-05 |
| time_elapsed            | 1952          |
| total timesteps         | 275110        |
| value_loss              | 4.457583e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010157379  |
| ent_coef_loss           | -0.82155347   |
| entropy                 | 1.5599422     |
| episodes                | 1196          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 275831        |
| policy_loss             | -0.5927746    |
| qf1_loss                | 6.0086375e-05 |
| qf2_loss                | 2.6939479e-05 |
| time_elapsed            | 1958          |
| total timesteps         | 275931        |
| value_loss              | 4.4519125e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009769775  |
| ent_coef_loss           | -0.9581969    |
| entropy                 | 1.563551      |
| episodes                | 1200          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 276525        |
| policy_loss             | -0.55942345   |
| qf1_loss                | 2.683986e-05  |
| qf2_loss                | 3.7501362e-05 |
| time_elapsed            | 1963          |
| total timesteps         | 276625        |
| value_loss              | 3.6152054e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009772142  |
| ent_coef_loss           | -2.8314114    |
| entropy                 | 1.5980299     |
| episodes                | 1204          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 277233        |
| policy_loss             | -0.5944964    |
| qf1_loss                | 1.4190629e-05 |
| qf2_loss                | 1.407275e-05  |
| time_elapsed            | 1968          |
| total timesteps         | 277333        |
| value_loss              | 1.7039736e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009871301  |
| ent_coef_loss           | -1.4664178    |
| entropy                 | 1.535242      |
| episodes                | 1208          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 278278        |
| policy_loss             | -0.56194687   |
| qf1_loss                | 1.9766187e-05 |
| qf2_loss                | 2.2905588e-05 |
| time_elapsed            | 1976          |
| total timesteps         | 278378        |
| value_loss              | 2.5909869e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000926053   |
| ent_coef_loss           | -1.7084       |
| entropy                 | 1.3717213     |
| episodes                | 1212          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 278956        |
| policy_loss             | -0.6228769    |
| qf1_loss                | 1.0350999e-05 |
| qf2_loss                | 1.1452155e-05 |
| time_elapsed            | 1981          |
| total timesteps         | 279056        |
| value_loss              | 3.886233e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092605874 |
| ent_coef_loss           | 0.27120548    |
| entropy                 | 1.4715526     |
| episodes                | 1216          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 279675        |
| policy_loss             | -0.58631843   |
| qf1_loss                | 3.2281758e-05 |
| qf2_loss                | 4.1756593e-05 |
| time_elapsed            | 1986          |
| total timesteps         | 279775        |
| value_loss              | 3.080062e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097052066 |
| ent_coef_loss           | -1.0914868    |
| entropy                 | 1.5174291     |
| episodes                | 1220          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 280358        |
| policy_loss             | -0.61053777   |
| qf1_loss                | 2.7304348e-05 |
| qf2_loss                | 2.0927822e-05 |
| time_elapsed            | 1990          |
| total timesteps         | 280458        |
| value_loss              | 0.0007236933  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010164982  |
| ent_coef_loss           | 0.38147444    |
| entropy                 | 1.5001111     |
| episodes                | 1224          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 281157        |
| policy_loss             | -0.5865681    |
| qf1_loss                | 2.5414003e-05 |
| qf2_loss                | 2.2721128e-05 |
| time_elapsed            | 1996          |
| total timesteps         | 281257        |
| value_loss              | 4.713355e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010086892  |
| ent_coef_loss           | -3.1857827    |
| entropy                 | 1.4994652     |
| episodes                | 1228          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 282071        |
| policy_loss             | -0.5460179    |
| qf1_loss                | 2.5188474e-05 |
| qf2_loss                | 4.3085944e-05 |
| time_elapsed            | 2003          |
| total timesteps         | 282171        |
| value_loss              | 5.2093972e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009655608  |
| ent_coef_loss           | -1.1706178    |
| entropy                 | 1.4496584     |
| episodes                | 1232          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 282746        |
| policy_loss             | -0.5590278    |
| qf1_loss                | 2.4476962e-05 |
| qf2_loss                | 4.4647895e-05 |
| time_elapsed            | 2008          |
| total timesteps         | 282846        |
| value_loss              | 0.00017650322 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089970685 |
| ent_coef_loss           | 1.9071416     |
| entropy                 | 1.3941584     |
| episodes                | 1236          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 283423        |
| policy_loss             | -0.59289294   |
| qf1_loss                | 4.601671e-05  |
| qf2_loss                | 2.914172e-05  |
| time_elapsed            | 2012          |
| total timesteps         | 283523        |
| value_loss              | 4.175023e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089837273 |
| ent_coef_loss           | 2.1938217     |
| entropy                 | 1.32608       |
| episodes                | 1240          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 284163        |
| policy_loss             | -0.5562691    |
| qf1_loss                | 2.5908535e-05 |
| qf2_loss                | 2.6659829e-05 |
| time_elapsed            | 2018          |
| total timesteps         | 284263        |
| value_loss              | 2.5146175e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010364623  |
| ent_coef_loss           | -0.95342183   |
| entropy                 | 1.3602133     |
| episodes                | 1244          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 284968        |
| policy_loss             | -0.5834334    |
| qf1_loss                | 4.1239073e-05 |
| qf2_loss                | 5.7673264e-05 |
| time_elapsed            | 2023          |
| total timesteps         | 285068        |
| value_loss              | 3.394737e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096168637 |
| ent_coef_loss           | 3.5261602     |
| entropy                 | 1.3389169     |
| episodes                | 1248          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 285893        |
| policy_loss             | -0.576172     |
| qf1_loss                | 2.2671e-05    |
| qf2_loss                | 3.533187e-05  |
| time_elapsed            | 2030          |
| total timesteps         | 285993        |
| value_loss              | 2.3510831e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000895687   |
| ent_coef_loss           | -3.5798018    |
| entropy                 | 1.4000701     |
| episodes                | 1252          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 286656        |
| policy_loss             | -0.6147574    |
| qf1_loss                | 1.4099499e-05 |
| qf2_loss                | 1.1665574e-05 |
| time_elapsed            | 2035          |
| total timesteps         | 286756        |
| value_loss              | 1.9911542e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009278431  |
| ent_coef_loss           | -4.2313333    |
| entropy                 | 1.5776985     |
| episodes                | 1256          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 287327        |
| policy_loss             | -0.5948447    |
| qf1_loss                | 2.7512726e-05 |
| qf2_loss                | 1.5144757e-05 |
| time_elapsed            | 2040          |
| total timesteps         | 287427        |
| value_loss              | 3.5563353e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091676455 |
| ent_coef_loss           | -0.433833     |
| entropy                 | 1.4729161     |
| episodes                | 1260          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 288117        |
| policy_loss             | -0.5442426    |
| qf1_loss                | 3.171662e-05  |
| qf2_loss                | 2.7277414e-05 |
| time_elapsed            | 2046          |
| total timesteps         | 288217        |
| value_loss              | 4.742187e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095506874 |
| ent_coef_loss           | -6.6356354    |
| entropy                 | 1.5862733     |
| episodes                | 1264          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 288840        |
| policy_loss             | -0.57559806   |
| qf1_loss                | 7.1593044e-05 |
| qf2_loss                | 6.6467284e-05 |
| time_elapsed            | 2051          |
| total timesteps         | 288940        |
| value_loss              | 6.869889e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009538904  |
| ent_coef_loss           | -2.1315799    |
| entropy                 | 1.4893757     |
| episodes                | 1268          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 289679        |
| policy_loss             | -0.54997486   |
| qf1_loss                | 4.9759168e-05 |
| qf2_loss                | 5.016184e-05  |
| time_elapsed            | 2057          |
| total timesteps         | 289779        |
| value_loss              | 2.8906643e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095460936 |
| ent_coef_loss           | 3.8940349     |
| entropy                 | 1.3536898     |
| episodes                | 1272          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 290334        |
| policy_loss             | -0.54555076   |
| qf1_loss                | 2.0241529e-05 |
| qf2_loss                | 1.9095729e-05 |
| time_elapsed            | 2062          |
| total timesteps         | 290434        |
| value_loss              | 6.399485e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000991526   |
| ent_coef_loss           | 1.0277028     |
| entropy                 | 1.5736367     |
| episodes                | 1276          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 290982        |
| policy_loss             | -0.5358675    |
| qf1_loss                | 3.8988426e-05 |
| qf2_loss                | 4.2135118e-05 |
| time_elapsed            | 2066          |
| total timesteps         | 291082        |
| value_loss              | 5.1918403e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010369264  |
| ent_coef_loss           | -1.7498804    |
| entropy                 | 1.4697814     |
| episodes                | 1280          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 291648        |
| policy_loss             | -0.5645168    |
| qf1_loss                | 3.5235207e-05 |
| qf2_loss                | 2.7706048e-05 |
| time_elapsed            | 2071          |
| total timesteps         | 291748        |
| value_loss              | 2.5149846e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010283283  |
| ent_coef_loss           | -0.6870886    |
| entropy                 | 1.4899313     |
| episodes                | 1284          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 292416        |
| policy_loss             | -0.57368845   |
| qf1_loss                | 3.31275e-05   |
| qf2_loss                | 7.434444e-05  |
| time_elapsed            | 2076          |
| total timesteps         | 292516        |
| value_loss              | 3.6288624e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010547548  |
| ent_coef_loss           | -0.5714992    |
| entropy                 | 1.4297504     |
| episodes                | 1288          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 293094        |
| policy_loss             | -0.5425036    |
| qf1_loss                | 6.055693e-05  |
| qf2_loss                | 5.0364255e-05 |
| time_elapsed            | 2081          |
| total timesteps         | 293194        |
| value_loss              | 4.938857e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010454813  |
| ent_coef_loss           | -3.234549     |
| entropy                 | 1.5609701     |
| episodes                | 1292          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 293777        |
| policy_loss             | -0.5392871    |
| qf1_loss                | 2.9684112e-05 |
| qf2_loss                | 2.1938708e-05 |
| time_elapsed            | 2086          |
| total timesteps         | 293877        |
| value_loss              | 2.245328e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008979526  |
| ent_coef_loss           | -0.28413594   |
| entropy                 | 1.4954622     |
| episodes                | 1296          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 294544        |
| policy_loss             | -0.5752451    |
| qf1_loss                | 3.1715153e-05 |
| qf2_loss                | 2.7293781e-05 |
| time_elapsed            | 2091          |
| total timesteps         | 294644        |
| value_loss              | 1.4149114e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091592077 |
| ent_coef_loss           | 3.0853834     |
| entropy                 | 1.5385628     |
| episodes                | 1300          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 295306        |
| policy_loss             | -0.57531023   |
| qf1_loss                | 4.8253347e-05 |
| qf2_loss                | 5.356192e-05  |
| time_elapsed            | 2097          |
| total timesteps         | 295406        |
| value_loss              | 8.2465034e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010362547  |
| ent_coef_loss           | 2.3014555     |
| entropy                 | 1.522402      |
| episodes                | 1304          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 296242        |
| policy_loss             | -0.56915605   |
| qf1_loss                | 2.9566272e-05 |
| qf2_loss                | 5.618124e-05  |
| time_elapsed            | 2104          |
| total timesteps         | 296342        |
| value_loss              | 4.048655e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009939865  |
| ent_coef_loss           | -0.030603945  |
| entropy                 | 1.4196872     |
| episodes                | 1308          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 296946        |
| policy_loss             | -0.5228842    |
| qf1_loss                | 1.249647e-05  |
| qf2_loss                | 1.2406828e-05 |
| time_elapsed            | 2108          |
| total timesteps         | 297046        |
| value_loss              | 2.599126e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010128998  |
| ent_coef_loss           | 1.6000309     |
| entropy                 | 1.4433975     |
| episodes                | 1312          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 297643        |
| policy_loss             | -0.57238644   |
| qf1_loss                | 2.7712005e-05 |
| qf2_loss                | 2.4279994e-05 |
| time_elapsed            | 2113          |
| total timesteps         | 297743        |
| value_loss              | 1.4342229e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001033651   |
| ent_coef_loss           | 0.10990095    |
| entropy                 | 1.454936      |
| episodes                | 1316          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 298440        |
| policy_loss             | -0.5317754    |
| qf1_loss                | 2.2966024e-05 |
| qf2_loss                | 1.6508755e-05 |
| time_elapsed            | 2119          |
| total timesteps         | 298540        |
| value_loss              | 7.8454425e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097601966 |
| ent_coef_loss           | -1.1632731    |
| entropy                 | 1.5875591     |
| episodes                | 1320          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 299151        |
| policy_loss             | -0.5868058    |
| qf1_loss                | 3.076095e-05  |
| qf2_loss                | 5.097803e-05  |
| time_elapsed            | 2124          |
| total timesteps         | 299251        |
| value_loss              | 2.5310605e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090932794 |
| ent_coef_loss           | 1.0168452     |
| entropy                 | 1.4809704     |
| episodes                | 1324          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 299879        |
| policy_loss             | -0.5740966    |
| qf1_loss                | 1.3620605e-05 |
| qf2_loss                | 1.765648e-05  |
| time_elapsed            | 2129          |
| total timesteps         | 299979        |
| value_loss              | 1.8962399e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009524832  |
| ent_coef_loss           | -1.602839     |
| entropy                 | 1.460755      |
| episodes                | 1328          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 300541        |
| policy_loss             | -0.59288985   |
| qf1_loss                | 2.5547433e-05 |
| qf2_loss                | 3.3766035e-05 |
| time_elapsed            | 2134          |
| total timesteps         | 300641        |
| value_loss              | 9.444612e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095553795 |
| ent_coef_loss           | 0.6252057     |
| entropy                 | 1.4627469     |
| episodes                | 1332          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 301231        |
| policy_loss             | -0.5124569    |
| qf1_loss                | 1.4291377e-05 |
| qf2_loss                | 3.319252e-05  |
| time_elapsed            | 2139          |
| total timesteps         | 301331        |
| value_loss              | 2.2638522e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092211633 |
| ent_coef_loss           | 0.5786003     |
| entropy                 | 1.5102236     |
| episodes                | 1336          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 301915        |
| policy_loss             | -0.569684     |
| qf1_loss                | 3.1886386e-05 |
| qf2_loss                | 1.8433182e-05 |
| time_elapsed            | 2144          |
| total timesteps         | 302015        |
| value_loss              | 1.4675847e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093405205 |
| ent_coef_loss           | 0.56083626    |
| entropy                 | 1.5971458     |
| episodes                | 1340          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 302627        |
| policy_loss             | -0.58169425   |
| qf1_loss                | 1.1529262e-05 |
| qf2_loss                | 9.319869e-06  |
| time_elapsed            | 2149          |
| total timesteps         | 302727        |
| value_loss              | 1.6063894e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091225904 |
| ent_coef_loss           | 0.09554148    |
| entropy                 | 1.4840932     |
| episodes                | 1344          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 303312        |
| policy_loss             | -0.56242853   |
| qf1_loss                | 1.3900928e-05 |
| qf2_loss                | 1.8339704e-05 |
| time_elapsed            | 2154          |
| total timesteps         | 303412        |
| value_loss              | 2.8599763e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009058895  |
| ent_coef_loss           | -0.8491534    |
| entropy                 | 1.4820209     |
| episodes                | 1348          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 303960        |
| policy_loss             | -0.5553075    |
| qf1_loss                | 1.9330899e-05 |
| qf2_loss                | 2.8602251e-05 |
| time_elapsed            | 2158          |
| total timesteps         | 304060        |
| value_loss              | 2.8443214e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094735983 |
| ent_coef_loss           | -4.9160175    |
| entropy                 | 1.5330238     |
| episodes                | 1352          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 304760        |
| policy_loss             | -0.57371366   |
| qf1_loss                | 1.1835357e-05 |
| qf2_loss                | 1.8910056e-05 |
| time_elapsed            | 2164          |
| total timesteps         | 304860        |
| value_loss              | 1.886216e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091847405 |
| ent_coef_loss           | -2.0253859    |
| entropy                 | 1.4997747     |
| episodes                | 1356          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 305454        |
| policy_loss             | -0.5427454    |
| qf1_loss                | 2.7084607e-05 |
| qf2_loss                | 2.0385014e-05 |
| time_elapsed            | 2169          |
| total timesteps         | 305554        |
| value_loss              | 3.2346827e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008950167  |
| ent_coef_loss           | 0.6682632     |
| entropy                 | 1.6544709     |
| episodes                | 1360          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 306095        |
| policy_loss             | -0.54504424   |
| qf1_loss                | 1.9796506e-05 |
| qf2_loss                | 1.8152528e-05 |
| time_elapsed            | 2173          |
| total timesteps         | 306195        |
| value_loss              | 3.2734544e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008881617  |
| ent_coef_loss           | 2.3547497     |
| entropy                 | 1.5606966     |
| episodes                | 1364          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 306810        |
| policy_loss             | -0.5608257    |
| qf1_loss                | 1.9665484e-05 |
| qf2_loss                | 1.9427085e-05 |
| time_elapsed            | 2179          |
| total timesteps         | 306910        |
| value_loss              | 5.207458e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009429841  |
| ent_coef_loss           | -0.07763895   |
| entropy                 | 1.5464369     |
| episodes                | 1368          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 307536        |
| policy_loss             | -0.59977007   |
| qf1_loss                | 3.8158232e-05 |
| qf2_loss                | 6.484724e-05  |
| time_elapsed            | 2184          |
| total timesteps         | 307636        |
| value_loss              | 9.255882e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010057656  |
| ent_coef_loss           | 1.3315469     |
| entropy                 | 1.5021507     |
| episodes                | 1372          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 308212        |
| policy_loss             | -0.6071671    |
| qf1_loss                | 1.572436e-05  |
| qf2_loss                | 1.0486257e-05 |
| time_elapsed            | 2189          |
| total timesteps         | 308312        |
| value_loss              | 2.609535e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096647564 |
| ent_coef_loss           | 0.24655846    |
| entropy                 | 1.6124413     |
| episodes                | 1376          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 309018        |
| policy_loss             | -0.6264433    |
| qf1_loss                | 2.1326949e-05 |
| qf2_loss                | 1.7478022e-05 |
| time_elapsed            | 2194          |
| total timesteps         | 309118        |
| value_loss              | 1.3684615e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009789136  |
| ent_coef_loss           | -0.64415234   |
| entropy                 | 1.493331      |
| episodes                | 1380          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 309680        |
| policy_loss             | -0.5771517    |
| qf1_loss                | 1.7133798e-05 |
| qf2_loss                | 2.2435303e-05 |
| time_elapsed            | 2199          |
| total timesteps         | 309780        |
| value_loss              | 3.153734e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092845917 |
| ent_coef_loss           | 0.25452203    |
| entropy                 | 1.542715      |
| episodes                | 1384          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 310380        |
| policy_loss             | -0.5669222    |
| qf1_loss                | 2.4878433e-05 |
| qf2_loss                | 1.7055167e-05 |
| time_elapsed            | 2204          |
| total timesteps         | 310480        |
| value_loss              | 2.2092943e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091014866 |
| ent_coef_loss           | -1.2268759    |
| entropy                 | 1.5778226     |
| episodes                | 1388          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 311085        |
| policy_loss             | -0.54134786   |
| qf1_loss                | 1.3822617e-05 |
| qf2_loss                | 2.2638247e-05 |
| time_elapsed            | 2209          |
| total timesteps         | 311185        |
| value_loss              | 3.0827905e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091601774 |
| ent_coef_loss           | -1.4776115    |
| entropy                 | 1.3906125     |
| episodes                | 1392          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 311773        |
| policy_loss             | -0.5813862    |
| qf1_loss                | 1.795349e-05  |
| qf2_loss                | 0.00012205558 |
| time_elapsed            | 2214          |
| total timesteps         | 311873        |
| value_loss              | 4.5564084e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009307642  |
| ent_coef_loss           | -2.049812     |
| entropy                 | 1.6350162     |
| episodes                | 1396          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 312447        |
| policy_loss             | -0.5882834    |
| qf1_loss                | 1.4229765e-05 |
| qf2_loss                | 1.2424172e-05 |
| time_elapsed            | 2219          |
| total timesteps         | 312547        |
| value_loss              | 1.8079161e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009888521  |
| ent_coef_loss           | 0.95601064    |
| entropy                 | 1.4645478     |
| episodes                | 1400          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 313110        |
| policy_loss             | -0.5883144    |
| qf1_loss                | 2.3582636e-05 |
| qf2_loss                | 5.106817e-05  |
| time_elapsed            | 2223          |
| total timesteps         | 313210        |
| value_loss              | 4.9454964e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092936057 |
| ent_coef_loss           | 0.7730043     |
| entropy                 | 1.3801532     |
| episodes                | 1404          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 313772        |
| policy_loss             | -0.53857166   |
| qf1_loss                | 1.6917244e-05 |
| qf2_loss                | 2.5445874e-05 |
| time_elapsed            | 2228          |
| total timesteps         | 313872        |
| value_loss              | 5.3838477e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092017755 |
| ent_coef_loss           | -0.62148017   |
| entropy                 | 1.3963649     |
| episodes                | 1408          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 314724        |
| policy_loss             | -0.56286716   |
| qf1_loss                | 2.2872635e-05 |
| qf2_loss                | 2.5925427e-05 |
| time_elapsed            | 2235          |
| total timesteps         | 314824        |
| value_loss              | 2.3672335e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092283555 |
| ent_coef_loss           | 1.6089168     |
| entropy                 | 1.4109869     |
| episodes                | 1412          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 315381        |
| policy_loss             | -0.54266423   |
| qf1_loss                | 2.3329614e-05 |
| qf2_loss                | 1.9418607e-05 |
| time_elapsed            | 2239          |
| total timesteps         | 315481        |
| value_loss              | 5.456289e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000906042   |
| ent_coef_loss           | -1.2850007    |
| entropy                 | 1.4344251     |
| episodes                | 1416          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 316056        |
| policy_loss             | -0.58576095   |
| qf1_loss                | 3.2666907e-05 |
| qf2_loss                | 2.6011774e-05 |
| time_elapsed            | 2244          |
| total timesteps         | 316156        |
| value_loss              | 1.8906925e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092744234 |
| ent_coef_loss           | 0.8827882     |
| entropy                 | 1.5062153     |
| episodes                | 1420          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 316710        |
| policy_loss             | -0.6183703    |
| qf1_loss                | 1.3708358e-05 |
| qf2_loss                | 8.431562e-06  |
| time_elapsed            | 2249          |
| total timesteps         | 316810        |
| value_loss              | 2.964853e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009405707  |
| ent_coef_loss           | -2.685072     |
| entropy                 | 1.6100457     |
| episodes                | 1424          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 317350        |
| policy_loss             | -0.61757976   |
| qf1_loss                | 1.4296452e-05 |
| qf2_loss                | 1.8355193e-05 |
| time_elapsed            | 2254          |
| total timesteps         | 317450        |
| value_loss              | 2.2341485e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009279949  |
| ent_coef_loss           | -0.5000655    |
| entropy                 | 1.5616412     |
| episodes                | 1428          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 317993        |
| policy_loss             | -0.6121304    |
| qf1_loss                | 1.7757724e-05 |
| qf2_loss                | 8.932234e-06  |
| time_elapsed            | 2258          |
| total timesteps         | 318093        |
| value_loss              | 2.7881762e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091703865 |
| ent_coef_loss           | 1.9992458     |
| entropy                 | 1.5654324     |
| episodes                | 1432          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 318633        |
| policy_loss             | -0.5956099    |
| qf1_loss                | 2.6084985e-05 |
| qf2_loss                | 2.3482517e-05 |
| time_elapsed            | 2263          |
| total timesteps         | 318733        |
| value_loss              | 2.2763248e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090092694 |
| ent_coef_loss           | 0.5964392     |
| entropy                 | 1.5326686     |
| episodes                | 1436          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 319311        |
| policy_loss             | -0.58910674   |
| qf1_loss                | 1.364936e-05  |
| qf2_loss                | 1.619312e-05  |
| time_elapsed            | 2267          |
| total timesteps         | 319411        |
| value_loss              | 3.7176775e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091154984 |
| ent_coef_loss           | -3.60853      |
| entropy                 | 1.5080391     |
| episodes                | 1440          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 319992        |
| policy_loss             | -0.5826434    |
| qf1_loss                | 1.2799974e-05 |
| qf2_loss                | 1.0302485e-05 |
| time_elapsed            | 2272          |
| total timesteps         | 320092        |
| value_loss              | 2.2655466e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091341295 |
| ent_coef_loss           | -0.6981442    |
| entropy                 | 1.5377281     |
| episodes                | 1444          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 320687        |
| policy_loss             | -0.57996535   |
| qf1_loss                | 1.1837468e-05 |
| qf2_loss                | 1.7210506e-05 |
| time_elapsed            | 2277          |
| total timesteps         | 320787        |
| value_loss              | 2.0548992e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008946745  |
| ent_coef_loss           | 1.0316236     |
| entropy                 | 1.5253451     |
| episodes                | 1448          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 321321        |
| policy_loss             | -0.55933386   |
| qf1_loss                | 1.8513269e-05 |
| qf2_loss                | 1.5103817e-05 |
| time_elapsed            | 2282          |
| total timesteps         | 321421        |
| value_loss              | 1.4105851e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008655578  |
| ent_coef_loss           | -1.587108     |
| entropy                 | 1.5777495     |
| episodes                | 1452          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 321978        |
| policy_loss             | -0.5929396    |
| qf1_loss                | 1.4861365e-05 |
| qf2_loss                | 2.1073422e-05 |
| time_elapsed            | 2286          |
| total timesteps         | 322078        |
| value_loss              | 4.4705048e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096839975 |
| ent_coef_loss           | -0.08429769   |
| entropy                 | 1.5057137     |
| episodes                | 1456          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 322622        |
| policy_loss             | -0.589483     |
| qf1_loss                | 9.757354e-06  |
| qf2_loss                | 8.017491e-06  |
| time_elapsed            | 2291          |
| total timesteps         | 322722        |
| value_loss              | 1.7565257e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091835496 |
| ent_coef_loss           | 1.6439332     |
| entropy                 | 1.6320184     |
| episodes                | 1460          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 323246        |
| policy_loss             | -0.5986131    |
| qf1_loss                | 1.5650396e-05 |
| qf2_loss                | 2.0784202e-05 |
| time_elapsed            | 2295          |
| total timesteps         | 323346        |
| value_loss              | 2.3641001e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00085500884  |
| ent_coef_loss           | -1.205918      |
| entropy                 | 1.6939946      |
| episodes                | 1464           |
| fps                     | 140            |
| mean 100 episode reward | 0.9            |
| n_updates               | 323924         |
| policy_loss             | -0.54769015    |
| qf1_loss                | 2.5359986e-05  |
| qf2_loss                | 1.25477345e-05 |
| time_elapsed            | 2300           |
| total timesteps         | 324024         |
| value_loss              | 1.6472995e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085078005 |
| ent_coef_loss           | 2.2930994     |
| entropy                 | 1.508576      |
| episodes                | 1468          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 324597        |
| policy_loss             | -0.6108554    |
| qf1_loss                | 2.348775e-05  |
| qf2_loss                | 2.931794e-05  |
| time_elapsed            | 2305          |
| total timesteps         | 324697        |
| value_loss              | 3.7308466e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008307001  |
| ent_coef_loss           | -2.0261035    |
| entropy                 | 1.534927      |
| episodes                | 1472          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 325224        |
| policy_loss             | -0.6162095    |
| qf1_loss                | 1.2839193e-05 |
| qf2_loss                | 1.3182777e-05 |
| time_elapsed            | 2309          |
| total timesteps         | 325324        |
| value_loss              | 3.103734e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0008302372   |
| ent_coef_loss           | -1.1381785     |
| entropy                 | 1.5983422      |
| episodes                | 1476           |
| fps                     | 140            |
| mean 100 episode reward | 0.9            |
| n_updates               | 325876         |
| policy_loss             | -0.5985239     |
| qf1_loss                | 1.5595264e-05  |
| qf2_loss                | 1.49334055e-05 |
| time_elapsed            | 2314           |
| total timesteps         | 325976         |
| value_loss              | 3.4474582e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008250893  |
| ent_coef_loss           | -1.4914355    |
| entropy                 | 1.5807838     |
| episodes                | 1480          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 326534        |
| policy_loss             | -0.5985737    |
| qf1_loss                | 1.0991123e-05 |
| qf2_loss                | 1.0717409e-05 |
| time_elapsed            | 2319          |
| total timesteps         | 326634        |
| value_loss              | 3.0732932e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009313591  |
| ent_coef_loss           | 0.17090784    |
| entropy                 | 1.6271502     |
| episodes                | 1484          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 327279        |
| policy_loss             | -0.60469186   |
| qf1_loss                | 1.4110117e-05 |
| qf2_loss                | 8.8885645e-06 |
| time_elapsed            | 2324          |
| total timesteps         | 327379        |
| value_loss              | 3.640708e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094965333 |
| ent_coef_loss           | 0.31856763    |
| entropy                 | 1.506193      |
| episodes                | 1488          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 327937        |
| policy_loss             | -0.51084375   |
| qf1_loss                | 7.14894e-05   |
| qf2_loss                | 2.9777668e-05 |
| time_elapsed            | 2329          |
| total timesteps         | 328037        |
| value_loss              | 4.909751e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009239658  |
| ent_coef_loss           | 0.90682507    |
| entropy                 | 1.5671852     |
| episodes                | 1492          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 328588        |
| policy_loss             | -0.5487145    |
| qf1_loss                | 1.593983e-05  |
| qf2_loss                | 1.6840091e-05 |
| time_elapsed            | 2333          |
| total timesteps         | 328688        |
| value_loss              | 3.922059e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094223436 |
| ent_coef_loss           | 3.902332      |
| entropy                 | 1.5747734     |
| episodes                | 1496          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 329316        |
| policy_loss             | -0.5874548    |
| qf1_loss                | 2.0173191e-05 |
| qf2_loss                | 1.7078924e-05 |
| time_elapsed            | 2339          |
| total timesteps         | 329416        |
| value_loss              | 4.406352e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093063636 |
| ent_coef_loss           | 1.2443805     |
| entropy                 | 1.5480297     |
| episodes                | 1500          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 329996        |
| policy_loss             | -0.55241406   |
| qf1_loss                | 1.8570216e-05 |
| qf2_loss                | 1.2146604e-05 |
| time_elapsed            | 2343          |
| total timesteps         | 330096        |
| value_loss              | 1.4344183e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092395965 |
| ent_coef_loss           | 0.81645066    |
| entropy                 | 1.5162253     |
| episodes                | 1504          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 330643        |
| policy_loss             | -0.54653513   |
| qf1_loss                | 8.449604e-06  |
| qf2_loss                | 2.0260766e-05 |
| time_elapsed            | 2348          |
| total timesteps         | 330743        |
| value_loss              | 2.4639483e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008830794  |
| ent_coef_loss           | -0.78777075   |
| entropy                 | 1.5439107     |
| episodes                | 1508          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 331300        |
| policy_loss             | -0.5947241    |
| qf1_loss                | 6.0201833e-06 |
| qf2_loss                | 7.0889514e-06 |
| time_elapsed            | 2353          |
| total timesteps         | 331400        |
| value_loss              | 1.6317194e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008637169  |
| ent_coef_loss           | 1.0654898     |
| entropy                 | 1.6557243     |
| episodes                | 1512          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 331975        |
| policy_loss             | -0.5756221    |
| qf1_loss                | 1.1915417e-05 |
| qf2_loss                | 2.1544465e-05 |
| time_elapsed            | 2357          |
| total timesteps         | 332075        |
| value_loss              | 2.415279e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008597041  |
| ent_coef_loss           | -2.5206974    |
| entropy                 | 1.6003147     |
| episodes                | 1516          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 332646        |
| policy_loss             | -0.60121655   |
| qf1_loss                | 2.4951736e-05 |
| qf2_loss                | 2.1688998e-05 |
| time_elapsed            | 2362          |
| total timesteps         | 332746        |
| value_loss              | 1.4823402e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009392549  |
| ent_coef_loss           | -0.18406045   |
| entropy                 | 1.6312366     |
| episodes                | 1520          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 333291        |
| policy_loss             | -0.5826352    |
| qf1_loss                | 7.6104743e-06 |
| qf2_loss                | 1.0900161e-05 |
| time_elapsed            | 2367          |
| total timesteps         | 333391        |
| value_loss              | 2.1253067e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009311833  |
| ent_coef_loss           | -0.40960437   |
| entropy                 | 1.6735044     |
| episodes                | 1524          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 333858        |
| policy_loss             | -0.6415882    |
| qf1_loss                | 1.0165479e-05 |
| qf2_loss                | 1.7783672e-05 |
| time_elapsed            | 2371          |
| total timesteps         | 333958        |
| value_loss              | 1.8770741e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086118607 |
| ent_coef_loss           | 1.593674      |
| entropy                 | 1.5907178     |
| episodes                | 1528          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 334595        |
| policy_loss             | -0.6101939    |
| qf1_loss                | 1.5135172e-05 |
| qf2_loss                | 2.7916674e-05 |
| time_elapsed            | 2376          |
| total timesteps         | 334695        |
| value_loss              | 1.314486e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00080152875 |
| ent_coef_loss           | 1.3694135     |
| entropy                 | 1.4758418     |
| episodes                | 1532          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 335259        |
| policy_loss             | -0.56867874   |
| qf1_loss                | 1.7390928e-05 |
| qf2_loss                | 8.064011e-06  |
| time_elapsed            | 2381          |
| total timesteps         | 335359        |
| value_loss              | 1.4738788e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007686689  |
| ent_coef_loss           | 1.3684074     |
| entropy                 | 1.4562315     |
| episodes                | 1536          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 336000        |
| policy_loss             | -0.58575493   |
| qf1_loss                | 1.9636293e-05 |
| qf2_loss                | 1.5387648e-05 |
| time_elapsed            | 2386          |
| total timesteps         | 336100        |
| value_loss              | 1.7861807e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0007675668   |
| ent_coef_loss           | -1.3250843     |
| entropy                 | 1.5632504      |
| episodes                | 1540           |
| fps                     | 140            |
| mean 100 episode reward | 0.9            |
| n_updates               | 336663         |
| policy_loss             | -0.60448474    |
| qf1_loss                | 1.33958365e-05 |
| qf2_loss                | 1.2547594e-05  |
| time_elapsed            | 2391           |
| total timesteps         | 336763         |
| value_loss              | 1.5364414e-05  |
--------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00080192904  |
| ent_coef_loss           | 1.1344893      |
| entropy                 | 1.5342448      |
| episodes                | 1544           |
| fps                     | 140            |
| mean 100 episode reward | 0.9            |
| n_updates               | 337310         |
| policy_loss             | -0.60477114    |
| qf1_loss                | 3.121565e-05   |
| qf2_loss                | 1.26276955e-05 |
| time_elapsed            | 2395           |
| total timesteps         | 337410         |
| value_loss              | 1.7023636e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008457866  |
| ent_coef_loss           | -0.15216875   |
| entropy                 | 1.6119702     |
| episodes                | 1548          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 337986        |
| policy_loss             | -0.618899     |
| qf1_loss                | 9.07444e-06   |
| qf2_loss                | 1.1117229e-05 |
| time_elapsed            | 2400          |
| total timesteps         | 338086        |
| value_loss              | 1.1690792e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008591689  |
| ent_coef_loss           | 1.2238257     |
| entropy                 | 1.4875588     |
| episodes                | 1552          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 338652        |
| policy_loss             | -0.5540089    |
| qf1_loss                | 0.00010990158 |
| qf2_loss                | 4.8439564e-05 |
| time_elapsed            | 2405          |
| total timesteps         | 338752        |
| value_loss              | 0.0003007564  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008533511  |
| ent_coef_loss           | 0.9525635     |
| entropy                 | 1.5432711     |
| episodes                | 1556          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 339314        |
| policy_loss             | -0.5807638    |
| qf1_loss                | 1.7510887e-05 |
| qf2_loss                | 1.1242817e-05 |
| time_elapsed            | 2409          |
| total timesteps         | 339414        |
| value_loss              | 1.6409063e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008298244  |
| ent_coef_loss           | -1.0196488    |
| entropy                 | 1.5410689     |
| episodes                | 1560          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 339960        |
| policy_loss             | -0.6160345    |
| qf1_loss                | 6.565903e-06  |
| qf2_loss                | 2.1701357e-05 |
| time_elapsed            | 2414          |
| total timesteps         | 340060        |
| value_loss              | 1.0688886e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0008346014   |
| ent_coef_loss           | 0.24983984     |
| entropy                 | 1.5795124      |
| episodes                | 1564           |
| fps                     | 140            |
| mean 100 episode reward | 0.9            |
| n_updates               | 340643         |
| policy_loss             | -0.5508229     |
| qf1_loss                | 1.02872655e-05 |
| qf2_loss                | 8.295373e-06   |
| time_elapsed            | 2419           |
| total timesteps         | 340743         |
| value_loss              | 1.3298439e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00084235746 |
| ent_coef_loss           | -1.0851628    |
| entropy                 | 1.7059095     |
| episodes                | 1568          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 341363        |
| policy_loss             | -0.64153576   |
| qf1_loss                | 1.2342647e-05 |
| qf2_loss                | 2.2416007e-05 |
| time_elapsed            | 2424          |
| total timesteps         | 341463        |
| value_loss              | 2.465129e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008303615  |
| ent_coef_loss           | 1.5967693     |
| entropy                 | 1.583281      |
| episodes                | 1572          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 342117        |
| policy_loss             | -0.6009611    |
| qf1_loss                | 3.065993e-05  |
| qf2_loss                | 2.9655697e-05 |
| time_elapsed            | 2429          |
| total timesteps         | 342217        |
| value_loss              | 9.302639e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008412391  |
| ent_coef_loss           | 0.07054454    |
| entropy                 | 1.6728035     |
| episodes                | 1576          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 342845        |
| policy_loss             | -0.56684476   |
| qf1_loss                | 2.0101439e-05 |
| qf2_loss                | 1.007693e-05  |
| time_elapsed            | 2435          |
| total timesteps         | 342945        |
| value_loss              | 3.218386e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008904049  |
| ent_coef_loss           | -0.18433443   |
| entropy                 | 1.6273539     |
| episodes                | 1580          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 343564        |
| policy_loss             | -0.56501687   |
| qf1_loss                | 8.312641e-06  |
| qf2_loss                | 1.1557065e-05 |
| time_elapsed            | 2440          |
| total timesteps         | 343664        |
| value_loss              | 3.4849596e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085523963 |
| ent_coef_loss           | -0.04450965   |
| entropy                 | 1.6667836     |
| episodes                | 1584          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 344280        |
| policy_loss             | -0.5753595    |
| qf1_loss                | 2.4712384e-05 |
| qf2_loss                | 2.624288e-05  |
| time_elapsed            | 2445          |
| total timesteps         | 344380        |
| value_loss              | 3.3900375e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008950436  |
| ent_coef_loss           | -0.66540134   |
| entropy                 | 1.647055      |
| episodes                | 1588          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 344934        |
| policy_loss             | -0.60825527   |
| qf1_loss                | 0.00010707569 |
| qf2_loss                | 2.7862083e-05 |
| time_elapsed            | 2449          |
| total timesteps         | 345034        |
| value_loss              | 3.334303e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00082973734 |
| ent_coef_loss           | -0.12237352   |
| entropy                 | 1.5949123     |
| episodes                | 1592          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 345604        |
| policy_loss             | -0.5711674    |
| qf1_loss                | 1.2750037e-05 |
| qf2_loss                | 1.6635502e-05 |
| time_elapsed            | 2454          |
| total timesteps         | 345704        |
| value_loss              | 2.1619537e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0008258635 |
| ent_coef_loss           | 0.13109091   |
| entropy                 | 1.664127     |
| episodes                | 1596         |
| fps                     | 140          |
| mean 100 episode reward | 0.9          |
| n_updates               | 346328       |
| policy_loss             | -0.5975872   |
| qf1_loss                | 9.492936e-06 |
| qf2_loss                | 1.317684e-05 |
| time_elapsed            | 2459         |
| total timesteps         | 346428       |
| value_loss              | 9.931286e-06 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008656193  |
| ent_coef_loss           | -0.87669325   |
| entropy                 | 1.6320095     |
| episodes                | 1600          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 346982        |
| policy_loss             | -0.5803455    |
| qf1_loss                | 1.1411522e-05 |
| qf2_loss                | 7.4687673e-06 |
| time_elapsed            | 2464          |
| total timesteps         | 347082        |
| value_loss              | 1.6930328e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086194737 |
| ent_coef_loss           | 2.2395725     |
| entropy                 | 1.7163949     |
| episodes                | 1604          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 347686        |
| policy_loss             | -0.60674316   |
| qf1_loss                | 1.0623839e-05 |
| qf2_loss                | 1.4876449e-05 |
| time_elapsed            | 2469          |
| total timesteps         | 347786        |
| value_loss              | 3.1120362e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008402349  |
| ent_coef_loss           | -2.1994367    |
| entropy                 | 1.6723979     |
| episodes                | 1608          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 348329        |
| policy_loss             | -0.58979744   |
| qf1_loss                | 2.9236317e-05 |
| qf2_loss                | 2.050858e-05  |
| time_elapsed            | 2473          |
| total timesteps         | 348429        |
| value_loss              | 1.9372526e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008391062  |
| ent_coef_loss           | -0.24727416   |
| entropy                 | 1.687618      |
| episodes                | 1612          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 348995        |
| policy_loss             | -0.6197937    |
| qf1_loss                | 1.3348823e-05 |
| qf2_loss                | 1.401706e-05  |
| time_elapsed            | 2478          |
| total timesteps         | 349095        |
| value_loss              | 1.2908807e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008484975  |
| ent_coef_loss           | -1.7289315    |
| entropy                 | 1.6949459     |
| episodes                | 1616          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 349670        |
| policy_loss             | -0.6184535    |
| qf1_loss                | 1.7524213e-05 |
| qf2_loss                | 1.3598674e-05 |
| time_elapsed            | 2483          |
| total timesteps         | 349770        |
| value_loss              | 1.1510336e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008401207  |
| ent_coef_loss           | 0.43223873    |
| entropy                 | 1.6597145     |
| episodes                | 1620          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 350339        |
| policy_loss             | -0.6354383    |
| qf1_loss                | 7.0008246e-06 |
| qf2_loss                | 2.9189981e-05 |
| time_elapsed            | 2488          |
| total timesteps         | 350439        |
| value_loss              | 1.8447905e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00082550757 |
| ent_coef_loss           | 0.0133603215  |
| entropy                 | 1.6437128     |
| episodes                | 1624          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 351060        |
| policy_loss             | -0.5718199    |
| qf1_loss                | 3.4113775e-05 |
| qf2_loss                | 1.2879106e-05 |
| time_elapsed            | 2493          |
| total timesteps         | 351160        |
| value_loss              | 1.6809488e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008455793  |
| ent_coef_loss           | -0.7052548    |
| entropy                 | 1.6644993     |
| episodes                | 1628          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 351752        |
| policy_loss             | -0.6287807    |
| qf1_loss                | 1.1192081e-05 |
| qf2_loss                | 7.766981e-06  |
| time_elapsed            | 2498          |
| total timesteps         | 351852        |
| value_loss              | 9.955181e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087873026 |
| ent_coef_loss           | -0.13121569   |
| entropy                 | 1.7795464     |
| episodes                | 1632          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 352438        |
| policy_loss             | -0.63827604   |
| qf1_loss                | 4.0502664e-06 |
| qf2_loss                | 3.856247e-06  |
| time_elapsed            | 2503          |
| total timesteps         | 352538        |
| value_loss              | 9.260512e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008626278  |
| ent_coef_loss           | -0.17135942   |
| entropy                 | 1.6791329     |
| episodes                | 1636          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 353093        |
| policy_loss             | -0.61120737   |
| qf1_loss                | 1.4128879e-05 |
| qf2_loss                | 7.062449e-06  |
| time_elapsed            | 2507          |
| total timesteps         | 353193        |
| value_loss              | 1.1621392e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0008585161   |
| ent_coef_loss           | 0.09344798     |
| entropy                 | 1.6860336      |
| episodes                | 1640           |
| fps                     | 140            |
| mean 100 episode reward | 0.9            |
| n_updates               | 353716         |
| policy_loss             | -0.55929387    |
| qf1_loss                | 9.107314e-06   |
| qf2_loss                | 1.36129365e-05 |
| time_elapsed            | 2512           |
| total timesteps         | 353816         |
| value_loss              | 1.6273492e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086685637 |
| ent_coef_loss           | 1.5503902     |
| entropy                 | 1.7114563     |
| episodes                | 1644          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 354371        |
| policy_loss             | -0.60854006   |
| qf1_loss                | 1.1798469e-05 |
| qf2_loss                | 9.285551e-06  |
| time_elapsed            | 2516          |
| total timesteps         | 354471        |
| value_loss              | 5.192498e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087916444 |
| ent_coef_loss           | -4.762942     |
| entropy                 | 1.6517713     |
| episodes                | 1648          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 355338        |
| policy_loss             | -0.5994707    |
| qf1_loss                | 5.8642754e-06 |
| qf2_loss                | 6.4399637e-06 |
| time_elapsed            | 2523          |
| total timesteps         | 355438        |
| value_loss              | 1.4049835e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008743679  |
| ent_coef_loss           | -0.21275324   |
| entropy                 | 1.7272494     |
| episodes                | 1652          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 356055        |
| policy_loss             | -0.6305375    |
| qf1_loss                | 5.8647256e-06 |
| qf2_loss                | 6.7081833e-06 |
| time_elapsed            | 2528          |
| total timesteps         | 356155        |
| value_loss              | 1.653474e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008773473  |
| ent_coef_loss           | 2.4808643     |
| entropy                 | 1.6933867     |
| episodes                | 1656          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 356721        |
| policy_loss             | -0.617905     |
| qf1_loss                | 1.6214868e-05 |
| qf2_loss                | 1.844091e-05  |
| time_elapsed            | 2533          |
| total timesteps         | 356821        |
| value_loss              | 4.750783e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008766176  |
| ent_coef_loss           | -1.3598021    |
| entropy                 | 1.6719762     |
| episodes                | 1660          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 357388        |
| policy_loss             | -0.65172756   |
| qf1_loss                | 8.364868e-06  |
| qf2_loss                | 9.141561e-06  |
| time_elapsed            | 2538          |
| total timesteps         | 357488        |
| value_loss              | 1.2624931e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085134985 |
| ent_coef_loss           | 1.3185487     |
| entropy                 | 1.567523      |
| episodes                | 1664          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 358062        |
| policy_loss             | -0.56871223   |
| qf1_loss                | 8.459477e-06  |
| qf2_loss                | 1.069805e-05  |
| time_elapsed            | 2542          |
| total timesteps         | 358162        |
| value_loss              | 1.1981027e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085617235 |
| ent_coef_loss           | 4.3390746     |
| entropy                 | 1.756768      |
| episodes                | 1668          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 358719        |
| policy_loss             | -0.5771992    |
| qf1_loss                | 3.0644187e-05 |
| qf2_loss                | 2.8824772e-05 |
| time_elapsed            | 2547          |
| total timesteps         | 358819        |
| value_loss              | 2.7925502e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008027658  |
| ent_coef_loss           | 0.30780044    |
| entropy                 | 1.577984      |
| episodes                | 1672          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 359403        |
| policy_loss             | -0.58797383   |
| qf1_loss                | 8.361624e-06  |
| qf2_loss                | 2.0028925e-05 |
| time_elapsed            | 2552          |
| total timesteps         | 359503        |
| value_loss              | 4.4994842e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008048048  |
| ent_coef_loss           | 0.9417648     |
| entropy                 | 1.5829463     |
| episodes                | 1676          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 360066        |
| policy_loss             | -0.60575116   |
| qf1_loss                | 1.2313192e-05 |
| qf2_loss                | 1.2766539e-05 |
| time_elapsed            | 2557          |
| total timesteps         | 360166        |
| value_loss              | 1.4175184e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0008357252 |
| ent_coef_loss           | 0.44204178   |
| entropy                 | 1.7729379    |
| episodes                | 1680         |
| fps                     | 140          |
| mean 100 episode reward | 0.9          |
| n_updates               | 360725       |
| policy_loss             | -0.56961983  |
| qf1_loss                | 2.17189e-05  |
| qf2_loss                | 2.191237e-05 |
| time_elapsed            | 2561         |
| total timesteps         | 360825       |
| value_loss              | 3.675031e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008675834  |
| ent_coef_loss           | 0.97354275    |
| entropy                 | 1.6013894     |
| episodes                | 1684          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 361591        |
| policy_loss             | -0.6199229    |
| qf1_loss                | 1.267554e-05  |
| qf2_loss                | 1.2428799e-05 |
| time_elapsed            | 2567          |
| total timesteps         | 361691        |
| value_loss              | 1.4677553e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00076275214 |
| ent_coef_loss           | 2.564948      |
| entropy                 | 1.5407903     |
| episodes                | 1688          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 362238        |
| policy_loss             | -0.5690224    |
| qf1_loss                | 5.0838767e-05 |
| qf2_loss                | 3.9829618e-05 |
| time_elapsed            | 2572          |
| total timesteps         | 362338        |
| value_loss              | 5.850886e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00089321367  |
| ent_coef_loss           | -1.70433       |
| entropy                 | 1.6039007      |
| episodes                | 1692           |
| fps                     | 140            |
| mean 100 episode reward | 0.9            |
| n_updates               | 362906         |
| policy_loss             | -0.6332967     |
| qf1_loss                | 1.28798565e-05 |
| qf2_loss                | 1.5099547e-05  |
| time_elapsed            | 2577           |
| total timesteps         | 363006         |
| value_loss              | 3.9740436e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008479587  |
| ent_coef_loss           | -0.9728268    |
| entropy                 | 1.5515313     |
| episodes                | 1696          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 363602        |
| policy_loss             | -0.6321903    |
| qf1_loss                | 1.1425507e-05 |
| qf2_loss                | 1.3375896e-05 |
| time_elapsed            | 2582          |
| total timesteps         | 363702        |
| value_loss              | 1.682452e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.000798987    |
| ent_coef_loss           | -2.5521088     |
| entropy                 | 1.5907254      |
| episodes                | 1700           |
| fps                     | 140            |
| mean 100 episode reward | 0.9            |
| n_updates               | 364253         |
| policy_loss             | -0.58195186    |
| qf1_loss                | 1.276825e-05   |
| qf2_loss                | 1.44686255e-05 |
| time_elapsed            | 2586           |
| total timesteps         | 364353         |
| value_loss              | 1.214564e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000800856   |
| ent_coef_loss           | -2.2038865    |
| entropy                 | 1.6236126     |
| episodes                | 1704          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 364939        |
| policy_loss             | -0.6445302    |
| qf1_loss                | 8.00068e-06   |
| qf2_loss                | 7.3405436e-06 |
| time_elapsed            | 2591          |
| total timesteps         | 365039        |
| value_loss              | 7.0318083e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008003242  |
| ent_coef_loss           | -0.8396821    |
| entropy                 | 1.533846      |
| episodes                | 1708          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 365633        |
| policy_loss             | -0.6142927    |
| qf1_loss                | 1.5266594e-05 |
| qf2_loss                | 1.805191e-05  |
| time_elapsed            | 2596          |
| total timesteps         | 365733        |
| value_loss              | 2.0036314e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007712624  |
| ent_coef_loss           | -3.1416466    |
| entropy                 | 1.5585867     |
| episodes                | 1712          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 366344        |
| policy_loss             | -0.61164665   |
| qf1_loss                | 1.7844806e-05 |
| qf2_loss                | 2.076905e-05  |
| time_elapsed            | 2601          |
| total timesteps         | 366444        |
| value_loss              | 4.0417093e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00075049506 |
| ent_coef_loss           | -2.6660979    |
| entropy                 | 1.3524909     |
| episodes                | 1716          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 367055        |
| policy_loss             | -0.61661386   |
| qf1_loss                | 3.0440613e-05 |
| qf2_loss                | 2.921624e-05  |
| time_elapsed            | 2606          |
| total timesteps         | 367155        |
| value_loss              | 3.3283715e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008192909  |
| ent_coef_loss           | 0.590387      |
| entropy                 | 1.4685142     |
| episodes                | 1720          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 367720        |
| policy_loss             | -0.61326647   |
| qf1_loss                | 9.481569e-06  |
| qf2_loss                | 9.246582e-06  |
| time_elapsed            | 2611          |
| total timesteps         | 367820        |
| value_loss              | 2.0458854e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00079273025 |
| ent_coef_loss           | -0.29997605   |
| entropy                 | 1.5054196     |
| episodes                | 1724          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 368383        |
| policy_loss             | -0.5914341    |
| qf1_loss                | 2.3309138e-05 |
| qf2_loss                | 3.8015532e-05 |
| time_elapsed            | 2616          |
| total timesteps         | 368483        |
| value_loss              | 2.2740373e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007753865  |
| ent_coef_loss           | 0.43600696    |
| entropy                 | 1.5356281     |
| episodes                | 1728          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 369029        |
| policy_loss             | -0.6479917    |
| qf1_loss                | 1.0740542e-05 |
| qf2_loss                | 1.5407764e-05 |
| time_elapsed            | 2620          |
| total timesteps         | 369129        |
| value_loss              | 6.059694e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00078008743  |
| ent_coef_loss           | 3.7618577      |
| entropy                 | 1.4879714      |
| episodes                | 1732           |
| fps                     | 140            |
| mean 100 episode reward | 0.9            |
| n_updates               | 369881         |
| policy_loss             | -0.58808374    |
| qf1_loss                | 1.25364295e-05 |
| qf2_loss                | 1.3252531e-05  |
| time_elapsed            | 2626           |
| total timesteps         | 369981         |
| value_loss              | 2.7967588e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00074454705 |
| ent_coef_loss           | 0.8732333     |
| entropy                 | 1.4972849     |
| episodes                | 1736          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 370571        |
| policy_loss             | -0.62215334   |
| qf1_loss                | 1.6384734e-05 |
| qf2_loss                | 1.2782219e-05 |
| time_elapsed            | 2631          |
| total timesteps         | 370671        |
| value_loss              | 1.8232502e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00072895753 |
| ent_coef_loss           | -0.99287397   |
| entropy                 | 1.4423745     |
| episodes                | 1740          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 371254        |
| policy_loss             | -0.65974164   |
| qf1_loss                | 7.264078e-06  |
| qf2_loss                | 1.7812103e-05 |
| time_elapsed            | 2636          |
| total timesteps         | 371354        |
| value_loss              | 3.671285e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007710675  |
| ent_coef_loss           | -1.5634615    |
| entropy                 | 1.5411191     |
| episodes                | 1744          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 371889        |
| policy_loss             | -0.6427542    |
| qf1_loss                | 1.1673704e-05 |
| qf2_loss                | 2.4199962e-05 |
| time_elapsed            | 2641          |
| total timesteps         | 371989        |
| value_loss              | 3.3686287e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007280037  |
| ent_coef_loss           | -0.42890868   |
| entropy                 | 1.4737201     |
| episodes                | 1748          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 372561        |
| policy_loss             | -0.59973335   |
| qf1_loss                | 4.601065e-05  |
| qf2_loss                | 3.5934325e-05 |
| time_elapsed            | 2646          |
| total timesteps         | 372661        |
| value_loss              | 7.179141e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00073240965 |
| ent_coef_loss           | -0.42187592   |
| entropy                 | 1.4423884     |
| episodes                | 1752          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 373299        |
| policy_loss             | -0.62809473   |
| qf1_loss                | 9.902892e-06  |
| qf2_loss                | 1.1664941e-05 |
| time_elapsed            | 2651          |
| total timesteps         | 373399        |
| value_loss              | 2.9949304e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00079071807 |
| ent_coef_loss           | -0.056631804  |
| entropy                 | 1.48221       |
| episodes                | 1756          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 374057        |
| policy_loss             | -0.6502084    |
| qf1_loss                | 5.4683078e-05 |
| qf2_loss                | 6.87469e-05   |
| time_elapsed            | 2656          |
| total timesteps         | 374157        |
| value_loss              | 3.3958677e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009331773  |
| ent_coef_loss           | -1.9714165    |
| entropy                 | 1.6116902     |
| episodes                | 1760          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 374799        |
| policy_loss             | -0.58680284   |
| qf1_loss                | 2.9617058e-05 |
| qf2_loss                | 3.3959244e-05 |
| time_elapsed            | 2661          |
| total timesteps         | 374899        |
| value_loss              | 3.6015295e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008724284  |
| ent_coef_loss           | 1.0705667     |
| entropy                 | 1.4761193     |
| episodes                | 1764          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 375560        |
| policy_loss             | -0.6620542    |
| qf1_loss                | 3.074725e-05  |
| qf2_loss                | 4.107294e-05  |
| time_elapsed            | 2667          |
| total timesteps         | 375660        |
| value_loss              | 2.2014861e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00081315776 |
| ent_coef_loss           | 0.9620733     |
| entropy                 | 1.3818972     |
| episodes                | 1768          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 376307        |
| policy_loss             | -0.6061386    |
| qf1_loss                | 2.5837173e-05 |
| qf2_loss                | 2.4525445e-05 |
| time_elapsed            | 2672          |
| total timesteps         | 376407        |
| value_loss              | 6.597016e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00081899593 |
| ent_coef_loss           | 5.7940865     |
| entropy                 | 1.5053613     |
| episodes                | 1772          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 376980        |
| policy_loss             | -0.61044335   |
| qf1_loss                | 2.5827838e-05 |
| qf2_loss                | 2.1217793e-05 |
| time_elapsed            | 2677          |
| total timesteps         | 377080        |
| value_loss              | 1.9754749e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007538342  |
| ent_coef_loss           | -2.2212443    |
| entropy                 | 1.2008721     |
| episodes                | 1776          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 377639        |
| policy_loss             | -0.6069577    |
| qf1_loss                | 2.6548663e-05 |
| qf2_loss                | 1.733987e-05  |
| time_elapsed            | 2682          |
| total timesteps         | 377739        |
| value_loss              | 2.3126984e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007410957  |
| ent_coef_loss           | -0.45212847   |
| entropy                 | 1.439805      |
| episodes                | 1780          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 378384        |
| policy_loss             | -0.6091831    |
| qf1_loss                | 1.6483184e-05 |
| qf2_loss                | 1.8987397e-05 |
| time_elapsed            | 2687          |
| total timesteps         | 378484        |
| value_loss              | 2.387285e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0008723909 |
| ent_coef_loss           | -0.56125605  |
| entropy                 | 1.4149141    |
| episodes                | 1784         |
| fps                     | 140          |
| mean 100 episode reward | 0.8          |
| n_updates               | 379334       |
| policy_loss             | -0.5852322   |
| qf1_loss                | 3.314795e-05 |
| qf2_loss                | 3.201158e-05 |
| time_elapsed            | 2694         |
| total timesteps         | 379434       |
| value_loss              | 6.526675e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008714854  |
| ent_coef_loss           | -2.2620664    |
| entropy                 | 1.4065119     |
| episodes                | 1788          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 380079        |
| policy_loss             | -0.5658368    |
| qf1_loss                | 7.416367e-05  |
| qf2_loss                | 9.550002e-05  |
| time_elapsed            | 2699          |
| total timesteps         | 380179        |
| value_loss              | 8.5066684e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007968426  |
| ent_coef_loss           | -2.05019      |
| entropy                 | 1.2788807     |
| episodes                | 1792          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 381041        |
| policy_loss             | -0.6472955    |
| qf1_loss                | 3.4633566e-05 |
| qf2_loss                | 0.00013682448 |
| time_elapsed            | 2706          |
| total timesteps         | 381141        |
| value_loss              | 3.4443074e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00081327214 |
| ent_coef_loss           | -1.2155677    |
| entropy                 | 1.306534      |
| episodes                | 1796          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 381771        |
| policy_loss             | -0.56332207   |
| qf1_loss                | 2.5056022e-05 |
| qf2_loss                | 4.12949e-05   |
| time_elapsed            | 2711          |
| total timesteps         | 381871        |
| value_loss              | 4.3323816e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085848867 |
| ent_coef_loss           | -1.2996199    |
| entropy                 | 1.3008076     |
| episodes                | 1800          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 382560        |
| policy_loss             | -0.5833155    |
| qf1_loss                | 3.624244e-05  |
| qf2_loss                | 7.179313e-05  |
| time_elapsed            | 2717          |
| total timesteps         | 382660        |
| value_loss              | 6.689751e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008135328  |
| ent_coef_loss           | -0.8986471    |
| entropy                 | 1.378735      |
| episodes                | 1804          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 383329        |
| policy_loss             | -0.5741676    |
| qf1_loss                | 3.7361224e-05 |
| qf2_loss                | 2.8785013e-05 |
| time_elapsed            | 2722          |
| total timesteps         | 383429        |
| value_loss              | 2.7061546e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00078636396 |
| ent_coef_loss           | -0.7398198    |
| entropy                 | 1.4309893     |
| episodes                | 1808          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 383992        |
| policy_loss             | -0.62024534   |
| qf1_loss                | 1.758524e-05  |
| qf2_loss                | 4.7665744e-05 |
| time_elapsed            | 2727          |
| total timesteps         | 384092        |
| value_loss              | 3.0296796e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007962524  |
| ent_coef_loss           | 0.2082696     |
| entropy                 | 1.3979757     |
| episodes                | 1812          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 384936        |
| policy_loss             | -0.56899965   |
| qf1_loss                | 4.613608e-05  |
| qf2_loss                | 6.1240564e-05 |
| time_elapsed            | 2734          |
| total timesteps         | 385036        |
| value_loss              | 4.8408292e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097083265 |
| ent_coef_loss           | 1.6306508     |
| entropy                 | 1.4224586     |
| episodes                | 1816          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 385648        |
| policy_loss             | -0.5636358    |
| qf1_loss                | 5.6721132e-05 |
| qf2_loss                | 3.134259e-05  |
| time_elapsed            | 2739          |
| total timesteps         | 385748        |
| value_loss              | 6.7921006e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011055655  |
| ent_coef_loss           | -0.3393849    |
| entropy                 | 1.4944829     |
| episodes                | 1820          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 386403        |
| policy_loss             | -0.5565021    |
| qf1_loss                | 0.00081937417 |
| qf2_loss                | 0.0010962501  |
| time_elapsed            | 2744          |
| total timesteps         | 386503        |
| value_loss              | 3.4964847e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010770161  |
| ent_coef_loss           | -0.88141173   |
| entropy                 | 1.5785408     |
| episodes                | 1824          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 387101        |
| policy_loss             | -0.57608247   |
| qf1_loss                | 2.342303e-05  |
| qf2_loss                | 2.190868e-05  |
| time_elapsed            | 2749          |
| total timesteps         | 387201        |
| value_loss              | 4.7369504e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009835424  |
| ent_coef_loss           | -2.553941     |
| entropy                 | 1.5190556     |
| episodes                | 1828          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 387766        |
| policy_loss             | -0.63168585   |
| qf1_loss                | 4.640582e-05  |
| qf2_loss                | 9.2723014e-05 |
| time_elapsed            | 2754          |
| total timesteps         | 387866        |
| value_loss              | 2.1292217e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095491024 |
| ent_coef_loss           | -1.0940787    |
| entropy                 | 1.4011062     |
| episodes                | 1832          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 388422        |
| policy_loss             | -0.60756975   |
| qf1_loss                | 4.8015077e-05 |
| qf2_loss                | 2.2717499e-05 |
| time_elapsed            | 2759          |
| total timesteps         | 388522        |
| value_loss              | 3.079078e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00092022493  |
| ent_coef_loss           | 1.4048617      |
| entropy                 | 1.3978271      |
| episodes                | 1836           |
| fps                     | 140            |
| mean 100 episode reward | 0.7            |
| n_updates               | 389451         |
| policy_loss             | -0.6229745     |
| qf1_loss                | 3.6215148e-05  |
| qf2_loss                | 5.558953e-05   |
| time_elapsed            | 2766           |
| total timesteps         | 389551         |
| value_loss              | 0.000118000884 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009346348  |
| ent_coef_loss           | 2.6149907     |
| entropy                 | 1.4161708     |
| episodes                | 1840          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 390148        |
| policy_loss             | -0.5997318    |
| qf1_loss                | 1.7856628e-05 |
| qf2_loss                | 3.0460267e-05 |
| time_elapsed            | 2771          |
| total timesteps         | 390248        |
| value_loss              | 3.4861194e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009866309   |
| ent_coef_loss           | -1.9863609     |
| entropy                 | 1.4151149      |
| episodes                | 1844           |
| fps                     | 140            |
| mean 100 episode reward | 0.7            |
| n_updates               | 391150         |
| policy_loss             | -0.5118482     |
| qf1_loss                | 3.785873e-05   |
| qf2_loss                | 5.174146e-05   |
| time_elapsed            | 2778           |
| total timesteps         | 391250         |
| value_loss              | 0.000120435856 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010231505  |
| ent_coef_loss           | -3.184576     |
| entropy                 | 1.4166805     |
| episodes                | 1848          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 391802        |
| policy_loss             | -0.60253257   |
| qf1_loss                | 4.0335384e-05 |
| qf2_loss                | 1.898365e-05  |
| time_elapsed            | 2783          |
| total timesteps         | 391902        |
| value_loss              | 7.568753e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010354515  |
| ent_coef_loss           | -1.8150473    |
| entropy                 | 1.4910822     |
| episodes                | 1852          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 392455        |
| policy_loss             | -0.54895777   |
| qf1_loss                | 1.5022458e-05 |
| qf2_loss                | 2.1082928e-05 |
| time_elapsed            | 2787          |
| total timesteps         | 392555        |
| value_loss              | 2.6016261e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009955472  |
| ent_coef_loss           | -1.0293323    |
| entropy                 | 1.464921      |
| episodes                | 1856          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 393127        |
| policy_loss             | -0.63464      |
| qf1_loss                | 1.0404952e-05 |
| qf2_loss                | 1.2758876e-05 |
| time_elapsed            | 2792          |
| total timesteps         | 393227        |
| value_loss              | 1.661207e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010747373  |
| ent_coef_loss           | -0.2089209    |
| entropy                 | 1.403871      |
| episodes                | 1860          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 393770        |
| policy_loss             | -0.6030767    |
| qf1_loss                | 4.341079e-05  |
| qf2_loss                | 3.4038287e-05 |
| time_elapsed            | 2797          |
| total timesteps         | 393870        |
| value_loss              | 6.224982e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010750843  |
| ent_coef_loss           | 2.0269089     |
| entropy                 | 1.4408494     |
| episodes                | 1864          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 394434        |
| policy_loss             | -0.56507623   |
| qf1_loss                | 2.6705533e-05 |
| qf2_loss                | 1.7528677e-05 |
| time_elapsed            | 2801          |
| total timesteps         | 394534        |
| value_loss              | 5.1412426e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010407823  |
| ent_coef_loss           | 0.9891077     |
| entropy                 | 1.4527217     |
| episodes                | 1868          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 395108        |
| policy_loss             | -0.6227688    |
| qf1_loss                | 1.6586688e-05 |
| qf2_loss                | 2.3578397e-05 |
| time_elapsed            | 2806          |
| total timesteps         | 395208        |
| value_loss              | 5.750345e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010785327  |
| ent_coef_loss           | -1.0429902    |
| entropy                 | 1.415411      |
| episodes                | 1872          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 395785        |
| policy_loss             | -0.5844507    |
| qf1_loss                | 1.670234e-05  |
| qf2_loss                | 5.9942657e-05 |
| time_elapsed            | 2811          |
| total timesteps         | 395885        |
| value_loss              | 4.6641115e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009544464   |
| ent_coef_loss           | -1.7264419     |
| entropy                 | 1.4328024      |
| episodes                | 1876           |
| fps                     | 140            |
| mean 100 episode reward | 0.8            |
| n_updates               | 396591         |
| policy_loss             | -0.5530251     |
| qf1_loss                | 3.0209174e-05  |
| qf2_loss                | 1.24096505e-05 |
| time_elapsed            | 2817           |
| total timesteps         | 396691         |
| value_loss              | 2.9696015e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010354165  |
| ent_coef_loss           | 0.87006354    |
| entropy                 | 1.5254278     |
| episodes                | 1880          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 397231        |
| policy_loss             | -0.5780625    |
| qf1_loss                | 0.00017953037 |
| qf2_loss                | 0.00019400274 |
| time_elapsed            | 2821          |
| total timesteps         | 397331        |
| value_loss              | 2.4305798e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010635096  |
| ent_coef_loss           | -4.74679      |
| entropy                 | 1.422885      |
| episodes                | 1884          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 398058        |
| policy_loss             | -0.5576867    |
| qf1_loss                | 1.7432303e-05 |
| qf2_loss                | 4.6503632e-05 |
| time_elapsed            | 2827          |
| total timesteps         | 398158        |
| value_loss              | 5.394945e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009689393  |
| ent_coef_loss           | -1.0566746    |
| entropy                 | 1.356077      |
| episodes                | 1888          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 398762        |
| policy_loss             | -0.61756027   |
| qf1_loss                | 5.0861796e-05 |
| qf2_loss                | 2.592189e-05  |
| time_elapsed            | 2832          |
| total timesteps         | 398862        |
| value_loss              | 6.627744e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010220276  |
| ent_coef_loss           | -1.9847472    |
| entropy                 | 1.4739668     |
| episodes                | 1892          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 399529        |
| policy_loss             | -0.5930109    |
| qf1_loss                | 0.001445081   |
| qf2_loss                | 0.0013494988  |
| time_elapsed            | 2838          |
| total timesteps         | 399629        |
| value_loss              | 3.1592732e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010966214  |
| ent_coef_loss           | 1.9637799     |
| entropy                 | 1.4062283     |
| episodes                | 1896          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 400285        |
| policy_loss             | -0.5830349    |
| qf1_loss                | 4.3437263e-05 |
| qf2_loss                | 7.503858e-05  |
| time_elapsed            | 2843          |
| total timesteps         | 400385        |
| value_loss              | 5.8578764e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011580996  |
| ent_coef_loss           | -0.15569997   |
| entropy                 | 1.3108357     |
| episodes                | 1900          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 401035        |
| policy_loss             | -0.5320543    |
| qf1_loss                | 3.5847042e-05 |
| qf2_loss                | 2.0020081e-05 |
| time_elapsed            | 2848          |
| total timesteps         | 401135        |
| value_loss              | 3.5763078e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010031395  |
| ent_coef_loss           | -3.2936482    |
| entropy                 | 1.328313      |
| episodes                | 1904          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 401718        |
| policy_loss             | -0.599712     |
| qf1_loss                | 1.6378865e-05 |
| qf2_loss                | 4.0182516e-05 |
| time_elapsed            | 2853          |
| total timesteps         | 401818        |
| value_loss              | 4.4182674e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011316715  |
| ent_coef_loss           | -0.60333365   |
| entropy                 | 1.4996963     |
| episodes                | 1908          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 402364        |
| policy_loss             | -0.59801906   |
| qf1_loss                | 2.160609e-05  |
| qf2_loss                | 1.7472612e-05 |
| time_elapsed            | 2858          |
| total timesteps         | 402464        |
| value_loss              | 2.0015945e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012129461  |
| ent_coef_loss           | 2.3320527     |
| entropy                 | 1.4193826     |
| episodes                | 1912          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 403029        |
| policy_loss             | -0.53921413   |
| qf1_loss                | 3.998795e-05  |
| qf2_loss                | 4.241096e-05  |
| time_elapsed            | 2862          |
| total timesteps         | 403129        |
| value_loss              | 2.4407262e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0011351574 |
| ent_coef_loss           | -0.83679724  |
| entropy                 | 1.4685029    |
| episodes                | 1916         |
| fps                     | 140          |
| mean 100 episode reward | 0.8          |
| n_updates               | 403709       |
| policy_loss             | -0.51257753  |
| qf1_loss                | 8.091757e-05 |
| qf2_loss                | 0.0025078168 |
| time_elapsed            | 2867         |
| total timesteps         | 403809       |
| value_loss              | 0.0031492165 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010959957  |
| ent_coef_loss           | -0.12905887   |
| entropy                 | 1.3363001     |
| episodes                | 1920          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 404390        |
| policy_loss             | -0.57077366   |
| qf1_loss                | 7.215573e-05  |
| qf2_loss                | 9.503553e-05  |
| time_elapsed            | 2872          |
| total timesteps         | 404490        |
| value_loss              | 0.00012885433 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096852536 |
| ent_coef_loss           | -2.0326471    |
| entropy                 | 1.3742945     |
| episodes                | 1924          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 405072        |
| policy_loss             | -0.5817671    |
| qf1_loss                | 3.417534e-05  |
| qf2_loss                | 4.481768e-05  |
| time_elapsed            | 2877          |
| total timesteps         | 405172        |
| value_loss              | 4.108067e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096109364 |
| ent_coef_loss           | 2.9298923     |
| entropy                 | 1.3208975     |
| episodes                | 1928          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 405747        |
| policy_loss             | -0.5540782    |
| qf1_loss                | 7.259009e-05  |
| qf2_loss                | 3.6253474e-05 |
| time_elapsed            | 2882          |
| total timesteps         | 405847        |
| value_loss              | 5.2870593e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095322425 |
| ent_coef_loss           | -0.34017274   |
| entropy                 | 1.3666601     |
| episodes                | 1932          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 406391        |
| policy_loss             | -0.6080819    |
| qf1_loss                | 5.734652e-05  |
| qf2_loss                | 6.5536646e-05 |
| time_elapsed            | 2886          |
| total timesteps         | 406491        |
| value_loss              | 4.412549e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009354244  |
| ent_coef_loss           | -0.084295034  |
| entropy                 | 1.350111      |
| episodes                | 1936          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 407109        |
| policy_loss             | -0.54554796   |
| qf1_loss                | 2.1807395e-05 |
| qf2_loss                | 3.399156e-05  |
| time_elapsed            | 2892          |
| total timesteps         | 407209        |
| value_loss              | 0.00020854964 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087036745 |
| ent_coef_loss           | -1.2893398    |
| entropy                 | 1.2245665     |
| episodes                | 1940          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 407829        |
| policy_loss             | -0.5585127    |
| qf1_loss                | 4.686508e-05  |
| qf2_loss                | 4.2073138e-05 |
| time_elapsed            | 2897          |
| total timesteps         | 407929        |
| value_loss              | 9.913191e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008023582  |
| ent_coef_loss           | -1.6144139    |
| entropy                 | 1.2497305     |
| episodes                | 1944          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 408543        |
| policy_loss             | -0.5218062    |
| qf1_loss                | 0.00043383508 |
| qf2_loss                | 0.00069213606 |
| time_elapsed            | 2902          |
| total timesteps         | 408643        |
| value_loss              | 0.0001281705  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00088474975 |
| ent_coef_loss           | 1.1132884     |
| entropy                 | 1.3477168     |
| episodes                | 1948          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 409258        |
| policy_loss             | -0.62746656   |
| qf1_loss                | 2.7522947e-05 |
| qf2_loss                | 2.452273e-05  |
| time_elapsed            | 2907          |
| total timesteps         | 409358        |
| value_loss              | 3.5477722e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00083021703 |
| ent_coef_loss           | 1.234216      |
| entropy                 | 1.38045       |
| episodes                | 1952          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 409998        |
| policy_loss             | -0.5704872    |
| qf1_loss                | 2.274453e-05  |
| qf2_loss                | 3.8080434e-05 |
| time_elapsed            | 2912          |
| total timesteps         | 410098        |
| value_loss              | 4.2317362e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00098015    |
| ent_coef_loss           | 0.44849193    |
| entropy                 | 1.2898747     |
| episodes                | 1956          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 410699        |
| policy_loss             | -0.56709564   |
| qf1_loss                | 1.892157e-05  |
| qf2_loss                | 5.7087156e-05 |
| time_elapsed            | 2917          |
| total timesteps         | 410799        |
| value_loss              | 6.116592e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009818892  |
| ent_coef_loss           | 0.19516087    |
| entropy                 | 1.3998446     |
| episodes                | 1960          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 411364        |
| policy_loss             | -0.52220464   |
| qf1_loss                | 2.8507546e-05 |
| qf2_loss                | 8.787839e-05  |
| time_elapsed            | 2922          |
| total timesteps         | 411464        |
| value_loss              | 6.881389e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0008905276   |
| ent_coef_loss           | 2.3865201      |
| entropy                 | 1.3544612      |
| episodes                | 1964           |
| fps                     | 140            |
| mean 100 episode reward | 0.9            |
| n_updates               | 412214         |
| policy_loss             | -0.60525477    |
| qf1_loss                | 9.702422e-05   |
| qf2_loss                | 6.96622e-05    |
| time_elapsed            | 2928           |
| total timesteps         | 412314         |
| value_loss              | 0.000103692844 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091640704 |
| ent_coef_loss           | 0.83492523    |
| entropy                 | 1.4579821     |
| episodes                | 1968          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 413005        |
| policy_loss             | -0.53933823   |
| qf1_loss                | 3.933816e-05  |
| qf2_loss                | 5.61809e-05   |
| time_elapsed            | 2934          |
| total timesteps         | 413105        |
| value_loss              | 2.3649773e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009830196  |
| ent_coef_loss           | 1.3359053     |
| entropy                 | 1.4640845     |
| episodes                | 1972          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 413656        |
| policy_loss             | -0.5383855    |
| qf1_loss                | 2.470866e-05  |
| qf2_loss                | 1.6781905e-05 |
| time_elapsed            | 2938          |
| total timesteps         | 413756        |
| value_loss              | 4.6561836e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011065042  |
| ent_coef_loss           | -0.8669659    |
| entropy                 | 1.5303905     |
| episodes                | 1976          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 414331        |
| policy_loss             | -0.560705     |
| qf1_loss                | 5.594674e-05  |
| qf2_loss                | 0.000105456   |
| time_elapsed            | 2943          |
| total timesteps         | 414431        |
| value_loss              | 0.00013435424 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010665765  |
| ent_coef_loss           | 1.2622638     |
| entropy                 | 1.4898272     |
| episodes                | 1980          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 414985        |
| policy_loss             | -0.5520021    |
| qf1_loss                | 4.5499575e-05 |
| qf2_loss                | 9.872383e-05  |
| time_elapsed            | 2948          |
| total timesteps         | 415085        |
| value_loss              | 8.549706e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010379578  |
| ent_coef_loss           | 0.283231      |
| entropy                 | 1.4716246     |
| episodes                | 1984          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 415742        |
| policy_loss             | -0.5501032    |
| qf1_loss                | 2.4773315e-05 |
| qf2_loss                | 2.4238721e-05 |
| time_elapsed            | 2953          |
| total timesteps         | 415842        |
| value_loss              | 2.5106565e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010746368  |
| ent_coef_loss           | 2.1319609     |
| entropy                 | 1.4905679     |
| episodes                | 1988          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 416685        |
| policy_loss             | -0.5305354    |
| qf1_loss                | 3.2866083e-05 |
| qf2_loss                | 4.2367545e-05 |
| time_elapsed            | 2960          |
| total timesteps         | 416785        |
| value_loss              | 0.00014122642 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011876572  |
| ent_coef_loss           | 0.12503952    |
| entropy                 | 1.5503395     |
| episodes                | 1992          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 417392        |
| policy_loss             | -0.51561356   |
| qf1_loss                | 0.00014182017 |
| qf2_loss                | 5.1357325e-05 |
| time_elapsed            | 2965          |
| total timesteps         | 417492        |
| value_loss              | 5.117149e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010970519 |
| ent_coef_loss           | -1.624489    |
| entropy                 | 1.4440805    |
| episodes                | 1996         |
| fps                     | 140          |
| mean 100 episode reward | 0.9          |
| n_updates               | 418317       |
| policy_loss             | -0.5399899   |
| qf1_loss                | 0.0001234669 |
| qf2_loss                | 8.670696e-05 |
| time_elapsed            | 2971         |
| total timesteps         | 418417       |
| value_loss              | 9.198341e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009469046  |
| ent_coef_loss           | 0.5396452     |
| entropy                 | 1.3079606     |
| episodes                | 2000          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 419041        |
| policy_loss             | -0.52950084   |
| qf1_loss                | 6.756704e-05  |
| qf2_loss                | 6.5505e-05    |
| time_elapsed            | 2977          |
| total timesteps         | 419141        |
| value_loss              | 0.00014173218 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0009611793 |
| ent_coef_loss           | -0.80217266  |
| entropy                 | 1.3119702    |
| episodes                | 2004         |
| fps                     | 140          |
| mean 100 episode reward | 0.9          |
| n_updates               | 419746       |
| policy_loss             | -0.5274992   |
| qf1_loss                | 4.964153e-05 |
| qf2_loss                | 5.374624e-05 |
| time_elapsed            | 2982         |
| total timesteps         | 419846       |
| value_loss              | 0.0001258403 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089792005 |
| ent_coef_loss           | -1.0422941    |
| entropy                 | 1.4193082     |
| episodes                | 2008          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 420468        |
| policy_loss             | -0.5338056    |
| qf1_loss                | 8.9625384e-05 |
| qf2_loss                | 6.7692716e-05 |
| time_elapsed            | 2987          |
| total timesteps         | 420568        |
| value_loss              | 6.231172e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008240383  |
| ent_coef_loss           | -0.11296451   |
| entropy                 | 1.3955278     |
| episodes                | 2012          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 421468        |
| policy_loss             | -0.47689378   |
| qf1_loss                | 4.961838e-05  |
| qf2_loss                | 3.468524e-05  |
| time_elapsed            | 2994          |
| total timesteps         | 421568        |
| value_loss              | 9.9734534e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000820776   |
| ent_coef_loss           | -0.032321572  |
| entropy                 | 1.290033      |
| episodes                | 2016          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 422142        |
| policy_loss             | -0.54788435   |
| qf1_loss                | 0.000139945   |
| qf2_loss                | 7.897731e-05  |
| time_elapsed            | 2999          |
| total timesteps         | 422242        |
| value_loss              | 0.00013614244 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085305085 |
| ent_coef_loss           | 1.6897343     |
| entropy                 | 1.4372756     |
| episodes                | 2020          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 422832        |
| policy_loss             | -0.5475086    |
| qf1_loss                | 1.4522628e-05 |
| qf2_loss                | 8.228112e-06  |
| time_elapsed            | 3004          |
| total timesteps         | 422932        |
| value_loss              | 4.4855144e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086275657 |
| ent_coef_loss           | -2.2012749    |
| entropy                 | 1.3702582     |
| episodes                | 2024          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 423782        |
| policy_loss             | -0.5293894    |
| qf1_loss                | 8.287412e-05  |
| qf2_loss                | 3.7357204e-05 |
| time_elapsed            | 3010          |
| total timesteps         | 423882        |
| value_loss              | 6.153881e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092231994 |
| ent_coef_loss           | -4.663921     |
| entropy                 | 1.5247164     |
| episodes                | 2028          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 424469        |
| policy_loss             | -0.5438702    |
| qf1_loss                | 2.7264588e-05 |
| qf2_loss                | 2.0832125e-05 |
| time_elapsed            | 3015          |
| total timesteps         | 424569        |
| value_loss              | 6.429207e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000932889   |
| ent_coef_loss           | -1.7626494    |
| entropy                 | 1.5193012     |
| episodes                | 2032          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 425194        |
| policy_loss             | -0.5426463    |
| qf1_loss                | 1.742522e-05  |
| qf2_loss                | 2.7735805e-05 |
| time_elapsed            | 3020          |
| total timesteps         | 425294        |
| value_loss              | 2.7263159e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00082059397 |
| ent_coef_loss           | -1.0022204    |
| entropy                 | 1.3125952     |
| episodes                | 2036          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 425950        |
| policy_loss             | -0.51310563   |
| qf1_loss                | 4.2194373e-05 |
| qf2_loss                | 3.3330216e-05 |
| time_elapsed            | 3026          |
| total timesteps         | 426050        |
| value_loss              | 5.8161e-05    |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00078862376 |
| ent_coef_loss           | 2.4127724     |
| entropy                 | 1.2375281     |
| episodes                | 2040          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 426974        |
| policy_loss             | -0.5620136    |
| qf1_loss                | 5.063983e-05  |
| qf2_loss                | 6.826425e-05  |
| time_elapsed            | 3033          |
| total timesteps         | 427074        |
| value_loss              | 3.5609555e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00079938065  |
| ent_coef_loss           | -0.87982726    |
| entropy                 | 1.2781482      |
| episodes                | 2044           |
| fps                     | 140            |
| mean 100 episode reward | 0.8            |
| n_updates               | 427858         |
| policy_loss             | -0.47689503    |
| qf1_loss                | 7.087785e-05   |
| qf2_loss                | 0.000118749806 |
| time_elapsed            | 3039           |
| total timesteps         | 427958         |
| value_loss              | 0.00011891393  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00081362436 |
| ent_coef_loss           | -2.8710244    |
| entropy                 | 1.357897      |
| episodes                | 2048          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 428567        |
| policy_loss             | -0.5729156    |
| qf1_loss                | 3.183508e-05  |
| qf2_loss                | 3.092005e-05  |
| time_elapsed            | 3044          |
| total timesteps         | 428667        |
| value_loss              | 6.056424e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007866936  |
| ent_coef_loss           | -0.04998213   |
| entropy                 | 1.1798778     |
| episodes                | 2052          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 429514        |
| policy_loss             | -0.5398245    |
| qf1_loss                | 3.6426012e-05 |
| qf2_loss                | 7.655487e-05  |
| time_elapsed            | 3051          |
| total timesteps         | 429614        |
| value_loss              | 5.489999e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008802505  |
| ent_coef_loss           | -2.0710225    |
| entropy                 | 1.2421532     |
| episodes                | 2056          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 430180        |
| policy_loss             | -0.55529535   |
| qf1_loss                | 3.6404872e-05 |
| qf2_loss                | 2.77438e-05   |
| time_elapsed            | 3056          |
| total timesteps         | 430280        |
| value_loss              | 6.212061e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086771365 |
| ent_coef_loss           | 1.3916388     |
| entropy                 | 1.288943      |
| episodes                | 2060          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 431258        |
| policy_loss             | -0.55677307   |
| qf1_loss                | 2.5898302e-05 |
| qf2_loss                | 3.1906115e-05 |
| time_elapsed            | 3064          |
| total timesteps         | 431358        |
| value_loss              | 3.9171333e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010027627 |
| ent_coef_loss           | -0.32389003  |
| entropy                 | 1.2637787    |
| episodes                | 2064         |
| fps                     | 140          |
| mean 100 episode reward | 0.6          |
| n_updates               | 432031       |
| policy_loss             | -0.5045644   |
| qf1_loss                | 8.274463e-05 |
| qf2_loss                | 7.220637e-05 |
| time_elapsed            | 3069         |
| total timesteps         | 432131       |
| value_loss              | 0.0001022257 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001030099   |
| ent_coef_loss           | 2.3134513     |
| entropy                 | 1.4955707     |
| episodes                | 2068          |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 433018        |
| policy_loss             | -0.5700834    |
| qf1_loss                | 5.5477205e-05 |
| qf2_loss                | 6.167962e-05  |
| time_elapsed            | 3076          |
| total timesteps         | 433118        |
| value_loss              | 6.5571054e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0011319143   |
| ent_coef_loss           | 1.2930856      |
| entropy                 | 1.3940991      |
| episodes                | 2072           |
| fps                     | 140            |
| mean 100 episode reward | 0.6            |
| n_updates               | 433764         |
| policy_loss             | -0.5360341     |
| qf1_loss                | 6.3559026e-05  |
| qf2_loss                | 0.000113691465 |
| time_elapsed            | 3081           |
| total timesteps         | 433864         |
| value_loss              | 0.00010586201  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011051123  |
| ent_coef_loss           | 2.8534882     |
| entropy                 | 1.3185067     |
| episodes                | 2076          |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 434490        |
| policy_loss             | -0.50707173   |
| qf1_loss                | 3.8005837e-05 |
| qf2_loss                | 2.4174205e-05 |
| time_elapsed            | 3087          |
| total timesteps         | 434590        |
| value_loss              | 0.0036326     |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011405115  |
| ent_coef_loss           | -0.1108613    |
| entropy                 | 1.3858833     |
| episodes                | 2080          |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 435243        |
| policy_loss             | -0.48708087   |
| qf1_loss                | 4.9655097e-05 |
| qf2_loss                | 5.0895967e-05 |
| time_elapsed            | 3092          |
| total timesteps         | 435343        |
| value_loss              | 6.814356e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012040344  |
| ent_coef_loss           | -1.5092497    |
| entropy                 | 1.3373225     |
| episodes                | 2084          |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 435936        |
| policy_loss             | -0.5222719    |
| qf1_loss                | 3.3024335e-05 |
| qf2_loss                | 2.6625865e-05 |
| time_elapsed            | 3097          |
| total timesteps         | 436036        |
| value_loss              | 5.1714982e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011363402  |
| ent_coef_loss           | -0.39465934   |
| entropy                 | 1.393528      |
| episodes                | 2088          |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 436634        |
| policy_loss             | -0.55814064   |
| qf1_loss                | 5.364654e-05  |
| qf2_loss                | 3.4702032e-05 |
| time_elapsed            | 3102          |
| total timesteps         | 436734        |
| value_loss              | 4.6497807e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0010867584   |
| ent_coef_loss           | 0.35250902     |
| entropy                 | 1.339839       |
| episodes                | 2092           |
| fps                     | 140            |
| mean 100 episode reward | 0.7            |
| n_updates               | 437308         |
| policy_loss             | -0.55478144    |
| qf1_loss                | 0.000117129435 |
| qf2_loss                | 3.935294e-05   |
| time_elapsed            | 3107           |
| total timesteps         | 437408         |
| value_loss              | 9.859644e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012332228  |
| ent_coef_loss           | 0.33927822    |
| entropy                 | 1.5332766     |
| episodes                | 2096          |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 438354        |
| policy_loss             | -0.53985965   |
| qf1_loss                | 6.38347e-05   |
| qf2_loss                | 5.0399263e-05 |
| time_elapsed            | 3114          |
| total timesteps         | 438454        |
| value_loss              | 5.805833e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012331964  |
| ent_coef_loss           | 1.0304065     |
| entropy                 | 1.440345      |
| episodes                | 2100          |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 439061        |
| policy_loss             | -0.5480337    |
| qf1_loss                | 8.926223e-05  |
| qf2_loss                | 4.869008e-05  |
| time_elapsed            | 3119          |
| total timesteps         | 439161        |
| value_loss              | 0.00018795946 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00108153    |
| ent_coef_loss           | -0.9918357    |
| entropy                 | 1.4395549     |
| episodes                | 2104          |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 439794        |
| policy_loss             | -0.50680923   |
| qf1_loss                | 3.9471335e-05 |
| qf2_loss                | 3.4579272e-05 |
| time_elapsed            | 3124          |
| total timesteps         | 439894        |
| value_loss              | 7.263939e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011313629  |
| ent_coef_loss           | 0.9970728     |
| entropy                 | 1.4361169     |
| episodes                | 2108          |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 440458        |
| policy_loss             | -0.49668226   |
| qf1_loss                | 8.420249e-05  |
| qf2_loss                | 8.801879e-05  |
| time_elapsed            | 3129          |
| total timesteps         | 440558        |
| value_loss              | 0.00017672524 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011212382  |
| ent_coef_loss           | -0.9969245    |
| entropy                 | 1.4708376     |
| episodes                | 2112          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 441136        |
| policy_loss             | -0.49548614   |
| qf1_loss                | 3.9566046e-05 |
| qf2_loss                | 4.091014e-05  |
| time_elapsed            | 3134          |
| total timesteps         | 441236        |
| value_loss              | 6.7380846e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010504475  |
| ent_coef_loss           | 1.5027038     |
| entropy                 | 1.3826087     |
| episodes                | 2116          |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 441809        |
| policy_loss             | -0.5367599    |
| qf1_loss                | 3.1239968e-05 |
| qf2_loss                | 5.84761e-05   |
| time_elapsed            | 3138          |
| total timesteps         | 441909        |
| value_loss              | 8.2340885e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011371614  |
| ent_coef_loss           | -1.0208021    |
| entropy                 | 1.3249143     |
| episodes                | 2120          |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 442518        |
| policy_loss             | -0.55245894   |
| qf1_loss                | 2.3555804e-05 |
| qf2_loss                | 2.5559984e-05 |
| time_elapsed            | 3144          |
| total timesteps         | 442618        |
| value_loss              | 3.613661e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010374981  |
| ent_coef_loss           | 0.31567836    |
| entropy                 | 1.3200617     |
| episodes                | 2124          |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 443151        |
| policy_loss             | -0.46079296   |
| qf1_loss                | 0.0001064421  |
| qf2_loss                | 0.00019696186 |
| time_elapsed            | 3148          |
| total timesteps         | 443251        |
| value_loss              | 0.00018575725 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010849328  |
| ent_coef_loss           | 0.6291127     |
| entropy                 | 1.37813       |
| episodes                | 2128          |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 443862        |
| policy_loss             | -0.5130242    |
| qf1_loss                | 5.4943266e-05 |
| qf2_loss                | 3.2317963e-05 |
| time_elapsed            | 3153          |
| total timesteps         | 443962        |
| value_loss              | 0.00010117519 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011044948  |
| ent_coef_loss           | -0.6687299    |
| entropy                 | 1.4586658     |
| episodes                | 2132          |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 444552        |
| policy_loss             | -0.54880476   |
| qf1_loss                | 5.1017392e-05 |
| qf2_loss                | 3.6903446e-05 |
| time_elapsed            | 3158          |
| total timesteps         | 444652        |
| value_loss              | 0.0001798552  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010375427  |
| ent_coef_loss           | -0.80764854   |
| entropy                 | 1.3508692     |
| episodes                | 2136          |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 445576        |
| policy_loss             | -0.47640046   |
| qf1_loss                | 7.9235855e-05 |
| qf2_loss                | 8.082835e-05  |
| time_elapsed            | 3165          |
| total timesteps         | 445676        |
| value_loss              | 0.00010863638 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010407977  |
| ent_coef_loss           | -1.9193767    |
| entropy                 | 1.2994335     |
| episodes                | 2140          |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 446199        |
| policy_loss             | -0.5080776    |
| qf1_loss                | 4.5449087e-05 |
| qf2_loss                | 7.912272e-05  |
| time_elapsed            | 3170          |
| total timesteps         | 446299        |
| value_loss              | 7.940558e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010668053  |
| ent_coef_loss           | -1.481572     |
| entropy                 | 1.2659085     |
| episodes                | 2144          |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 446868        |
| policy_loss             | -0.5879358    |
| qf1_loss                | 4.7704692e-05 |
| qf2_loss                | 5.1902673e-05 |
| time_elapsed            | 3175          |
| total timesteps         | 446968        |
| value_loss              | 7.212891e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011280973  |
| ent_coef_loss           | 1.7610126     |
| entropy                 | 1.242001      |
| episodes                | 2148          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 447551        |
| policy_loss             | -0.42538807   |
| qf1_loss                | 8.7095796e-05 |
| qf2_loss                | 5.8226804e-05 |
| time_elapsed            | 3180          |
| total timesteps         | 447651        |
| value_loss              | 6.785684e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010143933  |
| ent_coef_loss           | -3.5125513    |
| entropy                 | 1.13076       |
| episodes                | 2152          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 448256        |
| policy_loss             | -0.51607436   |
| qf1_loss                | 4.8968497e-05 |
| qf2_loss                | 5.586708e-05  |
| time_elapsed            | 3185          |
| total timesteps         | 448356        |
| value_loss              | 6.944683e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096521096 |
| ent_coef_loss           | -1.3173356    |
| entropy                 | 1.2280619     |
| episodes                | 2156          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 448999        |
| policy_loss             | -0.52146673   |
| qf1_loss                | 4.9141538e-05 |
| qf2_loss                | 7.7383665e-05 |
| time_elapsed            | 3190          |
| total timesteps         | 449099        |
| value_loss              | 6.1302155e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009681029  |
| ent_coef_loss           | 0.79254353    |
| entropy                 | 1.2763758     |
| episodes                | 2160          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 449722        |
| policy_loss             | -0.51609564   |
| qf1_loss                | 2.6600592e-05 |
| qf2_loss                | 3.280151e-05  |
| time_elapsed            | 3195          |
| total timesteps         | 449822        |
| value_loss              | 3.181598e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097530184 |
| ent_coef_loss           | -0.09729338   |
| entropy                 | 1.3349602     |
| episodes                | 2164          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 450398        |
| policy_loss             | -0.5188488    |
| qf1_loss                | 5.4018576e-05 |
| qf2_loss                | 4.636162e-05  |
| time_elapsed            | 3200          |
| total timesteps         | 450498        |
| value_loss              | 9.10948e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009277546  |
| ent_coef_loss           | 0.07564242    |
| entropy                 | 1.3772988     |
| episodes                | 2168          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 451124        |
| policy_loss             | -0.51971227   |
| qf1_loss                | 3.9904997e-05 |
| qf2_loss                | 7.916457e-05  |
| time_elapsed            | 3205          |
| total timesteps         | 451224        |
| value_loss              | 6.171569e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009678762  |
| ent_coef_loss           | 2.762319      |
| entropy                 | 1.3770552     |
| episodes                | 2172          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 451910        |
| policy_loss             | -0.53150654   |
| qf1_loss                | 3.9353396e-05 |
| qf2_loss                | 5.3258827e-05 |
| time_elapsed            | 3211          |
| total timesteps         | 452010        |
| value_loss              | 4.724349e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092355086 |
| ent_coef_loss           | -1.1702507    |
| entropy                 | 1.2929224     |
| episodes                | 2176          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 452665        |
| policy_loss             | -0.56040555   |
| qf1_loss                | 3.1134998e-05 |
| qf2_loss                | 2.2117729e-05 |
| time_elapsed            | 3216          |
| total timesteps         | 452765        |
| value_loss              | 7.7178236e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009963607  |
| ent_coef_loss           | -2.1669025    |
| entropy                 | 1.168112      |
| episodes                | 2180          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 453413        |
| policy_loss             | -0.49659812   |
| qf1_loss                | 4.598892e-05  |
| qf2_loss                | 4.9206217e-05 |
| time_elapsed            | 3221          |
| total timesteps         | 453513        |
| value_loss              | 7.485863e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00107036    |
| ent_coef_loss           | -5.351124     |
| entropy                 | 1.198482      |
| episodes                | 2184          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 454058        |
| policy_loss             | -0.49351844   |
| qf1_loss                | 1.4556947e-05 |
| qf2_loss                | 4.63553e-05   |
| time_elapsed            | 3226          |
| total timesteps         | 454158        |
| value_loss              | 0.0012178901  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010982882  |
| ent_coef_loss           | -2.762766     |
| entropy                 | 1.3494284     |
| episodes                | 2188          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 454843        |
| policy_loss             | -0.5238711    |
| qf1_loss                | 2.7951512e-05 |
| qf2_loss                | 2.3975648e-05 |
| time_elapsed            | 3231          |
| total timesteps         | 454943        |
| value_loss              | 5.296256e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011354038  |
| ent_coef_loss           | -0.24587327   |
| entropy                 | 1.1380897     |
| episodes                | 2192          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 455527        |
| policy_loss             | -0.5512953    |
| qf1_loss                | 3.1170603e-05 |
| qf2_loss                | 3.129014e-05  |
| time_elapsed            | 3236          |
| total timesteps         | 455627        |
| value_loss              | 4.77095e-05   |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0011386047   |
| ent_coef_loss           | 2.0073874      |
| entropy                 | 1.3429621      |
| episodes                | 2196           |
| fps                     | 140            |
| mean 100 episode reward | 0.8            |
| n_updates               | 456278         |
| policy_loss             | -0.472841      |
| qf1_loss                | 0.00034382995  |
| qf2_loss                | 0.00012499592  |
| time_elapsed            | 3242           |
| total timesteps         | 456378         |
| value_loss              | 0.000118845695 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00119335    |
| ent_coef_loss           | -1.2295293    |
| entropy                 | 1.2079437     |
| episodes                | 2200          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 456967        |
| policy_loss             | -0.48023915   |
| qf1_loss                | 6.7166846e-05 |
| qf2_loss                | 5.5509452e-05 |
| time_elapsed            | 3247          |
| total timesteps         | 457067        |
| value_loss              | 0.0002233587  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011518351  |
| ent_coef_loss           | -0.31772447   |
| entropy                 | 1.3126695     |
| episodes                | 2204          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 457864        |
| policy_loss             | -0.55555385   |
| qf1_loss                | 3.2092823e-05 |
| qf2_loss                | 4.1079973e-05 |
| time_elapsed            | 3253          |
| total timesteps         | 457964        |
| value_loss              | 0.00011156021 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001126047   |
| ent_coef_loss           | 2.972265      |
| entropy                 | 1.1002405     |
| episodes                | 2208          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 458584        |
| policy_loss             | -0.5115546    |
| qf1_loss                | 3.458825e-05  |
| qf2_loss                | 4.0075924e-05 |
| time_elapsed            | 3258          |
| total timesteps         | 458684        |
| value_loss              | 4.4746794e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011573168  |
| ent_coef_loss           | -1.5595822    |
| entropy                 | 1.394552      |
| episodes                | 2212          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 459474        |
| policy_loss             | -0.4976291    |
| qf1_loss                | 4.4879853e-05 |
| qf2_loss                | 3.4874436e-05 |
| time_elapsed            | 3264          |
| total timesteps         | 459574        |
| value_loss              | 4.5425288e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011264412  |
| ent_coef_loss           | 1.3478918     |
| entropy                 | 1.2907538     |
| episodes                | 2216          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 460227        |
| policy_loss             | -0.51186347   |
| qf1_loss                | 2.415874e-05  |
| qf2_loss                | 1.7073882e-05 |
| time_elapsed            | 3270          |
| total timesteps         | 460327        |
| value_loss              | 6.32404e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011247017  |
| ent_coef_loss           | -0.67772675   |
| entropy                 | 1.4088621     |
| episodes                | 2220          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 460939        |
| policy_loss             | -0.5176211    |
| qf1_loss                | 4.3889457e-05 |
| qf2_loss                | 3.981629e-05  |
| time_elapsed            | 3275          |
| total timesteps         | 461039        |
| value_loss              | 4.6309517e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011023376  |
| ent_coef_loss           | -2.9378545    |
| entropy                 | 1.2868953     |
| episodes                | 2224          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 461611        |
| policy_loss             | -0.5605105    |
| qf1_loss                | 4.3050313e-05 |
| qf2_loss                | 4.8864316e-05 |
| time_elapsed            | 3280          |
| total timesteps         | 461711        |
| value_loss              | 7.087379e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010447314  |
| ent_coef_loss           | 5.197466      |
| entropy                 | 1.3901935     |
| episodes                | 2228          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 462481        |
| policy_loss             | -0.49810663   |
| qf1_loss                | 5.2858588e-05 |
| qf2_loss                | 3.7890517e-05 |
| time_elapsed            | 3286          |
| total timesteps         | 462581        |
| value_loss              | 4.1190768e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010602892  |
| ent_coef_loss           | 1.9500033     |
| entropy                 | 1.4478676     |
| episodes                | 2232          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 463251        |
| policy_loss             | -0.53043365   |
| qf1_loss                | 7.0890914e-05 |
| qf2_loss                | 5.5268374e-05 |
| time_elapsed            | 3291          |
| total timesteps         | 463351        |
| value_loss              | 4.5370467e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010587528  |
| ent_coef_loss           | 0.027163744   |
| entropy                 | 1.3697153     |
| episodes                | 2236          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 463925        |
| policy_loss             | -0.5161774    |
| qf1_loss                | 5.7070614e-05 |
| qf2_loss                | 4.120751e-05  |
| time_elapsed            | 3296          |
| total timesteps         | 464025        |
| value_loss              | 6.253855e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009494075  |
| ent_coef_loss           | 1.0790749     |
| entropy                 | 1.3065598     |
| episodes                | 2240          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 464761        |
| policy_loss             | -0.50301516   |
| qf1_loss                | 2.5228659e-05 |
| qf2_loss                | 5.535828e-05  |
| time_elapsed            | 3302          |
| total timesteps         | 464861        |
| value_loss              | 8.297109e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009709766  |
| ent_coef_loss           | 0.6736567     |
| entropy                 | 1.308353      |
| episodes                | 2244          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 465405        |
| policy_loss             | -0.5251115    |
| qf1_loss                | 5.746785e-05  |
| qf2_loss                | 6.944793e-05  |
| time_elapsed            | 3307          |
| total timesteps         | 465505        |
| value_loss              | 5.5079807e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009822522  |
| ent_coef_loss           | 5.0403094     |
| entropy                 | 1.2354484     |
| episodes                | 2248          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 466219        |
| policy_loss             | -0.49120805   |
| qf1_loss                | 0.0032685539  |
| qf2_loss                | 0.0021991471  |
| time_elapsed            | 3312          |
| total timesteps         | 466319        |
| value_loss              | 0.00010841769 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001129018   |
| ent_coef_loss           | -1.905139     |
| entropy                 | 1.3057566     |
| episodes                | 2252          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 466847        |
| policy_loss             | -0.48119327   |
| qf1_loss                | 5.183068e-05  |
| qf2_loss                | 7.589256e-05  |
| time_elapsed            | 3317          |
| total timesteps         | 466947        |
| value_loss              | 5.3439268e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0010763681   |
| ent_coef_loss           | 2.5583503      |
| entropy                 | 1.5215662      |
| episodes                | 2256           |
| fps                     | 140            |
| mean 100 episode reward | 0.8            |
| n_updates               | 467668         |
| policy_loss             | -0.49839503    |
| qf1_loss                | 0.00010047441  |
| qf2_loss                | 5.8263053e-05  |
| time_elapsed            | 3323           |
| total timesteps         | 467768         |
| value_loss              | 0.000113183254 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012315433  |
| ent_coef_loss           | 1.9644492     |
| entropy                 | 1.4036525     |
| episodes                | 2260          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 468760        |
| policy_loss             | -0.49250576   |
| qf1_loss                | 0.00010694715 |
| qf2_loss                | 0.00011027054 |
| time_elapsed            | 3331          |
| total timesteps         | 468860        |
| value_loss              | 0.00015298309 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012222442  |
| ent_coef_loss           | 1.1699107     |
| entropy                 | 1.434033      |
| episodes                | 2264          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 469456        |
| policy_loss             | -0.54712236   |
| qf1_loss                | 3.1170428e-05 |
| qf2_loss                | 4.2516047e-05 |
| time_elapsed            | 3336          |
| total timesteps         | 469556        |
| value_loss              | 7.7082506e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011515956  |
| ent_coef_loss           | 0.50815725    |
| entropy                 | 1.3568923     |
| episodes                | 2268          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 470205        |
| policy_loss             | -0.5194019    |
| qf1_loss                | 9.0578236e-05 |
| qf2_loss                | 4.833314e-05  |
| time_elapsed            | 3341          |
| total timesteps         | 470305        |
| value_loss              | 9.326961e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012045839  |
| ent_coef_loss           | -0.79909337   |
| entropy                 | 1.4343463     |
| episodes                | 2272          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 470949        |
| policy_loss             | -0.55822796   |
| qf1_loss                | 3.705991e-05  |
| qf2_loss                | 3.0196103e-05 |
| time_elapsed            | 3346          |
| total timesteps         | 471049        |
| value_loss              | 3.144807e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011614759  |
| ent_coef_loss           | 0.8820767     |
| entropy                 | 1.405807      |
| episodes                | 2276          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 471647        |
| policy_loss             | -0.45754611   |
| qf1_loss                | 5.5709337e-05 |
| qf2_loss                | 6.2041465e-05 |
| time_elapsed            | 3351          |
| total timesteps         | 471747        |
| value_loss              | 7.2717405e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011551683  |
| ent_coef_loss           | -0.35737997   |
| entropy                 | 1.3641886     |
| episodes                | 2280          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 472291        |
| policy_loss             | -0.47611803   |
| qf1_loss                | 0.00028171326 |
| qf2_loss                | 0.0001300846  |
| time_elapsed            | 3356          |
| total timesteps         | 472391        |
| value_loss              | 0.00035677443 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010569067  |
| ent_coef_loss           | -3.161859     |
| entropy                 | 1.3252422     |
| episodes                | 2284          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 473015        |
| policy_loss             | -0.5354507    |
| qf1_loss                | 3.3513992e-05 |
| qf2_loss                | 3.2504253e-05 |
| time_elapsed            | 3361          |
| total timesteps         | 473115        |
| value_loss              | 4.784957e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011045996  |
| ent_coef_loss           | -1.5307549    |
| entropy                 | 1.351549      |
| episodes                | 2288          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 473694        |
| policy_loss             | -0.5541091    |
| qf1_loss                | 2.4402534e-05 |
| qf2_loss                | 2.2986585e-05 |
| time_elapsed            | 3366          |
| total timesteps         | 473794        |
| value_loss              | 3.228325e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010424254  |
| ent_coef_loss           | -2.6945274    |
| entropy                 | 1.3739972     |
| episodes                | 2292          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 474366        |
| policy_loss             | -0.58539593   |
| qf1_loss                | 4.410785e-05  |
| qf2_loss                | 3.0148485e-05 |
| time_elapsed            | 3371          |
| total timesteps         | 474466        |
| value_loss              | 3.6938218e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010130007  |
| ent_coef_loss           | 0.2037642     |
| entropy                 | 1.4433018     |
| episodes                | 2296          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 475046        |
| policy_loss             | -0.49383596   |
| qf1_loss                | 7.937882e-05  |
| qf2_loss                | 4.3529268e-05 |
| time_elapsed            | 3375          |
| total timesteps         | 475146        |
| value_loss              | 0.0001110143  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.001057499  |
| ent_coef_loss           | -0.91376436  |
| entropy                 | 1.446744     |
| episodes                | 2300         |
| fps                     | 140          |
| mean 100 episode reward | 0.8          |
| n_updates               | 475830       |
| policy_loss             | -0.5114324   |
| qf1_loss                | 3.002078e-05 |
| qf2_loss                | 3.040582e-05 |
| time_elapsed            | 3381         |
| total timesteps         | 475930       |
| value_loss              | 9.446337e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010524363  |
| ent_coef_loss           | 0.46900517    |
| entropy                 | 1.2703935     |
| episodes                | 2304          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 476584        |
| policy_loss             | -0.5383573    |
| qf1_loss                | 2.1221647e-05 |
| qf2_loss                | 2.290776e-05  |
| time_elapsed            | 3386          |
| total timesteps         | 476684        |
| value_loss              | 3.7529157e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010188239  |
| ent_coef_loss           | 3.963423      |
| entropy                 | 1.3429301     |
| episodes                | 2308          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 477415        |
| policy_loss             | -0.56817865   |
| qf1_loss                | 4.6858728e-05 |
| qf2_loss                | 5.706485e-05  |
| time_elapsed            | 3392          |
| total timesteps         | 477515        |
| value_loss              | 6.889085e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010630375  |
| ent_coef_loss           | -0.70125425   |
| entropy                 | 1.2616501     |
| episodes                | 2312          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 478097        |
| policy_loss             | -0.51106334   |
| qf1_loss                | 3.381309e-05  |
| qf2_loss                | 5.2513504e-05 |
| time_elapsed            | 3397          |
| total timesteps         | 478197        |
| value_loss              | 3.4592176e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010291043  |
| ent_coef_loss           | 0.5977614     |
| entropy                 | 1.3248886     |
| episodes                | 2316          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 478752        |
| policy_loss             | -0.48336667   |
| qf1_loss                | 5.2905532e-05 |
| qf2_loss                | 4.476205e-05  |
| time_elapsed            | 3402          |
| total timesteps         | 478852        |
| value_loss              | 9.552606e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010247628  |
| ent_coef_loss           | -2.7093227    |
| entropy                 | 1.3129888     |
| episodes                | 2320          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 479424        |
| policy_loss             | -0.53015935   |
| qf1_loss                | 3.4051965e-05 |
| qf2_loss                | 3.860186e-05  |
| time_elapsed            | 3406          |
| total timesteps         | 479524        |
| value_loss              | 9.105247e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010903098  |
| ent_coef_loss           | -1.5580101    |
| entropy                 | 1.4361329     |
| episodes                | 2324          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 480146        |
| policy_loss             | -0.5377913    |
| qf1_loss                | 1.2175928e-05 |
| qf2_loss                | 2.8194187e-05 |
| time_elapsed            | 3412          |
| total timesteps         | 480246        |
| value_loss              | 3.3998935e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010657946  |
| ent_coef_loss           | -2.942462     |
| entropy                 | 1.2874341     |
| episodes                | 2328          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 480826        |
| policy_loss             | -0.5864672    |
| qf1_loss                | 1.9919462e-05 |
| qf2_loss                | 1.2442291e-05 |
| time_elapsed            | 3416          |
| total timesteps         | 480926        |
| value_loss              | 2.3905739e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094514934 |
| ent_coef_loss           | 3.2180407     |
| entropy                 | 1.3125587     |
| episodes                | 2332          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 481548        |
| policy_loss             | -0.5814043    |
| qf1_loss                | 3.2584194e-05 |
| qf2_loss                | 1.7974477e-05 |
| time_elapsed            | 3422          |
| total timesteps         | 481648        |
| value_loss              | 0.00012120436 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096857385 |
| ent_coef_loss           | 0.5494777     |
| entropy                 | 1.3108966     |
| episodes                | 2336          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 482234        |
| policy_loss             | -0.59035873   |
| qf1_loss                | 2.9658431e-05 |
| qf2_loss                | 3.9342245e-05 |
| time_elapsed            | 3427          |
| total timesteps         | 482334        |
| value_loss              | 3.6317477e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010044577  |
| ent_coef_loss           | -0.39669305   |
| entropy                 | 1.3885514     |
| episodes                | 2340          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 482956        |
| policy_loss             | -0.5649951    |
| qf1_loss                | 4.3739255e-05 |
| qf2_loss                | 3.636082e-05  |
| time_elapsed            | 3432          |
| total timesteps         | 483056        |
| value_loss              | 1.6484499e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010666146  |
| ent_coef_loss           | 0.57035494    |
| entropy                 | 1.4375298     |
| episodes                | 2344          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 483635        |
| policy_loss             | -0.5257581    |
| qf1_loss                | 1.6221267e-05 |
| qf2_loss                | 2.1813063e-05 |
| time_elapsed            | 3436          |
| total timesteps         | 483735        |
| value_loss              | 6.1237864e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010291563  |
| ent_coef_loss           | 0.26336825    |
| entropy                 | 1.3980372     |
| episodes                | 2348          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 484308        |
| policy_loss             | -0.51963603   |
| qf1_loss                | 1.4421726e-05 |
| qf2_loss                | 1.7907822e-05 |
| time_elapsed            | 3441          |
| total timesteps         | 484408        |
| value_loss              | 2.7401287e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010039947  |
| ent_coef_loss           | -1.5137053    |
| entropy                 | 1.5445178     |
| episodes                | 2352          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 484976        |
| policy_loss             | -0.5689495    |
| qf1_loss                | 1.882091e-05  |
| qf2_loss                | 2.0668876e-05 |
| time_elapsed            | 3446          |
| total timesteps         | 485076        |
| value_loss              | 2.5308036e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010369926  |
| ent_coef_loss           | 1.1883358     |
| entropy                 | 1.4830551     |
| episodes                | 2356          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 485670        |
| policy_loss             | -0.4979186    |
| qf1_loss                | 2.172761e-05  |
| qf2_loss                | 4.6609443e-05 |
| time_elapsed            | 3451          |
| total timesteps         | 485770        |
| value_loss              | 8.437887e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001026175   |
| ent_coef_loss           | -0.62066853   |
| entropy                 | 1.377263      |
| episodes                | 2360          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 486346        |
| policy_loss             | -0.5595393    |
| qf1_loss                | 2.4298512e-05 |
| qf2_loss                | 1.8666484e-05 |
| time_elapsed            | 3456          |
| total timesteps         | 486446        |
| value_loss              | 4.0495914e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010192341  |
| ent_coef_loss           | 0.42331016    |
| entropy                 | 1.4443914     |
| episodes                | 2364          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 487015        |
| policy_loss             | -0.5416332    |
| qf1_loss                | 1.6130936e-05 |
| qf2_loss                | 2.3178862e-05 |
| time_elapsed            | 3460          |
| total timesteps         | 487115        |
| value_loss              | 2.7856004e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010369343 |
| ent_coef_loss           | 2.105686     |
| entropy                 | 1.3598874    |
| episodes                | 2368         |
| fps                     | 140          |
| mean 100 episode reward | 0.9          |
| n_updates               | 487758       |
| policy_loss             | -0.5547633   |
| qf1_loss                | 6.017372e-05 |
| qf2_loss                | 2.993811e-05 |
| time_elapsed            | 3466         |
| total timesteps         | 487858       |
| value_loss              | 4.107675e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010443014  |
| ent_coef_loss           | -2.1417582    |
| entropy                 | 1.4907666     |
| episodes                | 2372          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 488455        |
| policy_loss             | -0.4997192    |
| qf1_loss                | 2.7886208e-05 |
| qf2_loss                | 2.5037112e-05 |
| time_elapsed            | 3471          |
| total timesteps         | 488555        |
| value_loss              | 2.6228712e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009786662  |
| ent_coef_loss           | 2.3080435     |
| entropy                 | 1.3676603     |
| episodes                | 2376          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 489233        |
| policy_loss             | -0.54270005   |
| qf1_loss                | 5.1921397e-05 |
| qf2_loss                | 1.3704421e-05 |
| time_elapsed            | 3476          |
| total timesteps         | 489333        |
| value_loss              | 6.3833504e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009813107  |
| ent_coef_loss           | -1.3015314    |
| entropy                 | 1.3574302     |
| episodes                | 2380          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 489915        |
| policy_loss             | -0.5134417    |
| qf1_loss                | 2.0890331e-05 |
| qf2_loss                | 2.1020394e-05 |
| time_elapsed            | 3481          |
| total timesteps         | 490015        |
| value_loss              | 3.15892e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009961241  |
| ent_coef_loss           | -0.07734302   |
| entropy                 | 1.436953      |
| episodes                | 2384          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 490647        |
| policy_loss             | -0.5757671    |
| qf1_loss                | 4.504256e-05  |
| qf2_loss                | 1.4568641e-05 |
| time_elapsed            | 3486          |
| total timesteps         | 490747        |
| value_loss              | 2.6541835e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009798682  |
| ent_coef_loss           | 0.6320447     |
| entropy                 | 1.4503543     |
| episodes                | 2388          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 491303        |
| policy_loss             | -0.52668035   |
| qf1_loss                | 5.2332194e-05 |
| qf2_loss                | 4.0112405e-05 |
| time_elapsed            | 3491          |
| total timesteps         | 491403        |
| value_loss              | 5.2644435e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009921611  |
| ent_coef_loss           | -0.8859198    |
| entropy                 | 1.4553416     |
| episodes                | 2392          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 491965        |
| policy_loss             | -0.59266007   |
| qf1_loss                | 9.101261e-06  |
| qf2_loss                | 1.1568247e-05 |
| time_elapsed            | 3496          |
| total timesteps         | 492065        |
| value_loss              | 1.5126485e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009730489   |
| ent_coef_loss           | -2.6678047     |
| entropy                 | 1.3486502      |
| episodes                | 2396           |
| fps                     | 140            |
| mean 100 episode reward | 0.9            |
| n_updates               | 492720         |
| policy_loss             | -0.59060585    |
| qf1_loss                | 2.1557575e-05  |
| qf2_loss                | 1.29248765e-05 |
| time_elapsed            | 3501           |
| total timesteps         | 492820         |
| value_loss              | 4.1310115e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095473725 |
| ent_coef_loss           | -1.6831956    |
| entropy                 | 1.4504434     |
| episodes                | 2400          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 493373        |
| policy_loss             | -0.55513483   |
| qf1_loss                | 9.242307e-06  |
| qf2_loss                | 8.167016e-06  |
| time_elapsed            | 3506          |
| total timesteps         | 493473        |
| value_loss              | 1.0782136e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009286478  |
| ent_coef_loss           | -0.28867728   |
| entropy                 | 1.4881629     |
| episodes                | 2404          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 494316        |
| policy_loss             | -0.539284     |
| qf1_loss                | 2.5185116e-05 |
| qf2_loss                | 2.0248659e-05 |
| time_elapsed            | 3512          |
| total timesteps         | 494416        |
| value_loss              | 3.8837985e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001033205   |
| ent_coef_loss           | -0.39401484   |
| entropy                 | 1.4275149     |
| episodes                | 2408          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 495282        |
| policy_loss             | -0.5550395    |
| qf1_loss                | 2.903597e-05  |
| qf2_loss                | 2.7005248e-05 |
| time_elapsed            | 3519          |
| total timesteps         | 495382        |
| value_loss              | 6.5562475e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010043596  |
| ent_coef_loss           | -3.5434818    |
| entropy                 | 1.5538236     |
| episodes                | 2412          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 495932        |
| policy_loss             | -0.5774137    |
| qf1_loss                | 1.3308084e-05 |
| qf2_loss                | 9.470763e-06  |
| time_elapsed            | 3524          |
| total timesteps         | 496032        |
| value_loss              | 2.7558288e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010006209  |
| ent_coef_loss           | 3.210844      |
| entropy                 | 1.3439564     |
| episodes                | 2416          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 496609        |
| policy_loss             | -0.5571863    |
| qf1_loss                | 0.007289005   |
| qf2_loss                | 0.0065795477  |
| time_elapsed            | 3528          |
| total timesteps         | 496709        |
| value_loss              | 4.8179783e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010110444  |
| ent_coef_loss           | -0.1106326    |
| entropy                 | 1.3871639     |
| episodes                | 2420          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 497335        |
| policy_loss             | -0.5788596    |
| qf1_loss                | 2.5723257e-05 |
| qf2_loss                | 1.4395417e-05 |
| time_elapsed            | 3534          |
| total timesteps         | 497435        |
| value_loss              | 2.4291483e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010183762  |
| ent_coef_loss           | -2.1026394    |
| entropy                 | 1.4571033     |
| episodes                | 2424          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 498188        |
| policy_loss             | -0.5728175    |
| qf1_loss                | 3.31053e-05   |
| qf2_loss                | 2.5352194e-05 |
| time_elapsed            | 3540          |
| total timesteps         | 498288        |
| value_loss              | 3.442693e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009669527  |
| ent_coef_loss           | 1.9032857     |
| entropy                 | 1.4369797     |
| episodes                | 2428          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 498834        |
| policy_loss             | -0.56781745   |
| qf1_loss                | 4.2981577e-05 |
| qf2_loss                | 4.8438138e-05 |
| time_elapsed            | 3544          |
| total timesteps         | 498934        |
| value_loss              | 4.2533306e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091735704 |
| ent_coef_loss           | 0.24809556    |
| entropy                 | 1.3383579     |
| episodes                | 2432          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 499520        |
| policy_loss             | -0.5717013    |
| qf1_loss                | 1.3584189e-05 |
| qf2_loss                | 7.791416e-06  |
| time_elapsed            | 3549          |
| total timesteps         | 499620        |
| value_loss              | 1.9186045e-05 |
-------------------------------------------
>>>>> End testing <<<<< decay:_0__nn_layers:_[64__64__64]
Final weights saved at:  /home/admin/tensorboard_logs/sac_decay:_0__nn_layers:_[64__64__64]/stable_baselines.pkl
TEST COMMAND: python3 py3_learning.py --test --weights  /home/admin/tensorboard_logs/sac_decay:_0__nn_layers:_[64__64__64]/stable_baselines.pkl
Starting test with params: {'nn_layers': [1024, 512, 256]}
Namespace(draw_screen=False, env_config='configs/env.config', policy='multi_human_rl', policy_config='configs/policy.config', test=False, train_config='configs/train.config', weights=None)
Gym environment created.
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.54351294    |
| ent_coef_loss           | -2.0856915    |
| entropy                 | 2.6354504     |
| episodes                | 4             |
| fps                     | 144           |
| mean 100 episode reward | -0.1          |
| n_updates               | 1220          |
| policy_loss             | -5.4319763    |
| qf1_loss                | 0.00068398984 |
| qf2_loss                | 0.0008022653  |
| time_elapsed            | 9             |
| total timesteps         | 1320          |
| value_loss              | 0.0072565214  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.22562006   |
| ent_coef_loss           | -5.0170765   |
| entropy                 | 2.6382241    |
| episodes                | 8            |
| fps                     | 140          |
| mean 100 episode reward | -0.1         |
| n_updates               | 2980         |
| policy_loss             | -8.304401    |
| qf1_loss                | 0.0027448274 |
| qf2_loss                | 0.0023475178 |
| time_elapsed            | 21           |
| total timesteps         | 3080         |
| value_loss              | 0.007348125  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.093997695  |
| ent_coef_loss           | -7.8125067   |
| entropy                 | 2.5636966    |
| episodes                | 12           |
| fps                     | 140          |
| mean 100 episode reward | -0.1         |
| n_updates               | 4740         |
| policy_loss             | -8.961613    |
| qf1_loss                | 0.0076862844 |
| qf2_loss                | 0.008151468  |
| time_elapsed            | 34           |
| total timesteps         | 4840         |
| value_loss              | 0.05455478   |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0005      |
| ent_coef                | 0.03961679  |
| ent_coef_loss           | -10.604812  |
| entropy                 | 2.8805542   |
| episodes                | 16          |
| fps                     | 139         |
| mean 100 episode reward | -0.1        |
| n_updates               | 6500        |
| policy_loss             | -8.437814   |
| qf1_loss                | 0.011347795 |
| qf2_loss                | 0.01358651  |
| time_elapsed            | 47          |
| total timesteps         | 6600        |
| value_loss              | 0.05065892  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0005      |
| ent_coef                | 0.017097535 |
| ent_coef_loss           | -10.802797  |
| entropy                 | 3.235427    |
| episodes                | 20          |
| fps                     | 139         |
| mean 100 episode reward | -0.1        |
| n_updates               | 8260        |
| policy_loss             | -7.895461   |
| qf1_loss                | 0.008216298 |
| qf2_loss                | 0.008554214 |
| time_elapsed            | 59          |
| total timesteps         | 8360        |
| value_loss              | 0.00984231  |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.009748067  |
| ent_coef_loss           | -1.4716811   |
| entropy                 | 2.1348155    |
| episodes                | 24           |
| fps                     | 140          |
| mean 100 episode reward | -0.2         |
| n_updates               | 10020        |
| policy_loss             | -7.24039     |
| qf1_loss                | 0.0013685548 |
| qf2_loss                | 0.0006605324 |
| time_elapsed            | 72           |
| total timesteps         | 10120        |
| value_loss              | 0.0015002987 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0062256185 |
| ent_coef_loss           | -3.0505052   |
| entropy                 | 1.8213209    |
| episodes                | 28           |
| fps                     | 139          |
| mean 100 episode reward | -0.2         |
| n_updates               | 11780        |
| policy_loss             | -6.683816    |
| qf1_loss                | 0.0045933435 |
| qf2_loss                | 0.004764879  |
| time_elapsed            | 84           |
| total timesteps         | 11880        |
| value_loss              | 0.0025755498 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.005431632  |
| ent_coef_loss           | -1.2218602   |
| entropy                 | 0.5184566    |
| episodes                | 32           |
| fps                     | 140          |
| mean 100 episode reward | -0.1         |
| n_updates               | 13540        |
| policy_loss             | -6.2314873   |
| qf1_loss                | 0.008888591  |
| qf2_loss                | 0.0063978126 |
| time_elapsed            | 97           |
| total timesteps         | 13640        |
| value_loss              | 0.0063494435 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0037958648 |
| ent_coef_loss           | -0.6129793   |
| entropy                 | -0.9922821   |
| episodes                | 36           |
| fps                     | 140          |
| mean 100 episode reward | -0.3         |
| n_updates               | 15300        |
| policy_loss             | -5.4424076   |
| qf1_loss                | 0.0035340553 |
| qf2_loss                | 0.006461782  |
| time_elapsed            | 109          |
| total timesteps         | 15400        |
| value_loss              | 0.0035711224 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0039067753 |
| ent_coef_loss           | 1.1669261    |
| entropy                 | -0.30317867  |
| episodes                | 40           |
| fps                     | 140          |
| mean 100 episode reward | -0.3         |
| n_updates               | 17060        |
| policy_loss             | -4.956173    |
| qf1_loss                | 0.0016747772 |
| qf2_loss                | 0.0015401109 |
| time_elapsed            | 122          |
| total timesteps         | 17160        |
| value_loss              | 0.003948923  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0031135543 |
| ent_coef_loss           | -1.7069169   |
| entropy                 | -0.6111868   |
| episodes                | 44           |
| fps                     | 139          |
| mean 100 episode reward | -0.3         |
| n_updates               | 18820        |
| policy_loss             | -4.3902974   |
| qf1_loss                | 0.12597466   |
| qf2_loss                | 0.0973281    |
| time_elapsed            | 135          |
| total timesteps         | 18920        |
| value_loss              | 0.0031935524 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0026688976 |
| ent_coef_loss           | 0.40090477   |
| entropy                 | -0.23098296  |
| episodes                | 48           |
| fps                     | 140          |
| mean 100 episode reward | -0.3         |
| n_updates               | 20580        |
| policy_loss             | -3.9984055   |
| qf1_loss                | 0.04076644   |
| qf2_loss                | 0.041483343  |
| time_elapsed            | 147          |
| total timesteps         | 20680        |
| value_loss              | 0.006147006  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0021668032  |
| ent_coef_loss           | 0.12850854    |
| entropy                 | 0.10343355    |
| episodes                | 52            |
| fps                     | 140           |
| mean 100 episode reward | -0.3          |
| n_updates               | 22340         |
| policy_loss             | -3.5077624    |
| qf1_loss                | 0.00045366434 |
| qf2_loss                | 0.00048398785 |
| time_elapsed            | 160           |
| total timesteps         | 22440         |
| value_loss              | 0.00055909884 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0023444786  |
| ent_coef_loss           | 0.18707022    |
| entropy                 | -0.61906385   |
| episodes                | 56            |
| fps                     | 140           |
| mean 100 episode reward | -0.3          |
| n_updates               | 24100         |
| policy_loss             | -3.1513355    |
| qf1_loss                | 0.0007575313  |
| qf2_loss                | 0.00073823857 |
| time_elapsed            | 172           |
| total timesteps         | 24200         |
| value_loss              | 0.0008291909  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0020599111  |
| ent_coef_loss           | 0.9410169     |
| entropy                 | -0.29961005   |
| episodes                | 60            |
| fps                     | 140           |
| mean 100 episode reward | -0.3          |
| n_updates               | 25860         |
| policy_loss             | -2.753129     |
| qf1_loss                | 0.018333675   |
| qf2_loss                | 0.01901714    |
| time_elapsed            | 185           |
| total timesteps         | 25960         |
| value_loss              | 0.00046634712 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0020476247  |
| ent_coef_loss           | 1.084245      |
| entropy                 | -0.7506745    |
| episodes                | 64            |
| fps                     | 139           |
| mean 100 episode reward | -0.4          |
| n_updates               | 27313         |
| policy_loss             | -2.578983     |
| qf1_loss                | 0.00055222725 |
| qf2_loss                | 0.00045859424 |
| time_elapsed            | 195           |
| total timesteps         | 27413         |
| value_loss              | 0.000703585   |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0017406386 |
| ent_coef_loss           | -0.3580088   |
| entropy                 | -0.26306742  |
| episodes                | 68           |
| fps                     | 140          |
| mean 100 episode reward | -0.5         |
| n_updates               | 28614        |
| policy_loss             | -2.321723    |
| qf1_loss                | 0.0014994628 |
| qf2_loss                | 0.0008510137 |
| time_elapsed            | 204          |
| total timesteps         | 28714        |
| value_loss              | 0.0010376609 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0014761335 |
| ent_coef_loss           | -3.9810815   |
| entropy                 | -0.5064383   |
| episodes                | 72           |
| fps                     | 140          |
| mean 100 episode reward | -0.7         |
| n_updates               | 30108        |
| policy_loss             | -2.0773919   |
| qf1_loss                | 0.0046671247 |
| qf2_loss                | 0.00423648   |
| time_elapsed            | 215          |
| total timesteps         | 30208        |
| value_loss              | 0.0046513854 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0014873605 |
| ent_coef_loss           | -2.750148    |
| entropy                 | -0.61175823  |
| episodes                | 76           |
| fps                     | 140          |
| mean 100 episode reward | -0.7         |
| n_updates               | 31544        |
| policy_loss             | -2.0043726   |
| qf1_loss                | 0.027426537  |
| qf2_loss                | 0.03074578   |
| time_elapsed            | 225          |
| total timesteps         | 31644        |
| value_loss              | 0.0016621021 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.00143272   |
| ent_coef_loss           | -0.020502388 |
| entropy                 | -0.5827782   |
| episodes                | 80           |
| fps                     | 140          |
| mean 100 episode reward | -0.8         |
| n_updates               | 32654        |
| policy_loss             | -1.8279941   |
| qf1_loss                | 0.0006717256 |
| qf2_loss                | 0.000713029  |
| time_elapsed            | 233          |
| total timesteps         | 32754        |
| value_loss              | 0.000953502  |
------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0014347641   |
| ent_coef_loss           | 3.8270054      |
| entropy                 | -0.12850173    |
| episodes                | 84             |
| fps                     | 140            |
| mean 100 episode reward | -0.8           |
| n_updates               | 34414          |
| policy_loss             | -1.6738844     |
| qf1_loss                | 0.00016999884  |
| qf2_loss                | 0.000117766635 |
| time_elapsed            | 246            |
| total timesteps         | 34514          |
| value_loss              | 0.00018382329  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0015093501  |
| ent_coef_loss           | -5.632284     |
| entropy                 | 0.46017677    |
| episodes                | 88            |
| fps                     | 140           |
| mean 100 episode reward | -0.8          |
| n_updates               | 36174         |
| policy_loss             | -1.4773974    |
| qf1_loss                | 0.00022625508 |
| qf2_loss                | 0.0001278451  |
| time_elapsed            | 258           |
| total timesteps         | 36274         |
| value_loss              | 0.00027633877 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093706686 |
| ent_coef_loss           | -1.7530236    |
| entropy                 | -0.4553638    |
| episodes                | 92            |
| fps                     | 140           |
| mean 100 episode reward | -0.7          |
| n_updates               | 37844         |
| policy_loss             | -1.3372195    |
| qf1_loss                | 0.00010176691 |
| qf2_loss                | 0.00012064334 |
| time_elapsed            | 270           |
| total timesteps         | 37944         |
| value_loss              | 0.00021849308 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093250116 |
| ent_coef_loss           | -0.10235566   |
| entropy                 | -0.5534425    |
| episodes                | 96            |
| fps                     | 140           |
| mean 100 episode reward | -0.7          |
| n_updates               | 39604         |
| policy_loss             | -1.2059184    |
| qf1_loss                | 0.00015424412 |
| qf2_loss                | 0.00012517624 |
| time_elapsed            | 283           |
| total timesteps         | 39704         |
| value_loss              | 0.00015075771 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090816704 |
| ent_coef_loss           | 5.460874      |
| entropy                 | -0.03763059   |
| episodes                | 100           |
| fps                     | 140           |
| mean 100 episode reward | -0.7          |
| n_updates               | 41364         |
| policy_loss             | -1.1036539    |
| qf1_loss                | 0.0001740526  |
| qf2_loss                | 0.0001963761  |
| time_elapsed            | 295           |
| total timesteps         | 41464         |
| value_loss              | 8.2583705e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011302392  |
| ent_coef_loss           | 0.3466524     |
| entropy                 | 0.65011567    |
| episodes                | 104           |
| fps                     | 140           |
| mean 100 episode reward | -0.8          |
| n_updates               | 43102         |
| policy_loss             | -0.98893327   |
| qf1_loss                | 0.00011980865 |
| qf2_loss                | 7.057699e-05  |
| time_elapsed            | 308           |
| total timesteps         | 43202         |
| value_loss              | 0.00012249092 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0007465208   |
| ent_coef_loss           | 4.6818867      |
| entropy                 | 0.26156643     |
| episodes                | 108            |
| fps                     | 140            |
| mean 100 episode reward | -0.9           |
| n_updates               | 44862          |
| policy_loss             | -0.87063116    |
| qf1_loss                | 0.000115416115 |
| qf2_loss                | 8.654719e-05   |
| time_elapsed            | 320            |
| total timesteps         | 44962          |
| value_loss              | 8.951771e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006870906  |
| ent_coef_loss           | -0.49275917   |
| entropy                 | 0.10857592    |
| episodes                | 112           |
| fps                     | 140           |
| mean 100 episode reward | -0.9          |
| n_updates               | 46564         |
| policy_loss             | -0.764378     |
| qf1_loss                | 3.453271e-05  |
| qf2_loss                | 3.6676007e-05 |
| time_elapsed            | 332           |
| total timesteps         | 46664         |
| value_loss              | 3.643246e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00088907784 |
| ent_coef_loss           | 3.9388883     |
| entropy                 | 0.7611842     |
| episodes                | 116           |
| fps                     | 140           |
| mean 100 episode reward | -0.9          |
| n_updates               | 48324         |
| policy_loss             | -0.6796423    |
| qf1_loss                | 0.0016296353  |
| qf2_loss                | 0.0016053248  |
| time_elapsed            | 345           |
| total timesteps         | 48424         |
| value_loss              | 0.00019020573 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0006752871   |
| ent_coef_loss           | -0.19221985    |
| entropy                 | 0.32648033     |
| episodes                | 120            |
| fps                     | 140            |
| mean 100 episode reward | -0.9           |
| n_updates               | 50084          |
| policy_loss             | -0.5604212     |
| qf1_loss                | 7.8142344e-05  |
| qf2_loss                | 6.7498695e-05  |
| time_elapsed            | 357            |
| total timesteps         | 50184          |
| value_loss              | 0.000100821315 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00055753207 |
| ent_coef_loss           | -3.698185     |
| entropy                 | 0.4838578     |
| episodes                | 124           |
| fps                     | 140           |
| mean 100 episode reward | -0.9          |
| n_updates               | 51844         |
| policy_loss             | -0.5194008    |
| qf1_loss                | 4.6651425e-05 |
| qf2_loss                | 3.7872876e-05 |
| time_elapsed            | 370           |
| total timesteps         | 51944         |
| value_loss              | 0.0013840368  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00067781244 |
| ent_coef_loss           | -0.9324815    |
| entropy                 | 0.91611016    |
| episodes                | 128           |
| fps                     | 140           |
| mean 100 episode reward | -0.9          |
| n_updates               | 53604         |
| policy_loss             | -0.46613252   |
| qf1_loss                | 0.0010504273  |
| qf2_loss                | 0.0010454789  |
| time_elapsed            | 383           |
| total timesteps         | 53704         |
| value_loss              | 3.5472454e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006811441  |
| ent_coef_loss           | 4.8529553     |
| entropy                 | 0.4055904     |
| episodes                | 132           |
| fps                     | 140           |
| mean 100 episode reward | -0.9          |
| n_updates               | 55364         |
| policy_loss             | -0.39386588   |
| qf1_loss                | 5.6476772e-05 |
| qf2_loss                | 5.819757e-05  |
| time_elapsed            | 395           |
| total timesteps         | 55464         |
| value_loss              | 0.00013934314 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000731233   |
| ent_coef_loss           | -1.5588348    |
| entropy                 | 0.36871687    |
| episodes                | 136           |
| fps                     | 140           |
| mean 100 episode reward | -0.9          |
| n_updates               | 57124         |
| policy_loss             | -0.38127193   |
| qf1_loss                | 4.1260886e-05 |
| qf2_loss                | 5.448216e-05  |
| time_elapsed            | 408           |
| total timesteps         | 57224         |
| value_loss              | 9.235435e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006891522  |
| ent_coef_loss           | 2.6761756     |
| entropy                 | 0.88586146    |
| episodes                | 140           |
| fps                     | 140           |
| mean 100 episode reward | -0.8          |
| n_updates               | 58884         |
| policy_loss             | -0.30739164   |
| qf1_loss                | 3.2367006e-05 |
| qf2_loss                | 2.4649671e-05 |
| time_elapsed            | 420           |
| total timesteps         | 58984         |
| value_loss              | 6.0503236e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007506207  |
| ent_coef_loss           | 1.3271893     |
| entropy                 | 0.73313737    |
| episodes                | 144           |
| fps                     | 140           |
| mean 100 episode reward | -0.8          |
| n_updates               | 60644         |
| policy_loss             | -0.24091417   |
| qf1_loss                | 0.00040930358 |
| qf2_loss                | 0.0004797052  |
| time_elapsed            | 433           |
| total timesteps         | 60744         |
| value_loss              | 5.442143e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00053655775 |
| ent_coef_loss           | -3.7241273    |
| entropy                 | 0.4389134     |
| episodes                | 148           |
| fps                     | 140           |
| mean 100 episode reward | -0.8          |
| n_updates               | 62404         |
| policy_loss             | -0.19840357   |
| qf1_loss                | 5.599846e-05  |
| qf2_loss                | 4.836377e-05  |
| time_elapsed            | 445           |
| total timesteps         | 62504         |
| value_loss              | 8.473269e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00042692118 |
| ent_coef_loss           | -2.7675538    |
| entropy                 | 0.039959565   |
| episodes                | 152           |
| fps                     | 140           |
| mean 100 episode reward | -0.8          |
| n_updates               | 64164         |
| policy_loss             | -0.17388943   |
| qf1_loss                | 3.4496436e-05 |
| qf2_loss                | 7.619105e-05  |
| time_elapsed            | 458           |
| total timesteps         | 64264         |
| value_loss              | 5.19461e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00036604787 |
| ent_coef_loss           | -6.4471054    |
| entropy                 | 0.066674404   |
| episodes                | 156           |
| fps                     | 140           |
| mean 100 episode reward | -0.8          |
| n_updates               | 65924         |
| policy_loss             | -0.12753487   |
| qf1_loss                | 8.761673e-05  |
| qf2_loss                | 9.532489e-05  |
| time_elapsed            | 470           |
| total timesteps         | 66024         |
| value_loss              | 9.2215945e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00034610872 |
| ent_coef_loss           | 6.8851767     |
| entropy                 | 0.6106633     |
| episodes                | 160           |
| fps                     | 140           |
| mean 100 episode reward | -0.8          |
| n_updates               | 67684         |
| policy_loss             | -0.118291855  |
| qf1_loss                | 9.747566e-06  |
| qf2_loss                | 1.3770701e-05 |
| time_elapsed            | 483           |
| total timesteps         | 67784         |
| value_loss              | 3.1419862e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00040166758 |
| ent_coef_loss           | 7.317868      |
| entropy                 | 0.8281592     |
| episodes                | 164           |
| fps                     | 140           |
| mean 100 episode reward | -0.8          |
| n_updates               | 69444         |
| policy_loss             | -0.095278636  |
| qf1_loss                | 2.6383754e-05 |
| qf2_loss                | 6.345011e-05  |
| time_elapsed            | 496           |
| total timesteps         | 69544         |
| value_loss              | 4.974363e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00030650085 |
| ent_coef_loss           | 3.5530152     |
| entropy                 | 0.581816      |
| episodes                | 168           |
| fps                     | 140           |
| mean 100 episode reward | -0.7          |
| n_updates               | 71204         |
| policy_loss             | -0.08406956   |
| qf1_loss                | 8.4139356e-05 |
| qf2_loss                | 8.00702e-05   |
| time_elapsed            | 508           |
| total timesteps         | 71304         |
| value_loss              | 6.664954e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00032503984 |
| ent_coef_loss           | 0.72888947    |
| entropy                 | 0.5186032     |
| episodes                | 172           |
| fps                     | 140           |
| mean 100 episode reward | -0.5          |
| n_updates               | 72964         |
| policy_loss             | -0.07435597   |
| qf1_loss                | 2.1905646e-05 |
| qf2_loss                | 2.6302556e-05 |
| time_elapsed            | 520           |
| total timesteps         | 73064         |
| value_loss              | 1.8913935e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0003031002  |
| ent_coef_loss           | -4.218053     |
| entropy                 | 0.014441609   |
| episodes                | 176           |
| fps                     | 140           |
| mean 100 episode reward | -0.5          |
| n_updates               | 74496         |
| policy_loss             | -0.059102498  |
| qf1_loss                | 1.5445868e-05 |
| qf2_loss                | 2.810367e-05  |
| time_elapsed            | 531           |
| total timesteps         | 74596         |
| value_loss              | 5.7827776e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00022699316 |
| ent_coef_loss           | -1.275847     |
| entropy                 | -0.12474725   |
| episodes                | 180           |
| fps                     | 140           |
| mean 100 episode reward | -0.4          |
| n_updates               | 76041         |
| policy_loss             | -0.031067912  |
| qf1_loss                | 1.6872744e-05 |
| qf2_loss                | 1.6472655e-05 |
| time_elapsed            | 542           |
| total timesteps         | 76141         |
| value_loss              | 4.8256556e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00027174936 |
| ent_coef_loss           | -0.11837363   |
| entropy                 | -0.066356525  |
| episodes                | 184           |
| fps                     | 140           |
| mean 100 episode reward | -0.4          |
| n_updates               | 77801         |
| policy_loss             | -0.041777886  |
| qf1_loss                | 5.035758e-05  |
| qf2_loss                | 8.244749e-05  |
| time_elapsed            | 555           |
| total timesteps         | 77901         |
| value_loss              | 5.7359615e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00033752428 |
| ent_coef_loss           | 3.0251358     |
| entropy                 | 0.70703596    |
| episodes                | 188           |
| fps                     | 140           |
| mean 100 episode reward | -0.4          |
| n_updates               | 79561         |
| policy_loss             | -0.037787866  |
| qf1_loss                | 1.970283e-05  |
| qf2_loss                | 2.6364773e-05 |
| time_elapsed            | 567           |
| total timesteps         | 79661         |
| value_loss              | 3.8980692e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00031879192 |
| ent_coef_loss           | -1.0015063    |
| entropy                 | 0.56900215    |
| episodes                | 192           |
| fps                     | 140           |
| mean 100 episode reward | -0.3          |
| n_updates               | 80916         |
| policy_loss             | -0.027167536  |
| qf1_loss                | 1.5827922e-05 |
| qf2_loss                | 1.2036813e-05 |
| time_elapsed            | 577           |
| total timesteps         | 81016         |
| value_loss              | 1.1905375e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00034637717 |
| ent_coef_loss           | 1.5807829     |
| entropy                 | 0.36672574    |
| episodes                | 196           |
| fps                     | 140           |
| mean 100 episode reward | -0.3          |
| n_updates               | 82248         |
| policy_loss             | -0.030510876  |
| qf1_loss                | 2.0336447e-05 |
| qf2_loss                | 1.788754e-05  |
| time_elapsed            | 587           |
| total timesteps         | 82348         |
| value_loss              | 2.5647143e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0003793849  |
| ent_coef_loss           | -2.7809172    |
| entropy                 | 0.8040783     |
| episodes                | 200           |
| fps                     | 140           |
| mean 100 episode reward | -0.3          |
| n_updates               | 84008         |
| policy_loss             | -0.02919882   |
| qf1_loss                | 0.000195111   |
| qf2_loss                | 0.00017231361 |
| time_elapsed            | 599           |
| total timesteps         | 84108         |
| value_loss              | 2.9961597e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00034074328 |
| ent_coef_loss           | -2.6671896    |
| entropy                 | 0.63170004    |
| episodes                | 204           |
| fps                     | 140           |
| mean 100 episode reward | -0.2          |
| n_updates               | 85197         |
| policy_loss             | -0.035733845  |
| qf1_loss                | 0.00013310526 |
| qf2_loss                | 0.00011547479 |
| time_elapsed            | 607           |
| total timesteps         | 85297         |
| value_loss              | 6.6238215e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00033718502 |
| ent_coef_loss           | 0.3471737     |
| entropy                 | 0.49567872    |
| episodes                | 208           |
| fps                     | 140           |
| mean 100 episode reward | -0.2          |
| n_updates               | 86739         |
| policy_loss             | -0.024224466  |
| qf1_loss                | 5.453146e-05  |
| qf2_loss                | 7.846413e-05  |
| time_elapsed            | 619           |
| total timesteps         | 86839         |
| value_loss              | 7.501809e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0004331249  |
| ent_coef_loss           | -2.6148067    |
| entropy                 | 0.6925806     |
| episodes                | 212           |
| fps                     | 140           |
| mean 100 episode reward | -0.1          |
| n_updates               | 88499         |
| policy_loss             | -0.0010460423 |
| qf1_loss                | 0.0043358803  |
| qf2_loss                | 0.0043204078  |
| time_elapsed            | 631           |
| total timesteps         | 88599         |
| value_loss              | 2.8341205e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000529043   |
| ent_coef_loss           | 1.986618      |
| entropy                 | 0.97959113    |
| episodes                | 216           |
| fps                     | 140           |
| mean 100 episode reward | -0.1          |
| n_updates               | 89834         |
| policy_loss             | -0.022833651  |
| qf1_loss                | 3.0010988e-05 |
| qf2_loss                | 6.612528e-05  |
| time_elapsed            | 641           |
| total timesteps         | 89934         |
| value_loss              | 1.993607e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00038645184 |
| ent_coef_loss           | -4.9820156    |
| entropy                 | 0.7069334     |
| episodes                | 220           |
| fps                     | 140           |
| mean 100 episode reward | -0.1          |
| n_updates               | 90709         |
| policy_loss             | -0.047270138  |
| qf1_loss                | 0.0047264467  |
| qf2_loss                | 0.0042011053  |
| time_elapsed            | 647           |
| total timesteps         | 90809         |
| value_loss              | 9.304398e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00041958172 |
| ent_coef_loss           | -1.1708634    |
| entropy                 | 0.48009557    |
| episodes                | 224           |
| fps                     | 140           |
| mean 100 episode reward | -0.1          |
| n_updates               | 91601         |
| policy_loss             | -0.061410006  |
| qf1_loss                | 2.271243e-05  |
| qf2_loss                | 2.2188118e-05 |
| time_elapsed            | 653           |
| total timesteps         | 91701         |
| value_loss              | 2.0456648e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0003931113  |
| ent_coef_loss           | -5.033865     |
| entropy                 | 0.6723089     |
| episodes                | 228           |
| fps                     | 140           |
| mean 100 episode reward | -0            |
| n_updates               | 92637         |
| policy_loss             | -0.037059788  |
| qf1_loss                | 5.6619676e-05 |
| qf2_loss                | 4.6064135e-05 |
| time_elapsed            | 661           |
| total timesteps         | 92737         |
| value_loss              | 3.5366924e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00041568629 |
| ent_coef_loss           | -3.2967358    |
| entropy                 | 0.72574186    |
| episodes                | 232           |
| fps                     | 140           |
| mean 100 episode reward | -0            |
| n_updates               | 93914         |
| policy_loss             | -0.065416634  |
| qf1_loss                | 1.901992e-05  |
| qf2_loss                | 2.03449e-05   |
| time_elapsed            | 670           |
| total timesteps         | 94014         |
| value_loss              | 4.48048e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00041664796 |
| ent_coef_loss           | 1.4647026     |
| entropy                 | 0.4338615     |
| episodes                | 236           |
| fps                     | 140           |
| mean 100 episode reward | -0            |
| n_updates               | 94885         |
| policy_loss             | -0.057732962  |
| qf1_loss                | 2.0960932e-05 |
| qf2_loss                | 3.1918542e-05 |
| time_elapsed            | 677           |
| total timesteps         | 94985         |
| value_loss              | 0.00021693326 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00041333205 |
| ent_coef_loss           | 0.4582792     |
| entropy                 | 0.38839707    |
| episodes                | 240           |
| fps                     | 140           |
| mean 100 episode reward | 0             |
| n_updates               | 95874         |
| policy_loss             | -0.052410383  |
| qf1_loss                | 0.007456275   |
| qf2_loss                | 0.007745575   |
| time_elapsed            | 684           |
| total timesteps         | 95974         |
| value_loss              | 2.9274614e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00045729682 |
| ent_coef_loss           | -1.9241499    |
| entropy                 | 0.7149645     |
| episodes                | 244           |
| fps                     | 140           |
| mean 100 episode reward | 0.1           |
| n_updates               | 96915         |
| policy_loss             | -0.073462516  |
| qf1_loss                | 3.9550854e-05 |
| qf2_loss                | 3.341424e-05  |
| time_elapsed            | 691           |
| total timesteps         | 97015         |
| value_loss              | 5.5832883e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00056644424 |
| ent_coef_loss           | 1.8846784     |
| entropy                 | 0.80289495    |
| episodes                | 248           |
| fps                     | 140           |
| mean 100 episode reward | 0.1           |
| n_updates               | 98208         |
| policy_loss             | -0.09127624   |
| qf1_loss                | 2.4963298e-05 |
| qf2_loss                | 3.624346e-05  |
| time_elapsed            | 700           |
| total timesteps         | 98308         |
| value_loss              | 2.8514192e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00052771025 |
| ent_coef_loss           | 1.8265172     |
| entropy                 | 0.590986      |
| episodes                | 252           |
| fps                     | 140           |
| mean 100 episode reward | 0             |
| n_updates               | 99750         |
| policy_loss             | -0.08001333   |
| qf1_loss                | 5.618579e-05  |
| qf2_loss                | 9.116938e-05  |
| time_elapsed            | 712           |
| total timesteps         | 99850         |
| value_loss              | 0.00014670024 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00049897225 |
| ent_coef_loss           | -0.53272283   |
| entropy                 | 0.7838502     |
| episodes                | 256           |
| fps                     | 140           |
| mean 100 episode reward | 0.1           |
| n_updates               | 101055        |
| policy_loss             | -0.088247225  |
| qf1_loss                | 6.7292545e-05 |
| qf2_loss                | 3.102734e-05  |
| time_elapsed            | 721           |
| total timesteps         | 101155        |
| value_loss              | 8.6847605e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00047364627 |
| ent_coef_loss           | 1.9462957     |
| entropy                 | 0.39226663    |
| episodes                | 260           |
| fps                     | 140           |
| mean 100 episode reward | 0.1           |
| n_updates               | 102422        |
| policy_loss             | -0.08641091   |
| qf1_loss                | 0.00012905689 |
| qf2_loss                | 0.00012877531 |
| time_elapsed            | 730           |
| total timesteps         | 102522        |
| value_loss              | 9.303972e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00059011026 |
| ent_coef_loss           | 3.0643535     |
| entropy                 | 0.27685875    |
| episodes                | 264           |
| fps                     | 140           |
| mean 100 episode reward | 0.1           |
| n_updates               | 103930        |
| policy_loss             | -0.11015724   |
| qf1_loss                | 7.832308e-05  |
| qf2_loss                | 0.00014489923 |
| time_elapsed            | 741           |
| total timesteps         | 104030        |
| value_loss              | 7.795207e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00063228194 |
| ent_coef_loss           | 2.0549266     |
| entropy                 | 0.53089553    |
| episodes                | 268           |
| fps                     | 140           |
| mean 100 episode reward | 0.1           |
| n_updates               | 105027        |
| policy_loss             | -0.115880646  |
| qf1_loss                | 3.1841573e-05 |
| qf2_loss                | 3.1593627e-05 |
| time_elapsed            | 749           |
| total timesteps         | 105127        |
| value_loss              | 5.721626e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00069055124 |
| ent_coef_loss           | -1.5604669    |
| entropy                 | 0.561298      |
| episodes                | 272           |
| fps                     | 140           |
| mean 100 episode reward | 0.1           |
| n_updates               | 106174        |
| policy_loss             | -0.12542814   |
| qf1_loss                | 0.0001012633  |
| qf2_loss                | 0.00010715182 |
| time_elapsed            | 757           |
| total timesteps         | 106274        |
| value_loss              | 0.00011965466 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006793164  |
| ent_coef_loss           | 3.4274948     |
| entropy                 | 0.43421072    |
| episodes                | 276           |
| fps                     | 140           |
| mean 100 episode reward | 0.1           |
| n_updates               | 107716        |
| policy_loss             | -0.1793609    |
| qf1_loss                | 3.1876465e-05 |
| qf2_loss                | 5.1102055e-05 |
| time_elapsed            | 768           |
| total timesteps         | 107816        |
| value_loss              | 6.2301115e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0005990411  |
| ent_coef_loss           | -3.229177     |
| entropy                 | 0.69816905    |
| episodes                | 280           |
| fps                     | 140           |
| mean 100 episode reward | 0.2           |
| n_updates               | 108486        |
| policy_loss             | -0.16010284   |
| qf1_loss                | 3.1168005e-05 |
| qf2_loss                | 4.8329654e-05 |
| time_elapsed            | 774           |
| total timesteps         | 108586        |
| value_loss              | 2.5419922e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006543519  |
| ent_coef_loss           | 0.9566756     |
| entropy                 | 0.33147928    |
| episodes                | 284           |
| fps                     | 140           |
| mean 100 episode reward | 0.1           |
| n_updates               | 109673        |
| policy_loss             | -0.17304203   |
| qf1_loss                | 9.856279e-05  |
| qf2_loss                | 0.00017359229 |
| time_elapsed            | 782           |
| total timesteps         | 109773        |
| value_loss              | 0.0001516493  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00072097697 |
| ent_coef_loss           | -0.24642521   |
| entropy                 | 0.6273919     |
| episodes                | 288           |
| fps                     | 140           |
| mean 100 episode reward | 0.1           |
| n_updates               | 111219        |
| policy_loss             | -0.15897314   |
| qf1_loss                | 4.7989215e-05 |
| qf2_loss                | 6.155869e-05  |
| time_elapsed            | 793           |
| total timesteps         | 111319        |
| value_loss              | 4.473482e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00073629897 |
| ent_coef_loss           | -0.9719455    |
| entropy                 | 0.6566631     |
| episodes                | 292           |
| fps                     | 140           |
| mean 100 episode reward | 0.1           |
| n_updates               | 111981        |
| policy_loss             | -0.14823598   |
| qf1_loss                | 7.4036885e-05 |
| qf2_loss                | 7.278479e-05  |
| time_elapsed            | 799           |
| total timesteps         | 112081        |
| value_loss              | 4.5735484e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00079820555 |
| ent_coef_loss           | 2.0965557     |
| entropy                 | 0.19133511    |
| episodes                | 296           |
| fps                     | 140           |
| mean 100 episode reward | 0.1           |
| n_updates               | 112726        |
| policy_loss             | -0.22643684   |
| qf1_loss                | 7.214314e-05  |
| qf2_loss                | 7.6719996e-05 |
| time_elapsed            | 804           |
| total timesteps         | 112826        |
| value_loss              | 0.00025406145 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008911929  |
| ent_coef_loss           | -2.2539692    |
| entropy                 | 0.74090815    |
| episodes                | 300           |
| fps                     | 140           |
| mean 100 episode reward | 0.1           |
| n_updates               | 114043        |
| policy_loss             | -0.1859629    |
| qf1_loss                | 0.0029376417  |
| qf2_loss                | 0.0027333577  |
| time_elapsed            | 813           |
| total timesteps         | 114143        |
| value_loss              | 0.00017291115 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095312746 |
| ent_coef_loss           | 0.45454997    |
| entropy                 | 0.95633125    |
| episodes                | 304           |
| fps                     | 140           |
| mean 100 episode reward | 0.2           |
| n_updates               | 114964        |
| policy_loss             | -0.19583139   |
| qf1_loss                | 5.1896954e-05 |
| qf2_loss                | 8.82521e-05   |
| time_elapsed            | 820           |
| total timesteps         | 115064        |
| value_loss              | 6.991728e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009655424  |
| ent_coef_loss           | 0.60224634    |
| entropy                 | 0.8828082     |
| episodes                | 308           |
| fps                     | 140           |
| mean 100 episode reward | 0.2           |
| n_updates               | 115972        |
| policy_loss             | -0.23032348   |
| qf1_loss                | 7.533449e-05  |
| qf2_loss                | 9.348283e-05  |
| time_elapsed            | 827           |
| total timesteps         | 116072        |
| value_loss              | 0.00027509395 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090352114 |
| ent_coef_loss           | 1.2289459     |
| entropy                 | 0.76578       |
| episodes                | 312           |
| fps                     | 140           |
| mean 100 episode reward | 0.3           |
| n_updates               | 116786        |
| policy_loss             | -0.24000877   |
| qf1_loss                | 0.00012729825 |
| qf2_loss                | 0.00012653638 |
| time_elapsed            | 833           |
| total timesteps         | 116886        |
| value_loss              | 0.00013733766 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008216715  |
| ent_coef_loss           | -1.5424495    |
| entropy                 | 0.66368914    |
| episodes                | 316           |
| fps                     | 140           |
| mean 100 episode reward | 0.3           |
| n_updates               | 118132        |
| policy_loss             | -0.22222136   |
| qf1_loss                | 0.0013037695  |
| qf2_loss                | 0.0013915579  |
| time_elapsed            | 842           |
| total timesteps         | 118232        |
| value_loss              | 0.00017501127 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008225088  |
| ent_coef_loss           | -1.9496899    |
| entropy                 | 0.497168      |
| episodes                | 320           |
| fps                     | 140           |
| mean 100 episode reward | 0.3           |
| n_updates               | 119656        |
| policy_loss             | -0.24392022   |
| qf1_loss                | 7.312598e-05  |
| qf2_loss                | 0.00013274158 |
| time_elapsed            | 853           |
| total timesteps         | 119756        |
| value_loss              | 0.00018414896 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00088110083 |
| ent_coef_loss           | -0.6005728    |
| entropy                 | 0.63881314    |
| episodes                | 324           |
| fps                     | 140           |
| mean 100 episode reward | 0.3           |
| n_updates               | 120969        |
| policy_loss             | -0.23057376   |
| qf1_loss                | 0.0012319073  |
| qf2_loss                | 0.00097015616 |
| time_elapsed            | 863           |
| total timesteps         | 121069        |
| value_loss              | 0.0005288182  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0008972845   |
| ent_coef_loss           | -0.9648512     |
| entropy                 | 0.6591928      |
| episodes                | 328            |
| fps                     | 140            |
| mean 100 episode reward | 0.3            |
| n_updates               | 122209         |
| policy_loss             | -0.2485546     |
| qf1_loss                | 0.000113168266 |
| qf2_loss                | 0.00010865116  |
| time_elapsed            | 871            |
| total timesteps         | 122309         |
| value_loss              | 0.00015470141  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089439    |
| ent_coef_loss           | -0.92054135   |
| entropy                 | 0.68633986    |
| episodes                | 332           |
| fps                     | 140           |
| mean 100 episode reward | 0.3           |
| n_updates               | 123259        |
| policy_loss             | -0.23739617   |
| qf1_loss                | 9.5605035e-05 |
| qf2_loss                | 8.384569e-05  |
| time_elapsed            | 879           |
| total timesteps         | 123359        |
| value_loss              | 0.00012539835 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008185064  |
| ent_coef_loss           | 0.3135364     |
| entropy                 | 0.52119607    |
| episodes                | 336           |
| fps                     | 140           |
| mean 100 episode reward | 0.3           |
| n_updates               | 124367        |
| policy_loss             | -0.2649771    |
| qf1_loss                | 4.7166606e-05 |
| qf2_loss                | 7.099859e-05  |
| time_elapsed            | 887           |
| total timesteps         | 124467        |
| value_loss              | 5.9454087e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008427134  |
| ent_coef_loss           | 3.556105      |
| entropy                 | 0.793936      |
| episodes                | 340           |
| fps                     | 140           |
| mean 100 episode reward | 0.3           |
| n_updates               | 125779        |
| policy_loss             | -0.26315215   |
| qf1_loss                | 6.579756e-05  |
| qf2_loss                | 6.6539025e-05 |
| time_elapsed            | 897           |
| total timesteps         | 125879        |
| value_loss              | 0.00010616978 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096348976 |
| ent_coef_loss           | 1.1566672     |
| entropy                 | 0.46828055    |
| episodes                | 344           |
| fps                     | 140           |
| mean 100 episode reward | 0.3           |
| n_updates               | 126787        |
| policy_loss             | -0.27673015   |
| qf1_loss                | 0.0007167423  |
| qf2_loss                | 0.00068167126 |
| time_elapsed            | 904           |
| total timesteps         | 126887        |
| value_loss              | 7.128027e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010300047  |
| ent_coef_loss           | 0.58712023    |
| entropy                 | 0.8091424     |
| episodes                | 348           |
| fps                     | 140           |
| mean 100 episode reward | 0.3           |
| n_updates               | 127807        |
| policy_loss             | -0.2866403    |
| qf1_loss                | 9.54471e-05   |
| qf2_loss                | 7.6961966e-05 |
| time_elapsed            | 911           |
| total timesteps         | 127907        |
| value_loss              | 7.226608e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012051797  |
| ent_coef_loss           | 0.1871295     |
| entropy                 | 0.92474806    |
| episodes                | 352           |
| fps                     | 140           |
| mean 100 episode reward | 0.4           |
| n_updates               | 128681        |
| policy_loss             | -0.27817792   |
| qf1_loss                | 0.0008086194  |
| qf2_loss                | 0.00048357033 |
| time_elapsed            | 918           |
| total timesteps         | 128781        |
| value_loss              | 0.00039780067 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0012980099   |
| ent_coef_loss           | -1.358995      |
| entropy                 | 0.837321       |
| episodes                | 356            |
| fps                     | 140            |
| mean 100 episode reward | 0.4            |
| n_updates               | 129666         |
| policy_loss             | -0.3587997     |
| qf1_loss                | 0.00010731088  |
| qf2_loss                | 0.000101678816 |
| time_elapsed            | 925            |
| total timesteps         | 129766         |
| value_loss              | 9.2213406e-05  |
--------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0010247154   |
| ent_coef_loss           | 1.0592877      |
| entropy                 | 0.71036905     |
| episodes                | 360            |
| fps                     | 140            |
| mean 100 episode reward | 0.4            |
| n_updates               | 130548         |
| policy_loss             | -0.32076848    |
| qf1_loss                | 0.00012972747  |
| qf2_loss                | 0.0001268927   |
| time_elapsed            | 931            |
| total timesteps         | 130648         |
| value_loss              | 0.000108851375 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009827679  |
| ent_coef_loss           | 2.292998      |
| entropy                 | 0.77148485    |
| episodes                | 364           |
| fps                     | 140           |
| mean 100 episode reward | 0.5           |
| n_updates               | 131325        |
| policy_loss             | -0.2937925    |
| qf1_loss                | 0.00015066084 |
| qf2_loss                | 0.00010358453 |
| time_elapsed            | 936           |
| total timesteps         | 131425        |
| value_loss              | 5.7740257e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011356826  |
| ent_coef_loss           | -0.009801775  |
| entropy                 | 0.7466636     |
| episodes                | 368           |
| fps                     | 140           |
| mean 100 episode reward | 0.5           |
| n_updates               | 132686        |
| policy_loss             | -0.32239646   |
| qf1_loss                | 0.00074463757 |
| qf2_loss                | 0.00079250446 |
| time_elapsed            | 946           |
| total timesteps         | 132786        |
| value_loss              | 0.00054599385 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011349696  |
| ent_coef_loss           | 1.7351519     |
| entropy                 | 0.8459021     |
| episodes                | 372           |
| fps                     | 140           |
| mean 100 episode reward | 0.5           |
| n_updates               | 133612        |
| policy_loss             | -0.31678316   |
| qf1_loss                | 7.26939e-05   |
| qf2_loss                | 0.00020031838 |
| time_elapsed            | 953           |
| total timesteps         | 133712        |
| value_loss              | 0.00028490298 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011448028  |
| ent_coef_loss           | -0.75449145   |
| entropy                 | 0.8083358     |
| episodes                | 376           |
| fps                     | 140           |
| mean 100 episode reward | 0.4           |
| n_updates               | 134827        |
| policy_loss             | -0.3646772    |
| qf1_loss                | 0.00012076913 |
| qf2_loss                | 8.163612e-05  |
| time_elapsed            | 961           |
| total timesteps         | 134927        |
| value_loss              | 0.00019568656 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001059902   |
| ent_coef_loss           | 0.63686407    |
| entropy                 | 0.9199165     |
| episodes                | 380           |
| fps                     | 140           |
| mean 100 episode reward | 0.4           |
| n_updates               | 136042        |
| policy_loss             | -0.32101268   |
| qf1_loss                | 5.9792743e-05 |
| qf2_loss                | 8.203086e-05  |
| time_elapsed            | 970           |
| total timesteps         | 136142        |
| value_loss              | 0.00022273595 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0012150648   |
| ent_coef_loss           | 0.19183093     |
| entropy                 | 0.96664        |
| episodes                | 384            |
| fps                     | 140            |
| mean 100 episode reward | 0.5            |
| n_updates               | 136841         |
| policy_loss             | -0.3716157     |
| qf1_loss                | 0.00011391976  |
| qf2_loss                | 0.000114435956 |
| time_elapsed            | 976            |
| total timesteps         | 136941         |
| value_loss              | 0.0006245135   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012038627  |
| ent_coef_loss           | -1.2197329    |
| entropy                 | 0.9433242     |
| episodes                | 388           |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 137550        |
| policy_loss             | -0.37882048   |
| qf1_loss                | 9.6199205e-05 |
| qf2_loss                | 0.00010575952 |
| time_elapsed            | 981           |
| total timesteps         | 137650        |
| value_loss              | 0.00021028436 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012186037  |
| ent_coef_loss           | -0.46114653   |
| entropy                 | 0.93013275    |
| episodes                | 392           |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 138241        |
| policy_loss             | -0.3723123    |
| qf1_loss                | 9.989565e-05  |
| qf2_loss                | 0.0001497161  |
| time_elapsed            | 986           |
| total timesteps         | 138341        |
| value_loss              | 0.00013230278 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012696586  |
| ent_coef_loss           | 4.752646      |
| entropy                 | 0.86158836    |
| episodes                | 396           |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 139020        |
| policy_loss             | -0.32185143   |
| qf1_loss                | 9.2839735e-05 |
| qf2_loss                | 0.0001105761  |
| time_elapsed            | 991           |
| total timesteps         | 139120        |
| value_loss              | 0.00013406432 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013911655  |
| ent_coef_loss           | 0.3462069     |
| entropy                 | 1.0378107     |
| episodes                | 400           |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 139774        |
| policy_loss             | -0.36676532   |
| qf1_loss                | 0.0025647013  |
| qf2_loss                | 0.0025303783  |
| time_elapsed            | 996           |
| total timesteps         | 139874        |
| value_loss              | 0.00013685491 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0014330656  |
| ent_coef_loss           | 0.1416663     |
| entropy                 | 1.024538      |
| episodes                | 404           |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 140479        |
| policy_loss             | -0.3464894    |
| qf1_loss                | 6.0854276e-05 |
| qf2_loss                | 8.883321e-05  |
| time_elapsed            | 1001          |
| total timesteps         | 140579        |
| value_loss              | 0.00011761517 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013242163  |
| ent_coef_loss           | -2.8004394    |
| entropy                 | 0.98764694    |
| episodes                | 408           |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 141227        |
| policy_loss             | -0.3618086    |
| qf1_loss                | 5.4619148e-05 |
| qf2_loss                | 6.603556e-05  |
| time_elapsed            | 1007          |
| total timesteps         | 141327        |
| value_loss              | 0.0001689808  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012309473  |
| ent_coef_loss           | 1.7928512     |
| entropy                 | 1.183258      |
| episodes                | 412           |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 142576        |
| policy_loss             | -0.34355456   |
| qf1_loss                | 6.630264e-05  |
| qf2_loss                | 5.2221556e-05 |
| time_elapsed            | 1016          |
| total timesteps         | 142676        |
| value_loss              | 0.00012850967 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011521372  |
| ent_coef_loss           | 1.2586116     |
| entropy                 | 1.0212047     |
| episodes                | 416           |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 143360        |
| policy_loss             | -0.36950558   |
| qf1_loss                | 0.0017040949  |
| qf2_loss                | 0.0016527637  |
| time_elapsed            | 1022          |
| total timesteps         | 143460        |
| value_loss              | 0.00016722667 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097335514 |
| ent_coef_loss           | -0.74261886   |
| entropy                 | 0.72061396    |
| episodes                | 420           |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 144117        |
| policy_loss             | -0.43816394   |
| qf1_loss                | 0.00011695003 |
| qf2_loss                | 0.00015782178 |
| time_elapsed            | 1027          |
| total timesteps         | 144217        |
| value_loss              | 7.247843e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010388967  |
| ent_coef_loss           | 1.9756463     |
| entropy                 | 0.90189517    |
| episodes                | 424           |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 144983        |
| policy_loss             | -0.4399856    |
| qf1_loss                | 5.6136712e-05 |
| qf2_loss                | 0.00011670706 |
| time_elapsed            | 1034          |
| total timesteps         | 145083        |
| value_loss              | 7.416829e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010753955  |
| ent_coef_loss           | -2.3756077    |
| entropy                 | 0.9386034     |
| episodes                | 428           |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 145719        |
| policy_loss             | -0.40085217   |
| qf1_loss                | 7.2559116e-05 |
| qf2_loss                | 9.095107e-05  |
| time_elapsed            | 1039          |
| total timesteps         | 145819        |
| value_loss              | 0.00023599889 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001027597   |
| ent_coef_loss           | 1.3480246     |
| entropy                 | 0.93058395    |
| episodes                | 432           |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 146471        |
| policy_loss             | -0.41572574   |
| qf1_loss                | 0.00013751561 |
| qf2_loss                | 0.0001662932  |
| time_elapsed            | 1044          |
| total timesteps         | 146571        |
| value_loss              | 0.00018865333 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010420546  |
| ent_coef_loss           | 0.19701993    |
| entropy                 | 1.2852769     |
| episodes                | 436           |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 147207        |
| policy_loss             | -0.39052606   |
| qf1_loss                | 5.454794e-05  |
| qf2_loss                | 0.00012290079 |
| time_elapsed            | 1050          |
| total timesteps         | 147307        |
| value_loss              | 0.00017256083 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011107227  |
| ent_coef_loss           | 1.6364064     |
| entropy                 | 1.0205643     |
| episodes                | 440           |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 147932        |
| policy_loss             | -0.39501166   |
| qf1_loss                | 6.848713e-05  |
| qf2_loss                | 4.0021783e-05 |
| time_elapsed            | 1055          |
| total timesteps         | 148032        |
| value_loss              | 6.832874e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011212206  |
| ent_coef_loss           | 1.0518259     |
| entropy                 | 0.9608344     |
| episodes                | 444           |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 148618        |
| policy_loss             | -0.52415633   |
| qf1_loss                | 3.288402e-05  |
| qf2_loss                | 5.9102775e-05 |
| time_elapsed            | 1059          |
| total timesteps         | 148718        |
| value_loss              | 4.2513533e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011441784  |
| ent_coef_loss           | -0.25199473   |
| entropy                 | 0.8268063     |
| episodes                | 448           |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 149302        |
| policy_loss             | -0.43913978   |
| qf1_loss                | 5.009197e-05  |
| qf2_loss                | 0.00013111223 |
| time_elapsed            | 1064          |
| total timesteps         | 149402        |
| value_loss              | 0.00049996097 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010871099  |
| ent_coef_loss           | 2.2952523     |
| entropy                 | 0.9372443     |
| episodes                | 452           |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 150008        |
| policy_loss             | -0.5010723    |
| qf1_loss                | 0.00024602437 |
| qf2_loss                | 0.00014448239 |
| time_elapsed            | 1069          |
| total timesteps         | 150108        |
| value_loss              | 9.6949254e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010827142  |
| ent_coef_loss           | -1.5202549    |
| entropy                 | 0.9242219     |
| episodes                | 456           |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 150823        |
| policy_loss             | -0.5074424    |
| qf1_loss                | 4.4346074e-05 |
| qf2_loss                | 8.425348e-05  |
| time_elapsed            | 1075          |
| total timesteps         | 150923        |
| value_loss              | 0.00015155741 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010593618  |
| ent_coef_loss           | 2.7252827     |
| entropy                 | 0.98403305    |
| episodes                | 460           |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 151993        |
| policy_loss             | -0.47415042   |
| qf1_loss                | 0.000244923   |
| qf2_loss                | 0.00017016534 |
| time_elapsed            | 1084          |
| total timesteps         | 152093        |
| value_loss              | 8.54994e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011384152  |
| ent_coef_loss           | 0.84362954    |
| entropy                 | 1.1596105     |
| episodes                | 464           |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 152862        |
| policy_loss             | -0.44771507   |
| qf1_loss                | 5.8328016e-05 |
| qf2_loss                | 9.928451e-05  |
| time_elapsed            | 1090          |
| total timesteps         | 152962        |
| value_loss              | 9.6276664e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011997081  |
| ent_coef_loss           | 2.226371      |
| entropy                 | 1.2086117     |
| episodes                | 468           |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 153611        |
| policy_loss             | -0.5171319    |
| qf1_loss                | 0.00012333471 |
| qf2_loss                | 0.00010927381 |
| time_elapsed            | 1095          |
| total timesteps         | 153711        |
| value_loss              | 5.9344555e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010705927 |
| ent_coef_loss           | -0.29878336  |
| entropy                 | 1.09406      |
| episodes                | 472          |
| fps                     | 140          |
| mean 100 episode reward | 0.8          |
| n_updates               | 154301       |
| policy_loss             | -0.47014087  |
| qf1_loss                | 0.0003791565 |
| qf2_loss                | 0.0002630803 |
| time_elapsed            | 1100         |
| total timesteps         | 154401       |
| value_loss              | 8.260188e-05 |
------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0010606634   |
| ent_coef_loss           | 2.9622936      |
| entropy                 | 0.9608004      |
| episodes                | 476            |
| fps                     | 140            |
| mean 100 episode reward | 0.8            |
| n_updates               | 155325         |
| policy_loss             | -0.46939403    |
| qf1_loss                | 5.79029e-05    |
| qf2_loss                | 0.000118416414 |
| time_elapsed            | 1107           |
| total timesteps         | 155425         |
| value_loss              | 4.9406815e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010582057  |
| ent_coef_loss           | -0.4022938    |
| entropy                 | 0.99455446    |
| episodes                | 480           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 156024        |
| policy_loss             | -0.44279104   |
| qf1_loss                | 3.612408e-05  |
| qf2_loss                | 3.997414e-05  |
| time_elapsed            | 1112          |
| total timesteps         | 156124        |
| value_loss              | 5.8020596e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001095068   |
| ent_coef_loss           | -1.1871698    |
| entropy                 | 1.171824      |
| episodes                | 484           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 157030        |
| policy_loss             | -0.48882937   |
| qf1_loss                | 3.7738737e-05 |
| qf2_loss                | 4.3518412e-05 |
| time_elapsed            | 1119          |
| total timesteps         | 157130        |
| value_loss              | 8.5179105e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010589957  |
| ent_coef_loss           | -0.24478841   |
| entropy                 | 1.0400017     |
| episodes                | 488           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 157660        |
| policy_loss             | -0.4677764    |
| qf1_loss                | 4.1929514e-05 |
| qf2_loss                | 6.7077475e-05 |
| time_elapsed            | 1124          |
| total timesteps         | 157760        |
| value_loss              | 9.0823625e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010613231  |
| ent_coef_loss           | -0.374357     |
| entropy                 | 0.97422814    |
| episodes                | 492           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 158322        |
| policy_loss             | -0.47315788   |
| qf1_loss                | 0.00010153583 |
| qf2_loss                | 0.0002437365  |
| time_elapsed            | 1129          |
| total timesteps         | 158422        |
| value_loss              | 0.00025492208 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010732772  |
| ent_coef_loss           | 0.9986038     |
| entropy                 | 0.9915602     |
| episodes                | 496           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 159102        |
| policy_loss             | -0.5257522    |
| qf1_loss                | 5.0053997e-05 |
| qf2_loss                | 4.3838292e-05 |
| time_elapsed            | 1134          |
| total timesteps         | 159202        |
| value_loss              | 6.0881022e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011197861  |
| ent_coef_loss           | 3.3751621     |
| entropy                 | 1.0322285     |
| episodes                | 500           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 159764        |
| policy_loss             | -0.4518444    |
| qf1_loss                | 0.00010942914 |
| qf2_loss                | 3.26467e-05   |
| time_elapsed            | 1139          |
| total timesteps         | 159864        |
| value_loss              | 0.00012247726 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011071608  |
| ent_coef_loss           | 2.2438931     |
| entropy                 | 1.2571638     |
| episodes                | 504           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 160425        |
| policy_loss             | -0.53185606   |
| qf1_loss                | 0.00013106834 |
| qf2_loss                | 0.00010627197 |
| time_elapsed            | 1144          |
| total timesteps         | 160525        |
| value_loss              | 7.7740304e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011125249  |
| ent_coef_loss           | -1.3318415    |
| entropy                 | 1.090316      |
| episodes                | 508           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 161099        |
| policy_loss             | -0.48849255   |
| qf1_loss                | 0.0004999961  |
| qf2_loss                | 0.00043125558 |
| time_elapsed            | 1148          |
| total timesteps         | 161199        |
| value_loss              | 0.00013567728 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011156189  |
| ent_coef_loss           | -0.2931068    |
| entropy                 | 1.0471896     |
| episodes                | 512           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 161762        |
| policy_loss             | -0.5032982    |
| qf1_loss                | 6.391146e-05  |
| qf2_loss                | 5.5240693e-05 |
| time_elapsed            | 1153          |
| total timesteps         | 161862        |
| value_loss              | 8.61436e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011336715  |
| ent_coef_loss           | -0.17581892   |
| entropy                 | 1.1336577     |
| episodes                | 516           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 162500        |
| policy_loss             | -0.48250985   |
| qf1_loss                | 4.506552e-05  |
| qf2_loss                | 5.6842102e-05 |
| time_elapsed            | 1159          |
| total timesteps         | 162600        |
| value_loss              | 6.281708e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011325255  |
| ent_coef_loss           | 0.8874864     |
| entropy                 | 1.1272846     |
| episodes                | 520           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 163181        |
| policy_loss             | -0.51299715   |
| qf1_loss                | 0.00035895535 |
| qf2_loss                | 0.0003553264  |
| time_elapsed            | 1163          |
| total timesteps         | 163281        |
| value_loss              | 8.573831e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010264799  |
| ent_coef_loss           | 0.3874526     |
| entropy                 | 1.3039408     |
| episodes                | 524           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 163866        |
| policy_loss             | -0.48492074   |
| qf1_loss                | 4.7482274e-05 |
| qf2_loss                | 0.00021616691 |
| time_elapsed            | 1168          |
| total timesteps         | 163966        |
| value_loss              | 0.00021747086 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010504529  |
| ent_coef_loss           | 2.156921      |
| entropy                 | 1.2355204     |
| episodes                | 528           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 164582        |
| policy_loss             | -0.4717475    |
| qf1_loss                | 0.00032075332 |
| qf2_loss                | 0.00028473765 |
| time_elapsed            | 1173          |
| total timesteps         | 164682        |
| value_loss              | 0.00013775959 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009681481  |
| ent_coef_loss           | 2.244657      |
| entropy                 | 0.8680053     |
| episodes                | 532           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 165277        |
| policy_loss             | -0.44667405   |
| qf1_loss                | 0.0017858816  |
| qf2_loss                | 0.001608813   |
| time_elapsed            | 1178          |
| total timesteps         | 165377        |
| value_loss              | 0.00012600987 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010363066  |
| ent_coef_loss           | 2.4207606     |
| entropy                 | 1.1920494     |
| episodes                | 536           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 166252        |
| policy_loss             | -0.5529721    |
| qf1_loss                | 0.00019013995 |
| qf2_loss                | 7.06656e-05   |
| time_elapsed            | 1185          |
| total timesteps         | 166352        |
| value_loss              | 3.0240042e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010045023  |
| ent_coef_loss           | -3.7553396    |
| entropy                 | 1.2441722     |
| episodes                | 540           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 166931        |
| policy_loss             | -0.48957312   |
| qf1_loss                | 0.0005072229  |
| qf2_loss                | 0.0005374606  |
| time_elapsed            | 1190          |
| total timesteps         | 167031        |
| value_loss              | 3.1474934e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010190139  |
| ent_coef_loss           | -2.4826446    |
| entropy                 | 1.0912442     |
| episodes                | 544           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 168148        |
| policy_loss             | -0.47146076   |
| qf1_loss                | 3.163568e-05  |
| qf2_loss                | 2.0611558e-05 |
| time_elapsed            | 1199          |
| total timesteps         | 168248        |
| value_loss              | 3.0329622e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010384915  |
| ent_coef_loss           | -0.5695874    |
| entropy                 | 1.1318336     |
| episodes                | 548           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 168846        |
| policy_loss             | -0.49257588   |
| qf1_loss                | 5.6217446e-05 |
| qf2_loss                | 7.260161e-05  |
| time_elapsed            | 1204          |
| total timesteps         | 168946        |
| value_loss              | 0.0001284546  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010989907  |
| ent_coef_loss           | -2.3395123    |
| entropy                 | 1.2417775     |
| episodes                | 552           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 169484        |
| policy_loss             | -0.46347702   |
| qf1_loss                | 1.7093465e-05 |
| qf2_loss                | 3.181488e-05  |
| time_elapsed            | 1208          |
| total timesteps         | 169584        |
| value_loss              | 3.0867384e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0011211988   |
| ent_coef_loss           | -0.7548971     |
| entropy                 | 1.1616468      |
| episodes                | 556            |
| fps                     | 140            |
| mean 100 episode reward | 0.8            |
| n_updates               | 170344         |
| policy_loss             | -0.5055629     |
| qf1_loss                | 0.00014221459  |
| qf2_loss                | 0.000117716096 |
| time_elapsed            | 1214           |
| total timesteps         | 170444         |
| value_loss              | 4.1269734e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001036226   |
| ent_coef_loss           | 1.6421887     |
| entropy                 | 1.3478782     |
| episodes                | 560           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 170998        |
| policy_loss             | -0.48985457   |
| qf1_loss                | 0.00019257635 |
| qf2_loss                | 9.716075e-05  |
| time_elapsed            | 1219          |
| total timesteps         | 171098        |
| value_loss              | 2.7338181e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010460148  |
| ent_coef_loss           | 2.5792656     |
| entropy                 | 1.2538009     |
| episodes                | 564           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 171781        |
| policy_loss             | -0.4824711    |
| qf1_loss                | 0.00018527253 |
| qf2_loss                | 0.00021005356 |
| time_elapsed            | 1225          |
| total timesteps         | 171881        |
| value_loss              | 0.00010050474 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010646055  |
| ent_coef_loss           | 0.08034855    |
| entropy                 | 0.9431745     |
| episodes                | 568           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 172473        |
| policy_loss             | -0.41907606   |
| qf1_loss                | 5.962852e-05  |
| qf2_loss                | 2.9876977e-05 |
| time_elapsed            | 1229          |
| total timesteps         | 172573        |
| value_loss              | 7.9712016e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010023478  |
| ent_coef_loss           | -2.0165796    |
| entropy                 | 1.1875188     |
| episodes                | 572           |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 173293        |
| policy_loss             | -0.45075092   |
| qf1_loss                | 3.0879863e-05 |
| qf2_loss                | 4.536703e-05  |
| time_elapsed            | 1235          |
| total timesteps         | 173393        |
| value_loss              | 5.3129046e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009759238  |
| ent_coef_loss           | 1.3537405     |
| entropy                 | 1.1917181     |
| episodes                | 576           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 173963        |
| policy_loss             | -0.47707686   |
| qf1_loss                | 0.00039769954 |
| qf2_loss                | 0.0003091019  |
| time_elapsed            | 1240          |
| total timesteps         | 174063        |
| value_loss              | 5.675349e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009619396  |
| ent_coef_loss           | -0.38147354   |
| entropy                 | 1.1278744     |
| episodes                | 580           |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 174682        |
| policy_loss             | -0.47531855   |
| qf1_loss                | 1.8158327e-05 |
| qf2_loss                | 4.4693585e-05 |
| time_elapsed            | 1245          |
| total timesteps         | 174782        |
| value_loss              | 4.86575e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010335962  |
| ent_coef_loss           | 0.946988      |
| entropy                 | 1.1172795     |
| episodes                | 584           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 175360        |
| policy_loss             | -0.5138737    |
| qf1_loss                | 3.86045e-05   |
| qf2_loss                | 3.6455418e-05 |
| time_elapsed            | 1250          |
| total timesteps         | 175460        |
| value_loss              | 3.423896e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010869011  |
| ent_coef_loss           | 0.63326836    |
| entropy                 | 1.2319834     |
| episodes                | 588           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 176056        |
| policy_loss             | -0.50019586   |
| qf1_loss                | 2.5423566e-05 |
| qf2_loss                | 3.512315e-05  |
| time_elapsed            | 1255          |
| total timesteps         | 176156        |
| value_loss              | 2.6492617e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001006708   |
| ent_coef_loss           | 0.90408206    |
| entropy                 | 1.1763438     |
| episodes                | 592           |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 176745        |
| policy_loss             | -0.550141     |
| qf1_loss                | 2.2038046e-05 |
| qf2_loss                | 2.9621824e-05 |
| time_elapsed            | 1260          |
| total timesteps         | 176845        |
| value_loss              | 2.198574e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010174942  |
| ent_coef_loss           | -0.37620103   |
| entropy                 | 1.193432      |
| episodes                | 596           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 177582        |
| policy_loss             | -0.5057483    |
| qf1_loss                | 5.127443e-05  |
| qf2_loss                | 4.3458705e-05 |
| time_elapsed            | 1266          |
| total timesteps         | 177682        |
| value_loss              | 3.436741e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000973396   |
| ent_coef_loss           | -1.3621991    |
| entropy                 | 1.2351187     |
| episodes                | 600           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 178274        |
| policy_loss             | -0.56285876   |
| qf1_loss                | 3.3230353e-05 |
| qf2_loss                | 5.0754254e-05 |
| time_elapsed            | 1271          |
| total timesteps         | 178374        |
| value_loss              | 3.7665337e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009596859  |
| ent_coef_loss           | -4.270712     |
| entropy                 | 1.1361759     |
| episodes                | 604           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 179001        |
| policy_loss             | -0.5316039    |
| qf1_loss                | 5.353654e-05  |
| qf2_loss                | 4.9296832e-05 |
| time_elapsed            | 1276          |
| total timesteps         | 179101        |
| value_loss              | 0.00010778979 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.000949417  |
| ent_coef_loss           | -2.0277252   |
| entropy                 | 1.2440557    |
| episodes                | 608          |
| fps                     | 140          |
| mean 100 episode reward | 0.8          |
| n_updates               | 179658       |
| policy_loss             | -0.52713317  |
| qf1_loss                | 6.728572e-05 |
| qf2_loss                | 4.651035e-05 |
| time_elapsed            | 1281         |
| total timesteps         | 179758       |
| value_loss              | 4.745846e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000933524   |
| ent_coef_loss           | 2.232205      |
| entropy                 | 1.329041      |
| episodes                | 612           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 180309        |
| policy_loss             | -0.58344173   |
| qf1_loss                | 3.3144028e-05 |
| qf2_loss                | 5.5753262e-05 |
| time_elapsed            | 1285          |
| total timesteps         | 180409        |
| value_loss              | 6.656084e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009797056  |
| ent_coef_loss           | -1.1600937    |
| entropy                 | 1.2383983     |
| episodes                | 616           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 181045        |
| policy_loss             | -0.5244117    |
| qf1_loss                | 5.639792e-05  |
| qf2_loss                | 7.955735e-05  |
| time_elapsed            | 1291          |
| total timesteps         | 181145        |
| value_loss              | 4.2735912e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097579585 |
| ent_coef_loss           | 0.34019184    |
| entropy                 | 1.226196      |
| episodes                | 620           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 181708        |
| policy_loss             | -0.5337906    |
| qf1_loss                | 3.2136868e-05 |
| qf2_loss                | 2.8671533e-05 |
| time_elapsed            | 1295          |
| total timesteps         | 181808        |
| value_loss              | 6.998765e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093385077 |
| ent_coef_loss           | -0.035784304  |
| entropy                 | 1.2030296     |
| episodes                | 624           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 182387        |
| policy_loss             | -0.50532174   |
| qf1_loss                | 5.460828e-05  |
| qf2_loss                | 2.8523264e-05 |
| time_elapsed            | 1300          |
| total timesteps         | 182487        |
| value_loss              | 0.0001266064  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094622036 |
| ent_coef_loss           | 0.9085978     |
| entropy                 | 1.1544577     |
| episodes                | 628           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 183217        |
| policy_loss             | -0.5563866    |
| qf1_loss                | 2.2885633e-05 |
| qf2_loss                | 2.4815e-05    |
| time_elapsed            | 1306          |
| total timesteps         | 183317        |
| value_loss              | 2.3664754e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000900908   |
| ent_coef_loss           | 1.111392      |
| entropy                 | 1.1161771     |
| episodes                | 632           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 183923        |
| policy_loss             | -0.50615716   |
| qf1_loss                | 0.00013411054 |
| qf2_loss                | 5.8480582e-05 |
| time_elapsed            | 1311          |
| total timesteps         | 184023        |
| value_loss              | 4.6673333e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091786287 |
| ent_coef_loss           | -2.5752103    |
| entropy                 | 1.0702839     |
| episodes                | 636           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 184625        |
| policy_loss             | -0.5154271    |
| qf1_loss                | 0.00018250098 |
| qf2_loss                | 0.00017844923 |
| time_elapsed            | 1316          |
| total timesteps         | 184725        |
| value_loss              | 7.110405e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010143783  |
| ent_coef_loss           | -0.61403155   |
| entropy                 | 1.2548339     |
| episodes                | 640           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 185255        |
| policy_loss             | -0.5632923    |
| qf1_loss                | 3.0590698e-05 |
| qf2_loss                | 3.2628333e-05 |
| time_elapsed            | 1321          |
| total timesteps         | 185355        |
| value_loss              | 3.0233728e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096517877 |
| ent_coef_loss           | 1.9051903     |
| entropy                 | 1.2475965     |
| episodes                | 644           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 185939        |
| policy_loss             | -0.5388651    |
| qf1_loss                | 3.856583e-05  |
| qf2_loss                | 3.1895037e-05 |
| time_elapsed            | 1325          |
| total timesteps         | 186039        |
| value_loss              | 2.8974599e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009925528  |
| ent_coef_loss           | 4.7984457     |
| entropy                 | 1.3842676     |
| episodes                | 648           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 186626        |
| policy_loss             | -0.5527613    |
| qf1_loss                | 5.346172e-05  |
| qf2_loss                | 4.3517826e-05 |
| time_elapsed            | 1330          |
| total timesteps         | 186726        |
| value_loss              | 4.5079712e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097285263 |
| ent_coef_loss           | 1.3579698     |
| entropy                 | 1.2326343     |
| episodes                | 652           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 187337        |
| policy_loss             | -0.5220024    |
| qf1_loss                | 1.3305555e-05 |
| qf2_loss                | 2.666718e-05  |
| time_elapsed            | 1336          |
| total timesteps         | 187437        |
| value_loss              | 2.3057662e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010101091  |
| ent_coef_loss           | 0.39665174    |
| entropy                 | 1.2224293     |
| episodes                | 656           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 187996        |
| policy_loss             | -0.5411046    |
| qf1_loss                | 5.1828665e-05 |
| qf2_loss                | 4.821949e-05  |
| time_elapsed            | 1340          |
| total timesteps         | 188096        |
| value_loss              | 5.09929e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097367406 |
| ent_coef_loss           | 1.1087468     |
| entropy                 | 1.1340396     |
| episodes                | 660           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 188682        |
| policy_loss             | -0.5228509    |
| qf1_loss                | 2.0295174e-05 |
| qf2_loss                | 3.028082e-05  |
| time_elapsed            | 1345          |
| total timesteps         | 188782        |
| value_loss              | 2.4053008e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009975715  |
| ent_coef_loss           | -2.4660702    |
| entropy                 | 1.2755368     |
| episodes                | 664           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 189404        |
| policy_loss             | -0.58998567   |
| qf1_loss                | 1.6380858e-05 |
| qf2_loss                | 2.9489654e-05 |
| time_elapsed            | 1350          |
| total timesteps         | 189504        |
| value_loss              | 2.7738135e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010471392  |
| ent_coef_loss           | 1.86096       |
| entropy                 | 1.382649      |
| episodes                | 668           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 190130        |
| policy_loss             | -0.52032226   |
| qf1_loss                | 0.00023746201 |
| qf2_loss                | 0.00019756629 |
| time_elapsed            | 1355          |
| total timesteps         | 190230        |
| value_loss              | 4.3353793e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010388442  |
| ent_coef_loss           | -0.94527304   |
| entropy                 | 1.0819361     |
| episodes                | 672           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 190833        |
| policy_loss             | -0.53059745   |
| qf1_loss                | 0.00012709743 |
| qf2_loss                | 0.00012521142 |
| time_elapsed            | 1360          |
| total timesteps         | 190933        |
| value_loss              | 7.358422e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001053644   |
| ent_coef_loss           | 1.3649222     |
| entropy                 | 1.2282927     |
| episodes                | 676           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 191884        |
| policy_loss             | -0.5547331    |
| qf1_loss                | 5.7757796e-05 |
| qf2_loss                | 5.1532774e-05 |
| time_elapsed            | 1368          |
| total timesteps         | 191984        |
| value_loss              | 5.475918e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010678859  |
| ent_coef_loss           | 1.3265315     |
| entropy                 | 1.3981223     |
| episodes                | 680           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 192524        |
| policy_loss             | -0.5873074    |
| qf1_loss                | 9.598216e-05  |
| qf2_loss                | 0.000128819   |
| time_elapsed            | 1372          |
| total timesteps         | 192624        |
| value_loss              | 2.2204033e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010078176  |
| ent_coef_loss           | 0.69752145    |
| entropy                 | 1.1572123     |
| episodes                | 684           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 193229        |
| policy_loss             | -0.55433005   |
| qf1_loss                | 0.00015918745 |
| qf2_loss                | 0.00018013205 |
| time_elapsed            | 1377          |
| total timesteps         | 193329        |
| value_loss              | 6.380536e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010129336  |
| ent_coef_loss           | 0.87848014    |
| entropy                 | 1.3544008     |
| episodes                | 688           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 193885        |
| policy_loss             | -0.5413735    |
| qf1_loss                | 7.387657e-05  |
| qf2_loss                | 6.795682e-05  |
| time_elapsed            | 1382          |
| total timesteps         | 193985        |
| value_loss              | 0.00011179145 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009901883  |
| ent_coef_loss           | 0.78386766    |
| entropy                 | 1.1936195     |
| episodes                | 692           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 194541        |
| policy_loss             | -0.5751487    |
| qf1_loss                | 2.583399e-05  |
| qf2_loss                | 2.5110086e-05 |
| time_elapsed            | 1387          |
| total timesteps         | 194641        |
| value_loss              | 5.190458e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009285681  |
| ent_coef_loss           | -0.30710757   |
| entropy                 | 1.2588531     |
| episodes                | 696           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 195226        |
| policy_loss             | -0.55649406   |
| qf1_loss                | 8.1292375e-05 |
| qf2_loss                | 5.1500352e-05 |
| time_elapsed            | 1392          |
| total timesteps         | 195326        |
| value_loss              | 2.5990132e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000952535   |
| ent_coef_loss           | -1.9404364    |
| entropy                 | 1.2523956     |
| episodes                | 700           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 195904        |
| policy_loss             | -0.55143917   |
| qf1_loss                | 2.9066447e-05 |
| qf2_loss                | 2.3811117e-05 |
| time_elapsed            | 1396          |
| total timesteps         | 196004        |
| value_loss              | 3.718002e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094088743 |
| ent_coef_loss           | 0.22794753    |
| entropy                 | 1.3321939     |
| episodes                | 704           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 196647        |
| policy_loss             | -0.5747877    |
| qf1_loss                | 2.4175206e-05 |
| qf2_loss                | 1.9363279e-05 |
| time_elapsed            | 1402          |
| total timesteps         | 196747        |
| value_loss              | 1.9228642e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089333765 |
| ent_coef_loss           | 0.9538048     |
| entropy                 | 1.1268752     |
| episodes                | 708           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 197445        |
| policy_loss             | -0.5522531    |
| qf1_loss                | 6.732651e-05  |
| qf2_loss                | 5.8679972e-05 |
| time_elapsed            | 1407          |
| total timesteps         | 197545        |
| value_loss              | 7.7014825e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087994704 |
| ent_coef_loss           | 0.761376      |
| entropy                 | 1.0565879     |
| episodes                | 712           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 198322        |
| policy_loss             | -0.50168484   |
| qf1_loss                | 0.00020163976 |
| qf2_loss                | 0.00019279335 |
| time_elapsed            | 1414          |
| total timesteps         | 198422        |
| value_loss              | 8.714863e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093242247 |
| ent_coef_loss           | 1.6631484     |
| entropy                 | 1.3712568     |
| episodes                | 716           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 198983        |
| policy_loss             | -0.5185278    |
| qf1_loss                | 2.9413426e-05 |
| qf2_loss                | 3.1031625e-05 |
| time_elapsed            | 1418          |
| total timesteps         | 199083        |
| value_loss              | 3.0740197e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010034466  |
| ent_coef_loss           | 0.33387315    |
| entropy                 | 1.2445614     |
| episodes                | 720           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 199664        |
| policy_loss             | -0.58507097   |
| qf1_loss                | 0.00036645037 |
| qf2_loss                | 0.000557386   |
| time_elapsed            | 1423          |
| total timesteps         | 199764        |
| value_loss              | 8.63588e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010911482  |
| ent_coef_loss           | -1.0501201    |
| entropy                 | 1.3232628     |
| episodes                | 724           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 200306        |
| policy_loss             | -0.486503     |
| qf1_loss                | 5.4306067e-05 |
| qf2_loss                | 3.6465754e-05 |
| time_elapsed            | 1428          |
| total timesteps         | 200406        |
| value_loss              | 8.194093e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010455193  |
| ent_coef_loss           | -0.018695623  |
| entropy                 | 1.2246948     |
| episodes                | 728           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 201121        |
| policy_loss             | -0.6398494    |
| qf1_loss                | 3.4989753e-05 |
| qf2_loss                | 2.7598846e-05 |
| time_elapsed            | 1434          |
| total timesteps         | 201221        |
| value_loss              | 2.7095775e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001061146   |
| ent_coef_loss           | -1.1397481    |
| entropy                 | 1.3635874     |
| episodes                | 732           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 201759        |
| policy_loss             | -0.58579147   |
| qf1_loss                | 1.7666003e-05 |
| qf2_loss                | 3.2384214e-05 |
| time_elapsed            | 1438          |
| total timesteps         | 201859        |
| value_loss              | 1.8826271e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010527485  |
| ent_coef_loss           | -1.3818545    |
| entropy                 | 1.3884146     |
| episodes                | 736           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 202410        |
| policy_loss             | -0.55995655   |
| qf1_loss                | 0.0001798327  |
| qf2_loss                | 0.00027883344 |
| time_elapsed            | 1443          |
| total timesteps         | 202510        |
| value_loss              | 8.870219e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009742704  |
| ent_coef_loss           | 1.1181519     |
| entropy                 | 1.5109558     |
| episodes                | 740           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 203194        |
| policy_loss             | -0.6318981    |
| qf1_loss                | 3.085731e-05  |
| qf2_loss                | 5.3283467e-05 |
| time_elapsed            | 1448          |
| total timesteps         | 203294        |
| value_loss              | 6.509994e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008974663  |
| ent_coef_loss           | 0.36543936    |
| entropy                 | 1.3362747     |
| episodes                | 744           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 203893        |
| policy_loss             | -0.5890039    |
| qf1_loss                | 2.3057702e-05 |
| qf2_loss                | 1.949885e-05  |
| time_elapsed            | 1453          |
| total timesteps         | 203993        |
| value_loss              | 2.0588868e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093576213 |
| ent_coef_loss           | -2.4869213    |
| entropy                 | 1.5030293     |
| episodes                | 748           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 204577        |
| policy_loss             | -0.5255652    |
| qf1_loss                | 1.8097633e-05 |
| qf2_loss                | 1.3772156e-05 |
| time_elapsed            | 1458          |
| total timesteps         | 204677        |
| value_loss              | 4.545525e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008687814  |
| ent_coef_loss           | -2.1324573    |
| entropy                 | 1.233228      |
| episodes                | 752           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 205354        |
| policy_loss             | -0.5142455    |
| qf1_loss                | 0.00016780417 |
| qf2_loss                | 7.134122e-05  |
| time_elapsed            | 1464          |
| total timesteps         | 205454        |
| value_loss              | 8.145941e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093277334 |
| ent_coef_loss           | -0.303998     |
| entropy                 | 1.4316936     |
| episodes                | 756           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 206074        |
| policy_loss             | -0.60270077   |
| qf1_loss                | 1.9872004e-05 |
| qf2_loss                | 2.0251406e-05 |
| time_elapsed            | 1469          |
| total timesteps         | 206174        |
| value_loss              | 2.2694834e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008738469  |
| ent_coef_loss           | -2.5898447    |
| entropy                 | 1.3389435     |
| episodes                | 760           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 206809        |
| policy_loss             | -0.5844757    |
| qf1_loss                | 1.7766886e-05 |
| qf2_loss                | 2.0021393e-05 |
| time_elapsed            | 1474          |
| total timesteps         | 206909        |
| value_loss              | 3.221169e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087568344 |
| ent_coef_loss           | 3.7558346     |
| entropy                 | 1.3337464     |
| episodes                | 764           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 207516        |
| policy_loss             | -0.5764767    |
| qf1_loss                | 4.929786e-05  |
| qf2_loss                | 4.8474103e-05 |
| time_elapsed            | 1479          |
| total timesteps         | 207616        |
| value_loss              | 0.00012247298 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000958463   |
| ent_coef_loss           | 0.6184592     |
| entropy                 | 1.1892767     |
| episodes                | 768           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 208221        |
| policy_loss             | -0.6142607    |
| qf1_loss                | 1.7579818e-05 |
| qf2_loss                | 1.2464546e-05 |
| time_elapsed            | 1485          |
| total timesteps         | 208321        |
| value_loss              | 5.6192053e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000915272   |
| ent_coef_loss           | 1.5048163     |
| entropy                 | 1.226123      |
| episodes                | 772           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 209023        |
| policy_loss             | -0.58304524   |
| qf1_loss                | 1.0623111e-05 |
| qf2_loss                | 1.7228718e-05 |
| time_elapsed            | 1490          |
| total timesteps         | 209123        |
| value_loss              | 2.600461e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092670764 |
| ent_coef_loss           | -0.33135122   |
| entropy                 | 1.1673739     |
| episodes                | 776           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 209665        |
| policy_loss             | -0.5609275    |
| qf1_loss                | 2.6426109e-05 |
| qf2_loss                | 1.7817734e-05 |
| time_elapsed            | 1495          |
| total timesteps         | 209765        |
| value_loss              | 2.6588707e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008915516  |
| ent_coef_loss           | -2.4815345    |
| entropy                 | 1.1093805     |
| episodes                | 780           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 210300        |
| policy_loss             | -0.5671845    |
| qf1_loss                | 2.370769e-05  |
| qf2_loss                | 2.3816152e-05 |
| time_elapsed            | 1499          |
| total timesteps         | 210400        |
| value_loss              | 3.3598164e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008932324  |
| ent_coef_loss           | 1.144401      |
| entropy                 | 1.2174048     |
| episodes                | 784           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 210947        |
| policy_loss             | -0.58001745   |
| qf1_loss                | 3.034138e-05  |
| qf2_loss                | 4.3371663e-05 |
| time_elapsed            | 1504          |
| total timesteps         | 211047        |
| value_loss              | 2.2153261e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090496166 |
| ent_coef_loss           | 0.33419114    |
| entropy                 | 1.3759391     |
| episodes                | 788           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 211604        |
| policy_loss             | -0.61410415   |
| qf1_loss                | 1.2590697e-05 |
| qf2_loss                | 8.154762e-06  |
| time_elapsed            | 1508          |
| total timesteps         | 211704        |
| value_loss              | 1.6815295e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008807891  |
| ent_coef_loss           | -0.34502977   |
| entropy                 | 1.2603304     |
| episodes                | 792           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 212243        |
| policy_loss             | -0.61372507   |
| qf1_loss                | 2.0899744e-05 |
| qf2_loss                | 1.3388252e-05 |
| time_elapsed            | 1513          |
| total timesteps         | 212343        |
| value_loss              | 1.6878861e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008933977  |
| ent_coef_loss           | -0.5132239    |
| entropy                 | 1.1669335     |
| episodes                | 796           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 212877        |
| policy_loss             | -0.5953144    |
| qf1_loss                | 1.0251666e-05 |
| qf2_loss                | 1.1684818e-05 |
| time_elapsed            | 1518          |
| total timesteps         | 212977        |
| value_loss              | 2.885018e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095359073 |
| ent_coef_loss           | 0.761553      |
| entropy                 | 1.4449868     |
| episodes                | 800           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 213539        |
| policy_loss             | -0.54333055   |
| qf1_loss                | 1.5199737e-05 |
| qf2_loss                | 1.6064343e-05 |
| time_elapsed            | 1522          |
| total timesteps         | 213639        |
| value_loss              | 3.8438993e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009264629  |
| ent_coef_loss           | -0.013156414  |
| entropy                 | 1.3561835     |
| episodes                | 804           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 214207        |
| policy_loss             | -0.6238038    |
| qf1_loss                | 3.1172312e-05 |
| qf2_loss                | 1.8935978e-05 |
| time_elapsed            | 1527          |
| total timesteps         | 214307        |
| value_loss              | 2.236464e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009573686  |
| ent_coef_loss           | -0.9216031    |
| entropy                 | 1.4347715     |
| episodes                | 808           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 214846        |
| policy_loss             | -0.57598305   |
| qf1_loss                | 2.9437486e-05 |
| qf2_loss                | 4.5787358e-05 |
| time_elapsed            | 1531          |
| total timesteps         | 214946        |
| value_loss              | 2.1026835e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009650241  |
| ent_coef_loss           | 2.7326188     |
| entropy                 | 1.5325679     |
| episodes                | 812           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 215517        |
| policy_loss             | -0.6183922    |
| qf1_loss                | 1.4656678e-05 |
| qf2_loss                | 1.5961165e-05 |
| time_elapsed            | 1536          |
| total timesteps         | 215617        |
| value_loss              | 1.5409712e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091721094 |
| ent_coef_loss           | 2.5228417     |
| entropy                 | 1.3909726     |
| episodes                | 816           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 216208        |
| policy_loss             | -0.6425372    |
| qf1_loss                | 1.6793469e-05 |
| qf2_loss                | 1.974712e-05  |
| time_elapsed            | 1541          |
| total timesteps         | 216308        |
| value_loss              | 2.4486862e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009802944  |
| ent_coef_loss           | -1.2455062    |
| entropy                 | 1.4551392     |
| episodes                | 820           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 216860        |
| policy_loss             | -0.61164397   |
| qf1_loss                | 1.557978e-05  |
| qf2_loss                | 2.9968327e-05 |
| time_elapsed            | 1546          |
| total timesteps         | 216960        |
| value_loss              | 3.564111e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008790961  |
| ent_coef_loss           | 1.2279803     |
| entropy                 | 1.4813926     |
| episodes                | 824           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 217568        |
| policy_loss             | -0.6192549    |
| qf1_loss                | 3.5961748e-05 |
| qf2_loss                | 4.430195e-05  |
| time_elapsed            | 1551          |
| total timesteps         | 217668        |
| value_loss              | 2.6934082e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008560977  |
| ent_coef_loss           | -1.520655     |
| entropy                 | 1.3249981     |
| episodes                | 828           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 218474        |
| policy_loss             | -0.5668331    |
| qf1_loss                | 3.9028015e-05 |
| qf2_loss                | 2.3528963e-05 |
| time_elapsed            | 1557          |
| total timesteps         | 218574        |
| value_loss              | 5.0230305e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00083179807 |
| ent_coef_loss           | 0.46337014    |
| entropy                 | 1.3258346     |
| episodes                | 832           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 219117        |
| policy_loss             | -0.56984997   |
| qf1_loss                | 1.2270457e-05 |
| qf2_loss                | 2.297944e-05  |
| time_elapsed            | 1562          |
| total timesteps         | 219217        |
| value_loss              | 2.1543106e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008064805  |
| ent_coef_loss           | 1.0574358     |
| entropy                 | 1.3494536     |
| episodes                | 836           |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 219797        |
| policy_loss             | -0.6304521    |
| qf1_loss                | 4.2692758e-05 |
| qf2_loss                | 7.7570294e-05 |
| time_elapsed            | 1567          |
| total timesteps         | 219897        |
| value_loss              | 2.9918067e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008630903  |
| ent_coef_loss           | 0.06819618    |
| entropy                 | 1.3306029     |
| episodes                | 840           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 220478        |
| policy_loss             | -0.5934192    |
| qf1_loss                | 1.3589137e-05 |
| qf2_loss                | 2.0269767e-05 |
| time_elapsed            | 1571          |
| total timesteps         | 220578        |
| value_loss              | 4.0756982e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086919    |
| ent_coef_loss           | -0.7042748    |
| entropy                 | 1.3732605     |
| episodes                | 844           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 221214        |
| policy_loss             | -0.62968624   |
| qf1_loss                | 3.3014076e-05 |
| qf2_loss                | 3.8115624e-05 |
| time_elapsed            | 1577          |
| total timesteps         | 221314        |
| value_loss              | 4.3427222e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00083135715 |
| ent_coef_loss           | -2.0722477    |
| entropy                 | 1.2395449     |
| episodes                | 848           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 221863        |
| policy_loss             | -0.5769024    |
| qf1_loss                | 1.0836489e-05 |
| qf2_loss                | 2.2905784e-05 |
| time_elapsed            | 1582          |
| total timesteps         | 221963        |
| value_loss              | 2.4293571e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008435134  |
| ent_coef_loss           | 0.31808877    |
| entropy                 | 1.3532279     |
| episodes                | 852           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 222515        |
| policy_loss             | -0.6399337    |
| qf1_loss                | 2.1169388e-05 |
| qf2_loss                | 2.4760091e-05 |
| time_elapsed            | 1586          |
| total timesteps         | 222615        |
| value_loss              | 2.202905e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008603098  |
| ent_coef_loss           | 4.5326376     |
| entropy                 | 1.2718663     |
| episodes                | 856           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 223467        |
| policy_loss             | -0.63401705   |
| qf1_loss                | 2.7205975e-05 |
| qf2_loss                | 2.4629695e-05 |
| time_elapsed            | 1593          |
| total timesteps         | 223567        |
| value_loss              | 2.5546526e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00083818723 |
| ent_coef_loss           | -2.1400068    |
| entropy                 | 1.231241      |
| episodes                | 860           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 224116        |
| policy_loss             | -0.56161225   |
| qf1_loss                | 3.8777172e-05 |
| qf2_loss                | 2.9837745e-05 |
| time_elapsed            | 1598          |
| total timesteps         | 224216        |
| value_loss              | 2.4656285e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00080033415 |
| ent_coef_loss           | 0.77239984    |
| entropy                 | 1.1336954     |
| episodes                | 864           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 224840        |
| policy_loss             | -0.587248     |
| qf1_loss                | 2.5020701e-05 |
| qf2_loss                | 2.8679913e-05 |
| time_elapsed            | 1603          |
| total timesteps         | 224940        |
| value_loss              | 1.1473158e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00083230034 |
| ent_coef_loss           | -0.3937591    |
| entropy                 | 1.2375838     |
| episodes                | 868           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 225568        |
| policy_loss             | -0.60253686   |
| qf1_loss                | 1.1313019e-05 |
| qf2_loss                | 4.6766683e-05 |
| time_elapsed            | 1608          |
| total timesteps         | 225668        |
| value_loss              | 6.201287e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087363896 |
| ent_coef_loss           | -1.5285277    |
| entropy                 | 1.3658954     |
| episodes                | 872           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 226240        |
| policy_loss             | -0.59731317   |
| qf1_loss                | 2.9566982e-05 |
| qf2_loss                | 2.5709911e-05 |
| time_elapsed            | 1613          |
| total timesteps         | 226340        |
| value_loss              | 3.71894e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008608646  |
| ent_coef_loss           | -0.23348951   |
| entropy                 | 1.2802862     |
| episodes                | 876           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 226973        |
| policy_loss             | -0.6327112    |
| qf1_loss                | 2.9817646e-05 |
| qf2_loss                | 2.3096378e-05 |
| time_elapsed            | 1618          |
| total timesteps         | 227073        |
| value_loss              | 3.7566824e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085499295 |
| ent_coef_loss           | 0.21902394    |
| entropy                 | 1.3644766     |
| episodes                | 880           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 227611        |
| policy_loss             | -0.58703244   |
| qf1_loss                | 1.0660799e-05 |
| qf2_loss                | 1.1668115e-05 |
| time_elapsed            | 1623          |
| total timesteps         | 227711        |
| value_loss              | 1.8099581e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008096628  |
| ent_coef_loss           | 0.58893096    |
| entropy                 | 1.43817       |
| episodes                | 884           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 228599        |
| policy_loss             | -0.62137926   |
| qf1_loss                | 2.172857e-05  |
| qf2_loss                | 2.892295e-05  |
| time_elapsed            | 1630          |
| total timesteps         | 228699        |
| value_loss              | 1.8707538e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00077371305 |
| ent_coef_loss           | 1.1862376     |
| entropy                 | 1.3606938     |
| episodes                | 888           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 229573        |
| policy_loss             | -0.6229013    |
| qf1_loss                | 3.7899525e-05 |
| qf2_loss                | 4.4402976e-05 |
| time_elapsed            | 1636          |
| total timesteps         | 229673        |
| value_loss              | 4.652801e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00076175336 |
| ent_coef_loss           | 3.4223986     |
| entropy                 | 1.3618784     |
| episodes                | 892           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 230230        |
| policy_loss             | -0.6260718    |
| qf1_loss                | 2.6222535e-05 |
| qf2_loss                | 2.6629841e-05 |
| time_elapsed            | 1641          |
| total timesteps         | 230330        |
| value_loss              | 3.701628e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007633103  |
| ent_coef_loss           | 0.21451348    |
| entropy                 | 1.4011965     |
| episodes                | 896           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 230911        |
| policy_loss             | -0.61243516   |
| qf1_loss                | 3.563433e-05  |
| qf2_loss                | 3.3246084e-05 |
| time_elapsed            | 1646          |
| total timesteps         | 231011        |
| value_loss              | 1.336913e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007958777  |
| ent_coef_loss           | 2.5898771     |
| entropy                 | 1.247671      |
| episodes                | 900           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 231627        |
| policy_loss             | -0.57847273   |
| qf1_loss                | 3.0071718e-05 |
| qf2_loss                | 2.3681547e-05 |
| time_elapsed            | 1651          |
| total timesteps         | 231727        |
| value_loss              | 4.225367e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0007564256   |
| ent_coef_loss           | 1.2418356      |
| entropy                 | 1.5545045      |
| episodes                | 904            |
| fps                     | 140            |
| mean 100 episode reward | 0.9            |
| n_updates               | 232303         |
| policy_loss             | -0.6245297     |
| qf1_loss                | 1.1131418e-05  |
| qf2_loss                | 1.35179125e-05 |
| time_elapsed            | 1656           |
| total timesteps         | 232403         |
| value_loss              | 1.7116494e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00078280084 |
| ent_coef_loss           | 0.9403124     |
| entropy                 | 1.3123798     |
| episodes                | 908           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 232971        |
| policy_loss             | -0.62916386   |
| qf1_loss                | 1.9493516e-05 |
| qf2_loss                | 2.2203007e-05 |
| time_elapsed            | 1661          |
| total timesteps         | 233071        |
| value_loss              | 1.5142214e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00082726154 |
| ent_coef_loss           | -0.29128182   |
| entropy                 | 1.4422457     |
| episodes                | 912           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 233643        |
| policy_loss             | -0.62910163   |
| qf1_loss                | 1.2086539e-05 |
| qf2_loss                | 1.6524644e-05 |
| time_elapsed            | 1666          |
| total timesteps         | 233743        |
| value_loss              | 1.2627415e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00081974105  |
| ent_coef_loss           | -1.3267996     |
| entropy                 | 1.3606541      |
| episodes                | 916            |
| fps                     | 140            |
| mean 100 episode reward | 0.9            |
| n_updates               | 234378         |
| policy_loss             | -0.6014674     |
| qf1_loss                | 1.15685325e-05 |
| qf2_loss                | 1.089803e-05   |
| time_elapsed            | 1671           |
| total timesteps         | 234478         |
| value_loss              | 2.0824431e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00082390785 |
| ent_coef_loss           | -0.94127476   |
| entropy                 | 1.4491184     |
| episodes                | 920           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 235050        |
| policy_loss             | -0.60938007   |
| qf1_loss                | 1.6048649e-05 |
| qf2_loss                | 1.4748851e-05 |
| time_elapsed            | 1676          |
| total timesteps         | 235150        |
| value_loss              | 3.0032656e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008230589  |
| ent_coef_loss           | -0.05906117   |
| entropy                 | 1.4943192     |
| episodes                | 924           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 235706        |
| policy_loss             | -0.65686566   |
| qf1_loss                | 4.7951486e-05 |
| qf2_loss                | 6.706841e-05  |
| time_elapsed            | 1681          |
| total timesteps         | 235806        |
| value_loss              | 0.0001368272  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00083358644 |
| ent_coef_loss           | -2.269538     |
| entropy                 | 1.4198651     |
| episodes                | 928           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 236317        |
| policy_loss             | -0.6107625    |
| qf1_loss                | 1.3911332e-05 |
| qf2_loss                | 1.3147113e-05 |
| time_elapsed            | 1685          |
| total timesteps         | 236417        |
| value_loss              | 1.4578393e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0007632368   |
| ent_coef_loss           | -2.6795483     |
| entropy                 | 1.4641871      |
| episodes                | 932            |
| fps                     | 140            |
| mean 100 episode reward | 0.9            |
| n_updates               | 236998         |
| policy_loss             | -0.6348135     |
| qf1_loss                | 9.506673e-06   |
| qf2_loss                | 1.04953415e-05 |
| time_elapsed            | 1690           |
| total timesteps         | 237098         |
| value_loss              | 1.6555536e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007730935  |
| ent_coef_loss           | 0.33086255    |
| entropy                 | 1.5835422     |
| episodes                | 936           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 237702        |
| policy_loss             | -0.6234028    |
| qf1_loss                | 2.330932e-05  |
| qf2_loss                | 1.8920835e-05 |
| time_elapsed            | 1695          |
| total timesteps         | 237802        |
| value_loss              | 2.6649815e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007963773  |
| ent_coef_loss           | 0.27053493    |
| entropy                 | 1.4762304     |
| episodes                | 940           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 238435        |
| policy_loss             | -0.5673225    |
| qf1_loss                | 4.2445674e-05 |
| qf2_loss                | 3.1186926e-05 |
| time_elapsed            | 1700          |
| total timesteps         | 238535        |
| value_loss              | 5.0726398e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007532295  |
| ent_coef_loss           | -0.3007841    |
| entropy                 | 1.4681892     |
| episodes                | 944           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 239100        |
| policy_loss             | -0.60845554   |
| qf1_loss                | 1.063299e-05  |
| qf2_loss                | 1.2803548e-05 |
| time_elapsed            | 1705          |
| total timesteps         | 239200        |
| value_loss              | 2.058133e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007673348  |
| ent_coef_loss           | 0.92798805    |
| entropy                 | 1.4303608     |
| episodes                | 948           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 239742        |
| policy_loss             | -0.60363495   |
| qf1_loss                | 5.1522075e-05 |
| qf2_loss                | 3.0090981e-05 |
| time_elapsed            | 1709          |
| total timesteps         | 239842        |
| value_loss              | 5.062048e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00074582844 |
| ent_coef_loss           | -2.6774182    |
| entropy                 | 1.3777797     |
| episodes                | 952           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 240667        |
| policy_loss             | -0.6334901    |
| qf1_loss                | 1.0476874e-05 |
| qf2_loss                | 1.0892157e-05 |
| time_elapsed            | 1716          |
| total timesteps         | 240767        |
| value_loss              | 1.4181161e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00075154076 |
| ent_coef_loss           | -0.32906976   |
| entropy                 | 1.2628348     |
| episodes                | 956           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 241588        |
| policy_loss             | -0.63500583   |
| qf1_loss                | 1.1467141e-05 |
| qf2_loss                | 8.4725625e-06 |
| time_elapsed            | 1723          |
| total timesteps         | 241688        |
| value_loss              | 9.1567235e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00084268645 |
| ent_coef_loss           | 0.7575532     |
| entropy                 | 1.370477      |
| episodes                | 960           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 242509        |
| policy_loss             | -0.6342703    |
| qf1_loss                | 2.2770088e-05 |
| qf2_loss                | 1.3375742e-05 |
| time_elapsed            | 1729          |
| total timesteps         | 242609        |
| value_loss              | 1.971627e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00076375226 |
| ent_coef_loss           | -1.2903416    |
| entropy                 | 1.2924132     |
| episodes                | 964           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 243210        |
| policy_loss             | -0.6381129    |
| qf1_loss                | 8.657233e-06  |
| qf2_loss                | 1.1517037e-05 |
| time_elapsed            | 1734          |
| total timesteps         | 243310        |
| value_loss              | 1.5525824e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007524892  |
| ent_coef_loss           | 0.4984546     |
| entropy                 | 1.4655576     |
| episodes                | 968           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 243906        |
| policy_loss             | -0.64388025   |
| qf1_loss                | 9.656082e-06  |
| qf2_loss                | 5.376398e-06  |
| time_elapsed            | 1739          |
| total timesteps         | 244006        |
| value_loss              | 1.2173185e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007516651  |
| ent_coef_loss           | -1.8983692    |
| entropy                 | 1.3489234     |
| episodes                | 972           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 244560        |
| policy_loss             | -0.59929943   |
| qf1_loss                | 2.4351992e-05 |
| qf2_loss                | 2.7743537e-05 |
| time_elapsed            | 1744          |
| total timesteps         | 244660        |
| value_loss              | 2.3440207e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00081677415 |
| ent_coef_loss           | 2.8921325     |
| entropy                 | 1.4790978     |
| episodes                | 976           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 245323        |
| policy_loss             | -0.61966646   |
| qf1_loss                | 1.2684851e-05 |
| qf2_loss                | 7.979084e-06  |
| time_elapsed            | 1749          |
| total timesteps         | 245423        |
| value_loss              | 1.5072614e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007930399  |
| ent_coef_loss           | 3.9129105     |
| entropy                 | 1.3896742     |
| episodes                | 980           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 245967        |
| policy_loss             | -0.5754344    |
| qf1_loss                | 3.5868252e-05 |
| qf2_loss                | 3.8292063e-05 |
| time_elapsed            | 1754          |
| total timesteps         | 246067        |
| value_loss              | 5.3281598e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00075047003 |
| ent_coef_loss           | 1.9929972     |
| entropy                 | 1.2883309     |
| episodes                | 984           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 246613        |
| policy_loss             | -0.622942     |
| qf1_loss                | 1.4096223e-05 |
| qf2_loss                | 3.4583816e-05 |
| time_elapsed            | 1759          |
| total timesteps         | 246713        |
| value_loss              | 3.8396003e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0008231115 |
| ent_coef_loss           | 0.21565461   |
| entropy                 | 1.4864614    |
| episodes                | 988          |
| fps                     | 140          |
| mean 100 episode reward | 0.9          |
| n_updates               | 247257       |
| policy_loss             | -0.62217724  |
| qf1_loss                | 2.860542e-05 |
| qf2_loss                | 2.984381e-05 |
| time_elapsed            | 1763         |
| total timesteps         | 247357       |
| value_loss              | 1.390616e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008260786  |
| ent_coef_loss           | -1.0552539    |
| entropy                 | 1.4747584     |
| episodes                | 992           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 247963        |
| policy_loss             | -0.6130085    |
| qf1_loss                | 9.418793e-06  |
| qf2_loss                | 9.980632e-06  |
| time_elapsed            | 1768          |
| total timesteps         | 248063        |
| value_loss              | 3.1946744e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008178689  |
| ent_coef_loss           | 0.80480134    |
| entropy                 | 1.3415959     |
| episodes                | 996           |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 248675        |
| policy_loss             | -0.5996733    |
| qf1_loss                | 5.742114e-06  |
| qf2_loss                | 1.0675208e-05 |
| time_elapsed            | 1773          |
| total timesteps         | 248775        |
| value_loss              | 2.3577022e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085198093 |
| ent_coef_loss           | -0.877522     |
| entropy                 | 1.3769062     |
| episodes                | 1000          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 249395        |
| policy_loss             | -0.6277826    |
| qf1_loss                | 2.6888818e-05 |
| qf2_loss                | 1.8621287e-05 |
| time_elapsed            | 1778          |
| total timesteps         | 249495        |
| value_loss              | 3.931119e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086195517 |
| ent_coef_loss           | -2.5929039    |
| entropy                 | 1.6040354     |
| episodes                | 1004          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 250048        |
| policy_loss             | -0.63304746   |
| qf1_loss                | 7.501062e-06  |
| qf2_loss                | 1.1633432e-05 |
| time_elapsed            | 1783          |
| total timesteps         | 250148        |
| value_loss              | 1.7359096e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008872424  |
| ent_coef_loss           | 2.2286325     |
| entropy                 | 1.4657835     |
| episodes                | 1008          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 250687        |
| policy_loss             | -0.58147424   |
| qf1_loss                | 1.7552926e-05 |
| qf2_loss                | 1.9872694e-05 |
| time_elapsed            | 1788          |
| total timesteps         | 250787        |
| value_loss              | 3.0872834e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00088950276 |
| ent_coef_loss           | -2.0904112    |
| entropy                 | 1.5203936     |
| episodes                | 1012          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 251364        |
| policy_loss             | -0.6295761    |
| qf1_loss                | 0.004690945   |
| qf2_loss                | 0.0046924697  |
| time_elapsed            | 1793          |
| total timesteps         | 251464        |
| value_loss              | 3.096438e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007926297  |
| ent_coef_loss           | 0.092634976   |
| entropy                 | 1.3583641     |
| episodes                | 1016          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 251997        |
| policy_loss             | -0.6446253    |
| qf1_loss                | 1.9828782e-05 |
| qf2_loss                | 2.2169794e-05 |
| time_elapsed            | 1797          |
| total timesteps         | 252097        |
| value_loss              | 1.2079234e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007266462  |
| ent_coef_loss           | 0.19727856    |
| entropy                 | 1.3266976     |
| episodes                | 1020          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 252643        |
| policy_loss             | -0.59519756   |
| qf1_loss                | 4.983577e-05  |
| qf2_loss                | 4.2686726e-05 |
| time_elapsed            | 1802          |
| total timesteps         | 252743        |
| value_loss              | 4.7539746e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000720901   |
| ent_coef_loss           | 3.682315      |
| entropy                 | 1.33693       |
| episodes                | 1024          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 253329        |
| policy_loss             | -0.6448262    |
| qf1_loss                | 1.0853612e-05 |
| qf2_loss                | 1.1170941e-05 |
| time_elapsed            | 1806          |
| total timesteps         | 253429        |
| value_loss              | 2.4779216e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00079553167  |
| ent_coef_loss           | 0.21105945     |
| entropy                 | 1.3529227      |
| episodes                | 1028           |
| fps                     | 140            |
| mean 100 episode reward | 0.9            |
| n_updates               | 254054         |
| policy_loss             | -0.6195619     |
| qf1_loss                | 2.1662912e-05  |
| qf2_loss                | 2.8103967e-05  |
| time_elapsed            | 1812           |
| total timesteps         | 254154         |
| value_loss              | 1.48621375e-05 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00082322495 |
| ent_coef_loss           | 2.023806      |
| entropy                 | 1.4345641     |
| episodes                | 1032          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 254705        |
| policy_loss             | -0.6107015    |
| qf1_loss                | 3.7460435e-05 |
| qf2_loss                | 3.531928e-05  |
| time_elapsed            | 1816          |
| total timesteps         | 254805        |
| value_loss              | 2.2095326e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00076868536  |
| ent_coef_loss           | -0.086254835   |
| entropy                 | 1.4548161      |
| episodes                | 1036           |
| fps                     | 140            |
| mean 100 episode reward | 0.9            |
| n_updates               | 255392         |
| policy_loss             | -0.6438116     |
| qf1_loss                | 7.286205e-06   |
| qf2_loss                | 7.1108543e-06  |
| time_elapsed            | 1821           |
| total timesteps         | 255492         |
| value_loss              | 1.17368545e-05 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00079977256 |
| ent_coef_loss           | 0.5848657     |
| entropy                 | 1.6232462     |
| episodes                | 1040          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 256031        |
| policy_loss             | -0.63510215   |
| qf1_loss                | 2.7461014e-05 |
| qf2_loss                | 3.652827e-05  |
| time_elapsed            | 1826          |
| total timesteps         | 256131        |
| value_loss              | 6.170889e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00072496355 |
| ent_coef_loss           | -1.3151553    |
| entropy                 | 1.4314156     |
| episodes                | 1044          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 256690        |
| policy_loss             | -0.62319577   |
| qf1_loss                | 3.829017e-05  |
| qf2_loss                | 3.068702e-05  |
| time_elapsed            | 1831          |
| total timesteps         | 256790        |
| value_loss              | 3.249178e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007810816  |
| ent_coef_loss           | -2.1380153    |
| entropy                 | 1.5180559     |
| episodes                | 1048          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 257368        |
| policy_loss             | -0.59124845   |
| qf1_loss                | 2.4841494e-05 |
| qf2_loss                | 3.563253e-05  |
| time_elapsed            | 1835          |
| total timesteps         | 257468        |
| value_loss              | 4.2227526e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007812988  |
| ent_coef_loss           | -0.8917692    |
| entropy                 | 1.5321895     |
| episodes                | 1052          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 258063        |
| policy_loss             | -0.6257573    |
| qf1_loss                | 1.1991448e-05 |
| qf2_loss                | 1.1598375e-05 |
| time_elapsed            | 1840          |
| total timesteps         | 258163        |
| value_loss              | 1.4340358e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008188761  |
| ent_coef_loss           | -2.6411934    |
| entropy                 | 1.5278262     |
| episodes                | 1056          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 258681        |
| policy_loss             | -0.64344823   |
| qf1_loss                | 2.6631893e-05 |
| qf2_loss                | 5.136697e-05  |
| time_elapsed            | 1845          |
| total timesteps         | 258781        |
| value_loss              | 5.152284e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00078532187 |
| ent_coef_loss           | 0.5324861     |
| entropy                 | 1.2947972     |
| episodes                | 1060          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 259404        |
| policy_loss             | -0.6397117    |
| qf1_loss                | 2.5826796e-05 |
| qf2_loss                | 2.3555762e-05 |
| time_elapsed            | 1850          |
| total timesteps         | 259504        |
| value_loss              | 1.9640305e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0006317175 |
| ent_coef_loss           | 0.9254544    |
| entropy                 | 1.1130173    |
| episodes                | 1064         |
| fps                     | 140          |
| mean 100 episode reward | 0.9          |
| n_updates               | 260175       |
| policy_loss             | -0.5925547   |
| qf1_loss                | 8.898555e-05 |
| qf2_loss                | 6.889848e-05 |
| time_elapsed            | 1856         |
| total timesteps         | 260275       |
| value_loss              | 7.557616e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00055487617 |
| ent_coef_loss           | -1.6813056    |
| entropy                 | 0.82413214    |
| episodes                | 1068          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 260954        |
| policy_loss             | -0.62703097   |
| qf1_loss                | 1.2940391e-05 |
| qf2_loss                | 1.6559461e-05 |
| time_elapsed            | 1861          |
| total timesteps         | 261054        |
| value_loss              | 2.3790239e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00058461435 |
| ent_coef_loss           | 0.4988935     |
| entropy                 | 0.97633016    |
| episodes                | 1072          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 261704        |
| policy_loss             | -0.5919702    |
| qf1_loss                | 1.1181881e-05 |
| qf2_loss                | 2.6952768e-05 |
| time_elapsed            | 1866          |
| total timesteps         | 261804        |
| value_loss              | 3.754191e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006452019  |
| ent_coef_loss           | -1.2279723    |
| entropy                 | 1.2416365     |
| episodes                | 1076          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 262445        |
| policy_loss             | -0.6136322    |
| qf1_loss                | 0.0025874535  |
| qf2_loss                | 0.0027800763  |
| time_elapsed            | 1872          |
| total timesteps         | 262545        |
| value_loss              | 2.5364936e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00068864244 |
| ent_coef_loss           | -0.11076808   |
| entropy                 | 1.1625491     |
| episodes                | 1080          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 263350        |
| policy_loss             | -0.6232475    |
| qf1_loss                | 1.6322607e-05 |
| qf2_loss                | 2.2239492e-05 |
| time_elapsed            | 1878          |
| total timesteps         | 263450        |
| value_loss              | 4.8276765e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0007137302 |
| ent_coef_loss           | -0.40709656  |
| entropy                 | 1.2980646    |
| episodes                | 1084         |
| fps                     | 140          |
| mean 100 episode reward | 0.9          |
| n_updates               | 264118       |
| policy_loss             | -0.5992418   |
| qf1_loss                | 0.006196565  |
| qf2_loss                | 0.006136547  |
| time_elapsed            | 1884         |
| total timesteps         | 264218       |
| value_loss              | 1.128733e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00081562717 |
| ent_coef_loss           | -1.983539     |
| entropy                 | 1.2313759     |
| episodes                | 1088          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 264811        |
| policy_loss             | -0.6103945    |
| qf1_loss                | 0.0025425865  |
| qf2_loss                | 0.0024834743  |
| time_elapsed            | 1889          |
| total timesteps         | 264911        |
| value_loss              | 0.0012173617  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00080589193 |
| ent_coef_loss           | -1.5034834    |
| entropy                 | 1.3271811     |
| episodes                | 1092          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 265764        |
| policy_loss             | -0.56991416   |
| qf1_loss                | 4.298907e-05  |
| qf2_loss                | 3.0235167e-05 |
| time_elapsed            | 1895          |
| total timesteps         | 265864        |
| value_loss              | 3.7281898e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007622337  |
| ent_coef_loss           | 0.6030519     |
| entropy                 | 1.3195467     |
| episodes                | 1096          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 266518        |
| policy_loss             | -0.6070237    |
| qf1_loss                | 1.9577703e-05 |
| qf2_loss                | 2.2902464e-05 |
| time_elapsed            | 1901          |
| total timesteps         | 266618        |
| value_loss              | 1.8311288e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008108977  |
| ent_coef_loss           | 0.38311028    |
| entropy                 | 1.4035926     |
| episodes                | 1100          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 267209        |
| policy_loss             | -0.6301721    |
| qf1_loss                | 0.00011740427 |
| qf2_loss                | 0.00011519977 |
| time_elapsed            | 1906          |
| total timesteps         | 267309        |
| value_loss              | 4.6747424e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008022174  |
| ent_coef_loss           | 1.0970099     |
| entropy                 | 1.4533455     |
| episodes                | 1104          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 267902        |
| policy_loss             | -0.6211347    |
| qf1_loss                | 2.3492365e-05 |
| qf2_loss                | 3.5494377e-05 |
| time_elapsed            | 1911          |
| total timesteps         | 268002        |
| value_loss              | 3.141893e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008445864  |
| ent_coef_loss           | 4.096154      |
| entropy                 | 1.3645331     |
| episodes                | 1108          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 268819        |
| policy_loss             | -0.5928929    |
| qf1_loss                | 3.3107408e-05 |
| qf2_loss                | 2.3033052e-05 |
| time_elapsed            | 1917          |
| total timesteps         | 268919        |
| value_loss              | 1.9454577e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008729373  |
| ent_coef_loss           | 1.4599832     |
| entropy                 | 1.3899205     |
| episodes                | 1112          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 269489        |
| policy_loss             | -0.59391916   |
| qf1_loss                | 2.0227026e-05 |
| qf2_loss                | 1.9286988e-05 |
| time_elapsed            | 1922          |
| total timesteps         | 269589        |
| value_loss              | 5.1479066e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090084143 |
| ent_coef_loss           | 0.8965755     |
| entropy                 | 1.4927229     |
| episodes                | 1116          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 270190        |
| policy_loss             | -0.61672294   |
| qf1_loss                | 3.7733305e-05 |
| qf2_loss                | 4.516432e-05  |
| time_elapsed            | 1927          |
| total timesteps         | 270290        |
| value_loss              | 4.5966204e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00079413166 |
| ent_coef_loss           | 0.90512145    |
| entropy                 | 1.1869903     |
| episodes                | 1120          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 270925        |
| policy_loss             | -0.58377635   |
| qf1_loss                | 3.684644e-05  |
| qf2_loss                | 2.4523604e-05 |
| time_elapsed            | 1933          |
| total timesteps         | 271025        |
| value_loss              | 2.1682274e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008575808  |
| ent_coef_loss           | 5.706732      |
| entropy                 | 1.4631782     |
| episodes                | 1124          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 271675        |
| policy_loss             | -0.59332013   |
| qf1_loss                | 4.5060922e-05 |
| qf2_loss                | 8.624901e-05  |
| time_elapsed            | 1938          |
| total timesteps         | 271775        |
| value_loss              | 6.350863e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007826803  |
| ent_coef_loss           | -3.337606     |
| entropy                 | 1.2813787     |
| episodes                | 1128          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 272543        |
| policy_loss             | -0.60662186   |
| qf1_loss                | 2.8392922e-05 |
| qf2_loss                | 2.5247353e-05 |
| time_elapsed            | 1944          |
| total timesteps         | 272643        |
| value_loss              | 3.909308e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007494079  |
| ent_coef_loss           | 0.048023105   |
| entropy                 | 1.2977531     |
| episodes                | 1132          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 273257        |
| policy_loss             | -0.5946905    |
| qf1_loss                | 1.6395603e-05 |
| qf2_loss                | 1.7752995e-05 |
| time_elapsed            | 1949          |
| total timesteps         | 273357        |
| value_loss              | 3.424096e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00079896796 |
| ent_coef_loss           | 0.50111246    |
| entropy                 | 1.454472      |
| episodes                | 1136          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 273933        |
| policy_loss             | -0.61666036   |
| qf1_loss                | 1.3431227e-05 |
| qf2_loss                | 1.4584444e-05 |
| time_elapsed            | 1954          |
| total timesteps         | 274033        |
| value_loss              | 1.4774233e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008295158  |
| ent_coef_loss           | 1.0537105     |
| entropy                 | 1.3109131     |
| episodes                | 1140          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 274544        |
| policy_loss             | -0.6180451    |
| qf1_loss                | 0.00012489237 |
| qf2_loss                | 7.457439e-05  |
| time_elapsed            | 1958          |
| total timesteps         | 274644        |
| value_loss              | 3.6755213e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0008532449 |
| ent_coef_loss           | 0.21659595   |
| entropy                 | 1.4558616    |
| episodes                | 1144         |
| fps                     | 140          |
| mean 100 episode reward | 0.8          |
| n_updates               | 275231       |
| policy_loss             | -0.6084962   |
| qf1_loss                | 4.600363e-05 |
| qf2_loss                | 4.698528e-05 |
| time_elapsed            | 1963         |
| total timesteps         | 275331       |
| value_loss              | 5.469051e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008470875  |
| ent_coef_loss           | -3.8335524    |
| entropy                 | 1.264267      |
| episodes                | 1148          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 275949        |
| policy_loss             | -0.6171957    |
| qf1_loss                | 1.6662842e-05 |
| qf2_loss                | 3.3191696e-05 |
| time_elapsed            | 1969          |
| total timesteps         | 276049        |
| value_loss              | 2.4467667e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00083747454 |
| ent_coef_loss           | -2.0509675    |
| entropy                 | 1.3722537     |
| episodes                | 1152          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 276611        |
| policy_loss             | -0.5355204    |
| qf1_loss                | 1.9032048e-05 |
| qf2_loss                | 1.6452934e-05 |
| time_elapsed            | 1973          |
| total timesteps         | 276711        |
| value_loss              | 3.4205274e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0008620069   |
| ent_coef_loss           | 0.69365644     |
| entropy                 | 1.3392913      |
| episodes                | 1156           |
| fps                     | 140            |
| mean 100 episode reward | 0.8            |
| n_updates               | 277262         |
| policy_loss             | -0.6008144     |
| qf1_loss                | 1.46158145e-05 |
| qf2_loss                | 4.309643e-05   |
| time_elapsed            | 1978           |
| total timesteps         | 277362         |
| value_loss              | 7.506907e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087045913 |
| ent_coef_loss           | 1.9692906     |
| entropy                 | 1.383504      |
| episodes                | 1160          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 277926        |
| policy_loss             | -0.60365164   |
| qf1_loss                | 1.4304141e-05 |
| qf2_loss                | 1.91068e-05   |
| time_elapsed            | 1983          |
| total timesteps         | 278026        |
| value_loss              | 2.882515e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000810032   |
| ent_coef_loss           | -5.230852     |
| entropy                 | 1.2737434     |
| episodes                | 1164          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 278657        |
| policy_loss             | -0.59136415   |
| qf1_loss                | 2.5403257e-05 |
| qf2_loss                | 5.763663e-05  |
| time_elapsed            | 1988          |
| total timesteps         | 278757        |
| value_loss              | 2.3443803e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00084593904 |
| ent_coef_loss           | -1.7093515    |
| entropy                 | 1.3252642     |
| episodes                | 1168          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 279320        |
| policy_loss             | -0.5765133    |
| qf1_loss                | 9.833538e-06  |
| qf2_loss                | 1.2561939e-05 |
| time_elapsed            | 1993          |
| total timesteps         | 279420        |
| value_loss              | 3.2699598e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008065216  |
| ent_coef_loss           | -1.199765     |
| entropy                 | 1.5349877     |
| episodes                | 1172          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 279979        |
| policy_loss             | -0.62257624   |
| qf1_loss                | 2.4138426e-05 |
| qf2_loss                | 1.9030733e-05 |
| time_elapsed            | 1998          |
| total timesteps         | 280079        |
| value_loss              | 5.576774e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008085737  |
| ent_coef_loss           | 1.8038253     |
| entropy                 | 1.3712568     |
| episodes                | 1176          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 280946        |
| policy_loss             | -0.5768462    |
| qf1_loss                | 1.529069e-05  |
| qf2_loss                | 1.6392896e-05 |
| time_elapsed            | 2004          |
| total timesteps         | 281046        |
| value_loss              | 3.1979598e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008507452  |
| ent_coef_loss           | -1.1118287    |
| entropy                 | 1.3896395     |
| episodes                | 1180          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 281607        |
| policy_loss             | -0.5969145    |
| qf1_loss                | 1.4136316e-05 |
| qf2_loss                | 1.7393031e-05 |
| time_elapsed            | 2009          |
| total timesteps         | 281707        |
| value_loss              | 1.5426504e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008270509  |
| ent_coef_loss           | 2.3178663     |
| entropy                 | 1.3728783     |
| episodes                | 1184          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 282254        |
| policy_loss             | -0.58501756   |
| qf1_loss                | 1.9890393e-05 |
| qf2_loss                | 2.5455158e-05 |
| time_elapsed            | 2014          |
| total timesteps         | 282354        |
| value_loss              | 3.5911155e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000776006   |
| ent_coef_loss           | -0.17536134   |
| entropy                 | 1.3179846     |
| episodes                | 1188          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 283194        |
| policy_loss             | -0.557403     |
| qf1_loss                | 3.2923243e-05 |
| qf2_loss                | 4.0565086e-05 |
| time_elapsed            | 2020          |
| total timesteps         | 283294        |
| value_loss              | 4.125065e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007724343  |
| ent_coef_loss           | -3.0722744    |
| entropy                 | 1.303938      |
| episodes                | 1192          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 283936        |
| policy_loss             | -0.5641941    |
| qf1_loss                | 1.2215267e-05 |
| qf2_loss                | 2.026475e-05  |
| time_elapsed            | 2026          |
| total timesteps         | 284036        |
| value_loss              | 1.2670929e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008160524  |
| ent_coef_loss           | -0.7636068    |
| entropy                 | 1.342258      |
| episodes                | 1196          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 284592        |
| policy_loss             | -0.580812     |
| qf1_loss                | 0.00010749882 |
| qf2_loss                | 0.00010705227 |
| time_elapsed            | 2031          |
| total timesteps         | 284692        |
| value_loss              | 8.0773854e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087403983 |
| ent_coef_loss           | -1.5121775    |
| entropy                 | 1.3331418     |
| episodes                | 1200          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 285228        |
| policy_loss             | -0.6232955    |
| qf1_loss                | 2.7126312e-05 |
| qf2_loss                | 1.7302342e-05 |
| time_elapsed            | 2035          |
| total timesteps         | 285328        |
| value_loss              | 2.7116697e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00084806955 |
| ent_coef_loss           | 0.19030893    |
| entropy                 | 1.2833196     |
| episodes                | 1204          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 285927        |
| policy_loss             | -0.6015577    |
| qf1_loss                | 0.0001221397  |
| qf2_loss                | 0.0001338173  |
| time_elapsed            | 2040          |
| total timesteps         | 286027        |
| value_loss              | 0.00011342302 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000837645   |
| ent_coef_loss           | 1.1796051     |
| entropy                 | 1.3211174     |
| episodes                | 1208          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 286622        |
| policy_loss             | -0.5848373    |
| qf1_loss                | 2.02408e-05   |
| qf2_loss                | 1.5385383e-05 |
| time_elapsed            | 2045          |
| total timesteps         | 286722        |
| value_loss              | 3.2262742e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008570555  |
| ent_coef_loss           | 2.592043      |
| entropy                 | 1.395859      |
| episodes                | 1212          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 287306        |
| policy_loss             | -0.5816801    |
| qf1_loss                | 2.1883807e-05 |
| qf2_loss                | 2.2801636e-05 |
| time_elapsed            | 2050          |
| total timesteps         | 287406        |
| value_loss              | 0.00018688806 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00083637267 |
| ent_coef_loss           | 0.77148074    |
| entropy                 | 1.3707424     |
| episodes                | 1216          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 287965        |
| policy_loss             | -0.59155357   |
| qf1_loss                | 2.6319805e-05 |
| qf2_loss                | 4.5141143e-05 |
| time_elapsed            | 2055          |
| total timesteps         | 288065        |
| value_loss              | 3.3274217e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0008672831 |
| ent_coef_loss           | -0.4875735   |
| entropy                 | 1.5360152    |
| episodes                | 1220         |
| fps                     | 140          |
| mean 100 episode reward | 0.8          |
| n_updates               | 288617       |
| policy_loss             | -0.59584033  |
| qf1_loss                | 9.34173e-05  |
| qf2_loss                | 9.796637e-05 |
| time_elapsed            | 2059         |
| total timesteps         | 288717       |
| value_loss              | 3.770826e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008308879  |
| ent_coef_loss           | -1.0960243    |
| entropy                 | 1.4423614     |
| episodes                | 1224          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 289254        |
| policy_loss             | -0.54998946   |
| qf1_loss                | 1.0923229e-05 |
| qf2_loss                | 1.8173898e-05 |
| time_elapsed            | 2064          |
| total timesteps         | 289354        |
| value_loss              | 3.3382108e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00083920866 |
| ent_coef_loss           | -1.914703     |
| entropy                 | 1.4637511     |
| episodes                | 1228          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 289972        |
| policy_loss             | -0.62062776   |
| qf1_loss                | 2.3100576e-05 |
| qf2_loss                | 2.1756408e-05 |
| time_elapsed            | 2069          |
| total timesteps         | 290072        |
| value_loss              | 3.065059e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008555859  |
| ent_coef_loss           | -0.49788803   |
| entropy                 | 1.3979316     |
| episodes                | 1232          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 290611        |
| policy_loss             | -0.5806466    |
| qf1_loss                | 3.3583965e-05 |
| qf2_loss                | 5.7664645e-05 |
| time_elapsed            | 2074          |
| total timesteps         | 290711        |
| value_loss              | 4.2604865e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00079506333 |
| ent_coef_loss           | -2.4090745    |
| entropy                 | 1.3708726     |
| episodes                | 1236          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 291278        |
| policy_loss             | -0.59632826   |
| qf1_loss                | 2.0606381e-05 |
| qf2_loss                | 1.972441e-05  |
| time_elapsed            | 2078          |
| total timesteps         | 291378        |
| value_loss              | 4.1371117e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007603888  |
| ent_coef_loss           | 0.7556385     |
| entropy                 | 1.3554795     |
| episodes                | 1240          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 292028        |
| policy_loss             | -0.56539327   |
| qf1_loss                | 1.2064991e-05 |
| qf2_loss                | 2.0734735e-05 |
| time_elapsed            | 2084          |
| total timesteps         | 292128        |
| value_loss              | 3.0968164e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007890149  |
| ent_coef_loss           | 1.6295614     |
| entropy                 | 1.5547487     |
| episodes                | 1244          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 293100        |
| policy_loss             | -0.5580872    |
| qf1_loss                | 4.8595823e-05 |
| qf2_loss                | 2.445927e-05  |
| time_elapsed            | 2091          |
| total timesteps         | 293200        |
| value_loss              | 4.536721e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007928739  |
| ent_coef_loss           | 1.6484641     |
| entropy                 | 1.3621922     |
| episodes                | 1248          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 294142        |
| policy_loss             | -0.5547302    |
| qf1_loss                | 4.5805722e-05 |
| qf2_loss                | 3.2276046e-05 |
| time_elapsed            | 2099          |
| total timesteps         | 294242        |
| value_loss              | 5.7731148e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008027692  |
| ent_coef_loss           | 0.4719817     |
| entropy                 | 1.3875276     |
| episodes                | 1252          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 295645        |
| policy_loss             | -0.52903897   |
| qf1_loss                | 3.721402e-05  |
| qf2_loss                | 2.6858648e-05 |
| time_elapsed            | 2109          |
| total timesteps         | 295745        |
| value_loss              | 7.088569e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087608024 |
| ent_coef_loss           | -0.8108798    |
| entropy                 | 1.4738495     |
| episodes                | 1256          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 296552        |
| policy_loss             | -0.6523851    |
| qf1_loss                | 2.1321182e-05 |
| qf2_loss                | 1.6950537e-05 |
| time_elapsed            | 2116          |
| total timesteps         | 296652        |
| value_loss              | 2.2774946e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096839515 |
| ent_coef_loss           | -0.040901005  |
| entropy                 | 1.4128151     |
| episodes                | 1260          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 298062        |
| policy_loss             | -0.5210577    |
| qf1_loss                | 4.64416e-05   |
| qf2_loss                | 3.579597e-05  |
| time_elapsed            | 2127          |
| total timesteps         | 298162        |
| value_loss              | 5.0135495e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096482167 |
| ent_coef_loss           | 1.2649752     |
| entropy                 | 1.3696775     |
| episodes                | 1264          |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 299288        |
| policy_loss             | -0.52963614   |
| qf1_loss                | 4.4273776e-05 |
| qf2_loss                | 4.3462012e-05 |
| time_elapsed            | 2136          |
| total timesteps         | 299388        |
| value_loss              | 0.0001281547  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009539177  |
| ent_coef_loss           | 3.6060934     |
| entropy                 | 1.4003484     |
| episodes                | 1268          |
| fps                     | 140           |
| mean 100 episode reward | 0.6           |
| n_updates               | 299995        |
| policy_loss             | -0.5666519    |
| qf1_loss                | 0.00010190552 |
| qf2_loss                | 9.946561e-05  |
| time_elapsed            | 2141          |
| total timesteps         | 300095        |
| value_loss              | 7.6932294e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010228672 |
| ent_coef_loss           | -0.567266    |
| entropy                 | 1.3627658    |
| episodes                | 1272         |
| fps                     | 140          |
| mean 100 episode reward | 0.6          |
| n_updates               | 300680       |
| policy_loss             | -0.5556551   |
| qf1_loss                | 3.664293e-05 |
| qf2_loss                | 3.833089e-05 |
| time_elapsed            | 2146         |
| total timesteps         | 300780       |
| value_loss              | 6.205491e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010340202  |
| ent_coef_loss           | -0.19336829   |
| entropy                 | 1.560773      |
| episodes                | 1276          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 301325        |
| policy_loss             | -0.55170727   |
| qf1_loss                | 2.2103131e-05 |
| qf2_loss                | 3.8526814e-05 |
| time_elapsed            | 2150          |
| total timesteps         | 301425        |
| value_loss              | 5.8954385e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010112729  |
| ent_coef_loss           | 2.4185894     |
| entropy                 | 1.4481478     |
| episodes                | 1280          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 301976        |
| policy_loss             | -0.5546791    |
| qf1_loss                | 5.4645487e-05 |
| qf2_loss                | 5.1746e-05    |
| time_elapsed            | 2155          |
| total timesteps         | 302076        |
| value_loss              | 8.783093e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009654894  |
| ent_coef_loss           | -1.0899006    |
| entropy                 | 1.385443      |
| episodes                | 1284          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 302642        |
| policy_loss             | -0.540676     |
| qf1_loss                | 0.00014161404 |
| qf2_loss                | 0.00014521049 |
| time_elapsed            | 2160          |
| total timesteps         | 302742        |
| value_loss              | 6.0188635e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009981772  |
| ent_coef_loss           | 1.5661867     |
| entropy                 | 1.3902757     |
| episodes                | 1288          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 303321        |
| policy_loss             | -0.55120635   |
| qf1_loss                | 3.636678e-05  |
| qf2_loss                | 3.1857024e-05 |
| time_elapsed            | 2165          |
| total timesteps         | 303421        |
| value_loss              | 5.8246762e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009468477  |
| ent_coef_loss           | -2.6484308    |
| entropy                 | 1.2255754     |
| episodes                | 1292          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 303970        |
| policy_loss             | -0.54015195   |
| qf1_loss                | 2.7699632e-05 |
| qf2_loss                | 2.5534235e-05 |
| time_elapsed            | 2169          |
| total timesteps         | 304070        |
| value_loss              | 6.867062e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000968487   |
| ent_coef_loss           | -1.6358577    |
| entropy                 | 1.4369414     |
| episodes                | 1296          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 304691        |
| policy_loss             | -0.5888436    |
| qf1_loss                | 0.00020204004 |
| qf2_loss                | 0.00012535165 |
| time_elapsed            | 2175          |
| total timesteps         | 304791        |
| value_loss              | 4.5698216e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009279475  |
| ent_coef_loss           | 0.97884417    |
| entropy                 | 1.372632      |
| episodes                | 1300          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 305405        |
| policy_loss             | -0.59812844   |
| qf1_loss                | 3.2738273e-05 |
| qf2_loss                | 3.4016757e-05 |
| time_elapsed            | 2180          |
| total timesteps         | 305505        |
| value_loss              | 1.6942078e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096847315 |
| ent_coef_loss           | -0.36220542   |
| entropy                 | 1.302607      |
| episodes                | 1304          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 306347        |
| policy_loss             | -0.51917756   |
| qf1_loss                | 0.00013459896 |
| qf2_loss                | 0.00016102674 |
| time_elapsed            | 2186          |
| total timesteps         | 306447        |
| value_loss              | 2.3822377e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009796771  |
| ent_coef_loss           | 1.4365065     |
| entropy                 | 1.3894331     |
| episodes                | 1308          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 307020        |
| policy_loss             | -0.6028757    |
| qf1_loss                | 1.6664326e-05 |
| qf2_loss                | 2.3687851e-05 |
| time_elapsed            | 2191          |
| total timesteps         | 307120        |
| value_loss              | 2.309611e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010138991  |
| ent_coef_loss           | 0.7703991     |
| entropy                 | 1.236993      |
| episodes                | 1312          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 307969        |
| policy_loss             | -0.5377847    |
| qf1_loss                | 3.3531145e-05 |
| qf2_loss                | 4.258958e-05  |
| time_elapsed            | 2198          |
| total timesteps         | 308069        |
| value_loss              | 8.401938e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009963093  |
| ent_coef_loss           | 0.40854603    |
| entropy                 | 1.5167053     |
| episodes                | 1316          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 308637        |
| policy_loss             | -0.5867118    |
| qf1_loss                | 0.00012276063 |
| qf2_loss                | 2.213662e-05  |
| time_elapsed            | 2203          |
| total timesteps         | 308737        |
| value_loss              | 0.00012764803 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010447049 |
| ent_coef_loss           | 1.878267     |
| entropy                 | 1.448587     |
| episodes                | 1320         |
| fps                     | 140          |
| mean 100 episode reward | 0.7          |
| n_updates               | 309404       |
| policy_loss             | -0.56331444  |
| qf1_loss                | 4.966993e-05 |
| qf2_loss                | 4.044358e-05 |
| time_elapsed            | 2208         |
| total timesteps         | 309504       |
| value_loss              | 0.0001772978 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001040375   |
| ent_coef_loss           | -0.112561226  |
| entropy                 | 1.285481      |
| episodes                | 1324          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 310114        |
| policy_loss             | -0.5530714    |
| qf1_loss                | 5.28178e-05   |
| qf2_loss                | 8.6037806e-05 |
| time_elapsed            | 2213          |
| total timesteps         | 310214        |
| value_loss              | 0.00022307655 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010580352  |
| ent_coef_loss           | 0.9965154     |
| entropy                 | 1.4594853     |
| episodes                | 1328          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 310815        |
| policy_loss             | -0.50442684   |
| qf1_loss                | 5.2338364e-05 |
| qf2_loss                | 2.9970925e-05 |
| time_elapsed            | 2218          |
| total timesteps         | 310915        |
| value_loss              | 5.1341525e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010948717  |
| ent_coef_loss           | 1.9757533     |
| entropy                 | 1.4143734     |
| episodes                | 1332          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 311485        |
| policy_loss             | -0.500666     |
| qf1_loss                | 5.2658008e-05 |
| qf2_loss                | 6.832581e-05  |
| time_elapsed            | 2223          |
| total timesteps         | 311585        |
| value_loss              | 5.2566967e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001113775   |
| ent_coef_loss           | -0.47453046   |
| entropy                 | 1.3956255     |
| episodes                | 1336          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 312196        |
| policy_loss             | -0.5011829    |
| qf1_loss                | 5.4414628e-05 |
| qf2_loss                | 3.2240692e-05 |
| time_elapsed            | 2228          |
| total timesteps         | 312296        |
| value_loss              | 0.00012705298 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001083148   |
| ent_coef_loss           | 2.3312898     |
| entropy                 | 1.58535       |
| episodes                | 1340          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 313006        |
| policy_loss             | -0.5938158    |
| qf1_loss                | 4.0664516e-05 |
| qf2_loss                | 2.9244364e-05 |
| time_elapsed            | 2234          |
| total timesteps         | 313106        |
| value_loss              | 3.915023e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010951364  |
| ent_coef_loss           | -0.95133686   |
| entropy                 | 1.403458      |
| episodes                | 1344          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 313749        |
| policy_loss             | -0.52137554   |
| qf1_loss                | 6.7451285e-05 |
| qf2_loss                | 3.4193927e-05 |
| time_elapsed            | 2239          |
| total timesteps         | 313849        |
| value_loss              | 5.174925e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010402326  |
| ent_coef_loss           | 2.2063432     |
| entropy                 | 1.4844782     |
| episodes                | 1348          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 314390        |
| policy_loss             | -0.5327561    |
| qf1_loss                | 5.046926e-05  |
| qf2_loss                | 4.5485045e-05 |
| time_elapsed            | 2244          |
| total timesteps         | 314490        |
| value_loss              | 3.9912185e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001034037   |
| ent_coef_loss           | -0.20414776   |
| entropy                 | 1.5100305     |
| episodes                | 1352          |
| fps                     | 140           |
| mean 100 episode reward | 0.7           |
| n_updates               | 315069        |
| policy_loss             | -0.54583347   |
| qf1_loss                | 3.7956626e-05 |
| qf2_loss                | 4.446994e-05  |
| time_elapsed            | 2249          |
| total timesteps         | 315169        |
| value_loss              | 9.291687e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010734835  |
| ent_coef_loss           | 0.30821443    |
| entropy                 | 1.2723528     |
| episodes                | 1356          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 315727        |
| policy_loss             | -0.5288259    |
| qf1_loss                | 3.782517e-05  |
| qf2_loss                | 2.6785709e-05 |
| time_elapsed            | 2253          |
| total timesteps         | 315827        |
| value_loss              | 5.2410607e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010153631  |
| ent_coef_loss           | 2.5205448     |
| entropy                 | 1.3639417     |
| episodes                | 1360          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 316406        |
| policy_loss             | -0.5379596    |
| qf1_loss                | 2.7829643e-05 |
| qf2_loss                | 2.4799507e-05 |
| time_elapsed            | 2258          |
| total timesteps         | 316506        |
| value_loss              | 4.0890285e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001102967   |
| ent_coef_loss           | 0.8185929     |
| entropy                 | 1.3983092     |
| episodes                | 1364          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 317202        |
| policy_loss             | -0.51866233   |
| qf1_loss                | 2.7632776e-05 |
| qf2_loss                | 2.1328271e-05 |
| time_elapsed            | 2264          |
| total timesteps         | 317302        |
| value_loss              | 4.769888e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010582395  |
| ent_coef_loss           | 1.8571092     |
| entropy                 | 1.3029962     |
| episodes                | 1368          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 318142        |
| policy_loss             | -0.5031593    |
| qf1_loss                | 7.037005e-05  |
| qf2_loss                | 0.00010611024 |
| time_elapsed            | 2271          |
| total timesteps         | 318242        |
| value_loss              | 5.383673e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011337283  |
| ent_coef_loss           | -1.4712448    |
| entropy                 | 1.3950169     |
| episodes                | 1372          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 318799        |
| policy_loss             | -0.5244311    |
| qf1_loss                | 3.1984368e-05 |
| qf2_loss                | 8.112694e-05  |
| time_elapsed            | 2276          |
| total timesteps         | 318899        |
| value_loss              | 7.810762e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011076577  |
| ent_coef_loss           | 1.0235802     |
| entropy                 | 1.4249413     |
| episodes                | 1376          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 319577        |
| policy_loss             | -0.51207626   |
| qf1_loss                | 2.49343e-05   |
| qf2_loss                | 3.1309537e-05 |
| time_elapsed            | 2281          |
| total timesteps         | 319677        |
| value_loss              | 7.617583e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010847838  |
| ent_coef_loss           | 0.68686414    |
| entropy                 | 1.479852      |
| episodes                | 1380          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 320255        |
| policy_loss             | -0.55761313   |
| qf1_loss                | 4.0650324e-05 |
| qf2_loss                | 4.4728906e-05 |
| time_elapsed            | 2286          |
| total timesteps         | 320355        |
| value_loss              | 8.963735e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010371035  |
| ent_coef_loss           | -1.759079     |
| entropy                 | 1.5908504     |
| episodes                | 1384          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 321015        |
| policy_loss             | -0.5407404    |
| qf1_loss                | 2.2375989e-05 |
| qf2_loss                | 2.459835e-05  |
| time_elapsed            | 2291          |
| total timesteps         | 321115        |
| value_loss              | 6.580041e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010463117  |
| ent_coef_loss           | -0.6735216    |
| entropy                 | 1.4480469     |
| episodes                | 1388          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 321726        |
| policy_loss             | -0.5248561    |
| qf1_loss                | 6.267908e-05  |
| qf2_loss                | 4.638348e-05  |
| time_elapsed            | 2297          |
| total timesteps         | 321826        |
| value_loss              | 5.3888347e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011771152  |
| ent_coef_loss           | 3.4849539     |
| entropy                 | 1.494761      |
| episodes                | 1392          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 322645        |
| policy_loss             | -0.4541592    |
| qf1_loss                | 0.00100468    |
| qf2_loss                | 0.0009880794  |
| time_elapsed            | 2303          |
| total timesteps         | 322745        |
| value_loss              | 0.00013368591 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0012309509 |
| ent_coef_loss           | -2.9514434   |
| entropy                 | 1.5616628    |
| episodes                | 1396         |
| fps                     | 140          |
| mean 100 episode reward | 0.8          |
| n_updates               | 323328       |
| policy_loss             | -0.5164217   |
| qf1_loss                | 6.188779e-05 |
| qf2_loss                | 4.543364e-05 |
| time_elapsed            | 2308         |
| total timesteps         | 323428       |
| value_loss              | 9.110931e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011480318  |
| ent_coef_loss           | 0.008454323   |
| entropy                 | 1.4974701     |
| episodes                | 1400          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 323991        |
| policy_loss             | -0.53242946   |
| qf1_loss                | 0.0016359785  |
| qf2_loss                | 0.0077815987  |
| time_elapsed            | 2313          |
| total timesteps         | 324091        |
| value_loss              | 0.00015307756 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011930814  |
| ent_coef_loss           | -3.4818158    |
| entropy                 | 1.4766904     |
| episodes                | 1404          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 324667        |
| policy_loss             | -0.5399221    |
| qf1_loss                | 1.9824678e-05 |
| qf2_loss                | 2.8413004e-05 |
| time_elapsed            | 2317          |
| total timesteps         | 324767        |
| value_loss              | 5.209718e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001107729   |
| ent_coef_loss           | -0.027924538  |
| entropy                 | 1.4594725     |
| episodes                | 1408          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 325333        |
| policy_loss             | -0.5167899    |
| qf1_loss                | 5.2273885e-05 |
| qf2_loss                | 6.936223e-05  |
| time_elapsed            | 2322          |
| total timesteps         | 325433        |
| value_loss              | 4.2127722e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011194593  |
| ent_coef_loss           | 1.1225138     |
| entropy                 | 1.5185057     |
| episodes                | 1412          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 326003        |
| policy_loss             | -0.51446426   |
| qf1_loss                | 3.9178143e-05 |
| qf2_loss                | 4.2673382e-05 |
| time_elapsed            | 2327          |
| total timesteps         | 326103        |
| value_loss              | 5.4078217e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.000982092  |
| ent_coef_loss           | 0.6508116    |
| entropy                 | 1.4932244    |
| episodes                | 1416         |
| fps                     | 140          |
| mean 100 episode reward | 0.9          |
| n_updates               | 326709       |
| policy_loss             | -0.54752016  |
| qf1_loss                | 1.565399e-05 |
| qf2_loss                | 2.799902e-05 |
| time_elapsed            | 2332         |
| total timesteps         | 326809       |
| value_loss              | 8.51886e-05  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009913855  |
| ent_coef_loss           | -2.527845     |
| entropy                 | 1.4441216     |
| episodes                | 1420          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 327502        |
| policy_loss             | -0.53206193   |
| qf1_loss                | 2.0663061e-05 |
| qf2_loss                | 2.7084297e-05 |
| time_elapsed            | 2338          |
| total timesteps         | 327602        |
| value_loss              | 4.2467087e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009898739  |
| ent_coef_loss           | -0.15167433   |
| entropy                 | 1.491411      |
| episodes                | 1424          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 328163        |
| policy_loss             | -0.5492639    |
| qf1_loss                | 2.6749021e-05 |
| qf2_loss                | 2.7692326e-05 |
| time_elapsed            | 2342          |
| total timesteps         | 328263        |
| value_loss              | 3.888733e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001038968   |
| ent_coef_loss           | 0.099330574   |
| entropy                 | 1.485104      |
| episodes                | 1428          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 328817        |
| policy_loss             | -0.51081395   |
| qf1_loss                | 2.6597423e-05 |
| qf2_loss                | 2.409521e-05  |
| time_elapsed            | 2347          |
| total timesteps         | 328917        |
| value_loss              | 3.963026e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010552207 |
| ent_coef_loss           | 0.24539411   |
| entropy                 | 1.4435949    |
| episodes                | 1432         |
| fps                     | 140          |
| mean 100 episode reward | 0.9          |
| n_updates               | 329567       |
| policy_loss             | -0.5169836   |
| qf1_loss                | 3.19006e-05  |
| qf2_loss                | 4.968027e-05 |
| time_elapsed            | 2353         |
| total timesteps         | 329667       |
| value_loss              | 7.31234e-05  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009796921  |
| ent_coef_loss           | 3.3032813     |
| entropy                 | 1.55668       |
| episodes                | 1436          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 330260        |
| policy_loss             | -0.56497514   |
| qf1_loss                | 3.114197e-05  |
| qf2_loss                | 2.378592e-05  |
| time_elapsed            | 2358          |
| total timesteps         | 330360        |
| value_loss              | 2.9821444e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010050422  |
| ent_coef_loss           | -3.7236917    |
| entropy                 | 1.4454126     |
| episodes                | 1440          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 330905        |
| policy_loss             | -0.52644634   |
| qf1_loss                | 7.549964e-05  |
| qf2_loss                | 3.5549518e-05 |
| time_elapsed            | 2362          |
| total timesteps         | 331005        |
| value_loss              | 9.659262e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010658988  |
| ent_coef_loss           | 2.3501558     |
| entropy                 | 1.4790635     |
| episodes                | 1444          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 331889        |
| policy_loss             | -0.53122014   |
| qf1_loss                | 2.5373713e-05 |
| qf2_loss                | 3.126183e-05  |
| time_elapsed            | 2369          |
| total timesteps         | 331989        |
| value_loss              | 3.9070845e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010165737  |
| ent_coef_loss           | -4.35139      |
| entropy                 | 1.3563824     |
| episodes                | 1448          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 332869        |
| policy_loss             | -0.59568846   |
| qf1_loss                | 3.0096888e-05 |
| qf2_loss                | 2.3969349e-05 |
| time_elapsed            | 2376          |
| total timesteps         | 332969        |
| value_loss              | 3.9749037e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010754893  |
| ent_coef_loss           | 2.0861344     |
| entropy                 | 1.3665365     |
| episodes                | 1452          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 333663        |
| policy_loss             | -0.5042868    |
| qf1_loss                | 3.0976604e-05 |
| qf2_loss                | 2.4617446e-05 |
| time_elapsed            | 2382          |
| total timesteps         | 333763        |
| value_loss              | 3.876906e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096688955 |
| ent_coef_loss           | -1.1381724    |
| entropy                 | 1.1777856     |
| episodes                | 1456          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 334477        |
| policy_loss             | -0.48614955   |
| qf1_loss                | 2.7326625e-05 |
| qf2_loss                | 2.9272642e-05 |
| time_elapsed            | 2388          |
| total timesteps         | 334577        |
| value_loss              | 3.943842e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009881493  |
| ent_coef_loss           | -1.2869017    |
| entropy                 | 1.4380581     |
| episodes                | 1460          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 335455        |
| policy_loss             | -0.51551986   |
| qf1_loss                | 3.336668e-05  |
| qf2_loss                | 3.358384e-05  |
| time_elapsed            | 2395          |
| total timesteps         | 335555        |
| value_loss              | 7.1662085e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008651996  |
| ent_coef_loss           | 1.2641468     |
| entropy                 | 1.2837378     |
| episodes                | 1464          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 336584        |
| policy_loss             | -0.54683745   |
| qf1_loss                | 5.358654e-05  |
| qf2_loss                | 4.533922e-05  |
| time_elapsed            | 2403          |
| total timesteps         | 336684        |
| value_loss              | 0.00017255495 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008831598  |
| ent_coef_loss           | 2.5321755     |
| entropy                 | 1.3837423     |
| episodes                | 1468          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 337271        |
| policy_loss             | -0.5424284    |
| qf1_loss                | 4.2737138e-05 |
| qf2_loss                | 2.8275113e-05 |
| time_elapsed            | 2408          |
| total timesteps         | 337371        |
| value_loss              | 4.810739e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001026381   |
| ent_coef_loss           | -0.6952543    |
| entropy                 | 1.4878738     |
| episodes                | 1472          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 337910        |
| policy_loss             | -0.49518257   |
| qf1_loss                | 2.7957998e-05 |
| qf2_loss                | 2.2463519e-05 |
| time_elapsed            | 2413          |
| total timesteps         | 338010        |
| value_loss              | 1.8394805e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011464645  |
| ent_coef_loss           | 1.0951275     |
| entropy                 | 1.4656708     |
| episodes                | 1476          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 338618        |
| policy_loss             | -0.51259947   |
| qf1_loss                | 1.9323128e-05 |
| qf2_loss                | 3.7402817e-05 |
| time_elapsed            | 2418          |
| total timesteps         | 338718        |
| value_loss              | 4.7829584e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012008746  |
| ent_coef_loss           | 0.9631125     |
| entropy                 | 1.4790518     |
| episodes                | 1480          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 339288        |
| policy_loss             | -0.4889003    |
| qf1_loss                | 1.9504674e-05 |
| qf2_loss                | 2.241393e-05  |
| time_elapsed            | 2422          |
| total timesteps         | 339388        |
| value_loss              | 2.8486917e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011762243  |
| ent_coef_loss           | -3.5140488    |
| entropy                 | 1.5075076     |
| episodes                | 1484          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 340083        |
| policy_loss             | -0.5455519    |
| qf1_loss                | 2.136737e-05  |
| qf2_loss                | 3.3407236e-05 |
| time_elapsed            | 2428          |
| total timesteps         | 340183        |
| value_loss              | 6.0291542e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001042822   |
| ent_coef_loss           | -1.9619405    |
| entropy                 | 1.4375957     |
| episodes                | 1488          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 340769        |
| policy_loss             | -0.5590898    |
| qf1_loss                | 7.647877e-05  |
| qf2_loss                | 5.962251e-05  |
| time_elapsed            | 2433          |
| total timesteps         | 340869        |
| value_loss              | 6.9219765e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010057964  |
| ent_coef_loss           | 2.6898282     |
| entropy                 | 1.381046      |
| episodes                | 1492          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 341439        |
| policy_loss             | -0.5015824    |
| qf1_loss                | 1.9491916e-05 |
| qf2_loss                | 2.160062e-05  |
| time_elapsed            | 2437          |
| total timesteps         | 341539        |
| value_loss              | 3.2759264e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010403541  |
| ent_coef_loss           | 0.3161937     |
| entropy                 | 1.3179107     |
| episodes                | 1496          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 342186        |
| policy_loss             | -0.51288384   |
| qf1_loss                | 6.0243085e-05 |
| qf2_loss                | 6.0672388e-05 |
| time_elapsed            | 2443          |
| total timesteps         | 342286        |
| value_loss              | 4.2355183e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011196195  |
| ent_coef_loss           | -0.36695004   |
| entropy                 | 1.4186813     |
| episodes                | 1500          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 342912        |
| policy_loss             | -0.54905176   |
| qf1_loss                | 2.795045e-05  |
| qf2_loss                | 5.0849158e-05 |
| time_elapsed            | 2448          |
| total timesteps         | 343012        |
| value_loss              | 7.6389915e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010944373  |
| ent_coef_loss           | -0.6093711    |
| entropy                 | 1.344549      |
| episodes                | 1504          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 343586        |
| policy_loss             | -0.51366067   |
| qf1_loss                | 2.6246016e-05 |
| qf2_loss                | 2.9948089e-05 |
| time_elapsed            | 2453          |
| total timesteps         | 343686        |
| value_loss              | 3.8838225e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010888759  |
| ent_coef_loss           | 0.8714091     |
| entropy                 | 1.4812453     |
| episodes                | 1508          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 344396        |
| policy_loss             | -0.5974239    |
| qf1_loss                | 4.2121967e-05 |
| qf2_loss                | 2.5787162e-05 |
| time_elapsed            | 2459          |
| total timesteps         | 344496        |
| value_loss              | 1.8797775e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001064929   |
| ent_coef_loss           | -0.5313382    |
| entropy                 | 1.4941167     |
| episodes                | 1512          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 345165        |
| policy_loss             | -0.515889     |
| qf1_loss                | 5.5058255e-05 |
| qf2_loss                | 3.4252196e-05 |
| time_elapsed            | 2464          |
| total timesteps         | 345265        |
| value_loss              | 6.930424e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095080014 |
| ent_coef_loss           | -1.8051591    |
| entropy                 | 1.3059931     |
| episodes                | 1516          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 346151        |
| policy_loss             | -0.5457957    |
| qf1_loss                | 0.00016456874 |
| qf2_loss                | 5.4690317e-05 |
| time_elapsed            | 2471          |
| total timesteps         | 346251        |
| value_loss              | 0.00012081273 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093449134 |
| ent_coef_loss           | 0.3034675     |
| entropy                 | 1.4389825     |
| episodes                | 1520          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 346848        |
| policy_loss             | -0.5316771    |
| qf1_loss                | 1.5189225e-05 |
| qf2_loss                | 1.1489462e-05 |
| time_elapsed            | 2477          |
| total timesteps         | 346948        |
| value_loss              | 3.4738063e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010620465  |
| ent_coef_loss           | -0.63655907   |
| entropy                 | 1.5068667     |
| episodes                | 1524          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 347602        |
| policy_loss             | -0.5796421    |
| qf1_loss                | 2.2747037e-05 |
| qf2_loss                | 2.3224708e-05 |
| time_elapsed            | 2482          |
| total timesteps         | 347702        |
| value_loss              | 2.3624598e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00102165    |
| ent_coef_loss           | -0.10685879   |
| entropy                 | 1.5829924     |
| episodes                | 1528          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 348307        |
| policy_loss             | -0.50316346   |
| qf1_loss                | 2.8016608e-05 |
| qf2_loss                | 2.5962152e-05 |
| time_elapsed            | 2487          |
| total timesteps         | 348407        |
| value_loss              | 3.6074416e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095428847 |
| ent_coef_loss           | 1.5094386     |
| entropy                 | 1.4358621     |
| episodes                | 1532          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 349062        |
| policy_loss             | -0.57004976   |
| qf1_loss                | 7.3108844e-05 |
| qf2_loss                | 5.2882886e-05 |
| time_elapsed            | 2492          |
| total timesteps         | 349162        |
| value_loss              | 0.00016024677 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009977309  |
| ent_coef_loss           | -3.1104639    |
| entropy                 | 1.4445438     |
| episodes                | 1536          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 349796        |
| policy_loss             | -0.6134035    |
| qf1_loss                | 3.4842662e-05 |
| qf2_loss                | 9.890999e-05  |
| time_elapsed            | 2497          |
| total timesteps         | 349896        |
| value_loss              | 1.573302e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095900474 |
| ent_coef_loss           | 2.3708692     |
| entropy                 | 1.5311038     |
| episodes                | 1540          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 350486        |
| policy_loss             | -0.5727879    |
| qf1_loss                | 5.1950046e-05 |
| qf2_loss                | 6.0412673e-05 |
| time_elapsed            | 2502          |
| total timesteps         | 350586        |
| value_loss              | 3.401308e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010329144  |
| ent_coef_loss           | -0.3633402    |
| entropy                 | 1.4211221     |
| episodes                | 1544          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 351165        |
| policy_loss             | -0.5357912    |
| qf1_loss                | 5.1454976e-05 |
| qf2_loss                | 3.28526e-05   |
| time_elapsed            | 2508          |
| total timesteps         | 351265        |
| value_loss              | 2.5232024e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010275107  |
| ent_coef_loss           | 1.0272732     |
| entropy                 | 1.5877638     |
| episodes                | 1548          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 351906        |
| policy_loss             | -0.56919605   |
| qf1_loss                | 3.1166175e-05 |
| qf2_loss                | 2.8002756e-05 |
| time_elapsed            | 2513          |
| total timesteps         | 352006        |
| value_loss              | 2.662006e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010335081  |
| ent_coef_loss           | 0.77236277    |
| entropy                 | 1.4614911     |
| episodes                | 1552          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 352567        |
| policy_loss             | -0.52583873   |
| qf1_loss                | 2.3026201e-05 |
| qf2_loss                | 1.4057753e-05 |
| time_elapsed            | 2518          |
| total timesteps         | 352667        |
| value_loss              | 0.00024928583 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010663847  |
| ent_coef_loss           | 0.98812795    |
| entropy                 | 1.5508487     |
| episodes                | 1556          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 353243        |
| policy_loss             | -0.59635556   |
| qf1_loss                | 5.2019117e-05 |
| qf2_loss                | 4.1262327e-05 |
| time_elapsed            | 2522          |
| total timesteps         | 353343        |
| value_loss              | 2.2154436e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009921109  |
| ent_coef_loss           | -2.0041249    |
| entropy                 | 1.4659383     |
| episodes                | 1560          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 353909        |
| policy_loss             | -0.54755497   |
| qf1_loss                | 0.00010331492 |
| qf2_loss                | 0.0001204453  |
| time_elapsed            | 2527          |
| total timesteps         | 354009        |
| value_loss              | 0.0002776417  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010369992  |
| ent_coef_loss           | 0.14597917    |
| entropy                 | 1.5188937     |
| episodes                | 1564          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 354604        |
| policy_loss             | -0.5872881    |
| qf1_loss                | 5.2523043e-05 |
| qf2_loss                | 4.275112e-05  |
| time_elapsed            | 2532          |
| total timesteps         | 354704        |
| value_loss              | 3.732192e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010486917  |
| ent_coef_loss           | -0.8563769    |
| entropy                 | 1.46278       |
| episodes                | 1568          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 355316        |
| policy_loss             | -0.48353484   |
| qf1_loss                | 0.00013312392 |
| qf2_loss                | 3.7195627e-05 |
| time_elapsed            | 2538          |
| total timesteps         | 355416        |
| value_loss              | 5.0903327e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001012965   |
| ent_coef_loss           | 0.48044574    |
| entropy                 | 1.5978572     |
| episodes                | 1572          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 356000        |
| policy_loss             | -0.50994086   |
| qf1_loss                | 3.1727875e-05 |
| qf2_loss                | 3.280671e-05  |
| time_elapsed            | 2542          |
| total timesteps         | 356100        |
| value_loss              | 3.592862e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010683172  |
| ent_coef_loss           | 3.3584013     |
| entropy                 | 1.6177971     |
| episodes                | 1576          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 356648        |
| policy_loss             | -0.5898066    |
| qf1_loss                | 2.0890307e-05 |
| qf2_loss                | 1.6866219e-05 |
| time_elapsed            | 2547          |
| total timesteps         | 356748        |
| value_loss              | 2.0656229e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010135926  |
| ent_coef_loss           | -2.1110618    |
| entropy                 | 1.3788718     |
| episodes                | 1580          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 357405        |
| policy_loss             | -0.5512116    |
| qf1_loss                | 2.6162414e-05 |
| qf2_loss                | 0.00011221628 |
| time_elapsed            | 2552          |
| total timesteps         | 357505        |
| value_loss              | 4.510944e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009927625  |
| ent_coef_loss           | 0.16375273    |
| entropy                 | 1.5503922     |
| episodes                | 1584          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 358134        |
| policy_loss             | -0.530213     |
| qf1_loss                | 1.5924637e-05 |
| qf2_loss                | 1.951811e-05  |
| time_elapsed            | 2557          |
| total timesteps         | 358234        |
| value_loss              | 3.3929195e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094951026 |
| ent_coef_loss           | 1.514041      |
| entropy                 | 1.6322503     |
| episodes                | 1588          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 358813        |
| policy_loss             | -0.5909581    |
| qf1_loss                | 1.751574e-05  |
| qf2_loss                | 2.7948281e-05 |
| time_elapsed            | 2562          |
| total timesteps         | 358913        |
| value_loss              | 3.2435913e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000930336   |
| ent_coef_loss           | 2.0229268     |
| entropy                 | 1.5765803     |
| episodes                | 1592          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 359409        |
| policy_loss             | -0.5703821    |
| qf1_loss                | 0.00013495212 |
| qf2_loss                | 3.5172052e-05 |
| time_elapsed            | 2567          |
| total timesteps         | 359509        |
| value_loss              | 5.5084467e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009170614  |
| ent_coef_loss           | -2.9393315    |
| entropy                 | 1.327546      |
| episodes                | 1596          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 360119        |
| policy_loss             | -0.5753509    |
| qf1_loss                | 1.3332215e-05 |
| qf2_loss                | 1.6931153e-05 |
| time_elapsed            | 2572          |
| total timesteps         | 360219        |
| value_loss              | 2.086944e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090727326 |
| ent_coef_loss           | -1.6267619    |
| entropy                 | 1.6033242     |
| episodes                | 1600          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 360795        |
| policy_loss             | -0.60241556   |
| qf1_loss                | 2.0805326e-05 |
| qf2_loss                | 2.1385338e-05 |
| time_elapsed            | 2577          |
| total timesteps         | 360895        |
| value_loss              | 2.207822e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009084889  |
| ent_coef_loss           | -1.1201317    |
| entropy                 | 1.4624763     |
| episodes                | 1604          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 361588        |
| policy_loss             | -0.59557116   |
| qf1_loss                | 1.6168273e-05 |
| qf2_loss                | 3.131808e-05  |
| time_elapsed            | 2582          |
| total timesteps         | 361688        |
| value_loss              | 2.9674811e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087997055 |
| ent_coef_loss           | -1.5009543    |
| entropy                 | 1.4566337     |
| episodes                | 1608          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 362234        |
| policy_loss             | -0.59033644   |
| qf1_loss                | 2.5459996e-05 |
| qf2_loss                | 1.1653714e-05 |
| time_elapsed            | 2587          |
| total timesteps         | 362334        |
| value_loss              | 1.764597e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0008808933   |
| ent_coef_loss           | -1.7176577     |
| entropy                 | 1.346241       |
| episodes                | 1612           |
| fps                     | 140            |
| mean 100 episode reward | 0.9            |
| n_updates               | 362894         |
| policy_loss             | -0.6058185     |
| qf1_loss                | 1.4351159e-05  |
| qf2_loss                | 1.1705968e-05  |
| time_elapsed            | 2591           |
| total timesteps         | 362994         |
| value_loss              | 1.31724755e-05 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008223194  |
| ent_coef_loss           | 0.46083868    |
| entropy                 | 1.4281309     |
| episodes                | 1616          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 363728        |
| policy_loss             | -0.5944028    |
| qf1_loss                | 1.541409e-05  |
| qf2_loss                | 1.3620713e-05 |
| time_elapsed            | 2598          |
| total timesteps         | 363828        |
| value_loss              | 1.4615922e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086333975 |
| ent_coef_loss           | 1.6497667     |
| entropy                 | 1.4756341     |
| episodes                | 1620          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 364411        |
| policy_loss             | -0.5939363    |
| qf1_loss                | 6.2251456e-06 |
| qf2_loss                | 6.1521177e-06 |
| time_elapsed            | 2602          |
| total timesteps         | 364511        |
| value_loss              | 1.8888091e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086937856 |
| ent_coef_loss           | 2.0228736     |
| entropy                 | 1.4518764     |
| episodes                | 1624          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 365147        |
| policy_loss             | -0.60554725   |
| qf1_loss                | 2.0218427e-05 |
| qf2_loss                | 2.3815708e-05 |
| time_elapsed            | 2608          |
| total timesteps         | 365247        |
| value_loss              | 2.514981e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091667403 |
| ent_coef_loss           | -0.16404128   |
| entropy                 | 1.4498222     |
| episodes                | 1628          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 365889        |
| policy_loss             | -0.5691577    |
| qf1_loss                | 2.7100301e-05 |
| qf2_loss                | 2.062507e-05  |
| time_elapsed            | 2613          |
| total timesteps         | 365989        |
| value_loss              | 3.2782962e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008681437  |
| ent_coef_loss           | -0.4613604    |
| entropy                 | 1.4463134     |
| episodes                | 1632          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 366565        |
| policy_loss             | -0.5671221    |
| qf1_loss                | 2.0019315e-05 |
| qf2_loss                | 2.1878901e-05 |
| time_elapsed            | 2618          |
| total timesteps         | 366665        |
| value_loss              | 4.3868196e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087301014 |
| ent_coef_loss           | -4.3147564    |
| entropy                 | 1.2678645     |
| episodes                | 1636          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 367216        |
| policy_loss             | -0.59187925   |
| qf1_loss                | 1.5426009e-05 |
| qf2_loss                | 1.4397622e-05 |
| time_elapsed            | 2622          |
| total timesteps         | 367316        |
| value_loss              | 2.2383643e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00084430777 |
| ent_coef_loss           | 0.97699195    |
| entropy                 | 1.4208165     |
| episodes                | 1640          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 367842        |
| policy_loss             | -0.57161164   |
| qf1_loss                | 4.572257e-05  |
| qf2_loss                | 8.89254e-05   |
| time_elapsed            | 2627          |
| total timesteps         | 367942        |
| value_loss              | 7.9611025e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008186754  |
| ent_coef_loss           | -0.76296127   |
| entropy                 | 1.2496092     |
| episodes                | 1644          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 368375        |
| policy_loss             | -0.600054     |
| qf1_loss                | 1.8872426e-05 |
| qf2_loss                | 2.6531103e-05 |
| time_elapsed            | 2631          |
| total timesteps         | 368475        |
| value_loss              | 4.8786424e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00080026314 |
| ent_coef_loss           | 0.20720935    |
| entropy                 | 1.2871099     |
| episodes                | 1648          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 369058        |
| policy_loss             | -0.57715535   |
| qf1_loss                | 2.877972e-05  |
| qf2_loss                | 3.938132e-05  |
| time_elapsed            | 2636          |
| total timesteps         | 369158        |
| value_loss              | 3.1923395e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008186543  |
| ent_coef_loss           | 0.05945283    |
| entropy                 | 1.3402439     |
| episodes                | 1652          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 369737        |
| policy_loss             | -0.62604904   |
| qf1_loss                | 1.1573999e-05 |
| qf2_loss                | 1.8801771e-05 |
| time_elapsed            | 2640          |
| total timesteps         | 369837        |
| value_loss              | 2.0730453e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000854717   |
| ent_coef_loss           | 0.9090873     |
| entropy                 | 1.3055508     |
| episodes                | 1656          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 370400        |
| policy_loss             | -0.5868596    |
| qf1_loss                | 2.576008e-05  |
| qf2_loss                | 3.096312e-05  |
| time_elapsed            | 2645          |
| total timesteps         | 370500        |
| value_loss              | 3.8292565e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00084509404 |
| ent_coef_loss           | 0.9464828     |
| entropy                 | 1.377536      |
| episodes                | 1660          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 371077        |
| policy_loss             | -0.57885563   |
| qf1_loss                | 3.648374e-05  |
| qf2_loss                | 4.7140376e-05 |
| time_elapsed            | 2650          |
| total timesteps         | 371177        |
| value_loss              | 5.0601102e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008551748  |
| ent_coef_loss           | 3.589876      |
| entropy                 | 1.4387603     |
| episodes                | 1664          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 371792        |
| policy_loss             | -0.5827301    |
| qf1_loss                | 3.1590065e-05 |
| qf2_loss                | 4.199841e-05  |
| time_elapsed            | 2655          |
| total timesteps         | 371892        |
| value_loss              | 4.792435e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00081824843 |
| ent_coef_loss           | -4.3514323    |
| entropy                 | 1.4061795     |
| episodes                | 1668          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 372520        |
| policy_loss             | -0.5683285    |
| qf1_loss                | 1.4435804e-05 |
| qf2_loss                | 4.9853792e-05 |
| time_elapsed            | 2660          |
| total timesteps         | 372620        |
| value_loss              | 0.00011047564 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000780761   |
| ent_coef_loss           | -1.2862792    |
| entropy                 | 1.2761407     |
| episodes                | 1672          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 373262        |
| policy_loss             | -0.5774608    |
| qf1_loss                | 1.9441342e-05 |
| qf2_loss                | 1.3912633e-05 |
| time_elapsed            | 2666          |
| total timesteps         | 373362        |
| value_loss              | 1.8734328e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00072009984 |
| ent_coef_loss           | 0.117397726   |
| entropy                 | 1.4378254     |
| episodes                | 1676          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 373969        |
| policy_loss             | -0.6304161    |
| qf1_loss                | 1.8664978e-05 |
| qf2_loss                | 1.8376262e-05 |
| time_elapsed            | 2671          |
| total timesteps         | 374069        |
| value_loss              | 7.3123076e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000745443   |
| ent_coef_loss           | -2.1902514    |
| entropy                 | 1.1671954     |
| episodes                | 1680          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 374623        |
| policy_loss             | -0.5631788    |
| qf1_loss                | 2.455123e-05  |
| qf2_loss                | 2.3494515e-05 |
| time_elapsed            | 2675          |
| total timesteps         | 374723        |
| value_loss              | 4.304652e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007263348  |
| ent_coef_loss           | -1.1469718    |
| entropy                 | 1.2968624     |
| episodes                | 1684          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 375280        |
| policy_loss             | -0.6091182    |
| qf1_loss                | 3.1098374e-05 |
| qf2_loss                | 1.3281669e-05 |
| time_elapsed            | 2680          |
| total timesteps         | 375380        |
| value_loss              | 2.3330971e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00068440835 |
| ent_coef_loss           | -0.57772964   |
| entropy                 | 1.132742      |
| episodes                | 1688          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 376026        |
| policy_loss             | -0.5701449    |
| qf1_loss                | 2.8381855e-05 |
| qf2_loss                | 2.018067e-05  |
| time_elapsed            | 2685          |
| total timesteps         | 376126        |
| value_loss              | 3.091927e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00076950464  |
| ent_coef_loss           | -2.3169186     |
| entropy                 | 1.3211167      |
| episodes                | 1692           |
| fps                     | 140            |
| mean 100 episode reward | 0.8            |
| n_updates               | 376667         |
| policy_loss             | -0.6035876     |
| qf1_loss                | 1.1235504e-05  |
| qf2_loss                | 1.46281845e-05 |
| time_elapsed            | 2690           |
| total timesteps         | 376767         |
| value_loss              | 2.3159511e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007467013  |
| ent_coef_loss           | 1.4914942     |
| entropy                 | 1.3410281     |
| episodes                | 1696          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 377340        |
| policy_loss             | -0.58895975   |
| qf1_loss                | 2.0735419e-05 |
| qf2_loss                | 2.8078179e-05 |
| time_elapsed            | 2695          |
| total timesteps         | 377440        |
| value_loss              | 3.7293255e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00079818425  |
| ent_coef_loss           | -1.1864271     |
| entropy                 | 1.4243338      |
| episodes                | 1700           |
| fps                     | 140            |
| mean 100 episode reward | 0.8            |
| n_updates               | 377974         |
| policy_loss             | -0.6459694     |
| qf1_loss                | 1.17397885e-05 |
| qf2_loss                | 7.1074905e-06  |
| time_elapsed            | 2699           |
| total timesteps         | 378074         |
| value_loss              | 1.8062285e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000769966   |
| ent_coef_loss           | 1.5460664     |
| entropy                 | 1.4781601     |
| episodes                | 1704          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 378699        |
| policy_loss             | -0.6532375    |
| qf1_loss                | 2.3207502e-05 |
| qf2_loss                | 5.529847e-05  |
| time_elapsed            | 2704          |
| total timesteps         | 378799        |
| value_loss              | 0.0001066398  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00084398896 |
| ent_coef_loss           | -0.11536491   |
| entropy                 | 1.2765381     |
| episodes                | 1708          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 379467        |
| policy_loss             | -0.6266171    |
| qf1_loss                | 2.9145736e-05 |
| qf2_loss                | 3.660064e-05  |
| time_elapsed            | 2710          |
| total timesteps         | 379567        |
| value_loss              | 6.8765316e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00082536705 |
| ent_coef_loss           | 1.909182      |
| entropy                 | 1.4849424     |
| episodes                | 1712          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 380194        |
| policy_loss             | -0.6182735    |
| qf1_loss                | 2.7463167e-05 |
| qf2_loss                | 1.7965855e-05 |
| time_elapsed            | 2715          |
| total timesteps         | 380294        |
| value_loss              | 7.54892e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007762307  |
| ent_coef_loss           | 1.4351244     |
| entropy                 | 1.3414097     |
| episodes                | 1716          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 380921        |
| policy_loss             | -0.6409177    |
| qf1_loss                | 3.9869145e-05 |
| qf2_loss                | 1.811848e-05  |
| time_elapsed            | 2721          |
| total timesteps         | 381021        |
| value_loss              | 3.009236e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00079884985 |
| ent_coef_loss           | 0.12705076    |
| entropy                 | 1.2419877     |
| episodes                | 1720          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 381607        |
| policy_loss             | -0.64448714   |
| qf1_loss                | 3.6267513e-05 |
| qf2_loss                | 2.6486783e-05 |
| time_elapsed            | 2725          |
| total timesteps         | 381707        |
| value_loss              | 3.2580545e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008518229  |
| ent_coef_loss           | 0.05375713    |
| entropy                 | 1.2400147     |
| episodes                | 1724          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 382281        |
| policy_loss             | -0.60074484   |
| qf1_loss                | 1.3455726e-05 |
| qf2_loss                | 8.4047315e-06 |
| time_elapsed            | 2730          |
| total timesteps         | 382381        |
| value_loss              | 1.1528608e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008565427  |
| ent_coef_loss           | -0.34544492   |
| entropy                 | 1.2633862     |
| episodes                | 1728          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 382973        |
| policy_loss             | -0.6023955    |
| qf1_loss                | 2.2504615e-05 |
| qf2_loss                | 3.309959e-05  |
| time_elapsed            | 2735          |
| total timesteps         | 383073        |
| value_loss              | 5.115816e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008067305  |
| ent_coef_loss           | 2.0984983     |
| entropy                 | 1.4797333     |
| episodes                | 1732          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 383940        |
| policy_loss             | -0.60236895   |
| qf1_loss                | 1.1978129e-05 |
| qf2_loss                | 8.098511e-06  |
| time_elapsed            | 2742          |
| total timesteps         | 384040        |
| value_loss              | 2.9090945e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008597193  |
| ent_coef_loss           | 0.960536      |
| entropy                 | 1.4209623     |
| episodes                | 1736          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 384600        |
| policy_loss             | -0.6065041    |
| qf1_loss                | 1.6569293e-05 |
| qf2_loss                | 2.032461e-05  |
| time_elapsed            | 2747          |
| total timesteps         | 384700        |
| value_loss              | 5.08643e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009030211  |
| ent_coef_loss           | -0.7555742    |
| entropy                 | 1.4272538     |
| episodes                | 1740          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 385389        |
| policy_loss             | -0.5435303    |
| qf1_loss                | 2.1016085e-05 |
| qf2_loss                | 2.8003538e-05 |
| time_elapsed            | 2753          |
| total timesteps         | 385489        |
| value_loss              | 3.913288e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007890401  |
| ent_coef_loss           | -0.8195785    |
| entropy                 | 1.363686      |
| episodes                | 1744          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 386068        |
| policy_loss             | -0.6027616    |
| qf1_loss                | 1.4566606e-05 |
| qf2_loss                | 1.4006604e-05 |
| time_elapsed            | 2757          |
| total timesteps         | 386168        |
| value_loss              | 5.109238e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008657675  |
| ent_coef_loss           | -1.6347523    |
| entropy                 | 1.3006213     |
| episodes                | 1748          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 386815        |
| policy_loss             | -0.604144     |
| qf1_loss                | 1.5729529e-05 |
| qf2_loss                | 3.7046942e-05 |
| time_elapsed            | 2763          |
| total timesteps         | 386915        |
| value_loss              | 4.5058256e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00076525164 |
| ent_coef_loss           | -0.21239328   |
| entropy                 | 1.3069518     |
| episodes                | 1752          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 387655        |
| policy_loss             | -0.59454656   |
| qf1_loss                | 1.9687799e-05 |
| qf2_loss                | 1.9842195e-05 |
| time_elapsed            | 2769          |
| total timesteps         | 387755        |
| value_loss              | 2.8042487e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00084602577 |
| ent_coef_loss           | 2.1698213     |
| entropy                 | 1.4862949     |
| episodes                | 1756          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 388304        |
| policy_loss             | -0.59288657   |
| qf1_loss                | 3.0164581e-05 |
| qf2_loss                | 3.1909447e-05 |
| time_elapsed            | 2773          |
| total timesteps         | 388404        |
| value_loss              | 4.5105626e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00082541787 |
| ent_coef_loss           | -0.6991528    |
| entropy                 | 1.4689554     |
| episodes                | 1760          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 389041        |
| policy_loss             | -0.64015925   |
| qf1_loss                | 1.527584e-05  |
| qf2_loss                | 7.177282e-06  |
| time_elapsed            | 2779          |
| total timesteps         | 389141        |
| value_loss              | 3.2605065e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00080773205 |
| ent_coef_loss           | 1.3897038     |
| entropy                 | 1.3373601     |
| episodes                | 1764          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 389737        |
| policy_loss             | -0.56843346   |
| qf1_loss                | 3.328308e-05  |
| qf2_loss                | 1.681876e-05  |
| time_elapsed            | 2784          |
| total timesteps         | 389837        |
| value_loss              | 1.8399342e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00081640464 |
| ent_coef_loss           | 0.16147566    |
| entropy                 | 1.3771901     |
| episodes                | 1768          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 390444        |
| policy_loss             | -0.6415206    |
| qf1_loss                | 9.893296e-06  |
| qf2_loss                | 2.5438698e-05 |
| time_elapsed            | 2789          |
| total timesteps         | 390544        |
| value_loss              | 2.1041498e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094739825 |
| ent_coef_loss           | 1.2709367     |
| entropy                 | 1.4778426     |
| episodes                | 1772          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 391141        |
| policy_loss             | -0.6082336    |
| qf1_loss                | 0.0001351809  |
| qf2_loss                | 0.00011493033 |
| time_elapsed            | 2794          |
| total timesteps         | 391241        |
| value_loss              | 5.5626097e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008729165  |
| ent_coef_loss           | 0.75332415    |
| entropy                 | 1.4060454     |
| episodes                | 1776          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 391781        |
| policy_loss             | -0.59690773   |
| qf1_loss                | 7.669068e-05  |
| qf2_loss                | 8.475379e-05  |
| time_elapsed            | 2798          |
| total timesteps         | 391881        |
| value_loss              | 3.8819075e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009102828  |
| ent_coef_loss           | -1.3877816    |
| entropy                 | 1.4679602     |
| episodes                | 1780          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 392436        |
| policy_loss             | -0.5902473    |
| qf1_loss                | 5.4666867e-05 |
| qf2_loss                | 1.8070094e-05 |
| time_elapsed            | 2803          |
| total timesteps         | 392536        |
| value_loss              | 8.6118576e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008710504  |
| ent_coef_loss           | -2.3321285    |
| entropy                 | 1.4596927     |
| episodes                | 1784          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 393122        |
| policy_loss             | -0.6393608    |
| qf1_loss                | 2.3914621e-05 |
| qf2_loss                | 2.9448318e-05 |
| time_elapsed            | 2808          |
| total timesteps         | 393222        |
| value_loss              | 4.0953033e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00085590704  |
| ent_coef_loss           | 0.7050084      |
| entropy                 | 1.4738475      |
| episodes                | 1788           |
| fps                     | 140            |
| mean 100 episode reward | 0.9            |
| n_updates               | 393845         |
| policy_loss             | -0.59978527    |
| qf1_loss                | 1.33589965e-05 |
| qf2_loss                | 1.3262373e-05  |
| time_elapsed            | 2813           |
| total timesteps         | 393945         |
| value_loss              | 2.8985673e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008615442  |
| ent_coef_loss           | -1.1550919    |
| entropy                 | 1.4758866     |
| episodes                | 1792          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 394606        |
| policy_loss             | -0.57616717   |
| qf1_loss                | 3.2612345e-05 |
| qf2_loss                | 3.6475365e-05 |
| time_elapsed            | 2819          |
| total timesteps         | 394706        |
| value_loss              | 3.470748e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008305223  |
| ent_coef_loss           | 3.087131      |
| entropy                 | 1.4405098     |
| episodes                | 1796          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 395359        |
| policy_loss             | -0.62552285   |
| qf1_loss                | 0.00011498613 |
| qf2_loss                | 7.37389e-05   |
| time_elapsed            | 2824          |
| total timesteps         | 395459        |
| value_loss              | 7.226864e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008607021  |
| ent_coef_loss           | -0.19933355   |
| entropy                 | 1.3894286     |
| episodes                | 1800          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 396274        |
| policy_loss             | -0.5613941    |
| qf1_loss                | 2.5353784e-05 |
| qf2_loss                | 2.1185831e-05 |
| time_elapsed            | 2830          |
| total timesteps         | 396374        |
| value_loss              | 0.00030075893 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00084260973 |
| ent_coef_loss           | -0.075773954  |
| entropy                 | 1.4024204     |
| episodes                | 1804          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 396998        |
| policy_loss             | -0.6283293    |
| qf1_loss                | 4.1696017e-05 |
| qf2_loss                | 4.9733684e-05 |
| time_elapsed            | 2836          |
| total timesteps         | 397098        |
| value_loss              | 2.6278261e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089459814 |
| ent_coef_loss           | -0.5578425    |
| entropy                 | 1.6163971     |
| episodes                | 1808          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 397835        |
| policy_loss             | -0.6529994    |
| qf1_loss                | 7.1639565e-06 |
| qf2_loss                | 9.011714e-06  |
| time_elapsed            | 2842          |
| total timesteps         | 397935        |
| value_loss              | 3.060248e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008403439  |
| ent_coef_loss           | -0.9068082    |
| entropy                 | 1.4423745     |
| episodes                | 1812          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 398547        |
| policy_loss             | -0.5788965    |
| qf1_loss                | 4.620441e-05  |
| qf2_loss                | 2.0480467e-05 |
| time_elapsed            | 2847          |
| total timesteps         | 398647        |
| value_loss              | 3.4870856e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00092111394  |
| ent_coef_loss           | 1.7711362      |
| entropy                 | 1.3518102      |
| episodes                | 1816           |
| fps                     | 140            |
| mean 100 episode reward | 0.8            |
| n_updates               | 399262         |
| policy_loss             | -0.58009714    |
| qf1_loss                | 1.43846555e-05 |
| qf2_loss                | 4.0146508e-05  |
| time_elapsed            | 2852           |
| total timesteps         | 399362         |
| value_loss              | 7.525101e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008910348  |
| ent_coef_loss           | -2.049471     |
| entropy                 | 1.5593472     |
| episodes                | 1820          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 400207        |
| policy_loss             | -0.6410299    |
| qf1_loss                | 3.875475e-05  |
| qf2_loss                | 3.7893213e-05 |
| time_elapsed            | 2859          |
| total timesteps         | 400307        |
| value_loss              | 2.486513e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000959083   |
| ent_coef_loss           | -2.221252     |
| entropy                 | 1.2823477     |
| episodes                | 1824          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 400895        |
| policy_loss             | -0.5517119    |
| qf1_loss                | 3.7545426e-05 |
| qf2_loss                | 2.878053e-05  |
| time_elapsed            | 2864          |
| total timesteps         | 400995        |
| value_loss              | 8.168392e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009683208  |
| ent_coef_loss           | 3.3510838     |
| entropy                 | 1.3262382     |
| episodes                | 1828          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 401781        |
| policy_loss             | -0.5761602    |
| qf1_loss                | 2.726366e-05  |
| qf2_loss                | 4.0197287e-05 |
| time_elapsed            | 2870          |
| total timesteps         | 401881        |
| value_loss              | 5.6958244e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000942264   |
| ent_coef_loss           | 2.5764174     |
| entropy                 | 1.2319747     |
| episodes                | 1832          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 402497        |
| policy_loss             | -0.4929809    |
| qf1_loss                | 4.8102956e-05 |
| qf2_loss                | 5.3014886e-05 |
| time_elapsed            | 2875          |
| total timesteps         | 402597        |
| value_loss              | 3.7293175e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095581636 |
| ent_coef_loss           | 1.6603408     |
| entropy                 | 1.5137401     |
| episodes                | 1836          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 403418        |
| policy_loss             | -0.6129244    |
| qf1_loss                | 2.4910985e-05 |
| qf2_loss                | 2.8521185e-05 |
| time_elapsed            | 2882          |
| total timesteps         | 403518        |
| value_loss              | 2.818025e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093074556 |
| ent_coef_loss           | 5.0553417     |
| entropy                 | 1.4245265     |
| episodes                | 1840          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 404100        |
| policy_loss             | -0.5595183    |
| qf1_loss                | 4.4019023e-05 |
| qf2_loss                | 8.984356e-05  |
| time_elapsed            | 2887          |
| total timesteps         | 404200        |
| value_loss              | 8.035954e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097594847 |
| ent_coef_loss           | -1.1845933    |
| entropy                 | 1.5130925     |
| episodes                | 1844          |
| fps                     | 140           |
| mean 100 episode reward | 0.8           |
| n_updates               | 404866        |
| policy_loss             | -0.6480588    |
| qf1_loss                | 1.2960687e-05 |
| qf2_loss                | 9.083041e-06  |
| time_elapsed            | 2892          |
| total timesteps         | 404966        |
| value_loss              | 4.0657105e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010340606  |
| ent_coef_loss           | 0.30000895    |
| entropy                 | 1.5507064     |
| episodes                | 1848          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 405542        |
| policy_loss             | -0.6179488    |
| qf1_loss                | 5.9977156e-06 |
| qf2_loss                | 2.1492282e-05 |
| time_elapsed            | 2897          |
| total timesteps         | 405642        |
| value_loss              | 9.411498e-06  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010391206 |
| ent_coef_loss           | -0.800999    |
| entropy                 | 1.4223914    |
| episodes                | 1852         |
| fps                     | 140          |
| mean 100 episode reward | 0.8          |
| n_updates               | 406209       |
| policy_loss             | -0.5430949   |
| qf1_loss                | 0.0054470785 |
| qf2_loss                | 0.0052294214 |
| time_elapsed            | 2902         |
| total timesteps         | 406309       |
| value_loss              | 7.8657e-05   |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010490038  |
| ent_coef_loss           | -0.8639189    |
| entropy                 | 1.547327      |
| episodes                | 1856          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 406925        |
| policy_loss             | -0.60741234   |
| qf1_loss                | 9.045395e-06  |
| qf2_loss                | 1.1466418e-05 |
| time_elapsed            | 2907          |
| total timesteps         | 407025        |
| value_loss              | 2.891981e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009889634  |
| ent_coef_loss           | -1.5715799    |
| entropy                 | 1.4911544     |
| episodes                | 1860          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 407593        |
| policy_loss             | -0.59500027   |
| qf1_loss                | 2.0520982e-05 |
| qf2_loss                | 2.6844698e-05 |
| time_elapsed            | 2912          |
| total timesteps         | 407693        |
| value_loss              | 2.6971527e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000966636   |
| ent_coef_loss           | 0.9355465     |
| entropy                 | 1.4217771     |
| episodes                | 1864          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 408298        |
| policy_loss             | -0.590553     |
| qf1_loss                | 2.0309835e-05 |
| qf2_loss                | 6.315212e-05  |
| time_elapsed            | 2917          |
| total timesteps         | 408398        |
| value_loss              | 0.00028441346 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092483993 |
| ent_coef_loss           | 0.2651673     |
| entropy                 | 1.3844447     |
| episodes                | 1868          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 409090        |
| policy_loss             | -0.5983685    |
| qf1_loss                | 1.6603459e-05 |
| qf2_loss                | 2.0197393e-05 |
| time_elapsed            | 2922          |
| total timesteps         | 409190        |
| value_loss              | 5.3103613e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008739744  |
| ent_coef_loss           | -0.118113086  |
| entropy                 | 1.4939499     |
| episodes                | 1872          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 409763        |
| policy_loss             | -0.59668815   |
| qf1_loss                | 1.2021621e-05 |
| qf2_loss                | 2.4297557e-05 |
| time_elapsed            | 2927          |
| total timesteps         | 409863        |
| value_loss              | 2.5900772e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008990074  |
| ent_coef_loss           | -1.1264279    |
| entropy                 | 1.5514106     |
| episodes                | 1876          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 410632        |
| policy_loss             | -0.576146     |
| qf1_loss                | 1.8938226e-05 |
| qf2_loss                | 4.219603e-05  |
| time_elapsed            | 2933          |
| total timesteps         | 410732        |
| value_loss              | 3.1975444e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009173798  |
| ent_coef_loss           | -0.39689714   |
| entropy                 | 1.4510485     |
| episodes                | 1880          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 411590        |
| policy_loss             | -0.6205683    |
| qf1_loss                | 4.8086884e-05 |
| qf2_loss                | 7.728409e-06  |
| time_elapsed            | 2940          |
| total timesteps         | 411690        |
| value_loss              | 2.7498307e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009058899  |
| ent_coef_loss           | 0.9095609     |
| entropy                 | 1.4269991     |
| episodes                | 1884          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 412294        |
| policy_loss             | -0.6104828    |
| qf1_loss                | 2.1149677e-05 |
| qf2_loss                | 1.3372767e-05 |
| time_elapsed            | 2945          |
| total timesteps         | 412394        |
| value_loss              | 2.9082186e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089923723 |
| ent_coef_loss           | 2.0339265     |
| entropy                 | 1.4300522     |
| episodes                | 1888          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 413236        |
| policy_loss             | -0.57130414   |
| qf1_loss                | 2.1167118e-05 |
| qf2_loss                | 1.6025075e-05 |
| time_elapsed            | 2952          |
| total timesteps         | 413336        |
| value_loss              | 3.8496226e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086946855 |
| ent_coef_loss           | 0.7211395     |
| entropy                 | 1.6338713     |
| episodes                | 1892          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 413902        |
| policy_loss             | -0.59812236   |
| qf1_loss                | 2.0299121e-05 |
| qf2_loss                | 2.381019e-05  |
| time_elapsed            | 2957          |
| total timesteps         | 414002        |
| value_loss              | 1.6950096e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008482576  |
| ent_coef_loss           | -1.992002     |
| entropy                 | 1.2773972     |
| episodes                | 1896          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 414633        |
| policy_loss             | -0.5103657    |
| qf1_loss                | 9.1771144e-05 |
| qf2_loss                | 7.6438606e-05 |
| time_elapsed            | 2962          |
| total timesteps         | 414733        |
| value_loss              | 5.4514498e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008944245  |
| ent_coef_loss           | 2.900108      |
| entropy                 | 1.5488913     |
| episodes                | 1900          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 415295        |
| policy_loss             | -0.62257564   |
| qf1_loss                | 1.9327592e-05 |
| qf2_loss                | 1.7010718e-05 |
| time_elapsed            | 2967          |
| total timesteps         | 415395        |
| value_loss              | 2.5967485e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008769098  |
| ent_coef_loss           | -1.5001361    |
| entropy                 | 1.4898546     |
| episodes                | 1904          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 415944        |
| policy_loss             | -0.59661216   |
| qf1_loss                | 1.4009944e-05 |
| qf2_loss                | 1.3203527e-05 |
| time_elapsed            | 2971          |
| total timesteps         | 416044        |
| value_loss              | 2.5450561e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090898894 |
| ent_coef_loss           | -0.24546269   |
| entropy                 | 1.5868485     |
| episodes                | 1908          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 416628        |
| policy_loss             | -0.6114425    |
| qf1_loss                | 1.4009905e-05 |
| qf2_loss                | 2.4011713e-05 |
| time_elapsed            | 2976          |
| total timesteps         | 416728        |
| value_loss              | 4.7109123e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009138198  |
| ent_coef_loss           | -0.9128612    |
| entropy                 | 1.3154286     |
| episodes                | 1912          |
| fps                     | 140           |
| mean 100 episode reward | 0.9           |
| n_updates               | 417284        |
| policy_loss             | -0.5554855    |
| qf1_loss                | 3.391009e-05  |
| qf2_loss                | 9.084466e-05  |
| time_elapsed            | 2981          |
| total timesteps         | 417384        |
| value_loss              | 4.3427972e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008426893  |
| ent_coef_loss           | 0.65191936    |
| entropy                 | 1.2991931     |
| episodes                | 1916          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 417952        |
| policy_loss             | -0.56210935   |
| qf1_loss                | 1.9393476e-05 |
| qf2_loss                | 2.0309388e-05 |
| time_elapsed            | 2986          |
| total timesteps         | 418052        |
| value_loss              | 4.353954e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008300599  |
| ent_coef_loss           | 3.7108452     |
| entropy                 | 1.4555461     |
| episodes                | 1920          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 418690        |
| policy_loss             | -0.61328053   |
| qf1_loss                | 2.048345e-05  |
| qf2_loss                | 3.6581856e-05 |
| time_elapsed            | 2991          |
| total timesteps         | 418790        |
| value_loss              | 2.8758808e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009131669  |
| ent_coef_loss           | -2.7617567    |
| entropy                 | 1.440431      |
| episodes                | 1924          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 419416        |
| policy_loss             | -0.6231834    |
| qf1_loss                | 5.9318805e-05 |
| qf2_loss                | 6.888929e-05  |
| time_elapsed            | 2996          |
| total timesteps         | 419516        |
| value_loss              | 2.9529006e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009689157  |
| ent_coef_loss           | 0.26475275    |
| entropy                 | 1.3518796     |
| episodes                | 1928          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 420048        |
| policy_loss             | -0.5869437    |
| qf1_loss                | 7.3119576e-05 |
| qf2_loss                | 5.5820747e-05 |
| time_elapsed            | 3001          |
| total timesteps         | 420148        |
| value_loss              | 3.0036288e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009390811   |
| ent_coef_loss           | 1.0012206      |
| entropy                 | 1.4222915      |
| episodes                | 1932           |
| fps                     | 139            |
| mean 100 episode reward | 0.9            |
| n_updates               | 420792         |
| policy_loss             | -0.55656385    |
| qf1_loss                | 1.45937065e-05 |
| qf2_loss                | 9.772569e-06   |
| time_elapsed            | 3006           |
| total timesteps         | 420892         |
| value_loss              | 2.280472e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009676912  |
| ent_coef_loss           | 0.5678933     |
| entropy                 | 1.4747838     |
| episodes                | 1936          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 421444        |
| policy_loss             | -0.53640664   |
| qf1_loss                | 1.2181956e-05 |
| qf2_loss                | 4.5033754e-05 |
| time_elapsed            | 3011          |
| total timesteps         | 421544        |
| value_loss              | 4.915984e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009216416  |
| ent_coef_loss           | 4.132122      |
| entropy                 | 1.4224732     |
| episodes                | 1940          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 422122        |
| policy_loss             | -0.59229577   |
| qf1_loss                | 2.824193e-05  |
| qf2_loss                | 4.9116607e-05 |
| time_elapsed            | 3016          |
| total timesteps         | 422222        |
| value_loss              | 1.3048453e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00088325964 |
| ent_coef_loss           | 0.038514316   |
| entropy                 | 1.384573      |
| episodes                | 1944          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 422780        |
| policy_loss             | -0.59910166   |
| qf1_loss                | 2.0141888e-05 |
| qf2_loss                | 3.4218312e-05 |
| time_elapsed            | 3020          |
| total timesteps         | 422880        |
| value_loss              | 5.2700736e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089490786 |
| ent_coef_loss           | -1.4612062    |
| entropy                 | 1.4465593     |
| episodes                | 1948          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 423431        |
| policy_loss             | -0.6063192    |
| qf1_loss                | 2.1099502e-05 |
| qf2_loss                | 2.4019213e-05 |
| time_elapsed            | 3025          |
| total timesteps         | 423531        |
| value_loss              | 3.2903612e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008579088  |
| ent_coef_loss           | -0.18162107   |
| entropy                 | 1.3189588     |
| episodes                | 1952          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 424071        |
| policy_loss             | -0.5671669    |
| qf1_loss                | 1.6439637e-05 |
| qf2_loss                | 1.5571235e-05 |
| time_elapsed            | 3030          |
| total timesteps         | 424171        |
| value_loss              | 2.439825e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008605195  |
| ent_coef_loss           | -0.83615094   |
| entropy                 | 1.3759587     |
| episodes                | 1956          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 424720        |
| policy_loss             | -0.60768557   |
| qf1_loss                | 2.9489125e-05 |
| qf2_loss                | 2.8495211e-05 |
| time_elapsed            | 3034          |
| total timesteps         | 424820        |
| value_loss              | 4.9195016e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009280993  |
| ent_coef_loss           | 1.6542463     |
| entropy                 | 1.4204156     |
| episodes                | 1960          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 425354        |
| policy_loss             | -0.56796765   |
| qf1_loss                | 1.8402987e-05 |
| qf2_loss                | 2.4939836e-05 |
| time_elapsed            | 3039          |
| total timesteps         | 425454        |
| value_loss              | 4.2701915e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0008982177 |
| ent_coef_loss           | -0.5085635   |
| entropy                 | 1.603678     |
| episodes                | 1964         |
| fps                     | 139          |
| mean 100 episode reward | 0.9          |
| n_updates               | 426026       |
| policy_loss             | -0.6326988   |
| qf1_loss                | 6.626328e-06 |
| qf2_loss                | 6.656177e-06 |
| time_elapsed            | 3044         |
| total timesteps         | 426126       |
| value_loss              | 8.857987e-06 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093475875 |
| ent_coef_loss           | -2.6717825    |
| entropy                 | 1.4162362     |
| episodes                | 1968          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 426846        |
| policy_loss             | -0.5318459    |
| qf1_loss                | 1.651754e-05  |
| qf2_loss                | 1.1421873e-05 |
| time_elapsed            | 3049          |
| total timesteps         | 426946        |
| value_loss              | 9.314838e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096219784 |
| ent_coef_loss           | -0.22799098   |
| entropy                 | 1.5992482     |
| episodes                | 1972          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 427469        |
| policy_loss             | -0.5988631    |
| qf1_loss                | 2.7361099e-05 |
| qf2_loss                | 2.5991285e-05 |
| time_elapsed            | 3054          |
| total timesteps         | 427569        |
| value_loss              | 2.3585208e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009490825  |
| ent_coef_loss           | -0.62879753   |
| entropy                 | 1.5211272     |
| episodes                | 1976          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 428137        |
| policy_loss             | -0.58113074   |
| qf1_loss                | 1.4432697e-05 |
| qf2_loss                | 2.4600315e-05 |
| time_elapsed            | 3059          |
| total timesteps         | 428237        |
| value_loss              | 2.0096191e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009910589  |
| ent_coef_loss           | 0.55227226    |
| entropy                 | 1.6413741     |
| episodes                | 1980          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 428786        |
| policy_loss             | -0.61950815   |
| qf1_loss                | 1.6220367e-05 |
| qf2_loss                | 3.870819e-05  |
| time_elapsed            | 3063          |
| total timesteps         | 428886        |
| value_loss              | 2.6749618e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00091577886  |
| ent_coef_loss           | -3.3792052     |
| entropy                 | 1.3299618      |
| episodes                | 1984           |
| fps                     | 139            |
| mean 100 episode reward | 0.9            |
| n_updates               | 429447         |
| policy_loss             | -0.56254625    |
| qf1_loss                | 1.07446685e-05 |
| qf2_loss                | 2.7082548e-05  |
| time_elapsed            | 3068           |
| total timesteps         | 429547         |
| value_loss              | 3.788723e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092581724 |
| ent_coef_loss           | -2.2415302    |
| entropy                 | 1.4667194     |
| episodes                | 1988          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 430155        |
| policy_loss             | -0.56052685   |
| qf1_loss                | 2.0386371e-05 |
| qf2_loss                | 1.2764571e-05 |
| time_elapsed            | 3073          |
| total timesteps         | 430255        |
| value_loss              | 2.3578395e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090215384 |
| ent_coef_loss           | 0.37525406    |
| entropy                 | 1.513159      |
| episodes                | 1992          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 430858        |
| policy_loss             | -0.5390605    |
| qf1_loss                | 2.8922526e-05 |
| qf2_loss                | 4.7067373e-05 |
| time_elapsed            | 3078          |
| total timesteps         | 430958        |
| value_loss              | 6.504117e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008954278  |
| ent_coef_loss           | 1.0609148     |
| entropy                 | 1.4841207     |
| episodes                | 1996          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 431521        |
| policy_loss             | -0.6288438    |
| qf1_loss                | 2.893648e-05  |
| qf2_loss                | 4.7478083e-05 |
| time_elapsed            | 3083          |
| total timesteps         | 431621        |
| value_loss              | 3.922297e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009646174  |
| ent_coef_loss           | 2.5987196     |
| entropy                 | 1.5689343     |
| episodes                | 2000          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 432204        |
| policy_loss             | -0.62836194   |
| qf1_loss                | 7.5878866e-06 |
| qf2_loss                | 1.6898806e-05 |
| time_elapsed            | 3088          |
| total timesteps         | 432304        |
| value_loss              | 1.3401359e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094220915 |
| ent_coef_loss           | 1.2419007     |
| entropy                 | 1.6570264     |
| episodes                | 2004          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 432894        |
| policy_loss             | -0.58390045   |
| qf1_loss                | 1.3094765e-05 |
| qf2_loss                | 1.573448e-05  |
| time_elapsed            | 3093          |
| total timesteps         | 432994        |
| value_loss              | 3.6771162e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00083935994 |
| ent_coef_loss           | 0.7069192     |
| entropy                 | 1.515507      |
| episodes                | 2008          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 433565        |
| policy_loss             | -0.5508737    |
| qf1_loss                | 2.1302738e-05 |
| qf2_loss                | 1.737669e-05  |
| time_elapsed            | 3097          |
| total timesteps         | 433665        |
| value_loss              | 1.2563323e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008745755  |
| ent_coef_loss           | -0.91116315   |
| entropy                 | 1.413862      |
| episodes                | 2012          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 434304        |
| policy_loss             | -0.5430461    |
| qf1_loss                | 0.00011413027 |
| qf2_loss                | 0.00017707396 |
| time_elapsed            | 3103          |
| total timesteps         | 434404        |
| value_loss              | 2.0760468e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008255363  |
| ent_coef_loss           | 0.6275139     |
| entropy                 | 1.3036501     |
| episodes                | 2016          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 435016        |
| policy_loss             | -0.60977626   |
| qf1_loss                | 3.082702e-05  |
| qf2_loss                | 1.4073985e-05 |
| time_elapsed            | 3108          |
| total timesteps         | 435116        |
| value_loss              | 3.7019563e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008834492  |
| ent_coef_loss           | 0.6627962     |
| entropy                 | 1.4615964     |
| episodes                | 2020          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 435686        |
| policy_loss             | -0.598472     |
| qf1_loss                | 8.993289e-06  |
| qf2_loss                | 7.7701825e-06 |
| time_elapsed            | 3113          |
| total timesteps         | 435786        |
| value_loss              | 1.116107e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009044772  |
| ent_coef_loss           | 3.7445655     |
| entropy                 | 1.2764944     |
| episodes                | 2024          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 436441        |
| policy_loss             | -0.5828007    |
| qf1_loss                | 2.2050419e-05 |
| qf2_loss                | 1.8008475e-05 |
| time_elapsed            | 3118          |
| total timesteps         | 436541        |
| value_loss              | 3.2127184e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090606185 |
| ent_coef_loss           | -1.6697161    |
| entropy                 | 1.2109454     |
| episodes                | 2028          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 437189        |
| policy_loss             | -0.58716524   |
| qf1_loss                | 0.0012320213  |
| qf2_loss                | 0.0009412981  |
| time_elapsed            | 3123          |
| total timesteps         | 437289        |
| value_loss              | 0.00028432757 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089954986 |
| ent_coef_loss           | 1.2945211     |
| entropy                 | 1.3405457     |
| episodes                | 2032          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 437857        |
| policy_loss             | -0.60764456   |
| qf1_loss                | 8.768211e-06  |
| qf2_loss                | 1.6872993e-05 |
| time_elapsed            | 3128          |
| total timesteps         | 437957        |
| value_loss              | 2.095206e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009217884  |
| ent_coef_loss           | -0.39668912   |
| entropy                 | 1.3356953     |
| episodes                | 2036          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 438485        |
| policy_loss             | -0.5627136    |
| qf1_loss                | 1.7019698e-05 |
| qf2_loss                | 1.5586054e-05 |
| time_elapsed            | 3133          |
| total timesteps         | 438585        |
| value_loss              | 2.242337e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009285318  |
| ent_coef_loss           | -0.26037258   |
| entropy                 | 1.3961505     |
| episodes                | 2040          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 439191        |
| policy_loss             | -0.5644915    |
| qf1_loss                | 9.7004995e-06 |
| qf2_loss                | 2.9528843e-05 |
| time_elapsed            | 3138          |
| total timesteps         | 439291        |
| value_loss              | 1.6081798e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092105375 |
| ent_coef_loss           | -0.9542419    |
| entropy                 | 1.4675423     |
| episodes                | 2044          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 439849        |
| policy_loss             | -0.59975123   |
| qf1_loss                | 9.469055e-06  |
| qf2_loss                | 2.1810489e-05 |
| time_elapsed            | 3142          |
| total timesteps         | 439949        |
| value_loss              | 4.726283e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009312561  |
| ent_coef_loss           | -0.4437498    |
| entropy                 | 1.2967137     |
| episodes                | 2048          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 440536        |
| policy_loss             | -0.5714781    |
| qf1_loss                | 9.803121e-06  |
| qf2_loss                | 2.1980566e-05 |
| time_elapsed            | 3147          |
| total timesteps         | 440636        |
| value_loss              | 2.0629956e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092420244 |
| ent_coef_loss           | 0.37773293    |
| entropy                 | 1.2588706     |
| episodes                | 2052          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 441240        |
| policy_loss             | -0.5231053    |
| qf1_loss                | 4.0337512e-05 |
| qf2_loss                | 5.3458527e-05 |
| time_elapsed            | 3152          |
| total timesteps         | 441340        |
| value_loss              | 0.00017163489 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009689425  |
| ent_coef_loss           | -1.5780652    |
| entropy                 | 1.412777      |
| episodes                | 2056          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 442010        |
| policy_loss             | -0.58585095   |
| qf1_loss                | 2.3041925e-05 |
| qf2_loss                | 1.8715251e-05 |
| time_elapsed            | 3158          |
| total timesteps         | 442110        |
| value_loss              | 2.5093734e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010158241  |
| ent_coef_loss           | -2.2399921    |
| entropy                 | 1.3256142     |
| episodes                | 2060          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 442655        |
| policy_loss             | -0.58604485   |
| qf1_loss                | 1.8960181e-05 |
| qf2_loss                | 1.3678152e-05 |
| time_elapsed            | 3162          |
| total timesteps         | 442755        |
| value_loss              | 2.946542e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010710288  |
| ent_coef_loss           | -0.116672486  |
| entropy                 | 1.5176733     |
| episodes                | 2064          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 443395        |
| policy_loss             | -0.5738306    |
| qf1_loss                | 1.4112497e-05 |
| qf2_loss                | 1.4646303e-05 |
| time_elapsed            | 3168          |
| total timesteps         | 443495        |
| value_loss              | 4.2477135e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009940439  |
| ent_coef_loss           | 0.19411027    |
| entropy                 | 1.368992      |
| episodes                | 2068          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 444054        |
| policy_loss             | -0.5724977    |
| qf1_loss                | 1.8852672e-05 |
| qf2_loss                | 1.5921103e-05 |
| time_elapsed            | 3172          |
| total timesteps         | 444154        |
| value_loss              | 2.3459263e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009615759  |
| ent_coef_loss           | -1.2060709    |
| entropy                 | 1.4288923     |
| episodes                | 2072          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 444781        |
| policy_loss             | -0.562196     |
| qf1_loss                | 1.8449482e-05 |
| qf2_loss                | 1.656289e-05  |
| time_elapsed            | 3178          |
| total timesteps         | 444881        |
| value_loss              | 5.599149e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089069497 |
| ent_coef_loss           | -1.562717     |
| entropy                 | 1.4452803     |
| episodes                | 2076          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 445470        |
| policy_loss             | -0.6010985    |
| qf1_loss                | 9.141978e-06  |
| qf2_loss                | 1.4765869e-05 |
| time_elapsed            | 3182          |
| total timesteps         | 445570        |
| value_loss              | 3.1055177e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008344458  |
| ent_coef_loss           | -0.75801134   |
| entropy                 | 1.4433439     |
| episodes                | 2080          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 446258        |
| policy_loss             | -0.5825327    |
| qf1_loss                | 1.3186536e-05 |
| qf2_loss                | 1.9438477e-05 |
| time_elapsed            | 3188          |
| total timesteps         | 446358        |
| value_loss              | 2.1981105e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00077110133 |
| ent_coef_loss           | -2.961626     |
| entropy                 | 1.2159579     |
| episodes                | 2084          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 446962        |
| policy_loss             | -0.57290846   |
| qf1_loss                | 1.2443135e-05 |
| qf2_loss                | 1.7647073e-05 |
| time_elapsed            | 3193          |
| total timesteps         | 447062        |
| value_loss              | 2.7370688e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00083880255 |
| ent_coef_loss           | 3.9451938     |
| entropy                 | 1.4294531     |
| episodes                | 2088          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 447620        |
| policy_loss             | -0.58635056   |
| qf1_loss                | 2.6760226e-05 |
| qf2_loss                | 2.7068698e-05 |
| time_elapsed            | 3198          |
| total timesteps         | 447720        |
| value_loss              | 0.0031291894  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00084501784 |
| ent_coef_loss           | -1.4890403    |
| entropy                 | 1.2115535     |
| episodes                | 2092          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 448342        |
| policy_loss             | -0.5645058    |
| qf1_loss                | 1.4744289e-05 |
| qf2_loss                | 1.9560423e-05 |
| time_elapsed            | 3203          |
| total timesteps         | 448442        |
| value_loss              | 2.2839404e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008521357  |
| ent_coef_loss           | 1.8001583     |
| entropy                 | 1.4790672     |
| episodes                | 2096          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 449059        |
| policy_loss             | -0.6253407    |
| qf1_loss                | 9.581342e-06  |
| qf2_loss                | 1.575449e-05  |
| time_elapsed            | 3208          |
| total timesteps         | 449159        |
| value_loss              | 1.6870405e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009028747  |
| ent_coef_loss           | 0.86481154    |
| entropy                 | 1.5879877     |
| episodes                | 2100          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 449746        |
| policy_loss             | -0.60177827   |
| qf1_loss                | 1.6418531e-05 |
| qf2_loss                | 1.2405449e-05 |
| time_elapsed            | 3213          |
| total timesteps         | 449846        |
| value_loss              | 1.8250641e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092140125 |
| ent_coef_loss           | 1.5529363     |
| entropy                 | 1.4486005     |
| episodes                | 2104          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 450706        |
| policy_loss             | -0.5749989    |
| qf1_loss                | 1.037072e-05  |
| qf2_loss                | 1.1437541e-05 |
| time_elapsed            | 3220          |
| total timesteps         | 450806        |
| value_loss              | 1.7894406e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008982365  |
| ent_coef_loss           | 0.1650489     |
| entropy                 | 1.3537529     |
| episodes                | 2108          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 451371        |
| policy_loss             | -0.5730121    |
| qf1_loss                | 1.1512246e-05 |
| qf2_loss                | 1.4851423e-05 |
| time_elapsed            | 3225          |
| total timesteps         | 451471        |
| value_loss              | 3.4204393e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.000896657    |
| ent_coef_loss           | 2.9679122      |
| entropy                 | 1.4674592      |
| episodes                | 2112           |
| fps                     | 139            |
| mean 100 episode reward | 0.8            |
| n_updates               | 452008         |
| policy_loss             | -0.5950857     |
| qf1_loss                | 2.5039437e-05  |
| qf2_loss                | 1.06083935e-05 |
| time_elapsed            | 3229           |
| total timesteps         | 452108         |
| value_loss              | 3.1876792e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008341956  |
| ent_coef_loss           | 0.8345928     |
| entropy                 | 1.4153793     |
| episodes                | 2116          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 452999        |
| policy_loss             | -0.6288316    |
| qf1_loss                | 1.2180519e-05 |
| qf2_loss                | 1.5322565e-05 |
| time_elapsed            | 3236          |
| total timesteps         | 453099        |
| value_loss              | 1.5540458e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090110523 |
| ent_coef_loss           | -0.4671895    |
| entropy                 | 1.3627132     |
| episodes                | 2120          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 453706        |
| policy_loss             | -0.6139621    |
| qf1_loss                | 1.2297025e-05 |
| qf2_loss                | 1.281738e-05  |
| time_elapsed            | 3241          |
| total timesteps         | 453806        |
| value_loss              | 3.188864e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096559303 |
| ent_coef_loss           | 0.9601402     |
| entropy                 | 1.3821144     |
| episodes                | 2124          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 454487        |
| policy_loss             | -0.5726788    |
| qf1_loss                | 1.4086514e-05 |
| qf2_loss                | 1.3291763e-05 |
| time_elapsed            | 3247          |
| total timesteps         | 454587        |
| value_loss              | 2.5688816e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000986083   |
| ent_coef_loss           | 3.271758      |
| entropy                 | 1.5183672     |
| episodes                | 2128          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 455296        |
| policy_loss             | -0.5820539    |
| qf1_loss                | 2.6553138e-05 |
| qf2_loss                | 3.0456264e-05 |
| time_elapsed            | 3253          |
| total timesteps         | 455396        |
| value_loss              | 7.234911e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094949803 |
| ent_coef_loss           | -1.9616125    |
| entropy                 | 1.4563221     |
| episodes                | 2132          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 455983        |
| policy_loss             | -0.56064165   |
| qf1_loss                | 2.7459431e-05 |
| qf2_loss                | 2.3986002e-05 |
| time_elapsed            | 3258          |
| total timesteps         | 456083        |
| value_loss              | 4.4507964e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009679607  |
| ent_coef_loss           | 2.2959614     |
| entropy                 | 1.5379407     |
| episodes                | 2136          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 456628        |
| policy_loss             | -0.58806527   |
| qf1_loss                | 5.8470345e-05 |
| qf2_loss                | 0.00011228801 |
| time_elapsed            | 3262          |
| total timesteps         | 456728        |
| value_loss              | 4.9315102e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009977508  |
| ent_coef_loss           | 1.8147142     |
| entropy                 | 1.4795995     |
| episodes                | 2140          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 457271        |
| policy_loss             | -0.59236515   |
| qf1_loss                | 1.5777212e-05 |
| qf2_loss                | 9.371667e-06  |
| time_elapsed            | 3267          |
| total timesteps         | 457371        |
| value_loss              | 5.358197e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010380554  |
| ent_coef_loss           | 1.4829981     |
| entropy                 | 1.3964534     |
| episodes                | 2144          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 458210        |
| policy_loss             | -0.56423897   |
| qf1_loss                | 2.2350256e-05 |
| qf2_loss                | 3.1056974e-05 |
| time_elapsed            | 3274          |
| total timesteps         | 458310        |
| value_loss              | 3.792437e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010819375  |
| ent_coef_loss           | 1.7663015     |
| entropy                 | 1.5035125     |
| episodes                | 2148          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 458919        |
| policy_loss             | -0.5955191    |
| qf1_loss                | 2.5945968e-05 |
| qf2_loss                | 2.2721097e-05 |
| time_elapsed            | 3279          |
| total timesteps         | 459019        |
| value_loss              | 4.9712577e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000958623   |
| ent_coef_loss           | -0.8109573    |
| entropy                 | 1.3397596     |
| episodes                | 2152          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 459666        |
| policy_loss             | -0.53014016   |
| qf1_loss                | 2.8147593e-05 |
| qf2_loss                | 4.137518e-05  |
| time_elapsed            | 3284          |
| total timesteps         | 459766        |
| value_loss              | 9.3234485e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011212656  |
| ent_coef_loss           | 2.320857      |
| entropy                 | 1.508389      |
| episodes                | 2156          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 460439        |
| policy_loss             | -0.54613924   |
| qf1_loss                | 1.6888234e-05 |
| qf2_loss                | 2.7684353e-05 |
| time_elapsed            | 3290          |
| total timesteps         | 460539        |
| value_loss              | 7.745682e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011724484  |
| ent_coef_loss           | -1.8465453    |
| entropy                 | 1.5480816     |
| episodes                | 2160          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 461421        |
| policy_loss             | -0.5774946    |
| qf1_loss                | 1.857687e-05  |
| qf2_loss                | 1.3503362e-05 |
| time_elapsed            | 3297          |
| total timesteps         | 461521        |
| value_loss              | 3.4450226e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001101216   |
| ent_coef_loss           | 1.027909      |
| entropy                 | 1.4204423     |
| episodes                | 2164          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 462217        |
| policy_loss             | -0.5286511    |
| qf1_loss                | 2.6485612e-05 |
| qf2_loss                | 3.074037e-05  |
| time_elapsed            | 3302          |
| total timesteps         | 462317        |
| value_loss              | 8.892093e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001014655   |
| ent_coef_loss           | -1.2026583    |
| entropy                 | 1.4722298     |
| episodes                | 2168          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 462935        |
| policy_loss             | -0.5202278    |
| qf1_loss                | 2.7393573e-05 |
| qf2_loss                | 4.6251167e-05 |
| time_elapsed            | 3307          |
| total timesteps         | 463035        |
| value_loss              | 3.2273798e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092443824 |
| ent_coef_loss           | -0.56229633   |
| entropy                 | 1.5898349     |
| episodes                | 2172          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 463934        |
| policy_loss             | -0.5754015    |
| qf1_loss                | 1.6652446e-05 |
| qf2_loss                | 3.0473739e-05 |
| time_elapsed            | 3315          |
| total timesteps         | 464034        |
| value_loss              | 4.2686428e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095973717 |
| ent_coef_loss           | 0.5422417     |
| entropy                 | 1.5172629     |
| episodes                | 2176          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 464667        |
| policy_loss             | -0.5774742    |
| qf1_loss                | 3.2894437e-05 |
| qf2_loss                | 4.6091904e-05 |
| time_elapsed            | 3320          |
| total timesteps         | 464767        |
| value_loss              | 8.198667e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010234185  |
| ent_coef_loss           | 0.7338232     |
| entropy                 | 1.5777152     |
| episodes                | 2180          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 465360        |
| policy_loss             | -0.5472373    |
| qf1_loss                | 3.6364978e-05 |
| qf2_loss                | 3.0842722e-05 |
| time_elapsed            | 3325          |
| total timesteps         | 465460        |
| value_loss              | 3.7325495e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009279462  |
| ent_coef_loss           | 1.1020284     |
| entropy                 | 1.5078797     |
| episodes                | 2184          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 466111        |
| policy_loss             | -0.567173     |
| qf1_loss                | 5.6861303e-05 |
| qf2_loss                | 6.71375e-05   |
| time_elapsed            | 3330          |
| total timesteps         | 466211        |
| value_loss              | 9.160294e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008002811  |
| ent_coef_loss           | -4.750013     |
| entropy                 | 1.1968405     |
| episodes                | 2188          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 467069        |
| policy_loss             | -0.5605794    |
| qf1_loss                | 3.648911e-05  |
| qf2_loss                | 0.00014717932 |
| time_elapsed            | 3337          |
| total timesteps         | 467169        |
| value_loss              | 7.8774785e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007802749  |
| ent_coef_loss           | -1.7314887    |
| entropy                 | 1.268011      |
| episodes                | 2192          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 467787        |
| policy_loss             | -0.5756482    |
| qf1_loss                | 0.00012091446 |
| qf2_loss                | 3.823499e-05  |
| time_elapsed            | 3342          |
| total timesteps         | 467887        |
| value_loss              | 0.000301914   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008486035  |
| ent_coef_loss           | 2.3699656     |
| entropy                 | 1.2332238     |
| episodes                | 2196          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 468525        |
| policy_loss             | -0.55549383   |
| qf1_loss                | 2.0134728e-05 |
| qf2_loss                | 4.2689157e-05 |
| time_elapsed            | 3348          |
| total timesteps         | 468625        |
| value_loss              | 3.0303741e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00082967797 |
| ent_coef_loss           | -0.21736658   |
| entropy                 | 1.2323173     |
| episodes                | 2200          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 469203        |
| policy_loss             | -0.5882882    |
| qf1_loss                | 5.564385e-05  |
| qf2_loss                | 5.3964268e-05 |
| time_elapsed            | 3353          |
| total timesteps         | 469303        |
| value_loss              | 9.9859644e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007487918  |
| ent_coef_loss           | -1.6544683    |
| entropy                 | 1.196958      |
| episodes                | 2204          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 469938        |
| policy_loss             | -0.4976302    |
| qf1_loss                | 1.4845309e-05 |
| qf2_loss                | 3.3577635e-05 |
| time_elapsed            | 3358          |
| total timesteps         | 470038        |
| value_loss              | 4.5163062e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007685604  |
| ent_coef_loss           | 0.021062791   |
| entropy                 | 1.2570531     |
| episodes                | 2208          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 470654        |
| policy_loss             | -0.5567121    |
| qf1_loss                | 2.3921522e-05 |
| qf2_loss                | 3.467562e-05  |
| time_elapsed            | 3363          |
| total timesteps         | 470754        |
| value_loss              | 7.5178534e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007788601  |
| ent_coef_loss           | -0.38879013   |
| entropy                 | 1.3835952     |
| episodes                | 2212          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 471426        |
| policy_loss             | -0.54066515   |
| qf1_loss                | 2.3447185e-05 |
| qf2_loss                | 2.2908414e-05 |
| time_elapsed            | 3368          |
| total timesteps         | 471526        |
| value_loss              | 4.2392232e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007573994  |
| ent_coef_loss           | 0.19214976    |
| entropy                 | 1.200179      |
| episodes                | 2216          |
| fps                     | 139           |
| mean 100 episode reward | 0.9           |
| n_updates               | 472156        |
| policy_loss             | -0.5491924    |
| qf1_loss                | 3.2485437e-05 |
| qf2_loss                | 1.5018288e-05 |
| time_elapsed            | 3374          |
| total timesteps         | 472256        |
| value_loss              | 3.3809152e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007655812  |
| ent_coef_loss           | -2.4203098    |
| entropy                 | 1.2504262     |
| episodes                | 2220          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 472848        |
| policy_loss             | -0.5627689    |
| qf1_loss                | 3.55236e-05   |
| qf2_loss                | 2.6273663e-05 |
| time_elapsed            | 3379          |
| total timesteps         | 472948        |
| value_loss              | 8.660752e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006964294  |
| ent_coef_loss           | 2.1019886     |
| entropy                 | 1.2812626     |
| episodes                | 2224          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 473865        |
| policy_loss             | -0.6237589    |
| qf1_loss                | 1.1578256e-05 |
| qf2_loss                | 1.7135364e-05 |
| time_elapsed            | 3386          |
| total timesteps         | 473965        |
| value_loss              | 2.2419761e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00083379634 |
| ent_coef_loss           | -1.2220422    |
| entropy                 | 1.1684215     |
| episodes                | 2228          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 474527        |
| policy_loss             | -0.549618     |
| qf1_loss                | 2.4588955e-05 |
| qf2_loss                | 5.279278e-05  |
| time_elapsed            | 3391          |
| total timesteps         | 474627        |
| value_loss              | 6.8701316e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095682504 |
| ent_coef_loss           | -2.1799378    |
| entropy                 | 1.2620915     |
| episodes                | 2232          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 475250        |
| policy_loss             | -0.5350306    |
| qf1_loss                | 1.4516164e-05 |
| qf2_loss                | 1.4217323e-05 |
| time_elapsed            | 3396          |
| total timesteps         | 475350        |
| value_loss              | 2.2202723e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010242772  |
| ent_coef_loss           | 1.2706295     |
| entropy                 | 1.4697629     |
| episodes                | 2236          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 475964        |
| policy_loss             | -0.56599534   |
| qf1_loss                | 2.6972895e-05 |
| qf2_loss                | 3.2256656e-05 |
| time_elapsed            | 3401          |
| total timesteps         | 476064        |
| value_loss              | 1.5083913e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010702568  |
| ent_coef_loss           | 3.1081862     |
| entropy                 | 1.4855335     |
| episodes                | 2240          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 476805        |
| policy_loss             | -0.62302923   |
| qf1_loss                | 2.2041531e-05 |
| qf2_loss                | 2.6089212e-05 |
| time_elapsed            | 3407          |
| total timesteps         | 476905        |
| value_loss              | 2.8281305e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011048382  |
| ent_coef_loss           | 0.11926192    |
| entropy                 | 1.435163      |
| episodes                | 2244          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 477807        |
| policy_loss             | -0.5087304    |
| qf1_loss                | 3.1832104e-05 |
| qf2_loss                | 2.3232113e-05 |
| time_elapsed            | 3414          |
| total timesteps         | 477907        |
| value_loss              | 4.5997876e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0011027472 |
| ent_coef_loss           | 0.4831071    |
| entropy                 | 1.4183123    |
| episodes                | 2248         |
| fps                     | 139          |
| mean 100 episode reward | 0.8          |
| n_updates               | 478686       |
| policy_loss             | -0.5042343   |
| qf1_loss                | 0.0001090422 |
| qf2_loss                | 3.071812e-05 |
| time_elapsed            | 3420         |
| total timesteps         | 478786       |
| value_loss              | 7.028459e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010908985  |
| ent_coef_loss           | -1.100754     |
| entropy                 | 1.3758466     |
| episodes                | 2252          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 479450        |
| policy_loss             | -0.5822346    |
| qf1_loss                | 3.0507816e-05 |
| qf2_loss                | 4.2207852e-05 |
| time_elapsed            | 3426          |
| total timesteps         | 479550        |
| value_loss              | 6.139332e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00102745    |
| ent_coef_loss           | 0.13364094    |
| entropy                 | 1.4407897     |
| episodes                | 2256          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 480165        |
| policy_loss             | -0.52861124   |
| qf1_loss                | 4.2475625e-05 |
| qf2_loss                | 2.359618e-05  |
| time_elapsed            | 3431          |
| total timesteps         | 480265        |
| value_loss              | 3.2083364e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009462271  |
| ent_coef_loss           | -0.07496846   |
| entropy                 | 1.3702979     |
| episodes                | 2260          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 480826        |
| policy_loss             | -0.55468553   |
| qf1_loss                | 1.9806568e-05 |
| qf2_loss                | 2.8056864e-05 |
| time_elapsed            | 3436          |
| total timesteps         | 480926        |
| value_loss              | 5.6748017e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093355245 |
| ent_coef_loss           | -2.174947     |
| entropy                 | 1.376221      |
| episodes                | 2264          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 481667        |
| policy_loss             | -0.49591005   |
| qf1_loss                | 0.00023825312 |
| qf2_loss                | 0.00032433152 |
| time_elapsed            | 3442          |
| total timesteps         | 481767        |
| value_loss              | 8.739752e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086956227 |
| ent_coef_loss           | 1.9278626     |
| entropy                 | 1.3719829     |
| episodes                | 2268          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 482495        |
| policy_loss             | -0.5609856    |
| qf1_loss                | 1.5073474e-05 |
| qf2_loss                | 2.288104e-05  |
| time_elapsed            | 3448          |
| total timesteps         | 482595        |
| value_loss              | 5.4816202e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00084902445 |
| ent_coef_loss           | 1.9293172     |
| entropy                 | 1.470826      |
| episodes                | 2272          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 483237        |
| policy_loss             | -0.5182649    |
| qf1_loss                | 3.812537e-05  |
| qf2_loss                | 4.6406527e-05 |
| time_elapsed            | 3453          |
| total timesteps         | 483337        |
| value_loss              | 8.902987e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008919147  |
| ent_coef_loss           | -1.9559319    |
| entropy                 | 1.6163008     |
| episodes                | 2276          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 483911        |
| policy_loss             | -0.52625304   |
| qf1_loss                | 2.7214835e-05 |
| qf2_loss                | 3.0831157e-05 |
| time_elapsed            | 3458          |
| total timesteps         | 484011        |
| value_loss              | 3.666109e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00088808977 |
| ent_coef_loss           | -0.1993739    |
| entropy                 | 1.4988267     |
| episodes                | 2280          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 484623        |
| policy_loss             | -0.49847817   |
| qf1_loss                | 1.8033033e-05 |
| qf2_loss                | 2.299705e-05  |
| time_elapsed            | 3463          |
| total timesteps         | 484723        |
| value_loss              | 2.8721824e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009333197  |
| ent_coef_loss           | -0.0028765202 |
| entropy                 | 1.4762025     |
| episodes                | 2284          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 485352        |
| policy_loss             | -0.52741617   |
| qf1_loss                | 4.170437e-05  |
| qf2_loss                | 5.0867024e-05 |
| time_elapsed            | 3468          |
| total timesteps         | 485452        |
| value_loss              | 6.9084854e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090480765 |
| ent_coef_loss           | -4.3485765    |
| entropy                 | 1.5082066     |
| episodes                | 2288          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 486086        |
| policy_loss             | -0.54162854   |
| qf1_loss                | 1.0279175e-05 |
| qf2_loss                | 1.2128947e-05 |
| time_elapsed            | 3474          |
| total timesteps         | 486186        |
| value_loss              | 3.3409357e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008832083  |
| ent_coef_loss           | -3.7181678    |
| entropy                 | 1.5635024     |
| episodes                | 2292          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 486764        |
| policy_loss             | -0.5692548    |
| qf1_loss                | 1.8201605e-05 |
| qf2_loss                | 1.5135193e-05 |
| time_elapsed            | 3478          |
| total timesteps         | 486864        |
| value_loss              | 3.7967977e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009076406  |
| ent_coef_loss           | 2.5925884     |
| entropy                 | 1.5177292     |
| episodes                | 2296          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 487431        |
| policy_loss             | -0.5680212    |
| qf1_loss                | 3.65326e-05   |
| qf2_loss                | 2.0802545e-05 |
| time_elapsed            | 3483          |
| total timesteps         | 487531        |
| value_loss              | 4.6845704e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009117737  |
| ent_coef_loss           | -0.34040144   |
| entropy                 | 1.2919831     |
| episodes                | 2300          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 488189        |
| policy_loss             | -0.56077707   |
| qf1_loss                | 1.9631674e-05 |
| qf2_loss                | 2.2479588e-05 |
| time_elapsed            | 3488          |
| total timesteps         | 488289        |
| value_loss              | 4.344149e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009534561  |
| ent_coef_loss           | 3.8609884     |
| entropy                 | 1.3697724     |
| episodes                | 2304          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 489028        |
| policy_loss             | -0.55042005   |
| qf1_loss                | 7.916928e-05  |
| qf2_loss                | 6.426951e-05  |
| time_elapsed            | 3495          |
| total timesteps         | 489128        |
| value_loss              | 0.00023994836 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010057638  |
| ent_coef_loss           | -0.65359354   |
| entropy                 | 1.4446292     |
| episodes                | 2308          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 489698        |
| policy_loss             | -0.53303087   |
| qf1_loss                | 0.00012395857 |
| qf2_loss                | 0.00022256037 |
| time_elapsed            | 3500          |
| total timesteps         | 489798        |
| value_loss              | 0.00013564072 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0009395308 |
| ent_coef_loss           | 1.5235288    |
| entropy                 | 1.6028975    |
| episodes                | 2312         |
| fps                     | 139          |
| mean 100 episode reward | 0.8          |
| n_updates               | 490350       |
| policy_loss             | -0.553985    |
| qf1_loss                | 3.82129e-05  |
| qf2_loss                | 3.538551e-05 |
| time_elapsed            | 3504         |
| total timesteps         | 490450       |
| value_loss              | 3.214493e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010293609  |
| ent_coef_loss           | -1.9640648    |
| entropy                 | 1.3569558     |
| episodes                | 2316          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 491061        |
| policy_loss             | -0.52597797   |
| qf1_loss                | 4.415437e-05  |
| qf2_loss                | 7.6650744e-05 |
| time_elapsed            | 3509          |
| total timesteps         | 491161        |
| value_loss              | 8.32916e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009808055  |
| ent_coef_loss           | -1.8031293    |
| entropy                 | 1.2792907     |
| episodes                | 2320          |
| fps                     | 139           |
| mean 100 episode reward | 0.7           |
| n_updates               | 491801        |
| policy_loss             | -0.5349787    |
| qf1_loss                | 2.844115e-05  |
| qf2_loss                | 3.292341e-05  |
| time_elapsed            | 3514          |
| total timesteps         | 491901        |
| value_loss              | 0.00016039546 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010220017  |
| ent_coef_loss           | 0.7422993     |
| entropy                 | 1.4177089     |
| episodes                | 2324          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 492495        |
| policy_loss             | -0.5027858    |
| qf1_loss                | 2.9631714e-05 |
| qf2_loss                | 4.6019522e-05 |
| time_elapsed            | 3519          |
| total timesteps         | 492595        |
| value_loss              | 3.3642224e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010024161  |
| ent_coef_loss           | 5.6475577     |
| entropy                 | 1.5497543     |
| episodes                | 2328          |
| fps                     | 139           |
| mean 100 episode reward | 0.7           |
| n_updates               | 493708        |
| policy_loss             | -0.593736     |
| qf1_loss                | 5.0002778e-05 |
| qf2_loss                | 8.459533e-05  |
| time_elapsed            | 3528          |
| total timesteps         | 493808        |
| value_loss              | 0.00015515539 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000940438   |
| ent_coef_loss           | 0.7809801     |
| entropy                 | 1.3430104     |
| episodes                | 2332          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 494435        |
| policy_loss             | -0.5326723    |
| qf1_loss                | 0.00031728475 |
| qf2_loss                | 0.00013006429 |
| time_elapsed            | 3533          |
| total timesteps         | 494535        |
| value_loss              | 0.00032477552 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009350993  |
| ent_coef_loss           | 1.4617946     |
| entropy                 | 1.2752926     |
| episodes                | 2336          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 495132        |
| policy_loss             | -0.5178016    |
| qf1_loss                | 0.000346803   |
| qf2_loss                | 0.0004699626  |
| time_elapsed            | 3538          |
| total timesteps         | 495232        |
| value_loss              | 0.00018313964 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00094674976  |
| ent_coef_loss           | 1.042233       |
| entropy                 | 1.4806812      |
| episodes                | 2340           |
| fps                     | 139            |
| mean 100 episode reward | 0.8            |
| n_updates               | 495929         |
| policy_loss             | -0.56884897    |
| qf1_loss                | 5.6389006e-05  |
| qf2_loss                | 7.381158e-05   |
| time_elapsed            | 3544           |
| total timesteps         | 496029         |
| value_loss              | 0.000105168125 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010355405  |
| ent_coef_loss           | -0.7383088    |
| entropy                 | 1.4420633     |
| episodes                | 2344          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 496695        |
| policy_loss             | -0.5361462    |
| qf1_loss                | 8.959003e-05  |
| qf2_loss                | 4.8058275e-05 |
| time_elapsed            | 3549          |
| total timesteps         | 496795        |
| value_loss              | 4.9186216e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001014329   |
| ent_coef_loss           | -1.3920239    |
| entropy                 | 1.5066271     |
| episodes                | 2348          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 497374        |
| policy_loss             | -0.54062784   |
| qf1_loss                | 5.0418676e-05 |
| qf2_loss                | 4.1277086e-05 |
| time_elapsed            | 3555          |
| total timesteps         | 497474        |
| value_loss              | 3.3008615e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009787373  |
| ent_coef_loss           | -1.0356891    |
| entropy                 | 1.3946497     |
| episodes                | 2352          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 498100        |
| policy_loss             | -0.5376675    |
| qf1_loss                | 4.2213527e-05 |
| qf2_loss                | 5.5174336e-05 |
| time_elapsed            | 3560          |
| total timesteps         | 498200        |
| value_loss              | 6.446903e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095582183 |
| ent_coef_loss           | -1.2177258    |
| entropy                 | 1.4851717     |
| episodes                | 2356          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 498892        |
| policy_loss             | -0.57741386   |
| qf1_loss                | 1.8010596e-05 |
| qf2_loss                | 2.7969858e-05 |
| time_elapsed            | 3565          |
| total timesteps         | 498992        |
| value_loss              | 2.3465745e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009629492  |
| ent_coef_loss           | -1.2898738    |
| entropy                 | 1.4353426     |
| episodes                | 2360          |
| fps                     | 139           |
| mean 100 episode reward | 0.8           |
| n_updates               | 499638        |
| policy_loss             | -0.56414807   |
| qf1_loss                | 4.3229848e-05 |
| qf2_loss                | 9.175678e-05  |
| time_elapsed            | 3571          |
| total timesteps         | 499738        |
| value_loss              | 3.0893752e-05 |
-------------------------------------------
>>>>> End testing <<<<< decay:_0__nn_layers:_[1024__512__256]
Final weights saved at:  /home/admin/tensorboard_logs/sac_decay:_0__nn_layers:_[1024__512__256]/stable_baselines.pkl
TEST COMMAND: python3 py3_learning.py --test --weights  /home/admin/tensorboard_logs/sac_decay:_0__nn_layers:_[1024__512__256]/stable_baselines.pkl
Starting test with params: {'nn_layers': [512, 256, 128, 64]}
Namespace(draw_screen=False, env_config='configs/env.config', policy='multi_human_rl', policy_config='configs/policy.config', test=False, train_config='configs/train.config', weights=None)
Gym environment created.
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.5435123    |
| ent_coef_loss           | -2.063375    |
| entropy                 | 2.6010673    |
| episodes                | 4            |
| fps                     | 141          |
| mean 100 episode reward | -0.1         |
| n_updates               | 1220         |
| policy_loss             | -5.4307146   |
| qf1_loss                | 0.001834397  |
| qf2_loss                | 0.0013886627 |
| time_elapsed            | 9            |
| total timesteps         | 1320         |
| value_loss              | 0.019885015  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.22560033   |
| ent_coef_loss           | -4.879279    |
| entropy                 | 2.6823964    |
| episodes                | 8            |
| fps                     | 136          |
| mean 100 episode reward | -0.1         |
| n_updates               | 2980         |
| policy_loss             | -8.25791     |
| qf1_loss                | 0.0075229034 |
| qf2_loss                | 0.009379503  |
| time_elapsed            | 22           |
| total timesteps         | 3080         |
| value_loss              | 0.027515078  |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0005      |
| ent_coef                | 0.09391454  |
| ent_coef_loss           | -7.913665   |
| entropy                 | 2.5617583   |
| episodes                | 12          |
| fps                     | 138         |
| mean 100 episode reward | -0.1        |
| n_updates               | 4740        |
| policy_loss             | -8.987279   |
| qf1_loss                | 0.004791839 |
| qf2_loss                | 0.005617429 |
| time_elapsed            | 35          |
| total timesteps         | 4840        |
| value_loss              | 0.004700766 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0005      |
| ent_coef                | 0.039723497 |
| ent_coef_loss           | -9.899449   |
| entropy                 | 2.62391     |
| episodes                | 16          |
| fps                     | 137         |
| mean 100 episode reward | -0.1        |
| n_updates               | 6500        |
| policy_loss             | -8.612828   |
| qf1_loss                | 0.42554218  |
| qf2_loss                | 0.4213085   |
| time_elapsed            | 48          |
| total timesteps         | 6600        |
| value_loss              | 0.010882367 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.01920811   |
| ent_coef_loss           | -5.4207077   |
| entropy                 | 2.5321624    |
| episodes                | 20           |
| fps                     | 138          |
| mean 100 episode reward | -0.2         |
| n_updates               | 8260         |
| policy_loss             | -8.25153     |
| qf1_loss                | 0.01190651   |
| qf2_loss                | 0.0143190455 |
| time_elapsed            | 60           |
| total timesteps         | 8360         |
| value_loss              | 0.018673163  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.013065109  |
| ent_coef_loss           | -3.0637999   |
| entropy                 | 1.9750247    |
| episodes                | 24           |
| fps                     | 137          |
| mean 100 episode reward | -0.2         |
| n_updates               | 10020        |
| policy_loss             | -8.020706    |
| qf1_loss                | 0.0083189495 |
| qf2_loss                | 0.011170434  |
| time_elapsed            | 73           |
| total timesteps         | 10120        |
| value_loss              | 0.026512943  |
------------------------------------------
