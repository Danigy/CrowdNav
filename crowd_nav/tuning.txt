pygame 1.9.6
Hello from the pygame community. https://www.pygame.org/contribute.html
Loading chipmunk for Linux (64bit) [/usr/local/lib/python3.5/dist-packages/pymunk/libchipmunk.so]
Starting test with params: {'energy': -0.0005, 'slack': -0.0005}
Namespace(draw_screen=False, env_config='configs/env.config', policy='multi_human_rl', policy_config='configs/policy.config', test=False, train_config='configs/train.config', weights=None)
Gym environment created.
COLLISION PENALTY -0.25
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.33268476   |
| ent_coef_loss           | -3.6864302   |
| entropy                 | 2.6382713    |
| episodes                | 4            |
| fps                     | 157          |
| mean 100 episode reward | -1.9         |
| n_updates               | 1101         |
| policy_loss             | -3.827448    |
| qf1_loss                | 0.03366396   |
| qf2_loss                | 0.034267254  |
| time_elapsed            | 7            |
| total timesteps         | 1201         |
| value_loss              | 0.0036633315 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.074424595  |
| ent_coef_loss           | -8.586086    |
| entropy                 | 2.6908894    |
| episodes                | 8            |
| fps                     | 148          |
| mean 100 episode reward | -1.9         |
| n_updates               | 2611         |
| policy_loss             | -4.6111507   |
| qf1_loss                | 0.002501458  |
| qf2_loss                | 0.0020402563 |
| time_elapsed            | 18           |
| total timesteps         | 2711         |
| value_loss              | 0.011284398  |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.019689603  |
| ent_coef_loss           | -8.089239    |
| entropy                 | 2.4731514    |
| episodes                | 12           |
| fps                     | 147          |
| mean 100 episode reward | -1.5         |
| n_updates               | 4066         |
| policy_loss             | -4.407006    |
| qf1_loss                | 0.004959042  |
| qf2_loss                | 0.0026480227 |
| time_elapsed            | 28           |
| total timesteps         | 4166         |
| value_loss              | 0.0080931485 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.006674042  |
| ent_coef_loss           | -2.4950886   |
| entropy                 | 1.6977371    |
| episodes                | 16           |
| fps                     | 146          |
| mean 100 episode reward | -1.8         |
| n_updates               | 5824         |
| policy_loss             | -4.2961774   |
| qf1_loss                | 0.0019306034 |
| qf2_loss                | 0.0015559758 |
| time_elapsed            | 40           |
| total timesteps         | 5924         |
| value_loss              | 0.0014548046 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.004950283  |
| ent_coef_loss           | -0.5788456   |
| entropy                 | 1.140883     |
| episodes                | 20           |
| fps                     | 145          |
| mean 100 episode reward | -1.7         |
| n_updates               | 7342         |
| policy_loss             | -3.9899478   |
| qf1_loss                | 0.00366718   |
| qf2_loss                | 0.0036601638 |
| time_elapsed            | 51           |
| total timesteps         | 7442         |
| value_loss              | 0.0055807913 |
------------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.004505722 |
| ent_coef_loss           | -2.3062108  |
| entropy                 | 0.9917409   |
| episodes                | 24          |
| fps                     | 146         |
| mean 100 episode reward | -1.8        |
| n_updates               | 8983        |
| policy_loss             | -3.6780636  |
| qf1_loss                | 0.042936947 |
| qf2_loss                | 0.060762152 |
| time_elapsed            | 62          |
| total timesteps         | 9083        |
| value_loss              | 0.010476263 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0041776663 |
| ent_coef_loss           | -1.642796    |
| entropy                 | 1.1347537    |
| episodes                | 28           |
| fps                     | 146          |
| mean 100 episode reward | -1.7         |
| n_updates               | 10471        |
| policy_loss             | -3.476058    |
| qf1_loss                | 0.04643042   |
| qf2_loss                | 0.039287742  |
| time_elapsed            | 72           |
| total timesteps         | 10571        |
| value_loss              | 0.0010637317 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0041220346 |
| ent_coef_loss           | 1.5255078    |
| entropy                 | 1.2555978    |
| episodes                | 32           |
| fps                     | 147          |
| mean 100 episode reward | -1.6         |
| n_updates               | 12231        |
| policy_loss             | -2.9826295   |
| qf1_loss                | 0.033841547  |
| qf2_loss                | 0.03368944   |
| time_elapsed            | 83           |
| total timesteps         | 12331        |
| value_loss              | 0.0058711786 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.003203864  |
| ent_coef_loss           | -1.5349529   |
| entropy                 | 1.015483     |
| episodes                | 36           |
| fps                     | 147          |
| mean 100 episode reward | -1.5         |
| n_updates               | 13617        |
| policy_loss             | -2.7450438   |
| qf1_loss                | 0.0010856674 |
| qf2_loss                | 0.0011428428 |
| time_elapsed            | 93           |
| total timesteps         | 13717        |
| value_loss              | 0.002260592  |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0029757412 |
| ent_coef_loss           | -2.7848508   |
| entropy                 | 0.7036006    |
| episodes                | 40           |
| fps                     | 147          |
| mean 100 episode reward | -1.6         |
| n_updates               | 15377        |
| policy_loss             | -2.3741126   |
| qf1_loss                | 0.0034063922 |
| qf2_loss                | 0.0031992733 |
| time_elapsed            | 105          |
| total timesteps         | 15477        |
| value_loss              | 0.0024913482 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0026756357 |
| ent_coef_loss           | 0.85547566   |
| entropy                 | 0.7652832    |
| episodes                | 44           |
| fps                     | 146          |
| mean 100 episode reward | -1.6         |
| n_updates               | 17137        |
| policy_loss             | -2.364191    |
| qf1_loss                | 0.0009478283 |
| qf2_loss                | 0.0014113486 |
| time_elapsed            | 117          |
| total timesteps         | 17237        |
| value_loss              | 0.0057713934 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0021896064  |
| ent_coef_loss           | -1.6472719    |
| entropy                 | 0.79230535    |
| episodes                | 48            |
| fps                     | 146           |
| mean 100 episode reward | -1.5          |
| n_updates               | 18897         |
| policy_loss             | -2.0111475    |
| qf1_loss                | 0.0020232312  |
| qf2_loss                | 0.0020480042  |
| time_elapsed            | 129           |
| total timesteps         | 18997         |
| value_loss              | 0.00073663425 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0018708631  |
| ent_coef_loss           | 0.905074      |
| entropy                 | 0.5381372     |
| episodes                | 52            |
| fps                     | 146           |
| mean 100 episode reward | -1.4          |
| n_updates               | 20400         |
| policy_loss             | -1.8771522    |
| qf1_loss                | 0.00072347285 |
| qf2_loss                | 0.0007931149  |
| time_elapsed            | 140           |
| total timesteps         | 20500         |
| value_loss              | 0.0007123434  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0020008488 |
| ent_coef_loss           | -1.2232447   |
| entropy                 | 0.8424201    |
| episodes                | 56           |
| fps                     | 146          |
| mean 100 episode reward | -1.3         |
| n_updates               | 22160        |
| policy_loss             | -1.648143    |
| qf1_loss                | 0.001338513  |
| qf2_loss                | 0.0017217563 |
| time_elapsed            | 151          |
| total timesteps         | 22260        |
| value_loss              | 0.0030002645 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0016287975  |
| ent_coef_loss           | 5.320389      |
| entropy                 | 0.78217256    |
| episodes                | 60            |
| fps                     | 146           |
| mean 100 episode reward | -1.3          |
| n_updates               | 23677         |
| policy_loss             | -1.5842923    |
| qf1_loss                | 0.00200293    |
| qf2_loss                | 0.00063753093 |
| time_elapsed            | 162           |
| total timesteps         | 23777         |
| value_loss              | 0.000599852   |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0014387686 |
| ent_coef_loss           | 0.90642524   |
| entropy                 | 0.38429278   |
| episodes                | 64           |
| fps                     | 146          |
| mean 100 episode reward | -1.3         |
| n_updates               | 25437        |
| policy_loss             | -1.4689592   |
| qf1_loss                | 0.0068627843 |
| qf2_loss                | 0.0073683015 |
| time_elapsed            | 173          |
| total timesteps         | 25537        |
| value_loss              | 0.0009610576 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0013809411  |
| ent_coef_loss           | 1.907886      |
| entropy                 | 0.39048487    |
| episodes                | 68            |
| fps                     | 147           |
| mean 100 episode reward | -1.2          |
| n_updates               | 27197         |
| policy_loss             | -1.276876     |
| qf1_loss                | 0.0002524685  |
| qf2_loss                | 0.00014876542 |
| time_elapsed            | 185           |
| total timesteps         | 27297         |
| value_loss              | 0.00033687503 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.001483049   |
| ent_coef_loss           | -2.5592933    |
| entropy                 | 0.67799854    |
| episodes                | 72            |
| fps                     | 146           |
| mean 100 episode reward | -1.3          |
| n_updates               | 28957         |
| policy_loss             | -1.1702968    |
| qf1_loss                | 0.0004770162  |
| qf2_loss                | 0.00043979456 |
| time_elapsed            | 198           |
| total timesteps         | 29057         |
| value_loss              | 0.00029810442 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0012422723 |
| ent_coef_loss           | 2.4170656    |
| entropy                 | 0.3328241    |
| episodes                | 76           |
| fps                     | 146          |
| mean 100 episode reward | -1.2         |
| n_updates               | 30598        |
| policy_loss             | -1.0500892   |
| qf1_loss                | 0.0049035465 |
| qf2_loss                | 0.003783735  |
| time_elapsed            | 209          |
| total timesteps         | 30698        |
| value_loss              | 0.0005080225 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0012828234 |
| ent_coef_loss           | 0.7837784    |
| entropy                 | 0.5118454    |
| episodes                | 80           |
| fps                     | 146          |
| mean 100 episode reward | -1.2         |
| n_updates               | 32066        |
| policy_loss             | -1.0243676   |
| qf1_loss                | 0.010658245  |
| qf2_loss                | 0.010802463  |
| time_elapsed            | 219          |
| total timesteps         | 32166        |
| value_loss              | 0.0004857143 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0013170938  |
| ent_coef_loss           | 0.6411369     |
| entropy                 | 0.63117486    |
| episodes                | 84            |
| fps                     | 146           |
| mean 100 episode reward | -1.2          |
| n_updates               | 33797         |
| policy_loss             | -0.920344     |
| qf1_loss                | 0.0004088123  |
| qf2_loss                | 0.00034571032 |
| time_elapsed            | 231           |
| total timesteps         | 33897         |
| value_loss              | 0.0006533904  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0012793237  |
| ent_coef_loss           | 2.8583        |
| entropy                 | 0.7228417     |
| episodes                | 88            |
| fps                     | 146           |
| mean 100 episode reward | -1.2          |
| n_updates               | 35262         |
| policy_loss             | -0.7615845    |
| qf1_loss                | 0.008563951   |
| qf2_loss                | 0.008757289   |
| time_elapsed            | 241           |
| total timesteps         | 35362         |
| value_loss              | 0.00054720865 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.001          |
| ent_coef                | 0.0012789053   |
| ent_coef_loss           | -0.004518926   |
| entropy                 | 0.9156957      |
| episodes                | 92             |
| fps                     | 146            |
| mean 100 episode reward | -1.1           |
| n_updates               | 36788          |
| policy_loss             | -0.8106298     |
| qf1_loss                | 0.00014170553  |
| qf2_loss                | 0.000116141775 |
| time_elapsed            | 251            |
| total timesteps         | 36888          |
| value_loss              | 0.00040400997  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.001126964   |
| ent_coef_loss           | -1.6718001    |
| entropy                 | 1.1588695     |
| episodes                | 96            |
| fps                     | 146           |
| mean 100 episode reward | -1.2          |
| n_updates               | 38548         |
| policy_loss             | -0.7175319    |
| qf1_loss                | 8.276301e-05  |
| qf2_loss                | 9.195984e-05  |
| time_elapsed            | 263           |
| total timesteps         | 38648         |
| value_loss              | 0.00012691326 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0010375298  |
| ent_coef_loss           | -0.14409125   |
| entropy                 | 0.916807      |
| episodes                | 100           |
| fps                     | 146           |
| mean 100 episode reward | -1.1          |
| n_updates               | 40308         |
| policy_loss             | -0.58800423   |
| qf1_loss                | 0.00012020158 |
| qf2_loss                | 0.00011262451 |
| time_elapsed            | 275           |
| total timesteps         | 40408         |
| value_loss              | 0.00017775172 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0008435794  |
| ent_coef_loss           | 2.5914133     |
| entropy                 | 0.9016975     |
| episodes                | 104           |
| fps                     | 146           |
| mean 100 episode reward | -1.1          |
| n_updates               | 41758         |
| policy_loss             | -0.5590024    |
| qf1_loss                | 0.00025261904 |
| qf2_loss                | 0.00029140478 |
| time_elapsed            | 285           |
| total timesteps         | 41858         |
| value_loss              | 0.000386519   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00090965535 |
| ent_coef_loss           | -3.454402     |
| entropy                 | 0.7709099     |
| episodes                | 108           |
| fps                     | 146           |
| mean 100 episode reward | -1            |
| n_updates               | 43518         |
| policy_loss             | -0.5288264    |
| qf1_loss                | 0.00016942849 |
| qf2_loss                | 0.0002176358  |
| time_elapsed            | 297           |
| total timesteps         | 43618         |
| value_loss              | 0.0006645136  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.000802393   |
| ent_coef_loss           | 0.59359735    |
| entropy                 | 1.0786695     |
| episodes                | 112           |
| fps                     | 146           |
| mean 100 episode reward | -1.1          |
| n_updates               | 45184         |
| policy_loss             | -0.46176663   |
| qf1_loss                | 6.918013e-05  |
| qf2_loss                | 0.00012697035 |
| time_elapsed            | 309           |
| total timesteps         | 45284         |
| value_loss              | 0.00022658997 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0007838796 |
| ent_coef_loss           | 0.8706182    |
| entropy                 | 0.7782092    |
| episodes                | 116          |
| fps                     | 146          |
| mean 100 episode reward | -1           |
| n_updates               | 46944        |
| policy_loss             | -0.4246331   |
| qf1_loss                | 7.162839e-05 |
| qf2_loss                | 7.594844e-05 |
| time_elapsed            | 320          |
| total timesteps         | 47044        |
| value_loss              | 9.342504e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00074680994 |
| ent_coef_loss           | -2.8215065    |
| entropy                 | 0.885221      |
| episodes                | 120           |
| fps                     | 147           |
| mean 100 episode reward | -0.9          |
| n_updates               | 48704         |
| policy_loss             | -0.34261966   |
| qf1_loss                | 0.00012619891 |
| qf2_loss                | 0.00018079778 |
| time_elapsed            | 331           |
| total timesteps         | 48804         |
| value_loss              | 0.00027559884 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0007060819  |
| ent_coef_loss           | 2.945757      |
| entropy                 | 0.9185988     |
| episodes                | 124           |
| fps                     | 147           |
| mean 100 episode reward | -0.9          |
| n_updates               | 50464         |
| policy_loss             | -0.30014008   |
| qf1_loss                | 7.058875e-05  |
| qf2_loss                | 9.212352e-05  |
| time_elapsed            | 343           |
| total timesteps         | 50564         |
| value_loss              | 0.00011813262 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00057418976 |
| ent_coef_loss           | -1.3337448    |
| entropy                 | 0.9271676     |
| episodes                | 128           |
| fps                     | 146           |
| mean 100 episode reward | -0.9          |
| n_updates               | 52108         |
| policy_loss             | -0.25858206   |
| qf1_loss                | 8.4678664e-05 |
| qf2_loss                | 6.176365e-05  |
| time_elapsed            | 355           |
| total timesteps         | 52208         |
| value_loss              | 0.00014536525 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005979107  |
| ent_coef_loss           | -1.8755267    |
| entropy                 | 0.83473027    |
| episodes                | 132           |
| fps                     | 146           |
| mean 100 episode reward | -0.9          |
| n_updates               | 53868         |
| policy_loss             | -0.21832101   |
| qf1_loss                | 5.941299e-05  |
| qf2_loss                | 6.138384e-05  |
| time_elapsed            | 367           |
| total timesteps         | 53968         |
| value_loss              | 9.6147116e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00058943813 |
| ent_coef_loss           | -2.2402027    |
| entropy                 | 0.7292385     |
| episodes                | 136           |
| fps                     | 146           |
| mean 100 episode reward | -0.8          |
| n_updates               | 55628         |
| policy_loss             | -0.16817364   |
| qf1_loss                | 3.9788836e-05 |
| qf2_loss                | 3.626137e-05  |
| time_elapsed            | 380           |
| total timesteps         | 55728         |
| value_loss              | 0.00011821503 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00047315416 |
| ent_coef_loss           | -3.0150506    |
| entropy                 | 0.7182764     |
| episodes                | 140           |
| fps                     | 146           |
| mean 100 episode reward | -0.8          |
| n_updates               | 57085         |
| policy_loss             | -0.1469915    |
| qf1_loss                | 8.726305e-05  |
| qf2_loss                | 4.9182698e-05 |
| time_elapsed            | 390           |
| total timesteps         | 57185         |
| value_loss              | 7.639738e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004805789  |
| ent_coef_loss           | -3.137281     |
| entropy                 | 0.81996685    |
| episodes                | 144           |
| fps                     | 146           |
| mean 100 episode reward | -0.8          |
| n_updates               | 58845         |
| policy_loss             | -0.13518451   |
| qf1_loss                | 6.0677805e-05 |
| qf2_loss                | 4.6562138e-05 |
| time_elapsed            | 402           |
| total timesteps         | 58945         |
| value_loss              | 6.632296e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004607085  |
| ent_coef_loss           | -3.65425      |
| entropy                 | 0.5033617     |
| episodes                | 148           |
| fps                     | 146           |
| mean 100 episode reward | -0.8          |
| n_updates               | 60605         |
| policy_loss             | -0.09767803   |
| qf1_loss                | 7.131162e-05  |
| qf2_loss                | 8.5582215e-05 |
| time_elapsed            | 414           |
| total timesteps         | 60705         |
| value_loss              | 0.00010197545 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0005304207 |
| ent_coef_loss           | -1.2795982   |
| entropy                 | 0.64610374   |
| episodes                | 152          |
| fps                     | 146          |
| mean 100 episode reward | -0.8         |
| n_updates               | 62019        |
| policy_loss             | -0.08238273  |
| qf1_loss                | 4.979153e-05 |
| qf2_loss                | 8.61972e-05  |
| time_elapsed            | 424          |
| total timesteps         | 62119        |
| value_loss              | 5.308009e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00042307563 |
| ent_coef_loss           | 0.98141825    |
| entropy                 | 0.4761507     |
| episodes                | 156           |
| fps                     | 146           |
| mean 100 episode reward | -0.9          |
| n_updates               | 63259         |
| policy_loss             | -0.09836212   |
| qf1_loss                | 3.350005e-05  |
| qf2_loss                | 8.336085e-05  |
| time_elapsed            | 432           |
| total timesteps         | 63359         |
| value_loss              | 7.909382e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004404855  |
| ent_coef_loss           | 3.5467658     |
| entropy                 | 0.5883491     |
| episodes                | 160           |
| fps                     | 146           |
| mean 100 episode reward | -0.9          |
| n_updates               | 64354         |
| policy_loss             | -0.07737616   |
| qf1_loss                | 4.8772006e-05 |
| qf2_loss                | 0.00012479904 |
| time_elapsed            | 440           |
| total timesteps         | 64454         |
| value_loss              | 6.70329e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00043525407 |
| ent_coef_loss           | 2.290839      |
| entropy                 | 0.6604956     |
| episodes                | 164           |
| fps                     | 146           |
| mean 100 episode reward | -0.9          |
| n_updates               | 66114         |
| policy_loss             | -0.013656202  |
| qf1_loss                | 9.5523326e-05 |
| qf2_loss                | 8.033893e-05  |
| time_elapsed            | 452           |
| total timesteps         | 66214         |
| value_loss              | 8.4596824e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004881632  |
| ent_coef_loss           | -0.743878     |
| entropy                 | 1.025166      |
| episodes                | 168           |
| fps                     | 146           |
| mean 100 episode reward | -0.9          |
| n_updates               | 67716         |
| policy_loss             | -0.047876716  |
| qf1_loss                | 4.0728963e-05 |
| qf2_loss                | 4.5028853e-05 |
| time_elapsed            | 462           |
| total timesteps         | 67816         |
| value_loss              | 4.4904456e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00041190148 |
| ent_coef_loss           | -1.0589489    |
| entropy                 | 0.84039056    |
| episodes                | 172           |
| fps                     | 146           |
| mean 100 episode reward | -0.9          |
| n_updates               | 69476         |
| policy_loss             | -0.017244443  |
| qf1_loss                | 8.14039e-05   |
| qf2_loss                | 3.5371937e-05 |
| time_elapsed            | 473           |
| total timesteps         | 69576         |
| value_loss              | 4.1249907e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.001          |
| ent_coef                | 0.00043244325  |
| ent_coef_loss           | 1.0779029      |
| entropy                 | 0.93165886     |
| episodes                | 176            |
| fps                     | 146            |
| mean 100 episode reward | -0.9           |
| n_updates               | 70865          |
| policy_loss             | -0.007118607   |
| qf1_loss                | 7.995786e-05   |
| qf2_loss                | 0.000114322684 |
| time_elapsed            | 482            |
| total timesteps         | 70965          |
| value_loss              | 0.00016809726  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00036097667 |
| ent_coef_loss           | 1.0958892     |
| entropy                 | 0.68962526    |
| episodes                | 180           |
| fps                     | 147           |
| mean 100 episode reward | -1            |
| n_updates               | 72625         |
| policy_loss             | -0.005252476  |
| qf1_loss                | 2.5739415e-05 |
| qf2_loss                | 1.9286144e-05 |
| time_elapsed            | 494           |
| total timesteps         | 72725         |
| value_loss              | 4.7818234e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00037341332 |
| ent_coef_loss           | 0.38818192    |
| entropy                 | 0.80824864    |
| episodes                | 184           |
| fps                     | 147           |
| mean 100 episode reward | -1.1          |
| n_updates               | 74263         |
| policy_loss             | 0.026764212   |
| qf1_loss                | 0.00019746924 |
| qf2_loss                | 0.00017151736 |
| time_elapsed            | 504           |
| total timesteps         | 74363         |
| value_loss              | 7.4946045e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0003753005  |
| ent_coef_loss           | 4.136238      |
| entropy                 | 0.670591      |
| episodes                | 188           |
| fps                     | 147           |
| mean 100 episode reward | -1.1          |
| n_updates               | 76023         |
| policy_loss             | 0.06895761    |
| qf1_loss                | 9.280868e-05  |
| qf2_loss                | 5.9944487e-05 |
| time_elapsed            | 516           |
| total timesteps         | 76123         |
| value_loss              | 6.013916e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00039078202 |
| ent_coef_loss           | -0.65173393   |
| entropy                 | 0.78555864    |
| episodes                | 192           |
| fps                     | 147           |
| mean 100 episode reward | -1.1          |
| n_updates               | 77783         |
| policy_loss             | 0.04026155    |
| qf1_loss                | 6.0726998e-05 |
| qf2_loss                | 1.9238107e-05 |
| time_elapsed            | 527           |
| total timesteps         | 77883         |
| value_loss              | 4.5021e-05    |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00039882353 |
| ent_coef_loss           | -2.6228304    |
| entropy                 | 0.8702943     |
| episodes                | 196           |
| fps                     | 147           |
| mean 100 episode reward | -1            |
| n_updates               | 79543         |
| policy_loss             | 0.061947934   |
| qf1_loss                | 3.7427635e-05 |
| qf2_loss                | 4.567203e-05  |
| time_elapsed            | 539           |
| total timesteps         | 79643         |
| value_loss              | 6.958132e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00037745235 |
| ent_coef_loss           | -2.5871167    |
| entropy                 | 0.66228884    |
| episodes                | 200           |
| fps                     | 147           |
| mean 100 episode reward | -1.1          |
| n_updates               | 81038         |
| policy_loss             | 0.080099955   |
| qf1_loss                | 3.222602e-05  |
| qf2_loss                | 4.409242e-05  |
| time_elapsed            | 549           |
| total timesteps         | 81138         |
| value_loss              | 4.2626038e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00033529024 |
| ent_coef_loss           | 2.6026673     |
| entropy                 | 0.44610095    |
| episodes                | 204           |
| fps                     | 147           |
| mean 100 episode reward | -1.1          |
| n_updates               | 82798         |
| policy_loss             | 0.0670784     |
| qf1_loss                | 4.523325e-05  |
| qf2_loss                | 3.6613754e-05 |
| time_elapsed            | 561           |
| total timesteps         | 82898         |
| value_loss              | 2.6095902e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00032365532 |
| ent_coef_loss           | -1.1292176    |
| entropy                 | 0.6661674     |
| episodes                | 208           |
| fps                     | 147           |
| mean 100 episode reward | -1.1          |
| n_updates               | 84244         |
| policy_loss             | 0.07615319    |
| qf1_loss                | 0.0002679207  |
| qf2_loss                | 0.00022638674 |
| time_elapsed            | 571           |
| total timesteps         | 84344         |
| value_loss              | 5.175587e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00034079643 |
| ent_coef_loss           | -0.16984618   |
| entropy                 | 0.52455604    |
| episodes                | 212           |
| fps                     | 147           |
| mean 100 episode reward | -1            |
| n_updates               | 85914         |
| policy_loss             | 0.08649082    |
| qf1_loss                | 7.877407e-05  |
| qf2_loss                | 6.217002e-05  |
| time_elapsed            | 583           |
| total timesteps         | 86014         |
| value_loss              | 7.224822e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00036798205 |
| ent_coef_loss           | -1.3570478    |
| entropy                 | 1.0169016     |
| episodes                | 216           |
| fps                     | 147           |
| mean 100 episode reward | -1.1          |
| n_updates               | 87531         |
| policy_loss             | 0.08038265    |
| qf1_loss                | 2.2781951e-05 |
| qf2_loss                | 1.6020254e-05 |
| time_elapsed            | 594           |
| total timesteps         | 87631         |
| value_loss              | 3.3145552e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00039414832 |
| ent_coef_loss           | -1.4920285    |
| entropy                 | 0.7516111     |
| episodes                | 220           |
| fps                     | 147           |
| mean 100 episode reward | -1.1          |
| n_updates               | 89010         |
| policy_loss             | 0.08347416    |
| qf1_loss                | 0.0006031816  |
| qf2_loss                | 0.0009657996  |
| time_elapsed            | 604           |
| total timesteps         | 89110         |
| value_loss              | 0.00028263597 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00042759575 |
| ent_coef_loss           | 0.87765115    |
| entropy                 | 0.7583127     |
| episodes                | 224           |
| fps                     | 147           |
| mean 100 episode reward | -1.1          |
| n_updates               | 90770         |
| policy_loss             | 0.10750073    |
| qf1_loss                | 0.00055232574 |
| qf2_loss                | 0.0002947556  |
| time_elapsed            | 616           |
| total timesteps         | 90870         |
| value_loss              | 7.3418254e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004193113  |
| ent_coef_loss           | -3.952737     |
| entropy                 | 0.92526174    |
| episodes                | 228           |
| fps                     | 147           |
| mean 100 episode reward | -1.1          |
| n_updates               | 92064         |
| policy_loss             | 0.09583493    |
| qf1_loss                | 2.7677674e-05 |
| qf2_loss                | 4.2308835e-05 |
| time_elapsed            | 626           |
| total timesteps         | 92164         |
| value_loss              | 5.853758e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00032721137 |
| ent_coef_loss           | 1.4125324     |
| entropy                 | 0.62405354    |
| episodes                | 232           |
| fps                     | 146           |
| mean 100 episode reward | -1.1          |
| n_updates               | 93729         |
| policy_loss             | 0.098204486   |
| qf1_loss                | 1.373192e-05  |
| qf2_loss                | 1.8736664e-05 |
| time_elapsed            | 638           |
| total timesteps         | 93829         |
| value_loss              | 3.6331385e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0003635789 |
| ent_coef_loss           | 2.3857946    |
| entropy                 | 0.65517765   |
| episodes                | 236          |
| fps                     | 146          |
| mean 100 episode reward | -1.2         |
| n_updates               | 95358        |
| policy_loss             | 0.10343093   |
| qf1_loss                | 3.27671e-05  |
| qf2_loss                | 2.223532e-05 |
| time_elapsed            | 651          |
| total timesteps         | 95458        |
| value_loss              | 3.490822e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00041708487 |
| ent_coef_loss           | -3.6546254    |
| entropy                 | 0.8404825     |
| episodes                | 240           |
| fps                     | 146           |
| mean 100 episode reward | -1.1          |
| n_updates               | 97079         |
| policy_loss             | 0.104796425   |
| qf1_loss                | 4.191731e-05  |
| qf2_loss                | 1.6965683e-05 |
| time_elapsed            | 663           |
| total timesteps         | 97179         |
| value_loss              | 3.968591e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00039502833 |
| ent_coef_loss           | 0.32652164    |
| entropy                 | 0.5773879     |
| episodes                | 244           |
| fps                     | 146           |
| mean 100 episode reward | -1.1          |
| n_updates               | 98839         |
| policy_loss             | 0.13043194    |
| qf1_loss                | 6.602099e-05  |
| qf2_loss                | 2.948371e-05  |
| time_elapsed            | 676           |
| total timesteps         | 98939         |
| value_loss              | 4.0881718e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00049065374 |
| ent_coef_loss           | -3.902276     |
| entropy                 | 1.083569      |
| episodes                | 248           |
| fps                     | 146           |
| mean 100 episode reward | -1.1          |
| n_updates               | 100599        |
| policy_loss             | 0.114289805   |
| qf1_loss                | 2.2058375e-05 |
| qf2_loss                | 1.9256164e-05 |
| time_elapsed            | 689           |
| total timesteps         | 100699        |
| value_loss              | 6.404741e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00046115977 |
| ent_coef_loss           | -2.1520708    |
| entropy                 | 0.86178815    |
| episodes                | 252           |
| fps                     | 146           |
| mean 100 episode reward | -1.1          |
| n_updates               | 102138        |
| policy_loss             | 0.109671235   |
| qf1_loss                | 4.8302783e-05 |
| qf2_loss                | 3.315312e-05  |
| time_elapsed            | 699           |
| total timesteps         | 102238        |
| value_loss              | 7.779806e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00049989054 |
| ent_coef_loss           | -2.2776241    |
| entropy                 | 0.9696851     |
| episodes                | 256           |
| fps                     | 145           |
| mean 100 episode reward | -1.1          |
| n_updates               | 103898        |
| policy_loss             | 0.13194838    |
| qf1_loss                | 3.022383e-05  |
| qf2_loss                | 3.914987e-05  |
| time_elapsed            | 712           |
| total timesteps         | 103998        |
| value_loss              | 3.9069426e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005440793  |
| ent_coef_loss           | -0.9548843    |
| entropy                 | 1.2681417     |
| episodes                | 260           |
| fps                     | 145           |
| mean 100 episode reward | -1.2          |
| n_updates               | 105355        |
| policy_loss             | 0.13089722    |
| qf1_loss                | 2.2072585e-05 |
| qf2_loss                | 2.2228469e-05 |
| time_elapsed            | 723           |
| total timesteps         | 105455        |
| value_loss              | 8.431943e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00049475784 |
| ent_coef_loss           | -0.6415008    |
| entropy                 | 1.147826      |
| episodes                | 264           |
| fps                     | 145           |
| mean 100 episode reward | -1.2          |
| n_updates               | 106807        |
| policy_loss             | 0.14848703    |
| qf1_loss                | 3.8987033e-05 |
| qf2_loss                | 3.3010157e-05 |
| time_elapsed            | 733           |
| total timesteps         | 106907        |
| value_loss              | 1.7935909e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00052001886 |
| ent_coef_loss           | 3.7796912     |
| entropy                 | 0.95156956    |
| episodes                | 268           |
| fps                     | 145           |
| mean 100 episode reward | -1.2          |
| n_updates               | 108567        |
| policy_loss             | 0.13838243    |
| qf1_loss                | 8.2121165e-05 |
| qf2_loss                | 0.00027747508 |
| time_elapsed            | 745           |
| total timesteps         | 108667        |
| value_loss              | 6.373627e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.000526177   |
| ent_coef_loss           | -2.2466154    |
| entropy                 | 0.92847556    |
| episodes                | 272           |
| fps                     | 145           |
| mean 100 episode reward | -1.2          |
| n_updates               | 110011        |
| policy_loss             | 0.14063434    |
| qf1_loss                | 6.2910585e-05 |
| qf2_loss                | 5.7677484e-05 |
| time_elapsed            | 755           |
| total timesteps         | 110111        |
| value_loss              | 9.752875e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00046828418 |
| ent_coef_loss           | -1.2789555    |
| entropy                 | 0.7555397     |
| episodes                | 276           |
| fps                     | 145           |
| mean 100 episode reward | -1.2          |
| n_updates               | 111712        |
| policy_loss             | 0.14978555    |
| qf1_loss                | 8.423958e-05  |
| qf2_loss                | 5.2013478e-05 |
| time_elapsed            | 767           |
| total timesteps         | 111812        |
| value_loss              | 6.784003e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004997194  |
| ent_coef_loss           | 2.034731      |
| entropy                 | 0.92511827    |
| episodes                | 280           |
| fps                     | 145           |
| mean 100 episode reward | -1.2          |
| n_updates               | 113080        |
| policy_loss             | 0.158622      |
| qf1_loss                | 0.00013547292 |
| qf2_loss                | 7.5377495e-05 |
| time_elapsed            | 776           |
| total timesteps         | 113180        |
| value_loss              | 0.00023252159 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00053645595 |
| ent_coef_loss           | -7.2434697    |
| entropy                 | 1.1078126     |
| episodes                | 284           |
| fps                     | 145           |
| mean 100 episode reward | -1.1          |
| n_updates               | 114839        |
| policy_loss             | 0.17755017    |
| qf1_loss                | 7.3792806e-05 |
| qf2_loss                | 4.4695586e-05 |
| time_elapsed            | 788           |
| total timesteps         | 114939        |
| value_loss              | 8.042555e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00052745565 |
| ent_coef_loss           | -1.1054319    |
| entropy                 | 0.824366      |
| episodes                | 288           |
| fps                     | 145           |
| mean 100 episode reward | -1.1          |
| n_updates               | 116394        |
| policy_loss             | 0.15975249    |
| qf1_loss                | 6.30021e-05   |
| qf2_loss                | 6.239473e-05  |
| time_elapsed            | 799           |
| total timesteps         | 116494        |
| value_loss              | 6.660292e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004923291  |
| ent_coef_loss           | 0.08972633    |
| entropy                 | 0.9148294     |
| episodes                | 292           |
| fps                     | 145           |
| mean 100 episode reward | -1.2          |
| n_updates               | 118154        |
| policy_loss             | 0.15710068    |
| qf1_loss                | 3.256162e-05  |
| qf2_loss                | 2.7744529e-05 |
| time_elapsed            | 814           |
| total timesteps         | 118254        |
| value_loss              | 4.3251257e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00046510392 |
| ent_coef_loss           | -2.4225333    |
| entropy                 | 0.8440629     |
| episodes                | 296           |
| fps                     | 145           |
| mean 100 episode reward | -1.1          |
| n_updates               | 119914        |
| policy_loss             | 0.15475437    |
| qf1_loss                | 0.0054170787  |
| qf2_loss                | 0.0055641867  |
| time_elapsed            | 827           |
| total timesteps         | 120014        |
| value_loss              | 9.36507e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004912324  |
| ent_coef_loss           | 2.4916937     |
| entropy                 | 0.81159955    |
| episodes                | 300           |
| fps                     | 145           |
| mean 100 episode reward | -1.1          |
| n_updates               | 121461        |
| policy_loss             | 0.13250938    |
| qf1_loss                | 0.00023775175 |
| qf2_loss                | 0.0001724136  |
| time_elapsed            | 838           |
| total timesteps         | 121561        |
| value_loss              | 0.00011149899 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00044455694 |
| ent_coef_loss           | 0.082066715   |
| entropy                 | 0.7679855     |
| episodes                | 304           |
| fps                     | 144           |
| mean 100 episode reward | -1.1          |
| n_updates               | 122911        |
| policy_loss             | 0.19204226    |
| qf1_loss                | 3.6414407e-05 |
| qf2_loss                | 4.1339707e-05 |
| time_elapsed            | 849           |
| total timesteps         | 123011        |
| value_loss              | 9.100268e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00045630703 |
| ent_coef_loss           | -2.5290537    |
| entropy                 | 0.52319294    |
| episodes                | 308           |
| fps                     | 144           |
| mean 100 episode reward | -1.2          |
| n_updates               | 124652        |
| policy_loss             | 0.13524064    |
| qf1_loss                | 7.274253e-05  |
| qf2_loss                | 0.0007502974  |
| time_elapsed            | 863           |
| total timesteps         | 124752        |
| value_loss              | 8.156467e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00042563453 |
| ent_coef_loss           | -2.3490095    |
| entropy                 | 0.49846745    |
| episodes                | 312           |
| fps                     | 144           |
| mean 100 episode reward | -1.2          |
| n_updates               | 125927        |
| policy_loss             | 0.1519544     |
| qf1_loss                | 2.7652013e-05 |
| qf2_loss                | 3.0091407e-05 |
| time_elapsed            | 874           |
| total timesteps         | 126027        |
| value_loss              | 3.627663e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00050896744 |
| ent_coef_loss           | -1.443766     |
| entropy                 | 0.8144832     |
| episodes                | 316           |
| fps                     | 144           |
| mean 100 episode reward | -1.2          |
| n_updates               | 127657        |
| policy_loss             | 0.16154614    |
| qf1_loss                | 4.8850336e-05 |
| qf2_loss                | 3.031805e-05  |
| time_elapsed            | 886           |
| total timesteps         | 127757        |
| value_loss              | 4.6673398e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00051138166 |
| ent_coef_loss           | -3.0786903    |
| entropy                 | 0.7104849     |
| episodes                | 320           |
| fps                     | 143           |
| mean 100 episode reward | -1.2          |
| n_updates               | 129417        |
| policy_loss             | 0.16728884    |
| qf1_loss                | 2.8991575e-05 |
| qf2_loss                | 2.0692954e-05 |
| time_elapsed            | 899           |
| total timesteps         | 129517        |
| value_loss              | 6.609599e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005260837  |
| ent_coef_loss           | -3.2308683    |
| entropy                 | 0.80314744    |
| episodes                | 324           |
| fps                     | 143           |
| mean 100 episode reward | -1.2          |
| n_updates               | 130989        |
| policy_loss             | 0.119988725   |
| qf1_loss                | 4.5211724e-05 |
| qf2_loss                | 3.0118152e-05 |
| time_elapsed            | 910           |
| total timesteps         | 131089        |
| value_loss              | 8.4715466e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00052556745 |
| ent_coef_loss           | 1.6376553     |
| entropy                 | 0.5069504     |
| episodes                | 328           |
| fps                     | 144           |
| mean 100 episode reward | -1.2          |
| n_updates               | 132079        |
| policy_loss             | 0.15781413    |
| qf1_loss                | 5.1752602e-05 |
| qf2_loss                | 5.592552e-05  |
| time_elapsed            | 917           |
| total timesteps         | 132179        |
| value_loss              | 9.912472e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005501222  |
| ent_coef_loss           | 1.7812338     |
| entropy                 | 0.58389133    |
| episodes                | 332           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 132944        |
| policy_loss             | 0.13710578    |
| qf1_loss                | 3.3833032e-05 |
| qf2_loss                | 4.8590606e-05 |
| time_elapsed            | 923           |
| total timesteps         | 133044        |
| value_loss              | 9.5111594e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006429216  |
| ent_coef_loss           | 3.8055341     |
| entropy                 | 0.8596889     |
| episodes                | 336           |
| fps                     | 143           |
| mean 100 episode reward | -1.3          |
| n_updates               | 134136        |
| policy_loss             | 0.17590171    |
| qf1_loss                | 9.053841e-05  |
| qf2_loss                | 8.955371e-05  |
| time_elapsed            | 932           |
| total timesteps         | 134236        |
| value_loss              | 0.00027788617 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005589887  |
| ent_coef_loss           | -1.0547662    |
| entropy                 | 0.45862636    |
| episodes                | 340           |
| fps                     | 143           |
| mean 100 episode reward | -1.4          |
| n_updates               | 135758        |
| policy_loss             | 0.15884057    |
| qf1_loss                | 0.00041729695 |
| qf2_loss                | 0.0003929742  |
| time_elapsed            | 946           |
| total timesteps         | 135858        |
| value_loss              | 5.162791e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00054070825 |
| ent_coef_loss           | -3.1722       |
| entropy                 | 0.559759      |
| episodes                | 344           |
| fps                     | 143           |
| mean 100 episode reward | -1.5          |
| n_updates               | 136605        |
| policy_loss             | 0.18128562    |
| qf1_loss                | 7.90719e-05   |
| qf2_loss                | 7.248171e-05  |
| time_elapsed            | 952           |
| total timesteps         | 136705        |
| value_loss              | 0.0001388167  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.000501966   |
| ent_coef_loss           | 1.3590238     |
| entropy                 | 0.4696421     |
| episodes                | 348           |
| fps                     | 143           |
| mean 100 episode reward | -1.6          |
| n_updates               | 138041        |
| policy_loss             | 0.16334915    |
| qf1_loss                | 6.0284816e-05 |
| qf2_loss                | 4.6691377e-05 |
| time_elapsed            | 962           |
| total timesteps         | 138141        |
| value_loss              | 8.663527e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00061935274 |
| ent_coef_loss           | 1.5405378     |
| entropy                 | 0.5764855     |
| episodes                | 352           |
| fps                     | 143           |
| mean 100 episode reward | -1.6          |
| n_updates               | 139520        |
| policy_loss             | 0.2003052     |
| qf1_loss                | 0.00018427573 |
| qf2_loss                | 0.00017620176 |
| time_elapsed            | 972           |
| total timesteps         | 139620        |
| value_loss              | 0.0003416874  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00060777925 |
| ent_coef_loss           | -0.4047556    |
| entropy                 | 0.51003414    |
| episodes                | 356           |
| fps                     | 143           |
| mean 100 episode reward | -1.5          |
| n_updates               | 140727        |
| policy_loss             | 0.155606      |
| qf1_loss                | 0.00010575606 |
| qf2_loss                | 6.540117e-05  |
| time_elapsed            | 980           |
| total timesteps         | 140827        |
| value_loss              | 0.00014265126 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00057653023 |
| ent_coef_loss           | -3.7323043    |
| entropy                 | 0.60302824    |
| episodes                | 360           |
| fps                     | 143           |
| mean 100 episode reward | -1.6          |
| n_updates               | 142076        |
| policy_loss             | 0.22509776    |
| qf1_loss                | 8.923125e-05  |
| qf2_loss                | 8.091291e-05  |
| time_elapsed            | 989           |
| total timesteps         | 142176        |
| value_loss              | 8.312466e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006451976  |
| ent_coef_loss           | 1.2809496     |
| entropy                 | 0.46213916    |
| episodes                | 364           |
| fps                     | 143           |
| mean 100 episode reward | -1.6          |
| n_updates               | 143543        |
| policy_loss             | 0.19306764    |
| qf1_loss                | 8.736734e-05  |
| qf2_loss                | 5.8706948e-05 |
| time_elapsed            | 998           |
| total timesteps         | 143643        |
| value_loss              | 9.0225316e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006251657  |
| ent_coef_loss           | 1.272562      |
| entropy                 | 0.69920385    |
| episodes                | 368           |
| fps                     | 143           |
| mean 100 episode reward | -1.6          |
| n_updates               | 145028        |
| policy_loss             | 0.1694307     |
| qf1_loss                | 7.2047886e-05 |
| qf2_loss                | 7.031004e-05  |
| time_elapsed            | 1008          |
| total timesteps         | 145128        |
| value_loss              | 8.930791e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0007150017  |
| ent_coef_loss           | 0.82062453    |
| entropy                 | 0.8247316     |
| episodes                | 372           |
| fps                     | 143           |
| mean 100 episode reward | -1.6          |
| n_updates               | 146419        |
| policy_loss             | 0.19105363    |
| qf1_loss                | 9.4116614e-05 |
| qf2_loss                | 0.00013762526 |
| time_elapsed            | 1018          |
| total timesteps         | 146519        |
| value_loss              | 0.00013299947 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.000702647   |
| ent_coef_loss           | -1.8610909    |
| entropy                 | 0.7138493     |
| episodes                | 376           |
| fps                     | 143           |
| mean 100 episode reward | -1.6          |
| n_updates               | 147974        |
| policy_loss             | 0.22377114    |
| qf1_loss                | 0.00022305957 |
| qf2_loss                | 8.888006e-05  |
| time_elapsed            | 1029          |
| total timesteps         | 148074        |
| value_loss              | 0.00030701078 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0007138959  |
| ent_coef_loss           | 1.4835427     |
| entropy                 | 0.57210964    |
| episodes                | 380           |
| fps                     | 143           |
| mean 100 episode reward | -1.7          |
| n_updates               | 149493        |
| policy_loss             | 0.203484      |
| qf1_loss                | 9.207095e-05  |
| qf2_loss                | 9.429177e-05  |
| time_elapsed            | 1040          |
| total timesteps         | 149593        |
| value_loss              | 0.00016755724 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00073589775 |
| ent_coef_loss           | 5.879689      |
| entropy                 | 0.9074927     |
| episodes                | 384           |
| fps                     | 143           |
| mean 100 episode reward | -1.7          |
| n_updates               | 150389        |
| policy_loss             | 0.24336395    |
| qf1_loss                | 0.00013240552 |
| qf2_loss                | 8.7265755e-05 |
| time_elapsed            | 1046          |
| total timesteps         | 150489        |
| value_loss              | 0.00013233142 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.001          |
| ent_coef                | 0.00067368674  |
| ent_coef_loss           | 1.2404208      |
| entropy                 | 0.51899153     |
| episodes                | 388            |
| fps                     | 143            |
| mean 100 episode reward | -1.6           |
| n_updates               | 152149         |
| policy_loss             | 0.23721755     |
| qf1_loss                | 0.00017784984  |
| qf2_loss                | 0.000100831545 |
| time_elapsed            | 1058           |
| total timesteps         | 152249         |
| value_loss              | 0.00045698625  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00070892996 |
| ent_coef_loss           | -1.5793123    |
| entropy                 | 0.61181015    |
| episodes                | 392           |
| fps                     | 143           |
| mean 100 episode reward | -1.6          |
| n_updates               | 153909        |
| policy_loss             | 0.21485919    |
| qf1_loss                | 0.00012289046 |
| qf2_loss                | 0.00013511225 |
| time_elapsed            | 1071          |
| total timesteps         | 154009        |
| value_loss              | 0.00023852487 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00067067833 |
| ent_coef_loss           | -0.12980688   |
| entropy                 | 0.87732816    |
| episodes                | 396           |
| fps                     | 143           |
| mean 100 episode reward | -1.7          |
| n_updates               | 155501        |
| policy_loss             | 0.24241719    |
| qf1_loss                | 0.00019488392 |
| qf2_loss                | 0.00010558836 |
| time_elapsed            | 1082          |
| total timesteps         | 155601        |
| value_loss              | 0.00014369997 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006832638  |
| ent_coef_loss           | -1.4054215    |
| entropy                 | 0.35086986    |
| episodes                | 400           |
| fps                     | 143           |
| mean 100 episode reward | -1.6          |
| n_updates               | 157121        |
| policy_loss             | 0.20703703    |
| qf1_loss                | 0.00021956727 |
| qf2_loss                | 0.00018284871 |
| time_elapsed            | 1093          |
| total timesteps         | 157221        |
| value_loss              | 0.0002516962  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00068287004 |
| ent_coef_loss           | 0.8473053     |
| entropy                 | 0.7066532     |
| episodes                | 404           |
| fps                     | 143           |
| mean 100 episode reward | -1.7          |
| n_updates               | 158754        |
| policy_loss             | 0.24860808    |
| qf1_loss                | 0.00012388645 |
| qf2_loss                | 0.00014584936 |
| time_elapsed            | 1104          |
| total timesteps         | 158854        |
| value_loss              | 0.00025479886 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006236948  |
| ent_coef_loss           | 0.7380707     |
| entropy                 | 0.60466       |
| episodes                | 408           |
| fps                     | 143           |
| mean 100 episode reward | -1.7          |
| n_updates               | 160293        |
| policy_loss             | 0.21880808    |
| qf1_loss                | 0.0009391246  |
| qf2_loss                | 0.0010083728  |
| time_elapsed            | 1115          |
| total timesteps         | 160393        |
| value_loss              | 0.00020400016 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00070514693 |
| ent_coef_loss           | 2.3879328     |
| entropy                 | 0.5493529     |
| episodes                | 412           |
| fps                     | 143           |
| mean 100 episode reward | -1.7          |
| n_updates               | 161968        |
| policy_loss             | 0.2264181     |
| qf1_loss                | 0.00013312775 |
| qf2_loss                | 0.000184115   |
| time_elapsed            | 1127          |
| total timesteps         | 162068        |
| value_loss              | 0.00017680685 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00075110584 |
| ent_coef_loss           | 4.1139812     |
| entropy                 | 0.71763766    |
| episodes                | 416           |
| fps                     | 143           |
| mean 100 episode reward | -1.6          |
| n_updates               | 163728        |
| policy_loss             | 0.26016492    |
| qf1_loss                | 0.0010563844  |
| qf2_loss                | 0.0006990689  |
| time_elapsed            | 1139          |
| total timesteps         | 163828        |
| value_loss              | 0.00019122189 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00071911264 |
| ent_coef_loss           | 0.72686005    |
| entropy                 | 0.84511423    |
| episodes                | 420           |
| fps                     | 143           |
| mean 100 episode reward | -1.6          |
| n_updates               | 165446        |
| policy_loss             | 0.28432322    |
| qf1_loss                | 0.00022707289 |
| qf2_loss                | 0.00040911653 |
| time_elapsed            | 1151          |
| total timesteps         | 165546        |
| value_loss              | 0.00018495892 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0007365757  |
| ent_coef_loss           | 1.5308075     |
| entropy                 | 0.8104403     |
| episodes                | 424           |
| fps                     | 143           |
| mean 100 episode reward | -1.6          |
| n_updates               | 167059        |
| policy_loss             | 0.25819176    |
| qf1_loss                | 0.00018193544 |
| qf2_loss                | 0.00019726192 |
| time_elapsed            | 1162          |
| total timesteps         | 167159        |
| value_loss              | 0.0005520475  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00076546293 |
| ent_coef_loss           | -2.0149765    |
| entropy                 | 0.6412958     |
| episodes                | 428           |
| fps                     | 143           |
| mean 100 episode reward | -1.6          |
| n_updates               | 168632        |
| policy_loss             | 0.253406      |
| qf1_loss                | 9.7367956e-05 |
| qf2_loss                | 7.680553e-05  |
| time_elapsed            | 1173          |
| total timesteps         | 168732        |
| value_loss              | 9.404563e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0007672565  |
| ent_coef_loss           | -1.4331651    |
| entropy                 | 1.0467312     |
| episodes                | 432           |
| fps                     | 143           |
| mean 100 episode reward | -1.5          |
| n_updates               | 170392        |
| policy_loss             | 0.23625316    |
| qf1_loss                | 0.00012569093 |
| qf2_loss                | 8.522124e-05  |
| time_elapsed            | 1186          |
| total timesteps         | 170492        |
| value_loss              | 0.0001462049  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.001          |
| ent_coef                | 0.0007480131   |
| ent_coef_loss           | 1.4279643      |
| entropy                 | 0.9112989      |
| episodes                | 436            |
| fps                     | 143            |
| mean 100 episode reward | -1.4           |
| n_updates               | 171652         |
| policy_loss             | 0.26007974     |
| qf1_loss                | 0.00010049046  |
| qf2_loss                | 4.3190772e-05  |
| time_elapsed            | 1194           |
| total timesteps         | 171752         |
| value_loss              | 0.000116581476 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0007129179  |
| ent_coef_loss           | 3.5061386     |
| entropy                 | 0.6059441     |
| episodes                | 440           |
| fps                     | 143           |
| mean 100 episode reward | -1.3          |
| n_updates               | 173412        |
| policy_loss             | 0.24062091    |
| qf1_loss                | 7.345382e-05  |
| qf2_loss                | 0.00011399892 |
| time_elapsed            | 1207          |
| total timesteps         | 173512        |
| value_loss              | 0.00016635084 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00081196596 |
| ent_coef_loss           | -1.2870209    |
| entropy                 | 1.0392511     |
| episodes                | 444           |
| fps                     | 143           |
| mean 100 episode reward | -1.3          |
| n_updates               | 175091        |
| policy_loss             | 0.22504699    |
| qf1_loss                | 0.00036164586 |
| qf2_loss                | 0.00028380367 |
| time_elapsed            | 1220          |
| total timesteps         | 175191        |
| value_loss              | 7.1989474e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0007599212  |
| ent_coef_loss           | 3.6888924     |
| entropy                 | 0.8612322     |
| episodes                | 448           |
| fps                     | 143           |
| mean 100 episode reward | -1.3          |
| n_updates               | 176541        |
| policy_loss             | 0.25241816    |
| qf1_loss                | 0.00050603185 |
| qf2_loss                | 0.00052256807 |
| time_elapsed            | 1230          |
| total timesteps         | 176641        |
| value_loss              | 0.00016645252 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006812049  |
| ent_coef_loss           | 1.8949391     |
| entropy                 | 1.0159191     |
| episodes                | 452           |
| fps                     | 143           |
| mean 100 episode reward | -1.4          |
| n_updates               | 178119        |
| policy_loss             | 0.2419639     |
| qf1_loss                | 0.00016323908 |
| qf2_loss                | 0.00011764439 |
| time_elapsed            | 1241          |
| total timesteps         | 178219        |
| value_loss              | 0.00011809339 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.001          |
| ent_coef                | 0.00077963335  |
| ent_coef_loss           | -0.368356      |
| entropy                 | 1.175534       |
| episodes                | 456            |
| fps                     | 143            |
| mean 100 episode reward | -1.3           |
| n_updates               | 179751         |
| policy_loss             | 0.24845982     |
| qf1_loss                | 8.751089e-05   |
| qf2_loss                | 7.2705225e-05  |
| time_elapsed            | 1253           |
| total timesteps         | 179851         |
| value_loss              | 0.000116347335 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006950165  |
| ent_coef_loss           | 0.59639657    |
| entropy                 | 0.7174189     |
| episodes                | 460           |
| fps                     | 143           |
| mean 100 episode reward | -1.2          |
| n_updates               | 181162        |
| policy_loss             | 0.25388697    |
| qf1_loss                | 0.00016572341 |
| qf2_loss                | 0.00013904345 |
| time_elapsed            | 1263          |
| total timesteps         | 181262        |
| value_loss              | 0.00017277118 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00068738166 |
| ent_coef_loss           | -2.347338     |
| entropy                 | 1.1580598     |
| episodes                | 464           |
| fps                     | 143           |
| mean 100 episode reward | -1.2          |
| n_updates               | 182800        |
| policy_loss             | 0.27186695    |
| qf1_loss                | 0.0001334559  |
| qf2_loss                | 0.0001175892  |
| time_elapsed            | 1275          |
| total timesteps         | 182900        |
| value_loss              | 0.00014525026 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00068337034 |
| ent_coef_loss           | 2.3387618     |
| entropy                 | 0.7552365     |
| episodes                | 468           |
| fps                     | 143           |
| mean 100 episode reward | -1.2          |
| n_updates               | 183789        |
| policy_loss             | 0.23635378    |
| qf1_loss                | 7.8642755e-05 |
| qf2_loss                | 9.003199e-05  |
| time_elapsed            | 1282          |
| total timesteps         | 183889        |
| value_loss              | 0.0001618791  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006293708  |
| ent_coef_loss           | 1.5248885     |
| entropy                 | 0.8882309     |
| episodes                | 472           |
| fps                     | 143           |
| mean 100 episode reward | -1.2          |
| n_updates               | 185549        |
| policy_loss             | 0.2632944     |
| qf1_loss                | 7.83013e-05   |
| qf2_loss                | 9.064316e-05  |
| time_elapsed            | 1294          |
| total timesteps         | 185649        |
| value_loss              | 0.00010952528 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005799484  |
| ent_coef_loss           | -1.5634899    |
| entropy                 | 0.77789825    |
| episodes                | 476           |
| fps                     | 143           |
| mean 100 episode reward | -1.1          |
| n_updates               | 187309        |
| policy_loss             | 0.23991272    |
| qf1_loss                | 6.0492388e-05 |
| qf2_loss                | 5.538209e-05  |
| time_elapsed            | 1306          |
| total timesteps         | 187409        |
| value_loss              | 7.719228e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005324322  |
| ent_coef_loss           | -1.8794787    |
| entropy                 | 0.8550348     |
| episodes                | 480           |
| fps                     | 143           |
| mean 100 episode reward | -1.1          |
| n_updates               | 188900        |
| policy_loss             | 0.23812951    |
| qf1_loss                | 0.0001989157  |
| qf2_loss                | 0.00019531773 |
| time_elapsed            | 1317          |
| total timesteps         | 189000        |
| value_loss              | 0.00012257825 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005317984  |
| ent_coef_loss           | -2.320999     |
| entropy                 | 0.8866805     |
| episodes                | 484           |
| fps                     | 143           |
| mean 100 episode reward | -1            |
| n_updates               | 190534        |
| policy_loss             | 0.19713914    |
| qf1_loss                | 7.6779455e-05 |
| qf2_loss                | 8.7396525e-05 |
| time_elapsed            | 1328          |
| total timesteps         | 190634        |
| value_loss              | 4.5370303e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.001          |
| ent_coef                | 0.0004835377   |
| ent_coef_loss           | 2.145185       |
| entropy                 | 0.9194893      |
| episodes                | 488            |
| fps                     | 143            |
| mean 100 episode reward | -1             |
| n_updates               | 191990         |
| policy_loss             | 0.2164497      |
| qf1_loss                | 8.040123e-05   |
| qf2_loss                | 0.000113774135 |
| time_elapsed            | 1338           |
| total timesteps         | 192090         |
| value_loss              | 0.00020148657  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00049294275 |
| ent_coef_loss           | -2.6687446    |
| entropy                 | 0.79456675    |
| episodes                | 492           |
| fps                     | 143           |
| mean 100 episode reward | -1            |
| n_updates               | 193448        |
| policy_loss             | 0.22994505    |
| qf1_loss                | 0.00010160318 |
| qf2_loss                | 6.638553e-05  |
| time_elapsed            | 1348          |
| total timesteps         | 193548        |
| value_loss              | 0.00012555343 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00053117826 |
| ent_coef_loss           | -4.1562834    |
| entropy                 | 0.6895945     |
| episodes                | 496           |
| fps                     | 143           |
| mean 100 episode reward | -1            |
| n_updates               | 195208        |
| policy_loss             | 0.16717269    |
| qf1_loss                | 5.3387506e-05 |
| qf2_loss                | 3.2364325e-05 |
| time_elapsed            | 1360          |
| total timesteps         | 195308        |
| value_loss              | 6.893433e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005146049  |
| ent_coef_loss           | 1.0353754     |
| entropy                 | 0.84808415    |
| episodes                | 500           |
| fps                     | 143           |
| mean 100 episode reward | -1            |
| n_updates               | 196968        |
| policy_loss             | 0.20252608    |
| qf1_loss                | 8.48973e-05   |
| qf2_loss                | 0.00014502766 |
| time_elapsed            | 1373          |
| total timesteps         | 197068        |
| value_loss              | 0.00011556589 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00056347926 |
| ent_coef_loss           | 1.9918709     |
| entropy                 | 0.9943826     |
| episodes                | 504           |
| fps                     | 143           |
| mean 100 episode reward | -1            |
| n_updates               | 198728        |
| policy_loss             | 0.18987529    |
| qf1_loss                | 5.285354e-05  |
| qf2_loss                | 3.1096035e-05 |
| time_elapsed            | 1385          |
| total timesteps         | 198828        |
| value_loss              | 5.6763907e-05 |
-------------------------------------------
>>>>> End testing <<<<< energy:_-0.0005__slack:_-0.0005
Final weights saved at:  /home/patrick/tensorboard_logs/sac_energy:_-0.0005__slack:_-0.0005/stable_baselines.pkl
TEST COMMAND: python3 py3_learning.py --test --weights  /home/patrick/tensorboard_logs/sac_energy:_-0.0005__slack:_-0.0005/stable_baselines.pkl
Starting test with params: {'energy': -0.001, 'slack': -0.0005}
Namespace(draw_screen=False, env_config='configs/env.config', policy='multi_human_rl', policy_config='configs/policy.config', test=False, train_config='configs/train.config', weights=None)
Gym environment created.
COLLISION PENALTY -0.25
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.33286393   |
| ent_coef_loss           | -3.6824918   |
| entropy                 | 2.6024055    |
| episodes                | 4            |
| fps                     | 149          |
| mean 100 episode reward | -2.2         |
| n_updates               | 1100         |
| policy_loss             | -3.7412508   |
| qf1_loss                | 0.05663722   |
| qf2_loss                | 0.052668042  |
| time_elapsed            | 7            |
| total timesteps         | 1200         |
| value_loss              | 0.0040836576 |
------------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.05818048  |
| ent_coef_loss           | -9.301771   |
| entropy                 | 2.8646684   |
| episodes                | 8           |
| fps                     | 141         |
| mean 100 episode reward | -1.4        |
| n_updates               | 2860        |
| policy_loss             | -4.596984   |
| qf1_loss                | 0.05866436  |
| qf2_loss                | 0.058611818 |
| time_elapsed            | 20          |
| total timesteps         | 2960        |
| value_loss              | 0.013791363 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.023279855 |
| ent_coef_loss           | -11.9035845 |
| entropy                 | 2.7147498   |
| episodes                | 12          |
| fps                     | 140         |
| mean 100 episode reward | -1.4        |
| n_updates               | 3825        |
| policy_loss             | -4.6898966  |
| qf1_loss                | 0.006168723 |
| qf2_loss                | 0.005416819 |
| time_elapsed            | 27          |
| total timesteps         | 3925        |
| value_loss              | 0.010515553 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0060681384 |
| ent_coef_loss           | -4.712575    |
| entropy                 | 2.4406183    |
| episodes                | 16           |
| fps                     | 140          |
| mean 100 episode reward | -1.2         |
| n_updates               | 5585         |
| policy_loss             | -3.9918654   |
| qf1_loss                | 0.0021642535 |
| qf2_loss                | 0.0012983719 |
| time_elapsed            | 40           |
| total timesteps         | 5685         |
| value_loss              | 0.00785978   |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.004510705  |
| ent_coef_loss           | 1.8644382    |
| entropy                 | 1.7930326    |
| episodes                | 20           |
| fps                     | 140          |
| mean 100 episode reward | -1.2         |
| n_updates               | 7345         |
| policy_loss             | -3.7990398   |
| qf1_loss                | 0.0046523893 |
| qf2_loss                | 0.00408909   |
| time_elapsed            | 53           |
| total timesteps         | 7445         |
| value_loss              | 0.01302221   |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.003488371   |
| ent_coef_loss           | -2.2457523    |
| entropy                 | 1.9993169     |
| episodes                | 24            |
| fps                     | 139           |
| mean 100 episode reward | -1.4          |
| n_updates               | 8748          |
| policy_loss             | -3.4885812    |
| qf1_loss                | 0.0007004405  |
| qf2_loss                | 0.00084758666 |
| time_elapsed            | 63            |
| total timesteps         | 8848          |
| value_loss              | 0.0008962313  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0034179485 |
| ent_coef_loss           | 5.638774     |
| entropy                 | 1.188812     |
| episodes                | 28           |
| fps                     | 139          |
| mean 100 episode reward | -1.6         |
| n_updates               | 10308        |
| policy_loss             | -3.054356    |
| qf1_loss                | 0.0014951047 |
| qf2_loss                | 0.051750306  |
| time_elapsed            | 74           |
| total timesteps         | 10408        |
| value_loss              | 0.0032551575 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0038433939 |
| ent_coef_loss           | -0.88997287  |
| entropy                 | 1.2379687    |
| episodes                | 32           |
| fps                     | 140          |
| mean 100 episode reward | -1.5         |
| n_updates               | 12068        |
| policy_loss             | -2.740907    |
| qf1_loss                | 0.0286812    |
| qf2_loss                | 0.025500813  |
| time_elapsed            | 86           |
| total timesteps         | 12168        |
| value_loss              | 0.0012520504 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0038213262 |
| ent_coef_loss           | -3.848758    |
| entropy                 | 1.0833914    |
| episodes                | 36           |
| fps                     | 141          |
| mean 100 episode reward | -1.5         |
| n_updates               | 13770        |
| policy_loss             | -2.7851548   |
| qf1_loss                | 0.0024218608 |
| qf2_loss                | 0.0014377695 |
| time_elapsed            | 98           |
| total timesteps         | 13870        |
| value_loss              | 0.0020549912 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0037021318 |
| ent_coef_loss           | 0.37082028   |
| entropy                 | 0.7222143    |
| episodes                | 40           |
| fps                     | 140          |
| mean 100 episode reward | -1.4         |
| n_updates               | 15529        |
| policy_loss             | -2.5056267   |
| qf1_loss                | 0.0012878557 |
| qf2_loss                | 0.0015982242 |
| time_elapsed            | 110          |
| total timesteps         | 15629        |
| value_loss              | 0.0043143677 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0033718438 |
| ent_coef_loss           | -1.0542603   |
| entropy                 | 0.6083012    |
| episodes                | 44           |
| fps                     | 141          |
| mean 100 episode reward | -1.4         |
| n_updates               | 17289        |
| policy_loss             | -2.1532555   |
| qf1_loss                | 0.0038960853 |
| qf2_loss                | 0.001986612  |
| time_elapsed            | 122          |
| total timesteps         | 17389        |
| value_loss              | 0.008125106  |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0033269702 |
| ent_coef_loss           | -2.2384448   |
| entropy                 | 0.78227794   |
| episodes                | 48           |
| fps                     | 141          |
| mean 100 episode reward | -1.3         |
| n_updates               | 19049        |
| policy_loss             | -2.278075    |
| qf1_loss                | 0.0026435656 |
| qf2_loss                | 0.0085278535 |
| time_elapsed            | 135          |
| total timesteps         | 19149        |
| value_loss              | 0.022332529  |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0026263215 |
| ent_coef_loss           | -3.9297895   |
| entropy                 | 0.7761166    |
| episodes                | 52           |
| fps                     | 142          |
| mean 100 episode reward | -1.3         |
| n_updates               | 20713        |
| policy_loss             | -1.6993685   |
| qf1_loss                | 0.03145795   |
| qf2_loss                | 0.008673646  |
| time_elapsed            | 146          |
| total timesteps         | 20813        |
| value_loss              | 0.013212498  |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0032134862 |
| ent_coef_loss           | -0.3992647   |
| entropy                 | 1.037383     |
| episodes                | 56           |
| fps                     | 142          |
| mean 100 episode reward | -1.2         |
| n_updates               | 22141        |
| policy_loss             | -1.6965704   |
| qf1_loss                | 0.0025625085 |
| qf2_loss                | 0.0052558472 |
| time_elapsed            | 156          |
| total timesteps         | 22241        |
| value_loss              | 0.014028469  |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0043759523 |
| ent_coef_loss           | 2.1118674    |
| entropy                 | 0.79880166   |
| episodes                | 60           |
| fps                     | 142          |
| mean 100 episode reward | -1.2         |
| n_updates               | 23901        |
| policy_loss             | -1.6386435   |
| qf1_loss                | 0.0045499858 |
| qf2_loss                | 0.011225386  |
| time_elapsed            | 168          |
| total timesteps         | 24001        |
| value_loss              | 0.017427968  |
------------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.005078847 |
| ent_coef_loss           | -3.1479373  |
| entropy                 | 1.0052866   |
| episodes                | 64          |
| fps                     | 142         |
| mean 100 episode reward | -1.2        |
| n_updates               | 25500       |
| policy_loss             | -2.3146667  |
| qf1_loss                | 0.019128151 |
| qf2_loss                | 0.016548706 |
| time_elapsed            | 179         |
| total timesteps         | 25600       |
| value_loss              | 0.0472138   |
-----------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0054750997 |
| ent_coef_loss           | 0.07557124   |
| entropy                 | 1.1659021    |
| episodes                | 68           |
| fps                     | 142          |
| mean 100 episode reward | -1.2         |
| n_updates               | 26805        |
| policy_loss             | -1.6538856   |
| qf1_loss                | 0.0064608776 |
| qf2_loss                | 0.00796692   |
| time_elapsed            | 189          |
| total timesteps         | 26905        |
| value_loss              | 0.013660362  |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0058147945 |
| ent_coef_loss           | 0.97919226   |
| entropy                 | 0.6098907    |
| episodes                | 72           |
| fps                     | 142          |
| mean 100 episode reward | -1.2         |
| n_updates               | 28280        |
| policy_loss             | -2.933233    |
| qf1_loss                | 0.038879268  |
| qf2_loss                | 0.029354492  |
| time_elapsed            | 199          |
| total timesteps         | 28380        |
| value_loss              | 0.032311793  |
------------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.00676921  |
| ent_coef_loss           | -1.7127104  |
| entropy                 | 0.79899246  |
| episodes                | 76          |
| fps                     | 142         |
| mean 100 episode reward | -1.2        |
| n_updates               | 29128       |
| policy_loss             | -2.505299   |
| qf1_loss                | 0.011358182 |
| qf2_loss                | 0.009783335 |
| time_elapsed            | 204         |
| total timesteps         | 29228       |
| value_loss              | 0.035606228 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.006778755 |
| ent_coef_loss           | -2.3969548  |
| entropy                 | 0.7260488   |
| episodes                | 80          |
| fps                     | 142         |
| mean 100 episode reward | -1.2        |
| n_updates               | 30601       |
| policy_loss             | -2.6059566  |
| qf1_loss                | 0.022364188 |
| qf2_loss                | 0.01683541  |
| time_elapsed            | 214         |
| total timesteps         | 30701       |
| value_loss              | 0.039039638 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.008481812 |
| ent_coef_loss           | -2.7960336  |
| entropy                 | 1.3470387   |
| episodes                | 84          |
| fps                     | 142         |
| mean 100 episode reward | -1.3        |
| n_updates               | 32217       |
| policy_loss             | -2.5372458  |
| qf1_loss                | 0.042660862 |
| qf2_loss                | 0.055531327 |
| time_elapsed            | 226         |
| total timesteps         | 32317       |
| value_loss              | 0.18709967  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.008612842 |
| ent_coef_loss           | 1.562991    |
| entropy                 | 1.1921644   |
| episodes                | 88          |
| fps                     | 142         |
| mean 100 episode reward | -1.3        |
| n_updates               | 33977       |
| policy_loss             | -2.3471618  |
| qf1_loss                | 0.012944299 |
| qf2_loss                | 0.02512755  |
| time_elapsed            | 239         |
| total timesteps         | 34077       |
| value_loss              | 0.044846054 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.009490572 |
| ent_coef_loss           | -2.2655287  |
| entropy                 | 1.003593    |
| episodes                | 92          |
| fps                     | 141         |
| mean 100 episode reward | -1.4        |
| n_updates               | 35737       |
| policy_loss             | -2.2869537  |
| qf1_loss                | 0.015072171 |
| qf2_loss                | 0.02261329  |
| time_elapsed            | 253         |
| total timesteps         | 35837       |
| value_loss              | 0.045264382 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.010386971 |
| ent_coef_loss           | -1.0914462  |
| entropy                 | 0.8249707   |
| episodes                | 96          |
| fps                     | 141         |
| mean 100 episode reward | -1.4        |
| n_updates               | 37451       |
| policy_loss             | -2.4079566  |
| qf1_loss                | 0.0498117   |
| qf2_loss                | 0.027768089 |
| time_elapsed            | 265         |
| total timesteps         | 37551       |
| value_loss              | 0.19647922  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.009566704 |
| ent_coef_loss           | -0.8943121  |
| entropy                 | 0.7278336   |
| episodes                | 100         |
| fps                     | 141         |
| mean 100 episode reward | -1.4        |
| n_updates               | 39153       |
| policy_loss             | -3.5349007  |
| qf1_loss                | 0.06593718  |
| qf2_loss                | 0.049225308 |
| time_elapsed            | 278         |
| total timesteps         | 39253       |
| value_loss              | 0.13159782  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.008829434 |
| ent_coef_loss           | 0.19098401  |
| entropy                 | 0.42077217  |
| episodes                | 104         |
| fps                     | 140         |
| mean 100 episode reward | -1.3        |
| n_updates               | 40900       |
| policy_loss             | -3.6225765  |
| qf1_loss                | 0.1065997   |
| qf2_loss                | 0.037217487 |
| time_elapsed            | 290         |
| total timesteps         | 41000       |
| value_loss              | 0.043977622 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.008047062 |
| ent_coef_loss           | -0.76440734 |
| entropy                 | 0.6330457   |
| episodes                | 108         |
| fps                     | 140         |
| mean 100 episode reward | -1.4        |
| n_updates               | 42090       |
| policy_loss             | -2.2555377  |
| qf1_loss                | 0.032126833 |
| qf2_loss                | 0.021170532 |
| time_elapsed            | 299         |
| total timesteps         | 42190       |
| value_loss              | 0.027999675 |
-----------------------------------------
----------------------------------------
| current_lr              | 0.001      |
| ent_coef                | 0.00937024 |
| ent_coef_loss           | -2.3682954 |
| entropy                 | 0.9323894  |
| episodes                | 112        |
| fps                     | 141        |
| mean 100 episode reward | -1.3       |
| n_updates               | 43850      |
| policy_loss             | -2.6237974 |
| qf1_loss                | 0.19635966 |
| qf2_loss                | 0.2323024  |
| time_elapsed            | 311        |
| total timesteps         | 43950      |
| value_loss              | 0.15095392 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.008639946 |
| ent_coef_loss           | -2.052023   |
| entropy                 | 0.8637185   |
| episodes                | 116         |
| fps                     | 141         |
| mean 100 episode reward | -1.3        |
| n_updates               | 45416       |
| policy_loss             | -1.5341882  |
| qf1_loss                | 0.008715829 |
| qf2_loss                | 0.013739102 |
| time_elapsed            | 322         |
| total timesteps         | 45516       |
| value_loss              | 0.01525557  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.008488346 |
| ent_coef_loss           | 1.0776664   |
| entropy                 | 0.85243976  |
| episodes                | 120         |
| fps                     | 141         |
| mean 100 episode reward | -1.4        |
| n_updates               | 46931       |
| policy_loss             | -1.8519511  |
| qf1_loss                | 0.039904743 |
| qf2_loss                | 0.015583448 |
| time_elapsed            | 332         |
| total timesteps         | 47031       |
| value_loss              | 0.011266667 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.008007522 |
| ent_coef_loss           | -1.1232765  |
| entropy                 | 0.67625284  |
| episodes                | 124         |
| fps                     | 141         |
| mean 100 episode reward | -1.4        |
| n_updates               | 48184       |
| policy_loss             | -2.3736858  |
| qf1_loss                | 0.02461403  |
| qf2_loss                | 0.02703723  |
| time_elapsed            | 341         |
| total timesteps         | 48284       |
| value_loss              | 0.015082849 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.00899972  |
| ent_coef_loss           | -1.7452579  |
| entropy                 | 0.9410584   |
| episodes                | 128         |
| fps                     | 141         |
| mean 100 episode reward | -1.3        |
| n_updates               | 49938       |
| policy_loss             | -2.0243912  |
| qf1_loss                | 0.01129706  |
| qf2_loss                | 0.010477359 |
| time_elapsed            | 353         |
| total timesteps         | 50038       |
| value_loss              | 0.020779569 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.007991108 |
| ent_coef_loss           | -0.10357566 |
| entropy                 | 1.068196    |
| episodes                | 132         |
| fps                     | 141         |
| mean 100 episode reward | -1.3        |
| n_updates               | 51698       |
| policy_loss             | -1.6253333  |
| qf1_loss                | 0.02561986  |
| qf2_loss                | 0.018041333 |
| time_elapsed            | 365         |
| total timesteps         | 51798       |
| value_loss              | 0.029824112 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.007275123 |
| ent_coef_loss           | 1.757479    |
| entropy                 | 0.9265697   |
| episodes                | 136         |
| fps                     | 141         |
| mean 100 episode reward | -1.2        |
| n_updates               | 53458       |
| policy_loss             | -1.7490486  |
| qf1_loss                | 0.048473194 |
| qf2_loss                | 0.09477855  |
| time_elapsed            | 378         |
| total timesteps         | 53558       |
| value_loss              | 0.29482934  |
-----------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0069961706 |
| ent_coef_loss           | -1.1844046   |
| entropy                 | 1.1411285    |
| episodes                | 140          |
| fps                     | 141          |
| mean 100 episode reward | -1.2         |
| n_updates               | 54895        |
| policy_loss             | -2.146462    |
| qf1_loss                | 0.013201643  |
| qf2_loss                | 0.012934761  |
| time_elapsed            | 388          |
| total timesteps         | 54995        |
| value_loss              | 0.03230084   |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0073649245 |
| ent_coef_loss           | 3.1977983    |
| entropy                 | 1.2060206    |
| episodes                | 144          |
| fps                     | 141          |
| mean 100 episode reward | -1.2         |
| n_updates               | 56451        |
| policy_loss             | -1.3959713   |
| qf1_loss                | 0.004726541  |
| qf2_loss                | 0.008632498  |
| time_elapsed            | 398          |
| total timesteps         | 56551        |
| value_loss              | 0.013926955  |
------------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.0076907   |
| ent_coef_loss           | -1.7106578  |
| entropy                 | 1.0751626   |
| episodes                | 148         |
| fps                     | 141         |
| mean 100 episode reward | -1.2        |
| n_updates               | 58130       |
| policy_loss             | -2.0686374  |
| qf1_loss                | 0.012454364 |
| qf2_loss                | 0.01454033  |
| time_elapsed            | 410         |
| total timesteps         | 58230       |
| value_loss              | 0.040797733 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0070790914 |
| ent_coef_loss           | -0.7782786   |
| entropy                 | 1.1856546    |
| episodes                | 152          |
| fps                     | 141          |
| mean 100 episode reward | -1.2         |
| n_updates               | 59890        |
| policy_loss             | -1.7120694   |
| qf1_loss                | 0.006262796  |
| qf2_loss                | 0.005341026  |
| time_elapsed            | 422          |
| total timesteps         | 59990        |
| value_loss              | 0.0065885233 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0070761554 |
| ent_coef_loss           | 1.2683146    |
| entropy                 | 1.0873389    |
| episodes                | 156          |
| fps                     | 141          |
| mean 100 episode reward | -1.2         |
| n_updates               | 61650        |
| policy_loss             | -2.6039941   |
| qf1_loss                | 0.006543882  |
| qf2_loss                | 0.005897887  |
| time_elapsed            | 434          |
| total timesteps         | 61750        |
| value_loss              | 0.021420427  |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.006442793  |
| ent_coef_loss           | 0.084468484  |
| entropy                 | 1.4471343    |
| episodes                | 160          |
| fps                     | 142          |
| mean 100 episode reward | -1.2         |
| n_updates               | 63410        |
| policy_loss             | -1.126202    |
| qf1_loss                | 0.0063472753 |
| qf2_loss                | 0.006873274  |
| time_elapsed            | 447          |
| total timesteps         | 63510        |
| value_loss              | 0.011883952  |
------------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.006279966 |
| ent_coef_loss           | -0.7427052  |
| entropy                 | 1.1397922   |
| episodes                | 164         |
| fps                     | 142         |
| mean 100 episode reward | -1.2        |
| n_updates               | 65170       |
| policy_loss             | -2.0034585  |
| qf1_loss                | 0.013050506 |
| qf2_loss                | 0.012878383 |
| time_elapsed            | 459         |
| total timesteps         | 65270       |
| value_loss              | 0.071968526 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0061476068 |
| ent_coef_loss           | 0.4381324    |
| entropy                 | 1.4877027    |
| episodes                | 168          |
| fps                     | 142          |
| mean 100 episode reward | -1.1         |
| n_updates               | 66930        |
| policy_loss             | -1.1712276   |
| qf1_loss                | 0.0025030486 |
| qf2_loss                | 0.0018739083 |
| time_elapsed            | 471          |
| total timesteps         | 67030        |
| value_loss              | 0.0047919992 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0065000006 |
| ent_coef_loss           | -1.3540065   |
| entropy                 | 1.4390329    |
| episodes                | 172          |
| fps                     | 142          |
| mean 100 episode reward | -1.1         |
| n_updates               | 68690        |
| policy_loss             | -1.3923719   |
| qf1_loss                | 0.0060118698 |
| qf2_loss                | 0.009813679  |
| time_elapsed            | 483          |
| total timesteps         | 68790        |
| value_loss              | 0.007741358  |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0060777436 |
| ent_coef_loss           | 1.9995798    |
| entropy                 | 1.2986152    |
| episodes                | 176          |
| fps                     | 142          |
| mean 100 episode reward | -1           |
| n_updates               | 70450        |
| policy_loss             | -1.4889121   |
| qf1_loss                | 0.004086257  |
| qf2_loss                | 0.0034909302 |
| time_elapsed            | 496          |
| total timesteps         | 70550        |
| value_loss              | 0.010233693  |
------------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.005791611 |
| ent_coef_loss           | 0.4904278   |
| entropy                 | 1.1849036   |
| episodes                | 180         |
| fps                     | 142         |
| mean 100 episode reward | -0.9        |
| n_updates               | 72210       |
| policy_loss             | -1.4366344  |
| qf1_loss                | 0.005224383 |
| qf2_loss                | 0.009555672 |
| time_elapsed            | 508         |
| total timesteps         | 72310       |
| value_loss              | 0.008796178 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0047172345 |
| ent_coef_loss           | -0.9460202   |
| entropy                 | 1.2765795    |
| episodes                | 184          |
| fps                     | 142          |
| mean 100 episode reward | -0.8         |
| n_updates               | 73970        |
| policy_loss             | -1.3344917   |
| qf1_loss                | 0.0026063798 |
| qf2_loss                | 0.0041200626 |
| time_elapsed            | 520          |
| total timesteps         | 74070        |
| value_loss              | 0.0064876843 |
------------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.00421186  |
| ent_coef_loss           | -1.8329421  |
| entropy                 | 1.1354256   |
| episodes                | 188         |
| fps                     | 142         |
| mean 100 episode reward | -0.8        |
| n_updates               | 75730       |
| policy_loss             | -1.8775575  |
| qf1_loss                | 0.008015836 |
| qf2_loss                | 0.01242087  |
| time_elapsed            | 532         |
| total timesteps         | 75830       |
| value_loss              | 0.027391884 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.004131894 |
| ent_coef_loss           | -0.8332507  |
| entropy                 | 1.1593338   |
| episodes                | 192         |
| fps                     | 142         |
| mean 100 episode reward | -0.7        |
| n_updates               | 77490       |
| policy_loss             | -0.98065233 |
| qf1_loss                | 0.008686645 |
| qf2_loss                | 0.009221805 |
| time_elapsed            | 544         |
| total timesteps         | 77590       |
| value_loss              | 0.009894395 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0036317746 |
| ent_coef_loss           | 0.22011127   |
| entropy                 | 1.1745036    |
| episodes                | 196          |
| fps                     | 142          |
| mean 100 episode reward | -0.6         |
| n_updates               | 79250        |
| policy_loss             | -0.88771725  |
| qf1_loss                | 0.002800797  |
| qf2_loss                | 0.0021437237 |
| time_elapsed            | 556          |
| total timesteps         | 79350        |
| value_loss              | 0.0032285203 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.003899418  |
| ent_coef_loss           | -1.2136184   |
| entropy                 | 1.0162742    |
| episodes                | 200          |
| fps                     | 142          |
| mean 100 episode reward | -0.6         |
| n_updates               | 80856        |
| policy_loss             | -1.3528609   |
| qf1_loss                | 0.004267182  |
| qf2_loss                | 0.0044616684 |
| time_elapsed            | 568          |
| total timesteps         | 80956        |
| value_loss              | 0.0066506425 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0032993893 |
| ent_coef_loss           | -0.89096296  |
| entropy                 | 1.1591169    |
| episodes                | 204          |
| fps                     | 142          |
| mean 100 episode reward | -0.6         |
| n_updates               | 82616        |
| policy_loss             | -0.8471468   |
| qf1_loss                | 0.0027353084 |
| qf2_loss                | 0.002028906  |
| time_elapsed            | 580          |
| total timesteps         | 82716        |
| value_loss              | 0.0039454037 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0031386912 |
| ent_coef_loss           | 1.5777049    |
| entropy                 | 1.1356893    |
| episodes                | 208          |
| fps                     | 142          |
| mean 100 episode reward | -0.5         |
| n_updates               | 84376        |
| policy_loss             | -0.90780747  |
| qf1_loss                | 0.0021241894 |
| qf2_loss                | 0.0017036862 |
| time_elapsed            | 592          |
| total timesteps         | 84476        |
| value_loss              | 0.0040222188 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0026619923 |
| ent_coef_loss           | 2.6372874    |
| entropy                 | 1.0346241    |
| episodes                | 212          |
| fps                     | 142          |
| mean 100 episode reward | -0.5         |
| n_updates               | 86136        |
| policy_loss             | -1.0396025   |
| qf1_loss                | 0.0146831    |
| qf2_loss                | 0.013566112  |
| time_elapsed            | 604          |
| total timesteps         | 86236        |
| value_loss              | 0.0019585318 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0024350977 |
| ent_coef_loss           | -0.5386328   |
| entropy                 | 1.0104471    |
| episodes                | 216          |
| fps                     | 142          |
| mean 100 episode reward | -0.5         |
| n_updates               | 87744        |
| policy_loss             | -0.88986754  |
| qf1_loss                | 0.0023864852 |
| qf2_loss                | 0.0014903988 |
| time_elapsed            | 615          |
| total timesteps         | 87844        |
| value_loss              | 0.002280745  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0024859193  |
| ent_coef_loss           | 0.9709443     |
| entropy                 | 1.1899717     |
| episodes                | 220           |
| fps                     | 142           |
| mean 100 episode reward | -0.4          |
| n_updates               | 89504         |
| policy_loss             | -0.73659515   |
| qf1_loss                | 0.0007630056  |
| qf2_loss                | 0.00059964205 |
| time_elapsed            | 628           |
| total timesteps         | 89604         |
| value_loss              | 0.00063828577 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0022441838  |
| ent_coef_loss           | 1.9117635     |
| entropy                 | 1.0788183     |
| episodes                | 224           |
| fps                     | 142           |
| mean 100 episode reward | -0.4          |
| n_updates               | 91218         |
| policy_loss             | -0.8562829    |
| qf1_loss                | 0.00061675766 |
| qf2_loss                | 0.0007384717  |
| time_elapsed            | 640           |
| total timesteps         | 91318         |
| value_loss              | 0.001345801   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0017780539  |
| ent_coef_loss           | 2.497333      |
| entropy                 | 0.874459      |
| episodes                | 228           |
| fps                     | 142           |
| mean 100 episode reward | -0.4          |
| n_updates               | 92978         |
| policy_loss             | -0.91628575   |
| qf1_loss                | 0.0008523717  |
| qf2_loss                | 0.00065222825 |
| time_elapsed            | 652           |
| total timesteps         | 93078         |
| value_loss              | 0.0009806075  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0017981057  |
| ent_coef_loss           | 2.2751617     |
| entropy                 | 0.76593304    |
| episodes                | 232           |
| fps                     | 142           |
| mean 100 episode reward | -0.4          |
| n_updates               | 94615         |
| policy_loss             | -0.9458928    |
| qf1_loss                | 0.00044574874 |
| qf2_loss                | 0.00040945312 |
| time_elapsed            | 663           |
| total timesteps         | 94715         |
| value_loss              | 0.0008767934  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0016830536  |
| ent_coef_loss           | -3.785326     |
| entropy                 | 0.7609604     |
| episodes                | 236           |
| fps                     | 142           |
| mean 100 episode reward | -0.4          |
| n_updates               | 96375         |
| policy_loss             | -0.6966061    |
| qf1_loss                | 0.0005676233  |
| qf2_loss                | 0.00046366092 |
| time_elapsed            | 675           |
| total timesteps         | 96475         |
| value_loss              | 0.0018387584  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0013771285  |
| ent_coef_loss           | 0.30542207    |
| entropy                 | 0.689119      |
| episodes                | 240           |
| fps                     | 142           |
| mean 100 episode reward | -0.4          |
| n_updates               | 98135         |
| policy_loss             | -0.7661161    |
| qf1_loss                | 0.00064625323 |
| qf2_loss                | 0.0004496809  |
| time_elapsed            | 688           |
| total timesteps         | 98235         |
| value_loss              | 0.00069310487 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0014708849 |
| ent_coef_loss           | 0.35594243   |
| entropy                 | 1.0041764    |
| episodes                | 244          |
| fps                     | 142          |
| mean 100 episode reward | -0.4         |
| n_updates               | 99895        |
| policy_loss             | -0.58508813  |
| qf1_loss                | 0.000424227  |
| qf2_loss                | 0.0005031603 |
| time_elapsed            | 700          |
| total timesteps         | 99995        |
| value_loss              | 0.0006430407 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0011096131  |
| ent_coef_loss           | -0.086461425  |
| entropy                 | 0.8430362     |
| episodes                | 248           |
| fps                     | 142           |
| mean 100 episode reward | -0.4          |
| n_updates               | 101655        |
| policy_loss             | -0.52474606   |
| qf1_loss                | 0.0002324828  |
| qf2_loss                | 0.00030983728 |
| time_elapsed            | 712           |
| total timesteps         | 101755        |
| value_loss              | 0.00024354717 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0012966397  |
| ent_coef_loss           | -2.2602577    |
| entropy                 | 0.8190461     |
| episodes                | 252           |
| fps                     | 142           |
| mean 100 episode reward | -0.4          |
| n_updates               | 103162        |
| policy_loss             | -0.5282237    |
| qf1_loss                | 0.00021569157 |
| qf2_loss                | 0.00032823853 |
| time_elapsed            | 722           |
| total timesteps         | 103262        |
| value_loss              | 0.00021505803 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0012112064 |
| ent_coef_loss           | -1.2480099   |
| entropy                 | 1.0840564    |
| episodes                | 256          |
| fps                     | 142          |
| mean 100 episode reward | -0.4         |
| n_updates               | 104922       |
| policy_loss             | -0.5426574   |
| qf1_loss                | 0.017960176  |
| qf2_loss                | 0.018531675  |
| time_elapsed            | 735          |
| total timesteps         | 105022       |
| value_loss              | 0.0005600294 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0012456576 |
| ent_coef_loss           | 1.2691277    |
| entropy                 | 1.0304065    |
| episodes                | 260          |
| fps                     | 142          |
| mean 100 episode reward | -0.4         |
| n_updates               | 106334       |
| policy_loss             | -0.41836685  |
| qf1_loss                | 0.0021833326 |
| qf2_loss                | 0.00128253   |
| time_elapsed            | 745          |
| total timesteps         | 106434       |
| value_loss              | 0.0005801753 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0011063027  |
| ent_coef_loss           | 0.95492244    |
| entropy                 | 0.92111796    |
| episodes                | 264           |
| fps                     | 142           |
| mean 100 episode reward | -0.4          |
| n_updates               | 108094        |
| policy_loss             | -0.40989298   |
| qf1_loss                | 0.00019054182 |
| qf2_loss                | 0.00010903908 |
| time_elapsed            | 758           |
| total timesteps         | 108194        |
| value_loss              | 0.00032553708 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0010275773  |
| ent_coef_loss           | -0.24373901   |
| entropy                 | 0.8328168     |
| episodes                | 268           |
| fps                     | 142           |
| mean 100 episode reward | -0.4          |
| n_updates               | 109854        |
| policy_loss             | -0.46340096   |
| qf1_loss                | 0.00013516194 |
| qf2_loss                | 0.00012021753 |
| time_elapsed            | 770           |
| total timesteps         | 109954        |
| value_loss              | 0.00022582032 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.001          |
| ent_coef                | 0.0008792152   |
| ent_coef_loss           | -1.5696081     |
| entropy                 | 0.7951906      |
| episodes                | 272            |
| fps                     | 142            |
| mean 100 episode reward | -0.4           |
| n_updates               | 111479         |
| policy_loss             | -0.3417932     |
| qf1_loss                | 0.00018023798  |
| qf2_loss                | 0.000110347304 |
| time_elapsed            | 781            |
| total timesteps         | 111579         |
| value_loss              | 0.00032802759  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0007865777  |
| ent_coef_loss           | 4.793199      |
| entropy                 | 0.9126516     |
| episodes                | 276           |
| fps                     | 142           |
| mean 100 episode reward | -0.5          |
| n_updates               | 113239        |
| policy_loss             | -0.42738724   |
| qf1_loss                | 0.00013501021 |
| qf2_loss                | 0.00011930107 |
| time_elapsed            | 794           |
| total timesteps         | 113339        |
| value_loss              | 0.00013528472 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.001          |
| ent_coef                | 0.0006895881   |
| ent_coef_loss           | 2.1265967      |
| entropy                 | 0.9815967      |
| episodes                | 280            |
| fps                     | 142            |
| mean 100 episode reward | -0.5           |
| n_updates               | 114794         |
| policy_loss             | -0.2880603     |
| qf1_loss                | 0.0001365861   |
| qf2_loss                | 0.000106423715 |
| time_elapsed            | 805            |
| total timesteps         | 114894         |
| value_loss              | 0.0001651358   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006201208  |
| ent_coef_loss           | 1.2434982     |
| entropy                 | 0.6823348     |
| episodes                | 284           |
| fps                     | 142           |
| mean 100 episode reward | -0.6          |
| n_updates               | 116477        |
| policy_loss             | -0.25434422   |
| qf1_loss                | 8.783086e-05  |
| qf2_loss                | 4.5307643e-05 |
| time_elapsed            | 816           |
| total timesteps         | 116577        |
| value_loss              | 0.00013507855 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00069255946 |
| ent_coef_loss           | 0.79943186    |
| entropy                 | 0.76355153    |
| episodes                | 288           |
| fps                     | 142           |
| mean 100 episode reward | -0.6          |
| n_updates               | 118136        |
| policy_loss             | -0.21944305   |
| qf1_loss                | 7.4701515e-05 |
| qf2_loss                | 8.801518e-05  |
| time_elapsed            | 828           |
| total timesteps         | 118236        |
| value_loss              | 0.00013500026 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006671191  |
| ent_coef_loss           | -2.4720557    |
| entropy                 | 0.7431704     |
| episodes                | 292           |
| fps                     | 142           |
| mean 100 episode reward | -0.6          |
| n_updates               | 119511        |
| policy_loss             | -0.21881232   |
| qf1_loss                | 6.1014907e-05 |
| qf2_loss                | 5.3153177e-05 |
| time_elapsed            | 838           |
| total timesteps         | 119611        |
| value_loss              | 7.548982e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006840556  |
| ent_coef_loss           | 0.6130141     |
| entropy                 | 0.98088145    |
| episodes                | 296           |
| fps                     | 142           |
| mean 100 episode reward | -0.7          |
| n_updates               | 120622        |
| policy_loss             | -0.14869256   |
| qf1_loss                | 8.6183536e-05 |
| qf2_loss                | 6.387934e-05  |
| time_elapsed            | 845           |
| total timesteps         | 120722        |
| value_loss              | 0.00014462497 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005462663  |
| ent_coef_loss           | -3.1382608    |
| entropy                 | 0.7815289     |
| episodes                | 300           |
| fps                     | 142           |
| mean 100 episode reward | -0.7          |
| n_updates               | 122215        |
| policy_loss             | -0.14938991   |
| qf1_loss                | 3.538555e-05  |
| qf2_loss                | 0.00015442287 |
| time_elapsed            | 856           |
| total timesteps         | 122315        |
| value_loss              | 6.483702e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005752075  |
| ent_coef_loss           | -3.110403     |
| entropy                 | 0.7713244     |
| episodes                | 304           |
| fps                     | 142           |
| mean 100 episode reward | -0.7          |
| n_updates               | 123800        |
| policy_loss             | -0.1273134    |
| qf1_loss                | 8.730485e-05  |
| qf2_loss                | 4.682177e-05  |
| time_elapsed            | 867           |
| total timesteps         | 123900        |
| value_loss              | 0.00013487454 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00055767375 |
| ent_coef_loss           | 2.5440283     |
| entropy                 | 1.1073531     |
| episodes                | 308           |
| fps                     | 142           |
| mean 100 episode reward | -0.7          |
| n_updates               | 125421        |
| policy_loss             | -0.08560435   |
| qf1_loss                | 5.7156863e-05 |
| qf2_loss                | 5.8726062e-05 |
| time_elapsed            | 879           |
| total timesteps         | 125521        |
| value_loss              | 7.374714e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00053817075 |
| ent_coef_loss           | 1.5325146     |
| entropy                 | 0.79815143    |
| episodes                | 312           |
| fps                     | 142           |
| mean 100 episode reward | -0.7          |
| n_updates               | 127055        |
| policy_loss             | -0.081342824  |
| qf1_loss                | 6.5139684e-05 |
| qf2_loss                | 7.4349155e-05 |
| time_elapsed            | 890           |
| total timesteps         | 127155        |
| value_loss              | 5.894163e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00056838256 |
| ent_coef_loss           | -2.2892537    |
| entropy                 | 0.9507692     |
| episodes                | 316           |
| fps                     | 142           |
| mean 100 episode reward | -0.7          |
| n_updates               | 128815        |
| policy_loss             | -0.05652922   |
| qf1_loss                | 4.7284215e-05 |
| qf2_loss                | 3.9313898e-05 |
| time_elapsed            | 903           |
| total timesteps         | 128915        |
| value_loss              | 0.00016528921 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00056196057 |
| ent_coef_loss           | -0.027416557  |
| entropy                 | 0.9417479     |
| episodes                | 320           |
| fps                     | 142           |
| mean 100 episode reward | -0.8          |
| n_updates               | 130484        |
| policy_loss             | -0.048869077  |
| qf1_loss                | 5.4598764e-05 |
| qf2_loss                | 0.00011894958 |
| time_elapsed            | 914           |
| total timesteps         | 130584        |
| value_loss              | 7.2440336e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004642575  |
| ent_coef_loss           | 0.6327346     |
| entropy                 | 1.1229514     |
| episodes                | 324           |
| fps                     | 142           |
| mean 100 episode reward | -0.8          |
| n_updates               | 131947        |
| policy_loss             | -0.014956527  |
| qf1_loss                | 0.000508518   |
| qf2_loss                | 0.00023448294 |
| time_elapsed            | 924           |
| total timesteps         | 132047        |
| value_loss              | 7.229725e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00047313725 |
| ent_coef_loss           | -5.0415244    |
| entropy                 | 1.1104922     |
| episodes                | 328           |
| fps                     | 142           |
| mean 100 episode reward | -0.8          |
| n_updates               | 133410        |
| policy_loss             | -0.007186171  |
| qf1_loss                | 3.226145e-05  |
| qf2_loss                | 4.5234505e-05 |
| time_elapsed            | 934           |
| total timesteps         | 133510        |
| value_loss              | 4.8603506e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004607608  |
| ent_coef_loss           | -1.6574938    |
| entropy                 | 1.1900315     |
| episodes                | 332           |
| fps                     | 142           |
| mean 100 episode reward | -0.9          |
| n_updates               | 135170        |
| policy_loss             | 0.02049848    |
| qf1_loss                | 4.0932297e-05 |
| qf2_loss                | 6.437259e-05  |
| time_elapsed            | 947           |
| total timesteps         | 135270        |
| value_loss              | 5.73053e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00046782038 |
| ent_coef_loss           | -2.1249154    |
| entropy                 | 1.2316546     |
| episodes                | 336           |
| fps                     | 142           |
| mean 100 episode reward | -0.9          |
| n_updates               | 136930        |
| policy_loss             | 0.010278631   |
| qf1_loss                | 4.9526927e-05 |
| qf2_loss                | 3.944896e-05  |
| time_elapsed            | 959           |
| total timesteps         | 137030        |
| value_loss              | 7.986248e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004532764  |
| ent_coef_loss           | 4.7344384     |
| entropy                 | 1.0971076     |
| episodes                | 340           |
| fps                     | 142           |
| mean 100 episode reward | -0.9          |
| n_updates               | 138462        |
| policy_loss             | 0.060299896   |
| qf1_loss                | 5.488658e-05  |
| qf2_loss                | 3.8053404e-05 |
| time_elapsed            | 969           |
| total timesteps         | 138562        |
| value_loss              | 7.145402e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00045209608 |
| ent_coef_loss           | 0.8847425     |
| entropy                 | 1.188174      |
| episodes                | 344           |
| fps                     | 142           |
| mean 100 episode reward | -0.9          |
| n_updates               | 139450        |
| policy_loss             | 0.08252292    |
| qf1_loss                | 3.8745995e-05 |
| qf2_loss                | 5.550583e-05  |
| time_elapsed            | 976           |
| total timesteps         | 139550        |
| value_loss              | 3.960135e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00040123207 |
| ent_coef_loss           | 0.10875788    |
| entropy                 | 1.1389886     |
| episodes                | 348           |
| fps                     | 142           |
| mean 100 episode reward | -1            |
| n_updates               | 141210        |
| policy_loss             | 0.07058554    |
| qf1_loss                | 2.860108e-05  |
| qf2_loss                | 3.209615e-05  |
| time_elapsed            | 988           |
| total timesteps         | 141310        |
| value_loss              | 4.8093956e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00045465358 |
| ent_coef_loss           | -5.5245037    |
| entropy                 | 1.2735441     |
| episodes                | 352           |
| fps                     | 142           |
| mean 100 episode reward | -1            |
| n_updates               | 142970        |
| policy_loss             | 0.067065805   |
| qf1_loss                | 3.7466838e-05 |
| qf2_loss                | 5.056463e-05  |
| time_elapsed            | 1001          |
| total timesteps         | 143070        |
| value_loss              | 5.2272466e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00046822435 |
| ent_coef_loss           | -1.9213195    |
| entropy                 | 1.2237537     |
| episodes                | 356           |
| fps                     | 142           |
| mean 100 episode reward | -1            |
| n_updates               | 144730        |
| policy_loss             | 0.09504348    |
| qf1_loss                | 1.3344572e-05 |
| qf2_loss                | 1.9981613e-05 |
| time_elapsed            | 1013          |
| total timesteps         | 144830        |
| value_loss              | 5.4415483e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00044724403 |
| ent_coef_loss           | -0.75673485   |
| entropy                 | 1.1139603     |
| episodes                | 360           |
| fps                     | 142           |
| mean 100 episode reward | -1.1          |
| n_updates               | 146216        |
| policy_loss             | 0.09753418    |
| qf1_loss                | 4.4592216e-05 |
| qf2_loss                | 4.0179555e-05 |
| time_elapsed            | 1023          |
| total timesteps         | 146316        |
| value_loss              | 3.6843456e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00041285437 |
| ent_coef_loss           | 0.7443631     |
| entropy                 | 1.2471207     |
| episodes                | 364           |
| fps                     | 142           |
| mean 100 episode reward | -1.1          |
| n_updates               | 147933        |
| policy_loss             | 0.09632763    |
| qf1_loss                | 4.034068e-05  |
| qf2_loss                | 3.6732315e-05 |
| time_elapsed            | 1035          |
| total timesteps         | 148033        |
| value_loss              | 4.0711537e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00041352387 |
| ent_coef_loss           | 0.5962591     |
| entropy                 | 1.2067115     |
| episodes                | 368           |
| fps                     | 142           |
| mean 100 episode reward | -1.2          |
| n_updates               | 149593        |
| policy_loss             | 0.1256946     |
| qf1_loss                | 2.5751338e-05 |
| qf2_loss                | 3.6610523e-05 |
| time_elapsed            | 1047          |
| total timesteps         | 149693        |
| value_loss              | 3.6395446e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00043210707 |
| ent_coef_loss           | 2.6646934     |
| entropy                 | 0.8603862     |
| episodes                | 372           |
| fps                     | 142           |
| mean 100 episode reward | -1.2          |
| n_updates               | 150824        |
| policy_loss             | 0.1174639     |
| qf1_loss                | 0.00033172985 |
| qf2_loss                | 0.00049555785 |
| time_elapsed            | 1055          |
| total timesteps         | 150924        |
| value_loss              | 5.5853103e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00041411349 |
| ent_coef_loss           | -4.0949497    |
| entropy                 | 0.9784159     |
| episodes                | 376           |
| fps                     | 142           |
| mean 100 episode reward | -1.2          |
| n_updates               | 152249        |
| policy_loss             | 0.09934777    |
| qf1_loss                | 5.4198375e-05 |
| qf2_loss                | 4.8545906e-05 |
| time_elapsed            | 1065          |
| total timesteps         | 152349        |
| value_loss              | 7.5021424e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00040830742 |
| ent_coef_loss           | 0.59479976    |
| entropy                 | 1.0192398     |
| episodes                | 380           |
| fps                     | 142           |
| mean 100 episode reward | -1.2          |
| n_updates               | 153613        |
| policy_loss             | 0.124241725   |
| qf1_loss                | 3.8521597e-05 |
| qf2_loss                | 3.9802748e-05 |
| time_elapsed            | 1075          |
| total timesteps         | 153713        |
| value_loss              | 7.155747e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00043876885 |
| ent_coef_loss           | -2.8572602    |
| entropy                 | 1.2162352     |
| episodes                | 384           |
| fps                     | 142           |
| mean 100 episode reward | -1.2          |
| n_updates               | 154741        |
| policy_loss             | 0.12555952    |
| qf1_loss                | 3.831744e-05  |
| qf2_loss                | 2.8278255e-05 |
| time_elapsed            | 1083          |
| total timesteps         | 154841        |
| value_loss              | 4.0229825e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00041510296 |
| ent_coef_loss           | 1.953141      |
| entropy                 | 1.0328091     |
| episodes                | 388           |
| fps                     | 142           |
| mean 100 episode reward | -1.3          |
| n_updates               | 156208        |
| policy_loss             | 0.13093513    |
| qf1_loss                | 0.0007411052  |
| qf2_loss                | 0.0012861964  |
| time_elapsed            | 1093          |
| total timesteps         | 156308        |
| value_loss              | 0.00094433513 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00045279553 |
| ent_coef_loss           | 6.908851      |
| entropy                 | 1.2137003     |
| episodes                | 392           |
| fps                     | 142           |
| mean 100 episode reward | -1.3          |
| n_updates               | 157968        |
| policy_loss             | 0.15245315    |
| qf1_loss                | 6.155358e-05  |
| qf2_loss                | 4.994248e-05  |
| time_elapsed            | 1105          |
| total timesteps         | 158068        |
| value_loss              | 5.528122e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00039765396 |
| ent_coef_loss           | -2.977127     |
| entropy                 | 1.2728366     |
| episodes                | 396           |
| fps                     | 142           |
| mean 100 episode reward | -1.2          |
| n_updates               | 159404        |
| policy_loss             | 0.13194765    |
| qf1_loss                | 1.8148368e-05 |
| qf2_loss                | 1.6125476e-05 |
| time_elapsed            | 1115          |
| total timesteps         | 159504        |
| value_loss              | 3.690749e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00038027254 |
| ent_coef_loss           | 7.47938       |
| entropy                 | 1.2567596     |
| episodes                | 400           |
| fps                     | 142           |
| mean 100 episode reward | -1.2          |
| n_updates               | 160881        |
| policy_loss             | 0.15136006    |
| qf1_loss                | 5.7193673e-05 |
| qf2_loss                | 5.0614744e-05 |
| time_elapsed            | 1125          |
| total timesteps         | 160981        |
| value_loss              | 7.281831e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0003824746  |
| ent_coef_loss           | 3.145878      |
| entropy                 | 1.1005242     |
| episodes                | 404           |
| fps                     | 142           |
| mean 100 episode reward | -1.2          |
| n_updates               | 162367        |
| policy_loss             | 0.15532881    |
| qf1_loss                | 4.027297e-05  |
| qf2_loss                | 2.9818124e-05 |
| time_elapsed            | 1136          |
| total timesteps         | 162467        |
| value_loss              | 6.037241e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00033720882 |
| ent_coef_loss           | 3.2580867     |
| entropy                 | 0.77298796    |
| episodes                | 408           |
| fps                     | 142           |
| mean 100 episode reward | -1.2          |
| n_updates               | 163831        |
| policy_loss             | 0.17486408    |
| qf1_loss                | 2.642909e-05  |
| qf2_loss                | 3.4408542e-05 |
| time_elapsed            | 1146          |
| total timesteps         | 163931        |
| value_loss              | 6.1171086e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0003492492  |
| ent_coef_loss           | -2.7958717    |
| entropy                 | 1.054988      |
| episodes                | 412           |
| fps                     | 143           |
| mean 100 episode reward | -1.3          |
| n_updates               | 165591        |
| policy_loss             | 0.16317979    |
| qf1_loss                | 5.3992808e-05 |
| qf2_loss                | 6.2833315e-05 |
| time_elapsed            | 1158          |
| total timesteps         | 165691        |
| value_loss              | 5.8297206e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00039061473 |
| ent_coef_loss           | 0.43955854    |
| entropy                 | 0.9812029     |
| episodes                | 416           |
| fps                     | 143           |
| mean 100 episode reward | -1.3          |
| n_updates               | 167351        |
| policy_loss             | 0.15812176    |
| qf1_loss                | 5.7175268e-05 |
| qf2_loss                | 6.412466e-05  |
| time_elapsed            | 1170          |
| total timesteps         | 167451        |
| value_loss              | 5.7557525e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00037916173 |
| ent_coef_loss           | -3.140449     |
| entropy                 | 0.9141722     |
| episodes                | 420           |
| fps                     | 143           |
| mean 100 episode reward | -1.3          |
| n_updates               | 168689        |
| policy_loss             | 0.14810893    |
| qf1_loss                | 2.1767399e-05 |
| qf2_loss                | 2.1169642e-05 |
| time_elapsed            | 1180          |
| total timesteps         | 168789        |
| value_loss              | 1.628518e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004009364  |
| ent_coef_loss           | -2.6470954    |
| entropy                 | 1.2236795     |
| episodes                | 424           |
| fps                     | 143           |
| mean 100 episode reward | -1.3          |
| n_updates               | 170449        |
| policy_loss             | 0.1568373     |
| qf1_loss                | 6.691272e-05  |
| qf2_loss                | 5.1846047e-05 |
| time_elapsed            | 1192          |
| total timesteps         | 170549        |
| value_loss              | 6.0632785e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00040449874 |
| ent_coef_loss           | -0.6814099    |
| entropy                 | 0.96583617    |
| episodes                | 428           |
| fps                     | 143           |
| mean 100 episode reward | -1.2          |
| n_updates               | 172209        |
| policy_loss             | 0.15907215    |
| qf1_loss                | 3.0473462e-05 |
| qf2_loss                | 7.570311e-05  |
| time_elapsed            | 1204          |
| total timesteps         | 172309        |
| value_loss              | 5.933512e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.001          |
| ent_coef                | 0.00032045835  |
| ent_coef_loss           | 1.3582609      |
| entropy                 | 1.0600462      |
| episodes                | 432            |
| fps                     | 143            |
| mean 100 episode reward | -1.2           |
| n_updates               | 173969         |
| policy_loss             | 0.17185105     |
| qf1_loss                | 0.000118134914 |
| qf2_loss                | 0.00014830222  |
| time_elapsed            | 1217           |
| total timesteps         | 174069         |
| value_loss              | 2.5348516e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00033218102 |
| ent_coef_loss           | 0.59608126    |
| entropy                 | 0.7917001     |
| episodes                | 436           |
| fps                     | 143           |
| mean 100 episode reward | -1.3          |
| n_updates               | 175459        |
| policy_loss             | 0.15424126    |
| qf1_loss                | 0.00026393725 |
| qf2_loss                | 4.2554308e-05 |
| time_elapsed            | 1227          |
| total timesteps         | 175559        |
| value_loss              | 5.3706448e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00033193815 |
| ent_coef_loss           | 2.3039834     |
| entropy                 | 0.89307284    |
| episodes                | 440           |
| fps                     | 143           |
| mean 100 episode reward | -1.4          |
| n_updates               | 177219        |
| policy_loss             | 0.15050256    |
| qf1_loss                | 3.7536825e-05 |
| qf2_loss                | 3.9051487e-05 |
| time_elapsed            | 1239          |
| total timesteps         | 177319        |
| value_loss              | 6.5997614e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00031401057 |
| ent_coef_loss           | -2.4114256    |
| entropy                 | 1.1705296     |
| episodes                | 444           |
| fps                     | 143           |
| mean 100 episode reward | -1.3          |
| n_updates               | 178871        |
| policy_loss             | 0.14723185    |
| qf1_loss                | 0.00036333027 |
| qf2_loss                | 0.0003637482  |
| time_elapsed            | 1251          |
| total timesteps         | 178971        |
| value_loss              | 4.1136223e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0003127443  |
| ent_coef_loss           | 2.423338      |
| entropy                 | 0.7842173     |
| episodes                | 448           |
| fps                     | 143           |
| mean 100 episode reward | -1.4          |
| n_updates               | 180631        |
| policy_loss             | 0.17434111    |
| qf1_loss                | 4.7223934e-05 |
| qf2_loss                | 4.1026135e-05 |
| time_elapsed            | 1263          |
| total timesteps         | 180731        |
| value_loss              | 8.1076854e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0003323122  |
| ent_coef_loss           | 0.715335      |
| entropy                 | 0.8200994     |
| episodes                | 452           |
| fps                     | 143           |
| mean 100 episode reward | -1.4          |
| n_updates               | 182356        |
| policy_loss             | 0.15949889    |
| qf1_loss                | 4.8387268e-05 |
| qf2_loss                | 4.5907003e-05 |
| time_elapsed            | 1275          |
| total timesteps         | 182456        |
| value_loss              | 0.00012787711 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00035353136 |
| ent_coef_loss           | 0.7710384     |
| entropy                 | 1.1062698     |
| episodes                | 456           |
| fps                     | 143           |
| mean 100 episode reward | -1.4          |
| n_updates               | 184116        |
| policy_loss             | 0.1737503     |
| qf1_loss                | 3.484315e-05  |
| qf2_loss                | 2.0208747e-05 |
| time_elapsed            | 1287          |
| total timesteps         | 184216        |
| value_loss              | 3.2513242e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0003573359  |
| ent_coef_loss           | -2.7825959    |
| entropy                 | 0.9425272     |
| episodes                | 460           |
| fps                     | 143           |
| mean 100 episode reward | -1.4          |
| n_updates               | 185876        |
| policy_loss             | 0.16568016    |
| qf1_loss                | 5.5393928e-05 |
| qf2_loss                | 4.307978e-05  |
| time_elapsed            | 1300          |
| total timesteps         | 185976        |
| value_loss              | 5.5798868e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00035533684 |
| ent_coef_loss           | -2.0137553    |
| entropy                 | 0.95558774    |
| episodes                | 464           |
| fps                     | 143           |
| mean 100 episode reward | -1.4          |
| n_updates               | 187636        |
| policy_loss             | 0.16830383    |
| qf1_loss                | 4.6788184e-05 |
| qf2_loss                | 5.6005585e-05 |
| time_elapsed            | 1312          |
| total timesteps         | 187736        |
| value_loss              | 6.0315564e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00030622823 |
| ent_coef_loss           | 4.2579026     |
| entropy                 | 1.1614894     |
| episodes                | 468           |
| fps                     | 143           |
| mean 100 episode reward | -1.3          |
| n_updates               | 189396        |
| policy_loss             | 0.16286619    |
| qf1_loss                | 6.003928e-05  |
| qf2_loss                | 8.3905834e-05 |
| time_elapsed            | 1324          |
| total timesteps         | 189496        |
| value_loss              | 8.5292246e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00033081876 |
| ent_coef_loss           | -0.9008765    |
| entropy                 | 0.9950991     |
| episodes                | 472           |
| fps                     | 143           |
| mean 100 episode reward | -1.2          |
| n_updates               | 191156        |
| policy_loss             | 0.15435052    |
| qf1_loss                | 3.547175e-05  |
| qf2_loss                | 3.696412e-05  |
| time_elapsed            | 1336          |
| total timesteps         | 191256        |
| value_loss              | 4.56258e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.000328924   |
| ent_coef_loss           | 0.84257555    |
| entropy                 | 1.1148713     |
| episodes                | 476           |
| fps                     | 143           |
| mean 100 episode reward | -1.2          |
| n_updates               | 192916        |
| policy_loss             | 0.17229094    |
| qf1_loss                | 9.200299e-05  |
| qf2_loss                | 3.4623197e-05 |
| time_elapsed            | 1349          |
| total timesteps         | 193016        |
| value_loss              | 3.660842e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0003519924  |
| ent_coef_loss           | -2.7800882    |
| entropy                 | 0.9966423     |
| episodes                | 480           |
| fps                     | 143           |
| mean 100 episode reward | -1.2          |
| n_updates               | 194676        |
| policy_loss             | 0.15000379    |
| qf1_loss                | 2.8863684e-05 |
| qf2_loss                | 3.101104e-05  |
| time_elapsed            | 1361          |
| total timesteps         | 194776        |
| value_loss              | 2.40386e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00030293636 |
| ent_coef_loss           | 0.7905517     |
| entropy                 | 0.8383958     |
| episodes                | 484           |
| fps                     | 143           |
| mean 100 episode reward | -1.2          |
| n_updates               | 196310        |
| policy_loss             | 0.15333167    |
| qf1_loss                | 9.991956e-05  |
| qf2_loss                | 5.122328e-05  |
| time_elapsed            | 1372          |
| total timesteps         | 196410        |
| value_loss              | 0.00011925399 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00031243218 |
| ent_coef_loss           | -2.1204927    |
| entropy                 | 1.0448833     |
| episodes                | 488           |
| fps                     | 143           |
| mean 100 episode reward | -1.2          |
| n_updates               | 196970        |
| policy_loss             | 0.16451684    |
| qf1_loss                | 4.1741572e-05 |
| qf2_loss                | 2.8802633e-05 |
| time_elapsed            | 1377          |
| total timesteps         | 197070        |
| value_loss              | 3.0894378e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00027683732 |
| ent_coef_loss           | 3.1395159     |
| entropy                 | 0.67738724    |
| episodes                | 492           |
| fps                     | 143           |
| mean 100 episode reward | -1.3          |
| n_updates               | 198151        |
| policy_loss             | 0.14840831    |
| qf1_loss                | 0.0008231482  |
| qf2_loss                | 0.00082080846 |
| time_elapsed            | 1385          |
| total timesteps         | 198251        |
| value_loss              | 4.4210254e-05 |
-------------------------------------------
>>>>> End testing <<<<< energy:_-0.001__slack:_-0.0005
Final weights saved at:  /home/patrick/tensorboard_logs/sac_energy:_-0.001__slack:_-0.0005/stable_baselines.pkl
TEST COMMAND: python3 py3_learning.py --test --weights  /home/patrick/tensorboard_logs/sac_energy:_-0.001__slack:_-0.0005/stable_baselines.pkl
Starting test with params: {'energy': -0.005, 'slack': -0.0005}
Namespace(draw_screen=False, env_config='configs/env.config', policy='multi_human_rl', policy_config='configs/policy.config', test=False, train_config='configs/train.config', weights=None)
Gym environment created.
COLLISION PENALTY -0.25
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.29781243  |
| ent_coef_loss           | -4.076502   |
| entropy                 | 2.5980053   |
| episodes                | 4           |
| fps                     | 148         |
| mean 100 episode reward | -1.1        |
| n_updates               | 1212        |
| policy_loss             | -3.7474928  |
| qf1_loss                | 0.065269694 |
| qf2_loss                | 0.06573345  |
| time_elapsed            | 8           |
| total timesteps         | 1312        |
| value_loss              | 0.027483996 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.052108698  |
| ent_coef_loss           | -9.285663    |
| entropy                 | 2.5877893    |
| episodes                | 8            |
| fps                     | 145          |
| mean 100 episode reward | -1.7         |
| n_updates               | 2972         |
| policy_loss             | -4.5304213   |
| qf1_loss                | 0.002421433  |
| qf2_loss                | 0.001964204  |
| time_elapsed            | 21           |
| total timesteps         | 3072         |
| value_loss              | 0.0047363183 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.013743111  |
| ent_coef_loss           | -10.4769745  |
| entropy                 | 2.4193177    |
| episodes                | 12           |
| fps                     | 145          |
| mean 100 episode reward | -1.4         |
| n_updates               | 4422         |
| policy_loss             | -4.2317452   |
| qf1_loss                | 0.0021800515 |
| qf2_loss                | 0.0029125714 |
| time_elapsed            | 31           |
| total timesteps         | 4522         |
| value_loss              | 0.0049588727 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0051275585 |
| ent_coef_loss           | -2.1518908   |
| entropy                 | 1.9097956    |
| episodes                | 16           |
| fps                     | 145          |
| mean 100 episode reward | -2.1         |
| n_updates               | 6182         |
| policy_loss             | -3.8881345   |
| qf1_loss                | 0.0045473943 |
| qf2_loss                | 0.0055620586 |
| time_elapsed            | 43           |
| total timesteps         | 6282         |
| value_loss              | 0.011454534  |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0043540024 |
| ent_coef_loss           | -1.1560743   |
| entropy                 | 1.6477184    |
| episodes                | 20           |
| fps                     | 145          |
| mean 100 episode reward | -2.3         |
| n_updates               | 7520         |
| policy_loss             | -3.6862411   |
| qf1_loss                | 0.0032861428 |
| qf2_loss                | 0.0030652978 |
| time_elapsed            | 52           |
| total timesteps         | 7620         |
| value_loss              | 0.011794161  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0036510115  |
| ent_coef_loss           | 0.47467297    |
| entropy                 | 1.7229048     |
| episodes                | 24            |
| fps                     | 144           |
| mean 100 episode reward | -2.2          |
| n_updates               | 9006          |
| policy_loss             | -3.279142     |
| qf1_loss                | 0.00075033517 |
| qf2_loss                | 0.0009490412  |
| time_elapsed            | 63            |
| total timesteps         | 9106          |
| value_loss              | 0.0010139539  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0028008404 |
| ent_coef_loss           | -0.18844497  |
| entropy                 | 1.0898948    |
| episodes                | 28           |
| fps                     | 140          |
| mean 100 episode reward | -2.4         |
| n_updates               | 10685        |
| policy_loss             | -3.0980194   |
| qf1_loss                | 0.0007450943 |
| qf2_loss                | 0.0008064605 |
| time_elapsed            | 76           |
| total timesteps         | 10785        |
| value_loss              | 0.0012424652 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.002981084  |
| ent_coef_loss           | -2.1902802   |
| entropy                 | 0.6489959    |
| episodes                | 32           |
| fps                     | 136          |
| mean 100 episode reward | -2.2         |
| n_updates               | 12135        |
| policy_loss             | -2.5538964   |
| qf1_loss                | 0.002230091  |
| qf2_loss                | 0.0021026512 |
| time_elapsed            | 89           |
| total timesteps         | 12235        |
| value_loss              | 0.0030767927 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0026955772 |
| ent_coef_loss           | -1.32483     |
| entropy                 | 1.0797527    |
| episodes                | 36           |
| fps                     | 137          |
| mean 100 episode reward | -2.1         |
| n_updates               | 13758        |
| policy_loss             | -2.4730263   |
| qf1_loss                | 0.0040949727 |
| qf2_loss                | 0.009703089  |
| time_elapsed            | 100          |
| total timesteps         | 13858        |
| value_loss              | 0.0017187084 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0022567865  |
| ent_coef_loss           | 0.53893423    |
| entropy                 | 0.8949828     |
| episodes                | 40            |
| fps                     | 137           |
| mean 100 episode reward | -2.3          |
| n_updates               | 15163         |
| policy_loss             | -2.1662316    |
| qf1_loss                | 0.00048362877 |
| qf2_loss                | 0.00061052875 |
| time_elapsed            | 111           |
| total timesteps         | 15263         |
| value_loss              | 0.0006169152  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0018052818  |
| ent_coef_loss           | -1.0142999    |
| entropy                 | 0.44992587    |
| episodes                | 44            |
| fps                     | 137           |
| mean 100 episode reward | -2.1          |
| n_updates               | 16738         |
| policy_loss             | -1.9966532    |
| qf1_loss                | 0.0006061209  |
| qf2_loss                | 0.00068687554 |
| time_elapsed            | 122           |
| total timesteps         | 16838         |
| value_loss              | 0.0018880842  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0015171561 |
| ent_coef_loss           | -2.4161775   |
| entropy                 | 0.88069135   |
| episodes                | 48           |
| fps                     | 137          |
| mean 100 episode reward | -2           |
| n_updates               | 18429        |
| policy_loss             | -1.7053111   |
| qf1_loss                | 0.0011450299 |
| qf2_loss                | 0.012030015  |
| time_elapsed            | 134          |
| total timesteps         | 18529        |
| value_loss              | 0.0017059306 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0015918982  |
| ent_coef_loss           | 3.1241097     |
| entropy                 | 0.5421207     |
| episodes                | 52            |
| fps                     | 138           |
| mean 100 episode reward | -1.9          |
| n_updates               | 20189         |
| policy_loss             | -1.5075617    |
| qf1_loss                | 0.0005299654  |
| qf2_loss                | 0.00055171095 |
| time_elapsed            | 146           |
| total timesteps         | 20289         |
| value_loss              | 0.00085569813 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0013464794  |
| ent_coef_loss           | -1.8604614    |
| entropy                 | 0.7980043     |
| episodes                | 56            |
| fps                     | 138           |
| mean 100 episode reward | -1.9          |
| n_updates               | 21746         |
| policy_loss             | -1.3919222    |
| qf1_loss                | 0.0068704425  |
| qf2_loss                | 0.0075112493  |
| time_elapsed            | 157           |
| total timesteps         | 21846         |
| value_loss              | 0.00057659915 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0011764038  |
| ent_coef_loss           | -0.5141717    |
| entropy                 | 0.28485256    |
| episodes                | 60            |
| fps                     | 138           |
| mean 100 episode reward | -1.9          |
| n_updates               | 23099         |
| policy_loss             | -1.2487999    |
| qf1_loss                | 0.00030144132 |
| qf2_loss                | 0.00019780999 |
| time_elapsed            | 167           |
| total timesteps         | 23199         |
| value_loss              | 0.00044956576 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0012773055  |
| ent_coef_loss           | -3.1073022    |
| entropy                 | 0.47659168    |
| episodes                | 64            |
| fps                     | 139           |
| mean 100 episode reward | -1.9          |
| n_updates               | 23963         |
| policy_loss             | -1.1399753    |
| qf1_loss                | 0.00019704789 |
| qf2_loss                | 0.00018230826 |
| time_elapsed            | 173           |
| total timesteps         | 24063         |
| value_loss              | 0.00038060843 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0011962247  |
| ent_coef_loss           | -3.240841     |
| entropy                 | 0.36170977    |
| episodes                | 68            |
| fps                     | 139           |
| mean 100 episode reward | -1.8          |
| n_updates               | 25075         |
| policy_loss             | -1.0644217    |
| qf1_loss                | 0.00031136535 |
| qf2_loss                | 0.00046480197 |
| time_elapsed            | 180           |
| total timesteps         | 25175         |
| value_loss              | 0.0010029817  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0012211532  |
| ent_coef_loss           | 0.59012735    |
| entropy                 | 0.77012426    |
| episodes                | 72            |
| fps                     | 139           |
| mean 100 episode reward | -1.8          |
| n_updates               | 26143         |
| policy_loss             | -0.9271633    |
| qf1_loss                | 0.0002699244  |
| qf2_loss                | 0.00030343462 |
| time_elapsed            | 187           |
| total timesteps         | 26243         |
| value_loss              | 0.00038950087 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0011007277  |
| ent_coef_loss           | 2.8232307     |
| entropy                 | 0.5466647     |
| episodes                | 76            |
| fps                     | 139           |
| mean 100 episode reward | -1.8          |
| n_updates               | 27294         |
| policy_loss             | -0.87874097   |
| qf1_loss                | 0.0022142185  |
| qf2_loss                | 0.0010075145  |
| time_elapsed            | 195           |
| total timesteps         | 27394         |
| value_loss              | 0.00083851785 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0010638387  |
| ent_coef_loss           | -0.97866553   |
| entropy                 | 0.41438892    |
| episodes                | 80            |
| fps                     | 140           |
| mean 100 episode reward | -1.8          |
| n_updates               | 28494         |
| policy_loss             | -0.7454033    |
| qf1_loss                | 0.00023813374 |
| qf2_loss                | 0.0003654951  |
| time_elapsed            | 203           |
| total timesteps         | 28594         |
| value_loss              | 0.00047716202 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.001010882   |
| ent_coef_loss           | 1.1305445     |
| entropy                 | 0.52653146    |
| episodes                | 84            |
| fps                     | 140           |
| mean 100 episode reward | -1.8          |
| n_updates               | 29831         |
| policy_loss             | -0.67448395   |
| qf1_loss                | 0.00016414386 |
| qf2_loss                | 0.00022799759 |
| time_elapsed            | 213           |
| total timesteps         | 29931         |
| value_loss              | 0.00030164787 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0011128794 |
| ent_coef_loss           | 0.32870746   |
| entropy                 | 0.6607282    |
| episodes                | 88           |
| fps                     | 140          |
| mean 100 episode reward | -1.8         |
| n_updates               | 31340        |
| policy_loss             | -0.6228492   |
| qf1_loss                | 0.0013195041 |
| qf2_loss                | 0.0007575897 |
| time_elapsed            | 223          |
| total timesteps         | 31440        |
| value_loss              | 0.0008922348 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.001055659   |
| ent_coef_loss           | 2.3264728     |
| entropy                 | 0.7768191     |
| episodes                | 92            |
| fps                     | 141           |
| mean 100 episode reward | -1.8          |
| n_updates               | 32905         |
| policy_loss             | -0.49213615   |
| qf1_loss                | 0.00090961787 |
| qf2_loss                | 0.0006063441  |
| time_elapsed            | 233           |
| total timesteps         | 33005         |
| value_loss              | 0.0004692417  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0010535631  |
| ent_coef_loss           | -1.8884505    |
| entropy                 | 0.80997914    |
| episodes                | 96            |
| fps                     | 141           |
| mean 100 episode reward | -1.8          |
| n_updates               | 34326         |
| policy_loss             | -0.48973942   |
| qf1_loss                | 0.00019974833 |
| qf2_loss                | 0.00013907059 |
| time_elapsed            | 243           |
| total timesteps         | 34426         |
| value_loss              | 0.00033735228 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00095908204 |
| ent_coef_loss           | 2.1600862     |
| entropy                 | 0.6828486     |
| episodes                | 100           |
| fps                     | 141           |
| mean 100 episode reward | -1.7          |
| n_updates               | 35792         |
| policy_loss             | -0.4417035    |
| qf1_loss                | 0.00023401287 |
| qf2_loss                | 0.00021927606 |
| time_elapsed            | 253           |
| total timesteps         | 35892         |
| value_loss              | 0.0006179762  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0010128915 |
| ent_coef_loss           | 1.0293809    |
| entropy                 | 1.1292387    |
| episodes                | 104          |
| fps                     | 141          |
| mean 100 episode reward | -1.7         |
| n_updates               | 37552        |
| policy_loss             | -0.38879064  |
| qf1_loss                | 0.0053107003 |
| qf2_loss                | 0.0055458955 |
| time_elapsed            | 265          |
| total timesteps         | 37652        |
| value_loss              | 0.0012518932 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0009025381  |
| ent_coef_loss           | 0.4651105     |
| entropy                 | 0.6628667     |
| episodes                | 108           |
| fps                     | 141           |
| mean 100 episode reward | -1.7          |
| n_updates               | 39255         |
| policy_loss             | -0.3379853    |
| qf1_loss                | 0.00017167517 |
| qf2_loss                | 0.00014127968 |
| time_elapsed            | 277           |
| total timesteps         | 39355         |
| value_loss              | 0.00028594641 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00078152865 |
| ent_coef_loss           | -0.7437122    |
| entropy                 | 0.5671668     |
| episodes                | 112           |
| fps                     | 142           |
| mean 100 episode reward | -1.7          |
| n_updates               | 40864         |
| policy_loss             | -0.2391935    |
| qf1_loss                | 9.375699e-05  |
| qf2_loss                | 0.00016224344 |
| time_elapsed            | 288           |
| total timesteps         | 40964         |
| value_loss              | 0.00038941557 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0008174747  |
| ent_coef_loss           | 0.5137336     |
| entropy                 | 1.0855951     |
| episodes                | 116           |
| fps                     | 142           |
| mean 100 episode reward | -1.7          |
| n_updates               | 42624         |
| policy_loss             | -0.20422824   |
| qf1_loss                | 0.00011293628 |
| qf2_loss                | 0.00011192581 |
| time_elapsed            | 300           |
| total timesteps         | 42724         |
| value_loss              | 0.00019998287 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0007326776  |
| ent_coef_loss           | -1.657503     |
| entropy                 | 0.9725994     |
| episodes                | 120           |
| fps                     | 142           |
| mean 100 episode reward | -1.7          |
| n_updates               | 43767         |
| policy_loss             | -0.21178412   |
| qf1_loss                | 0.00010780683 |
| qf2_loss                | 0.00014563535 |
| time_elapsed            | 308           |
| total timesteps         | 43867         |
| value_loss              | 0.00011693016 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.000702082   |
| ent_coef_loss           | 3.2784343     |
| entropy                 | 1.1714993     |
| episodes                | 124           |
| fps                     | 142           |
| mean 100 episode reward | -1.6          |
| n_updates               | 45218         |
| policy_loss             | -0.12440197   |
| qf1_loss                | 0.00019484431 |
| qf2_loss                | 0.00029347147 |
| time_elapsed            | 318           |
| total timesteps         | 45318         |
| value_loss              | 0.00024975586 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00068278343 |
| ent_coef_loss           | 0.5890019     |
| entropy                 | 1.074466      |
| episodes                | 128           |
| fps                     | 142           |
| mean 100 episode reward | -1.6          |
| n_updates               | 46321         |
| policy_loss             | -0.11162709   |
| qf1_loss                | 0.00044302174 |
| qf2_loss                | 0.00020283624 |
| time_elapsed            | 325           |
| total timesteps         | 46421         |
| value_loss              | 0.0009461793  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.000714711   |
| ent_coef_loss           | -3.556504     |
| entropy                 | 0.9849963     |
| episodes                | 132           |
| fps                     | 142           |
| mean 100 episode reward | -1.7          |
| n_updates               | 47982         |
| policy_loss             | -0.11803426   |
| qf1_loss                | 0.00012474043 |
| qf2_loss                | 0.0001955993  |
| time_elapsed            | 336           |
| total timesteps         | 48082         |
| value_loss              | 0.0005278635  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006713137  |
| ent_coef_loss           | -0.55296475   |
| entropy                 | 1.0703044     |
| episodes                | 136           |
| fps                     | 142           |
| mean 100 episode reward | -1.7          |
| n_updates               | 49391         |
| policy_loss             | -0.067031346  |
| qf1_loss                | 0.0013540171  |
| qf2_loss                | 0.0024385543  |
| time_elapsed            | 346           |
| total timesteps         | 49491         |
| value_loss              | 0.00031021688 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00071755244 |
| ent_coef_loss           | -2.9141955    |
| entropy                 | 1.1976178     |
| episodes                | 140           |
| fps                     | 142           |
| mean 100 episode reward | -1.6          |
| n_updates               | 50681         |
| policy_loss             | -0.0318795    |
| qf1_loss                | 9.099684e-05  |
| qf2_loss                | 0.00018942462 |
| time_elapsed            | 355           |
| total timesteps         | 50781         |
| value_loss              | 0.00024340829 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00062737375 |
| ent_coef_loss           | -4.907399     |
| entropy                 | 0.9850745     |
| episodes                | 144           |
| fps                     | 143           |
| mean 100 episode reward | -1.7          |
| n_updates               | 52187         |
| policy_loss             | -0.047356598  |
| qf1_loss                | 0.00023440312 |
| qf2_loss                | 0.00030800787 |
| time_elapsed            | 365           |
| total timesteps         | 52287         |
| value_loss              | 0.0003062751  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00065365585 |
| ent_coef_loss           | 0.49737227    |
| entropy                 | 1.183304      |
| episodes                | 148           |
| fps                     | 143           |
| mean 100 episode reward | -1.7          |
| n_updates               | 53947         |
| policy_loss             | 0.02149126    |
| qf1_loss                | 0.00019144127 |
| qf2_loss                | 7.494952e-05  |
| time_elapsed            | 377           |
| total timesteps         | 54047         |
| value_loss              | 0.00016196615 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006444268  |
| ent_coef_loss           | 2.7730217     |
| entropy                 | 1.28747       |
| episodes                | 152           |
| fps                     | 143           |
| mean 100 episode reward | -1.7          |
| n_updates               | 55153         |
| policy_loss             | 0.06886038    |
| qf1_loss                | 9.103899e-05  |
| qf2_loss                | 7.5531694e-05 |
| time_elapsed            | 385           |
| total timesteps         | 55253         |
| value_loss              | 0.00012166003 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00066305214 |
| ent_coef_loss           | -2.6010647    |
| entropy                 | 1.1418417     |
| episodes                | 156           |
| fps                     | 143           |
| mean 100 episode reward | -1.7          |
| n_updates               | 56731         |
| policy_loss             | 0.02843374    |
| qf1_loss                | 9.9813886e-05 |
| qf2_loss                | 6.3799045e-05 |
| time_elapsed            | 396           |
| total timesteps         | 56831         |
| value_loss              | 0.00017933577 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00071819837 |
| ent_coef_loss           | 0.07930136    |
| entropy                 | 1.3249688     |
| episodes                | 160           |
| fps                     | 143           |
| mean 100 episode reward | -1.7          |
| n_updates               | 58215         |
| policy_loss             | 0.06514406    |
| qf1_loss                | 0.00012219112 |
| qf2_loss                | 9.681398e-05  |
| time_elapsed            | 406           |
| total timesteps         | 58315         |
| value_loss              | 0.00012477674 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00057378766 |
| ent_coef_loss           | 1.9268168     |
| entropy                 | 1.1773578     |
| episodes                | 164           |
| fps                     | 143           |
| mean 100 episode reward | -1.6          |
| n_updates               | 59975         |
| policy_loss             | 0.11431469    |
| qf1_loss                | 0.00011486737 |
| qf2_loss                | 0.000169912   |
| time_elapsed            | 419           |
| total timesteps         | 60075         |
| value_loss              | 0.0002765218  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00065127667 |
| ent_coef_loss           | 1.6652763     |
| entropy                 | 1.1633447     |
| episodes                | 168           |
| fps                     | 143           |
| mean 100 episode reward | -1.7          |
| n_updates               | 61735         |
| policy_loss             | 0.10194905    |
| qf1_loss                | 8.528629e-05  |
| qf2_loss                | 5.423615e-05  |
| time_elapsed            | 431           |
| total timesteps         | 61835         |
| value_loss              | 0.00015897116 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005725512  |
| ent_coef_loss           | -3.104786     |
| entropy                 | 0.94468045    |
| episodes                | 172           |
| fps                     | 143           |
| mean 100 episode reward | -1.7          |
| n_updates               | 62805         |
| policy_loss             | 0.07943854    |
| qf1_loss                | 0.00012575331 |
| qf2_loss                | 6.130249e-05  |
| time_elapsed            | 438           |
| total timesteps         | 62905         |
| value_loss              | 0.00010219974 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00052950793 |
| ent_coef_loss           | -1.8062155    |
| entropy                 | 0.91674095    |
| episodes                | 176           |
| fps                     | 143           |
| mean 100 episode reward | -1.7          |
| n_updates               | 64565         |
| policy_loss             | 0.10033896    |
| qf1_loss                | 4.8374735e-05 |
| qf2_loss                | 5.506963e-05  |
| time_elapsed            | 450           |
| total timesteps         | 64665         |
| value_loss              | 0.0001436466  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00049615244 |
| ent_coef_loss           | 4.402645      |
| entropy                 | 1.0244071     |
| episodes                | 180           |
| fps                     | 143           |
| mean 100 episode reward | -1.7          |
| n_updates               | 66205         |
| policy_loss             | 0.15603648    |
| qf1_loss                | 0.0002965543  |
| qf2_loss                | 0.00023172477 |
| time_elapsed            | 461           |
| total timesteps         | 66305         |
| value_loss              | 0.00033509295 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00055883813 |
| ent_coef_loss           | 3.2569327     |
| entropy                 | 1.1120887     |
| episodes                | 184           |
| fps                     | 143           |
| mean 100 episode reward | -1.7          |
| n_updates               | 67783         |
| policy_loss             | 0.13546252    |
| qf1_loss                | 7.772221e-05  |
| qf2_loss                | 8.823513e-05  |
| time_elapsed            | 472           |
| total timesteps         | 67883         |
| value_loss              | 0.00013366797 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004879084  |
| ent_coef_loss           | -1.9755528    |
| entropy                 | 1.0112386     |
| episodes                | 188           |
| fps                     | 143           |
| mean 100 episode reward | -1.7          |
| n_updates               | 68967         |
| policy_loss             | 0.16831273    |
| qf1_loss                | 7.412436e-05  |
| qf2_loss                | 6.8946276e-05 |
| time_elapsed            | 480           |
| total timesteps         | 69067         |
| value_loss              | 6.1332845e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005455934  |
| ent_coef_loss           | -1.4493332    |
| entropy                 | 1.2735457     |
| episodes                | 192           |
| fps                     | 143           |
| mean 100 episode reward | -1.6          |
| n_updates               | 70727         |
| policy_loss             | 0.19684257    |
| qf1_loss                | 7.494056e-05  |
| qf2_loss                | 8.303626e-05  |
| time_elapsed            | 492           |
| total timesteps         | 70827         |
| value_loss              | 0.00012744855 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005373276  |
| ent_coef_loss           | 2.1711981     |
| entropy                 | 0.84130955    |
| episodes                | 196           |
| fps                     | 143           |
| mean 100 episode reward | -1.6          |
| n_updates               | 72487         |
| policy_loss             | 0.14707938    |
| qf1_loss                | 0.00011398517 |
| qf2_loss                | 7.204464e-05  |
| time_elapsed            | 504           |
| total timesteps         | 72587         |
| value_loss              | 0.00011393405 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00056526595 |
| ent_coef_loss           | 0.1152457     |
| entropy                 | 1.1375141     |
| episodes                | 200           |
| fps                     | 143           |
| mean 100 episode reward | -1.6          |
| n_updates               | 74177         |
| policy_loss             | 0.16354959    |
| qf1_loss                | 0.00011738082 |
| qf2_loss                | 8.4835985e-05 |
| time_elapsed            | 516           |
| total timesteps         | 74277         |
| value_loss              | 0.00013264183 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005230845  |
| ent_coef_loss           | -1.9347641    |
| entropy                 | 0.94458765    |
| episodes                | 204           |
| fps                     | 143           |
| mean 100 episode reward | -1.6          |
| n_updates               | 75725         |
| policy_loss             | 0.17946717    |
| qf1_loss                | 9.504705e-05  |
| qf2_loss                | 6.30535e-05   |
| time_elapsed            | 526           |
| total timesteps         | 75825         |
| value_loss              | 0.00061738153 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005037795  |
| ent_coef_loss           | 1.2435896     |
| entropy                 | 1.0300341     |
| episodes                | 208           |
| fps                     | 143           |
| mean 100 episode reward | -1.7          |
| n_updates               | 77357         |
| policy_loss             | 0.19862331    |
| qf1_loss                | 0.0005812088  |
| qf2_loss                | 0.00076829444 |
| time_elapsed            | 538           |
| total timesteps         | 77457         |
| value_loss              | 0.00015370478 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00044830458 |
| ent_coef_loss           | 0.38401827    |
| entropy                 | 1.0229685     |
| episodes                | 212           |
| fps                     | 144           |
| mean 100 episode reward | -1.6          |
| n_updates               | 79022         |
| policy_loss             | 0.167746      |
| qf1_loss                | 0.00010329996 |
| qf2_loss                | 8.300769e-05  |
| time_elapsed            | 549           |
| total timesteps         | 79122         |
| value_loss              | 0.0002956149  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004610085  |
| ent_coef_loss           | 1.9567083     |
| entropy                 | 0.8696996     |
| episodes                | 216           |
| fps                     | 144           |
| mean 100 episode reward | -1.5          |
| n_updates               | 80712         |
| policy_loss             | 0.18461157    |
| qf1_loss                | 0.0002293523  |
| qf2_loss                | 0.00024748096 |
| time_elapsed            | 560           |
| total timesteps         | 80812         |
| value_loss              | 8.2497034e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00041713935 |
| ent_coef_loss           | -2.4048543    |
| entropy                 | 0.83239436    |
| episodes                | 220           |
| fps                     | 144           |
| mean 100 episode reward | -1.5          |
| n_updates               | 82472         |
| policy_loss             | 0.17036042    |
| qf1_loss                | 7.892793e-05  |
| qf2_loss                | 8.3165316e-05 |
| time_elapsed            | 573           |
| total timesteps         | 82572         |
| value_loss              | 6.50999e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00041205864 |
| ent_coef_loss           | 0.46238828    |
| entropy                 | 0.82116604    |
| episodes                | 224           |
| fps                     | 144           |
| mean 100 episode reward | -1.5          |
| n_updates               | 84232         |
| policy_loss             | 0.17198834    |
| qf1_loss                | 4.138153e-05  |
| qf2_loss                | 7.354813e-05  |
| time_elapsed            | 585           |
| total timesteps         | 84332         |
| value_loss              | 5.549472e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.000400932   |
| ent_coef_loss           | -1.6092218    |
| entropy                 | 0.59999084    |
| episodes                | 228           |
| fps                     | 144           |
| mean 100 episode reward | -1.5          |
| n_updates               | 85794         |
| policy_loss             | 0.18810765    |
| qf1_loss                | 0.00047794313 |
| qf2_loss                | 0.00050908996 |
| time_elapsed            | 596           |
| total timesteps         | 85894         |
| value_loss              | 9.43701e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00042261108 |
| ent_coef_loss           | -2.395611     |
| entropy                 | 0.7440544     |
| episodes                | 232           |
| fps                     | 144           |
| mean 100 episode reward | -1.4          |
| n_updates               | 87554         |
| policy_loss             | 0.16278026    |
| qf1_loss                | 6.473028e-05  |
| qf2_loss                | 4.2564097e-05 |
| time_elapsed            | 608           |
| total timesteps         | 87654         |
| value_loss              | 6.3653366e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004446409  |
| ent_coef_loss           | 0.54412174    |
| entropy                 | 1.0279272     |
| episodes                | 236           |
| fps                     | 144           |
| mean 100 episode reward | -1.4          |
| n_updates               | 89231         |
| policy_loss             | 0.19558863    |
| qf1_loss                | 0.00014962525 |
| qf2_loss                | 6.473827e-05  |
| time_elapsed            | 619           |
| total timesteps         | 89331         |
| value_loss              | 0.00037336044 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.001          |
| ent_coef                | 0.0003966336   |
| ent_coef_loss           | 2.9115894      |
| entropy                 | 0.83450246     |
| episodes                | 240            |
| fps                     | 144            |
| mean 100 episode reward | -1.4           |
| n_updates               | 90938          |
| policy_loss             | 0.21279433     |
| qf1_loss                | 0.00055664487  |
| qf2_loss                | 0.000650891    |
| time_elapsed            | 631            |
| total timesteps         | 91038          |
| value_loss              | 0.000107622946 |
--------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0004185542 |
| ent_coef_loss           | -5.057048    |
| entropy                 | 0.9940242    |
| episodes                | 244          |
| fps                     | 144          |
| mean 100 episode reward | -1.3         |
| n_updates               | 92407        |
| policy_loss             | 0.20168869   |
| qf1_loss                | 7.243018e-05 |
| qf2_loss                | 7.564201e-05 |
| time_elapsed            | 641          |
| total timesteps         | 92507        |
| value_loss              | 0.0001897188 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004064816  |
| ent_coef_loss           | 4.4691234     |
| entropy                 | 0.815028      |
| episodes                | 248           |
| fps                     | 144           |
| mean 100 episode reward | -1.2          |
| n_updates               | 94167         |
| policy_loss             | 0.22364426    |
| qf1_loss                | 0.00018013615 |
| qf2_loss                | 6.523522e-05  |
| time_elapsed            | 653           |
| total timesteps         | 94267         |
| value_loss              | 0.00015337    |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00044544984 |
| ent_coef_loss           | -0.82748866   |
| entropy                 | 0.78550994    |
| episodes                | 252           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 95927         |
| policy_loss             | 0.21620435    |
| qf1_loss                | 0.0004941556  |
| qf2_loss                | 0.00051889714 |
| time_elapsed            | 666           |
| total timesteps         | 96027         |
| value_loss              | 6.111002e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0003764517  |
| ent_coef_loss           | 0.06101924    |
| entropy                 | 0.86591434    |
| episodes                | 256           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 97687         |
| policy_loss             | 0.1964682     |
| qf1_loss                | 2.7094262e-05 |
| qf2_loss                | 3.5374578e-05 |
| time_elapsed            | 678           |
| total timesteps         | 97787         |
| value_loss              | 4.247328e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00038324427 |
| ent_coef_loss           | -2.2457929    |
| entropy                 | 0.8305237     |
| episodes                | 260           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 99100         |
| policy_loss             | 0.19289854    |
| qf1_loss                | 5.3334315e-05 |
| qf2_loss                | 9.9086734e-05 |
| time_elapsed            | 688           |
| total timesteps         | 99200         |
| value_loss              | 8.085526e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00035182343 |
| ent_coef_loss           | -6.510399     |
| entropy                 | 0.8386018     |
| episodes                | 264           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 100513        |
| policy_loss             | 0.16207677    |
| qf1_loss                | 2.5270805e-05 |
| qf2_loss                | 2.4424662e-05 |
| time_elapsed            | 697           |
| total timesteps         | 100613        |
| value_loss              | 6.346307e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00036589502 |
| ent_coef_loss           | -4.3533235    |
| entropy                 | 0.75135803    |
| episodes                | 268           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 102273        |
| policy_loss             | 0.14563316    |
| qf1_loss                | 6.427137e-05  |
| qf2_loss                | 5.231877e-05  |
| time_elapsed            | 709           |
| total timesteps         | 102373        |
| value_loss              | 6.869863e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0003509796  |
| ent_coef_loss           | 4.005928      |
| entropy                 | 0.9577405     |
| episodes                | 272           |
| fps                     | 144           |
| mean 100 episode reward | -1.2          |
| n_updates               | 104033        |
| policy_loss             | 0.20478569    |
| qf1_loss                | 4.358849e-05  |
| qf2_loss                | 6.6013425e-05 |
| time_elapsed            | 721           |
| total timesteps         | 104133        |
| value_loss              | 7.626124e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00035128449 |
| ent_coef_loss           | -2.0605204    |
| entropy                 | 1.0858911     |
| episodes                | 276           |
| fps                     | 144           |
| mean 100 episode reward | -1.2          |
| n_updates               | 105793        |
| policy_loss             | 0.18613744    |
| qf1_loss                | 3.616576e-05  |
| qf2_loss                | 5.44088e-05   |
| time_elapsed            | 733           |
| total timesteps         | 105893        |
| value_loss              | 4.638426e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00031938654 |
| ent_coef_loss           | -1.5317731    |
| entropy                 | 0.6747717     |
| episodes                | 280           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 107430        |
| policy_loss             | 0.17880723    |
| qf1_loss                | 2.4376188e-05 |
| qf2_loss                | 3.8238177e-05 |
| time_elapsed            | 745           |
| total timesteps         | 107530        |
| value_loss              | 4.7799607e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.000341112   |
| ent_coef_loss           | -2.3878498    |
| entropy                 | 0.7927718     |
| episodes                | 284           |
| fps                     | 144           |
| mean 100 episode reward | -1.2          |
| n_updates               | 109190        |
| policy_loss             | 0.19124566    |
| qf1_loss                | 0.00014252552 |
| qf2_loss                | 0.00011839022 |
| time_elapsed            | 757           |
| total timesteps         | 109290        |
| value_loss              | 0.00012057678 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00036747282 |
| ent_coef_loss           | -4.4037404    |
| entropy                 | 0.9277092     |
| episodes                | 288           |
| fps                     | 144           |
| mean 100 episode reward | -1.2          |
| n_updates               | 110666        |
| policy_loss             | 0.1552988     |
| qf1_loss                | 5.7693935e-05 |
| qf2_loss                | 5.3972683e-05 |
| time_elapsed            | 767           |
| total timesteps         | 110766        |
| value_loss              | 3.8014423e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0003622618  |
| ent_coef_loss           | -0.24417913   |
| entropy                 | 0.80513966    |
| episodes                | 292           |
| fps                     | 144           |
| mean 100 episode reward | -1.2          |
| n_updates               | 112242        |
| policy_loss             | 0.13791326    |
| qf1_loss                | 2.7798298e-05 |
| qf2_loss                | 2.2149548e-05 |
| time_elapsed            | 778           |
| total timesteps         | 112342        |
| value_loss              | 4.9306662e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00040026574 |
| ent_coef_loss           | -0.8398676    |
| entropy                 | 0.8677423     |
| episodes                | 296           |
| fps                     | 144           |
| mean 100 episode reward | -1.1          |
| n_updates               | 113737        |
| policy_loss             | 0.16105142    |
| qf1_loss                | 6.390744e-05  |
| qf2_loss                | 3.342831e-05  |
| time_elapsed            | 788           |
| total timesteps         | 113837        |
| value_loss              | 7.650383e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00037210085 |
| ent_coef_loss           | -0.6519234    |
| entropy                 | 0.8393359     |
| episodes                | 300           |
| fps                     | 144           |
| mean 100 episode reward | -1.2          |
| n_updates               | 115272        |
| policy_loss             | 0.16774552    |
| qf1_loss                | 2.7887068e-05 |
| qf2_loss                | 3.934643e-05  |
| time_elapsed            | 798           |
| total timesteps         | 115372        |
| value_loss              | 5.488615e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00036635066 |
| ent_coef_loss           | -1.7971623    |
| entropy                 | 0.81843925    |
| episodes                | 304           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 116760        |
| policy_loss             | 0.17954281    |
| qf1_loss                | 9.950652e-05  |
| qf2_loss                | 0.00015220749 |
| time_elapsed            | 809           |
| total timesteps         | 116860        |
| value_loss              | 9.454544e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00034088027 |
| ent_coef_loss           | -0.50129855   |
| entropy                 | 0.63466686    |
| episodes                | 308           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 118196        |
| policy_loss             | 0.20081133    |
| qf1_loss                | 0.00033005892 |
| qf2_loss                | 0.000276123   |
| time_elapsed            | 819           |
| total timesteps         | 118296        |
| value_loss              | 5.8224105e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0003858201  |
| ent_coef_loss           | -2.793947     |
| entropy                 | 0.80507016    |
| episodes                | 312           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 119956        |
| policy_loss             | 0.17920858    |
| qf1_loss                | 3.110055e-05  |
| qf2_loss                | 3.3416625e-05 |
| time_elapsed            | 831           |
| total timesteps         | 120056        |
| value_loss              | 5.3030453e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00039604586 |
| ent_coef_loss           | 3.0707111     |
| entropy                 | 0.7320871     |
| episodes                | 316           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 121716        |
| policy_loss             | 0.15633418    |
| qf1_loss                | 5.907782e-05  |
| qf2_loss                | 5.0508024e-05 |
| time_elapsed            | 843           |
| total timesteps         | 121816        |
| value_loss              | 6.694954e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0003744925  |
| ent_coef_loss           | -0.5991303    |
| entropy                 | 0.8483495     |
| episodes                | 320           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 123128        |
| policy_loss             | 0.17528294    |
| qf1_loss                | 4.0333543e-05 |
| qf2_loss                | 3.253796e-05  |
| time_elapsed            | 853           |
| total timesteps         | 123228        |
| value_loss              | 5.792919e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.001          |
| ent_coef                | 0.00042167548  |
| ent_coef_loss           | -2.5338        |
| entropy                 | 0.73599774     |
| episodes                | 324            |
| fps                     | 144            |
| mean 100 episode reward | -1.4           |
| n_updates               | 124538         |
| policy_loss             | 0.17388102     |
| qf1_loss                | 6.870443e-05   |
| qf2_loss                | 8.065066e-05   |
| time_elapsed            | 862            |
| total timesteps         | 124638         |
| value_loss              | 0.000100948106 |
--------------------------------------------
--------------------------------------------
| current_lr              | 0.001          |
| ent_coef                | 0.00038459108  |
| ent_coef_loss           | 1.688598       |
| entropy                 | 0.7786528      |
| episodes                | 328            |
| fps                     | 144            |
| mean 100 episode reward | -1.2           |
| n_updates               | 126298         |
| policy_loss             | 0.17045641     |
| qf1_loss                | 0.000110026114 |
| qf2_loss                | 0.00011231533  |
| time_elapsed            | 874            |
| total timesteps         | 126398         |
| value_loss              | 0.00018957887  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00038152887 |
| ent_coef_loss           | -2.5161097    |
| entropy                 | 0.92466795    |
| episodes                | 332           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 127618        |
| policy_loss             | 0.20506439    |
| qf1_loss                | 0.00011670772 |
| qf2_loss                | 9.145341e-05  |
| time_elapsed            | 883           |
| total timesteps         | 127718        |
| value_loss              | 6.868911e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00040724073 |
| ent_coef_loss           | -3.432937     |
| entropy                 | 0.9018372     |
| episodes                | 336           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 129036        |
| policy_loss             | 0.14922784    |
| qf1_loss                | 2.9844483e-05 |
| qf2_loss                | 4.6455556e-05 |
| time_elapsed            | 893           |
| total timesteps         | 129136        |
| value_loss              | 4.2021537e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004048542  |
| ent_coef_loss           | -0.7397429    |
| entropy                 | 0.97363615    |
| episodes                | 340           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 130543        |
| policy_loss             | 0.17481497    |
| qf1_loss                | 0.00049329724 |
| qf2_loss                | 0.00047680203 |
| time_elapsed            | 903           |
| total timesteps         | 130643        |
| value_loss              | 4.479933e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00043816818 |
| ent_coef_loss           | -5.100163     |
| entropy                 | 0.9473842     |
| episodes                | 344           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 132009        |
| policy_loss             | 0.16298883    |
| qf1_loss                | 0.0006192582  |
| qf2_loss                | 0.000620852   |
| time_elapsed            | 913           |
| total timesteps         | 132109        |
| value_loss              | 4.536469e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00041925092 |
| ent_coef_loss           | -1.4292606    |
| entropy                 | 0.8240391     |
| episodes                | 348           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 133769        |
| policy_loss             | 0.1744312     |
| qf1_loss                | 2.680413e-05  |
| qf2_loss                | 3.077466e-05  |
| time_elapsed            | 925           |
| total timesteps         | 133869        |
| value_loss              | 3.1196058e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0003906997  |
| ent_coef_loss           | 1.6700108     |
| entropy                 | 0.9252013     |
| episodes                | 352           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 135529        |
| policy_loss             | 0.20323943    |
| qf1_loss                | 0.00015181667 |
| qf2_loss                | 0.00015554386 |
| time_elapsed            | 938           |
| total timesteps         | 135629        |
| value_loss              | 5.002409e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00048335144 |
| ent_coef_loss           | 1.1855543     |
| entropy                 | 1.1859472     |
| episodes                | 356           |
| fps                     | 144           |
| mean 100 episode reward | -1.4          |
| n_updates               | 137289        |
| policy_loss             | 0.19193195    |
| qf1_loss                | 8.659827e-05  |
| qf2_loss                | 6.1256316e-05 |
| time_elapsed            | 950           |
| total timesteps         | 137389        |
| value_loss              | 9.89181e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00051661656 |
| ent_coef_loss           | -4.898699     |
| entropy                 | 1.070554      |
| episodes                | 360           |
| fps                     | 144           |
| mean 100 episode reward | -1.4          |
| n_updates               | 138468        |
| policy_loss             | 0.18646331    |
| qf1_loss                | 3.8344886e-05 |
| qf2_loss                | 3.495057e-05  |
| time_elapsed            | 958           |
| total timesteps         | 138568        |
| value_loss              | 3.0723124e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004986176  |
| ent_coef_loss           | -1.3534977    |
| entropy                 | 1.0463444     |
| episodes                | 364           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 140228        |
| policy_loss             | 0.17549315    |
| qf1_loss                | 6.249084e-05  |
| qf2_loss                | 5.5456854e-05 |
| time_elapsed            | 970           |
| total timesteps         | 140328        |
| value_loss              | 0.00010823364 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.001          |
| ent_coef                | 0.00046387798  |
| ent_coef_loss           | 4.3545613      |
| entropy                 | 1.235175       |
| episodes                | 368            |
| fps                     | 144            |
| mean 100 episode reward | -1.3           |
| n_updates               | 141745         |
| policy_loss             | 0.19691661     |
| qf1_loss                | 6.35179e-05    |
| qf2_loss                | 5.5069282e-05  |
| time_elapsed            | 980            |
| total timesteps         | 141845         |
| value_loss              | 0.000107181935 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004605864  |
| ent_coef_loss           | -0.6566209    |
| entropy                 | 0.97025007    |
| episodes                | 372           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 143035        |
| policy_loss             | 0.1413621     |
| qf1_loss                | 5.1263014e-05 |
| qf2_loss                | 2.9604296e-05 |
| time_elapsed            | 989           |
| total timesteps         | 143135        |
| value_loss              | 5.9784983e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00050477305 |
| ent_coef_loss           | -4.7952595    |
| entropy                 | 0.90105104    |
| episodes                | 376           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 144795        |
| policy_loss             | 0.20227322    |
| qf1_loss                | 8.277962e-05  |
| qf2_loss                | 8.076693e-05  |
| time_elapsed            | 1001          |
| total timesteps         | 144895        |
| value_loss              | 0.00011028525 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004971137  |
| ent_coef_loss           | -0.42014414   |
| entropy                 | 0.8956696     |
| episodes                | 380           |
| fps                     | 144           |
| mean 100 episode reward | -1.2          |
| n_updates               | 146188        |
| policy_loss             | 0.20231402    |
| qf1_loss                | 4.5609304e-05 |
| qf2_loss                | 3.8935807e-05 |
| time_elapsed            | 1010          |
| total timesteps         | 146288        |
| value_loss              | 6.3090825e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005258048  |
| ent_coef_loss           | 6.2135696     |
| entropy                 | 1.1333584     |
| episodes                | 384           |
| fps                     | 144           |
| mean 100 episode reward | -1.2          |
| n_updates               | 147445        |
| policy_loss             | 0.20492886    |
| qf1_loss                | 5.967604e-05  |
| qf2_loss                | 5.4845084e-05 |
| time_elapsed            | 1019          |
| total timesteps         | 147545        |
| value_loss              | 6.6587534e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006001464  |
| ent_coef_loss           | -3.4036222    |
| entropy                 | 0.95193017    |
| episodes                | 388           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 148855        |
| policy_loss             | 0.16838449    |
| qf1_loss                | 6.212919e-05  |
| qf2_loss                | 4.6077046e-05 |
| time_elapsed            | 1028          |
| total timesteps         | 148955        |
| value_loss              | 6.608299e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00060855417 |
| ent_coef_loss           | 0.11025524    |
| entropy                 | 0.9841174     |
| episodes                | 392           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 150615        |
| policy_loss             | 0.16855198    |
| qf1_loss                | 0.00012139296 |
| qf2_loss                | 0.00017211164 |
| time_elapsed            | 1041          |
| total timesteps         | 150715        |
| value_loss              | 0.00029820978 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006311713  |
| ent_coef_loss           | -1.778544     |
| entropy                 | 1.0796728     |
| episodes                | 396           |
| fps                     | 144           |
| mean 100 episode reward | -1.4          |
| n_updates               | 152278        |
| policy_loss             | 0.16409129    |
| qf1_loss                | 7.807847e-05  |
| qf2_loss                | 4.2675085e-05 |
| time_elapsed            | 1052          |
| total timesteps         | 152378        |
| value_loss              | 0.0002207523  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005799014  |
| ent_coef_loss           | -1.2877634    |
| entropy                 | 0.8829951     |
| episodes                | 400           |
| fps                     | 144           |
| mean 100 episode reward | -1.4          |
| n_updates               | 153922        |
| policy_loss             | 0.17585206    |
| qf1_loss                | 6.175866e-05  |
| qf2_loss                | 5.5104058e-05 |
| time_elapsed            | 1064          |
| total timesteps         | 154022        |
| value_loss              | 7.050343e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00059724797 |
| ent_coef_loss           | -1.2075863    |
| entropy                 | 1.0589373     |
| episodes                | 404           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 155240        |
| policy_loss             | 0.170847      |
| qf1_loss                | 4.4439897e-05 |
| qf2_loss                | 3.2068667e-05 |
| time_elapsed            | 1073          |
| total timesteps         | 155340        |
| value_loss              | 5.6044595e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00062677957 |
| ent_coef_loss           | -1.2427382    |
| entropy                 | 1.085461      |
| episodes                | 408           |
| fps                     | 144           |
| mean 100 episode reward | -1.4          |
| n_updates               | 156899        |
| policy_loss             | 0.15974113    |
| qf1_loss                | 3.4708588e-05 |
| qf2_loss                | 7.916345e-05  |
| time_elapsed            | 1084          |
| total timesteps         | 156999        |
| value_loss              | 6.819391e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005576817  |
| ent_coef_loss           | 0.046416163   |
| entropy                 | 0.96400094    |
| episodes                | 412           |
| fps                     | 144           |
| mean 100 episode reward | -1.4          |
| n_updates               | 158484        |
| policy_loss             | 0.16337095    |
| qf1_loss                | 9.0256784e-05 |
| qf2_loss                | 5.903896e-05  |
| time_elapsed            | 1095          |
| total timesteps         | 158584        |
| value_loss              | 0.00016330347 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00063122006 |
| ent_coef_loss           | 0.6189021     |
| entropy                 | 1.1485041     |
| episodes                | 416           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 159937        |
| policy_loss             | 0.17322695    |
| qf1_loss                | 9.720611e-05  |
| qf2_loss                | 5.9450424e-05 |
| time_elapsed            | 1105          |
| total timesteps         | 160037        |
| value_loss              | 0.00012753817 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.000613423   |
| ent_coef_loss           | 0.3269295     |
| entropy                 | 1.1320534     |
| episodes                | 420           |
| fps                     | 144           |
| mean 100 episode reward | -1.4          |
| n_updates               | 161697        |
| policy_loss             | 0.17342904    |
| qf1_loss                | 7.8739155e-05 |
| qf2_loss                | 5.7134923e-05 |
| time_elapsed            | 1117          |
| total timesteps         | 161797        |
| value_loss              | 0.00014175483 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00067388784 |
| ent_coef_loss           | 0.67973566    |
| entropy                 | 1.2019801     |
| episodes                | 424           |
| fps                     | 144           |
| mean 100 episode reward | -1.4          |
| n_updates               | 162745        |
| policy_loss             | 0.19097894    |
| qf1_loss                | 9.731004e-05  |
| qf2_loss                | 6.014608e-05  |
| time_elapsed            | 1124          |
| total timesteps         | 162845        |
| value_loss              | 9.388659e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006666904  |
| ent_coef_loss           | 0.23781979    |
| entropy                 | 1.2026496     |
| episodes                | 428           |
| fps                     | 144           |
| mean 100 episode reward | -1.4          |
| n_updates               | 164228        |
| policy_loss             | 0.17766333    |
| qf1_loss                | 7.301985e-05  |
| qf2_loss                | 0.00010379075 |
| time_elapsed            | 1135          |
| total timesteps         | 164328        |
| value_loss              | 0.00013552967 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00060909556 |
| ent_coef_loss           | -1.5984869    |
| entropy                 | 1.0743452     |
| episodes                | 432           |
| fps                     | 144           |
| mean 100 episode reward | -1.4          |
| n_updates               | 165988        |
| policy_loss             | 0.19105679    |
| qf1_loss                | 5.4378794e-05 |
| qf2_loss                | 0.00011765631 |
| time_elapsed            | 1150          |
| total timesteps         | 166088        |
| value_loss              | 0.00012127744 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006319094  |
| ent_coef_loss           | 0.68215954    |
| entropy                 | 1.0708172     |
| episodes                | 436           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 167748        |
| policy_loss             | 0.15039665    |
| qf1_loss                | 4.7957794e-05 |
| qf2_loss                | 0.00011195084 |
| time_elapsed            | 1163          |
| total timesteps         | 167848        |
| value_loss              | 0.00022331551 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0006707068 |
| ent_coef_loss           | -2.494857    |
| entropy                 | 1.0785186    |
| episodes                | 440          |
| fps                     | 144          |
| mean 100 episode reward | -1.3         |
| n_updates               | 169508       |
| policy_loss             | 0.15890032   |
| qf1_loss                | 7.979662e-05 |
| qf2_loss                | 6.554247e-05 |
| time_elapsed            | 1175         |
| total timesteps         | 169608       |
| value_loss              | 7.260416e-05 |
------------------------------------------
--------------------------------------------
| current_lr              | 0.001          |
| ent_coef                | 0.00061724446  |
| ent_coef_loss           | 0.6737586      |
| entropy                 | 1.0969226      |
| episodes                | 444            |
| fps                     | 144            |
| mean 100 episode reward | -1.3           |
| n_updates               | 170973         |
| policy_loss             | 0.17557481     |
| qf1_loss                | 0.000111317684 |
| qf2_loss                | 0.00011631049  |
| time_elapsed            | 1185           |
| total timesteps         | 171073         |
| value_loss              | 0.00012525056  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006672225  |
| ent_coef_loss           | -2.597883     |
| entropy                 | 1.0634193     |
| episodes                | 448           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 172733        |
| policy_loss             | 0.10847183    |
| qf1_loss                | 6.9824295e-05 |
| qf2_loss                | 4.6304485e-05 |
| time_elapsed            | 1198          |
| total timesteps         | 172833        |
| value_loss              | 0.00021849044 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006432515  |
| ent_coef_loss           | -0.07097739   |
| entropy                 | 1.0734177     |
| episodes                | 452           |
| fps                     | 144           |
| mean 100 episode reward | -1.4          |
| n_updates               | 174183        |
| policy_loss             | 0.124910206   |
| qf1_loss                | 0.00031588925 |
| qf2_loss                | 0.00025930878 |
| time_elapsed            | 1207          |
| total timesteps         | 174283        |
| value_loss              | 0.0002617122  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00070707686 |
| ent_coef_loss           | -2.555354     |
| entropy                 | 1.1046019     |
| episodes                | 456           |
| fps                     | 144           |
| mean 100 episode reward | -1.4          |
| n_updates               | 175745        |
| policy_loss             | 0.14947118    |
| qf1_loss                | 8.4564745e-05 |
| qf2_loss                | 9.306178e-05  |
| time_elapsed            | 1218          |
| total timesteps         | 175845        |
| value_loss              | 0.00016139685 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0008258635  |
| ent_coef_loss           | 2.0879657     |
| entropy                 | 1.1602529     |
| episodes                | 460           |
| fps                     | 144           |
| mean 100 episode reward | -1.4          |
| n_updates               | 177505        |
| policy_loss             | 0.16977552    |
| qf1_loss                | 0.00020531408 |
| qf2_loss                | 0.00014301896 |
| time_elapsed            | 1230          |
| total timesteps         | 177605        |
| value_loss              | 0.00020462296 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00077124365 |
| ent_coef_loss           | -1.5305245    |
| entropy                 | 1.1687089     |
| episodes                | 464           |
| fps                     | 144           |
| mean 100 episode reward | -1.4          |
| n_updates               | 179101        |
| policy_loss             | 0.19236656    |
| qf1_loss                | 0.0019358211  |
| qf2_loss                | 0.0014746634  |
| time_elapsed            | 1241          |
| total timesteps         | 179201        |
| value_loss              | 0.00013928732 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.001          |
| ent_coef                | 0.00071814185  |
| ent_coef_loss           | -2.9016159     |
| entropy                 | 1.0485872      |
| episodes                | 468            |
| fps                     | 144            |
| mean 100 episode reward | -1.4           |
| n_updates               | 180601         |
| policy_loss             | 0.15154576     |
| qf1_loss                | 5.660925e-05   |
| qf2_loss                | 8.348951e-05   |
| time_elapsed            | 1252           |
| total timesteps         | 180701         |
| value_loss              | 0.000104389794 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00074574305 |
| ent_coef_loss           | 3.7255826     |
| entropy                 | 1.0735673     |
| episodes                | 472           |
| fps                     | 144           |
| mean 100 episode reward | -1.4          |
| n_updates               | 182316        |
| policy_loss             | 0.16926008    |
| qf1_loss                | 0.0003031345  |
| qf2_loss                | 0.00032934896 |
| time_elapsed            | 1263          |
| total timesteps         | 182416        |
| value_loss              | 0.00017327265 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0007720071  |
| ent_coef_loss           | 0.41316915    |
| entropy                 | 1.1755815     |
| episodes                | 476           |
| fps                     | 144           |
| mean 100 episode reward | -1.4          |
| n_updates               | 183966        |
| policy_loss             | 0.14700985    |
| qf1_loss                | 0.00012850904 |
| qf2_loss                | 8.862993e-05  |
| time_elapsed            | 1275          |
| total timesteps         | 184066        |
| value_loss              | 0.00016022302 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.000746539   |
| ent_coef_loss           | -0.55968606   |
| entropy                 | 1.1304393     |
| episodes                | 480           |
| fps                     | 144           |
| mean 100 episode reward | -1.4          |
| n_updates               | 185726        |
| policy_loss             | 0.1012745     |
| qf1_loss                | 0.00012862905 |
| qf2_loss                | 0.0001382055  |
| time_elapsed            | 1287          |
| total timesteps         | 185826        |
| value_loss              | 0.0003819438  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0008680716  |
| ent_coef_loss           | 2.6144109     |
| entropy                 | 1.1174068     |
| episodes                | 484           |
| fps                     | 144           |
| mean 100 episode reward | -1.4          |
| n_updates               | 186966        |
| policy_loss             | 0.155972      |
| qf1_loss                | 0.0001976066  |
| qf2_loss                | 0.00014853051 |
| time_elapsed            | 1295          |
| total timesteps         | 187066        |
| value_loss              | 0.00023906554 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00082098343 |
| ent_coef_loss           | -0.51818323   |
| entropy                 | 1.1563953     |
| episodes                | 488           |
| fps                     | 144           |
| mean 100 episode reward | -1.5          |
| n_updates               | 188106        |
| policy_loss             | 0.1161536     |
| qf1_loss                | 0.00016095204 |
| qf2_loss                | 0.00017051277 |
| time_elapsed            | 1303          |
| total timesteps         | 188206        |
| value_loss              | 0.00016666467 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00084621867 |
| ent_coef_loss           | -3.1958032    |
| entropy                 | 1.1818619     |
| episodes                | 492           |
| fps                     | 144           |
| mean 100 episode reward | -1.5          |
| n_updates               | 189866        |
| policy_loss             | 0.12839344    |
| qf1_loss                | 0.0001459526  |
| qf2_loss                | 0.00015412798 |
| time_elapsed            | 1315          |
| total timesteps         | 189966        |
| value_loss              | 0.00046226557 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0008621956  |
| ent_coef_loss           | 1.1132824     |
| entropy                 | 1.2332542     |
| episodes                | 496           |
| fps                     | 144           |
| mean 100 episode reward | -1.4          |
| n_updates               | 191374        |
| policy_loss             | 0.20408626    |
| qf1_loss                | 0.00025444926 |
| qf2_loss                | 0.00017381311 |
| time_elapsed            | 1325          |
| total timesteps         | 191474        |
| value_loss              | 0.00031510025 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0009208684  |
| ent_coef_loss           | 0.8800494     |
| entropy                 | 1.2609923     |
| episodes                | 500           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 192814        |
| policy_loss             | 0.19957651    |
| qf1_loss                | 0.00010116123 |
| qf2_loss                | 0.00021399639 |
| time_elapsed            | 1335          |
| total timesteps         | 192914        |
| value_loss              | 0.0001398588  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0008745826  |
| ent_coef_loss           | 1.1072668     |
| entropy                 | 0.99760807    |
| episodes                | 504           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 194574        |
| policy_loss             | 0.14041017    |
| qf1_loss                | 0.00016387412 |
| qf2_loss                | 0.0002552999  |
| time_elapsed            | 1347          |
| total timesteps         | 194674        |
| value_loss              | 0.00014284105 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00087902904 |
| ent_coef_loss           | -0.6757546    |
| entropy                 | 1.1344721     |
| episodes                | 508           |
| fps                     | 144           |
| mean 100 episode reward | -1.3          |
| n_updates               | 196098        |
| policy_loss             | 0.09792984    |
| qf1_loss                | 0.0001308886  |
| qf2_loss                | 0.0001785394  |
| time_elapsed            | 1358          |
| total timesteps         | 196198        |
| value_loss              | 0.00012166059 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0008641684  |
| ent_coef_loss           | -5.0824556    |
| entropy                 | 1.2421958     |
| episodes                | 512           |
| fps                     | 144           |
| mean 100 episode reward | -1.2          |
| n_updates               | 197341        |
| policy_loss             | 0.18910432    |
| qf1_loss                | 9.3368435e-05 |
| qf2_loss                | 0.00018064422 |
| time_elapsed            | 1366          |
| total timesteps         | 197441        |
| value_loss              | 0.00013721347 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0009051606  |
| ent_coef_loss           | 4.306715      |
| entropy                 | 1.2028568     |
| episodes                | 516           |
| fps                     | 144           |
| mean 100 episode reward | -1.2          |
| n_updates               | 198985        |
| policy_loss             | 0.12872027    |
| qf1_loss                | 0.000393951   |
| qf2_loss                | 0.0005264417  |
| time_elapsed            | 1377          |
| total timesteps         | 199085        |
| value_loss              | 0.00018731602 |
-------------------------------------------
>>>>> End testing <<<<< energy:_-0.005__slack:_-0.0005
Final weights saved at:  /home/patrick/tensorboard_logs/sac_energy:_-0.005__slack:_-0.0005/stable_baselines.pkl
TEST COMMAND: python3 py3_learning.py --test --weights  /home/patrick/tensorboard_logs/sac_energy:_-0.005__slack:_-0.0005/stable_baselines.pkl
Starting test with params: {'energy': -0.01, 'slack': -0.0005}
Namespace(draw_screen=False, env_config='configs/env.config', policy='multi_human_rl', policy_config='configs/policy.config', test=False, train_config='configs/train.config', weights=None)
Gym environment created.
COLLISION PENALTY -0.25
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.31712592  |
| ent_coef_loss           | -3.8482435  |
| entropy                 | 2.5668917   |
| episodes                | 4           |
| fps                     | 153         |
| mean 100 episode reward | -0.6        |
| n_updates               | 1149        |
| policy_loss             | -3.690627   |
| qf1_loss                | 0.04812919  |
| qf2_loss                | 0.04834473  |
| time_elapsed            | 8           |
| total timesteps         | 1249        |
| value_loss              | 0.008265604 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.06783449   |
| ent_coef_loss           | -8.998077    |
| entropy                 | 2.6079144    |
| episodes                | 8            |
| fps                     | 148          |
| mean 100 episode reward | -1.1         |
| n_updates               | 2704         |
| policy_loss             | -4.6451035   |
| qf1_loss                | 0.0009455554 |
| qf2_loss                | 0.0011033711 |
| time_elapsed            | 18           |
| total timesteps         | 2804         |
| value_loss              | 0.0026609155 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.02160846   |
| ent_coef_loss           | -10.289181   |
| entropy                 | 2.2669463    |
| episodes                | 12           |
| fps                     | 145          |
| mean 100 episode reward | -1.2         |
| n_updates               | 3913         |
| policy_loss             | -4.677044    |
| qf1_loss                | 0.0025480213 |
| qf2_loss                | 0.0017172294 |
| time_elapsed            | 27           |
| total timesteps         | 4013         |
| value_loss              | 0.0033890693 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0061394335 |
| ent_coef_loss           | -5.5125866   |
| entropy                 | 2.042584     |
| episodes                | 16           |
| fps                     | 145          |
| mean 100 episode reward | -1.2         |
| n_updates               | 5662         |
| policy_loss             | -4.2353506   |
| qf1_loss                | 0.0032888087 |
| qf2_loss                | 0.002321398  |
| time_elapsed            | 39           |
| total timesteps         | 5762         |
| value_loss              | 0.0070719896 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0041412516 |
| ent_coef_loss           | -0.9523737   |
| entropy                 | 1.70591      |
| episodes                | 20           |
| fps                     | 144          |
| mean 100 episode reward | -1.2         |
| n_updates               | 7368         |
| policy_loss             | -4.013288    |
| qf1_loss                | 0.0849484    |
| qf2_loss                | 0.08042796   |
| time_elapsed            | 51           |
| total timesteps         | 7468         |
| value_loss              | 0.004197792  |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0037463144 |
| ent_coef_loss           | -2.4081054   |
| entropy                 | 1.4145155    |
| episodes                | 24           |
| fps                     | 143          |
| mean 100 episode reward | -1.4         |
| n_updates               | 9128         |
| policy_loss             | -3.527287    |
| qf1_loss                | 0.001067087  |
| qf2_loss                | 0.0019076089 |
| time_elapsed            | 64           |
| total timesteps         | 9228         |
| value_loss              | 0.0010238021 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0032434885 |
| ent_coef_loss           | -1.0461587   |
| entropy                 | 1.1573868    |
| episodes                | 28           |
| fps                     | 142          |
| mean 100 episode reward | -1.6         |
| n_updates               | 10888        |
| policy_loss             | -3.2087922   |
| qf1_loss                | 0.0011659474 |
| qf2_loss                | 0.0012822065 |
| time_elapsed            | 76           |
| total timesteps         | 10988        |
| value_loss              | 0.0020162617 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0026838866 |
| ent_coef_loss           | 1.0532522    |
| entropy                 | 1.1076584    |
| episodes                | 32           |
| fps                     | 143          |
| mean 100 episode reward | -1.6         |
| n_updates               | 12195        |
| policy_loss             | -2.9209137   |
| qf1_loss                | 0.0005906413 |
| qf2_loss                | 0.0005975788 |
| time_elapsed            | 85           |
| total timesteps         | 12295        |
| value_loss              | 0.001568798  |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0020352078 |
| ent_coef_loss           | -1.2020434   |
| entropy                 | 0.75233674   |
| episodes                | 36           |
| fps                     | 142          |
| mean 100 episode reward | -1.6         |
| n_updates               | 13945        |
| policy_loss             | -2.4371603   |
| qf1_loss                | 0.0014323177 |
| qf2_loss                | 0.0014642393 |
| time_elapsed            | 98           |
| total timesteps         | 14045        |
| value_loss              | 0.0018874253 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.001737881  |
| ent_coef_loss           | 1.6578388    |
| entropy                 | 0.57670224   |
| episodes                | 40           |
| fps                     | 142          |
| mean 100 episode reward | -1.6         |
| n_updates               | 15100        |
| policy_loss             | -2.5333571   |
| qf1_loss                | 0.027985144  |
| qf2_loss                | 0.028326616  |
| time_elapsed            | 106          |
| total timesteps         | 15200        |
| value_loss              | 0.0014448385 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0017904807  |
| ent_coef_loss           | -0.9789969    |
| entropy                 | 0.8556709     |
| episodes                | 44            |
| fps                     | 143           |
| mean 100 episode reward | -1.5          |
| n_updates               | 16860         |
| policy_loss             | -2.2543588    |
| qf1_loss                | 0.00042922236 |
| qf2_loss                | 0.00081525824 |
| time_elapsed            | 118           |
| total timesteps         | 16960         |
| value_loss              | 0.0012488592  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0021042917 |
| ent_coef_loss           | -0.4755733   |
| entropy                 | 0.76832706   |
| episodes                | 48           |
| fps                     | 142          |
| mean 100 episode reward | -1.4         |
| n_updates               | 18620        |
| policy_loss             | -2.0334225   |
| qf1_loss                | 0.015974993  |
| qf2_loss                | 0.014980737  |
| time_elapsed            | 131          |
| total timesteps         | 18720        |
| value_loss              | 0.0018558949 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0020014804 |
| ent_coef_loss           | -1.2750247   |
| entropy                 | 1.1733242    |
| episodes                | 52           |
| fps                     | 142          |
| mean 100 episode reward | -1.3         |
| n_updates               | 20380        |
| policy_loss             | -1.864907    |
| qf1_loss                | 0.0004663276 |
| qf2_loss                | 0.0007743992 |
| time_elapsed            | 143          |
| total timesteps         | 20480        |
| value_loss              | 0.001093141  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0018648645  |
| ent_coef_loss           | 5.1947527     |
| entropy                 | 0.70230985    |
| episodes                | 56            |
| fps                     | 142           |
| mean 100 episode reward | -1.2          |
| n_updates               | 22140         |
| policy_loss             | -1.7436321    |
| qf1_loss                | 0.00043811544 |
| qf2_loss                | 0.0008427303  |
| time_elapsed            | 156           |
| total timesteps         | 22240         |
| value_loss              | 0.0010243793  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0019990646  |
| ent_coef_loss           | -0.55641127   |
| entropy                 | 0.73054165    |
| episodes                | 60            |
| fps                     | 141           |
| mean 100 episode reward | -1.2          |
| n_updates               | 23647         |
| policy_loss             | -1.5469398    |
| qf1_loss                | 0.00074860913 |
| qf2_loss                | 0.00056543795 |
| time_elapsed            | 167           |
| total timesteps         | 23747         |
| value_loss              | 0.0006438942  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0024444466 |
| ent_coef_loss           | -0.23543894  |
| entropy                 | 0.83468294   |
| episodes                | 64           |
| fps                     | 141          |
| mean 100 episode reward | -1.1         |
| n_updates               | 25407        |
| policy_loss             | -1.4662224   |
| qf1_loss                | 0.010908248  |
| qf2_loss                | 0.010267555  |
| time_elapsed            | 180          |
| total timesteps         | 25507        |
| value_loss              | 0.0010105905 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0022322773  |
| ent_coef_loss           | 2.0301008     |
| entropy                 | 0.9297477     |
| episodes                | 68            |
| fps                     | 141           |
| mean 100 episode reward | -1.1          |
| n_updates               | 27167         |
| policy_loss             | -1.3651015    |
| qf1_loss                | 0.0008617533  |
| qf2_loss                | 0.00070115144 |
| time_elapsed            | 193           |
| total timesteps         | 27267         |
| value_loss              | 0.0010919338  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.002660519   |
| ent_coef_loss           | -0.11989242   |
| entropy                 | 1.2474849     |
| episodes                | 72            |
| fps                     | 140           |
| mean 100 episode reward | -1.1          |
| n_updates               | 28927         |
| policy_loss             | -1.1295788    |
| qf1_loss                | 0.0005438222  |
| qf2_loss                | 0.0006156015  |
| time_elapsed            | 206           |
| total timesteps         | 29027         |
| value_loss              | 0.00062625774 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0021518434 |
| ent_coef_loss           | 1.7445202    |
| entropy                 | 0.86454415   |
| episodes                | 76           |
| fps                     | 141          |
| mean 100 episode reward | -1.1         |
| n_updates               | 30350        |
| policy_loss             | -1.0180521   |
| qf1_loss                | 0.011714158  |
| qf2_loss                | 0.012045158  |
| time_elapsed            | 215          |
| total timesteps         | 30450        |
| value_loss              | 0.002764279  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0018992723  |
| ent_coef_loss           | 1.5099535     |
| entropy                 | 0.9395722     |
| episodes                | 80            |
| fps                     | 141           |
| mean 100 episode reward | -1.1          |
| n_updates               | 32110         |
| policy_loss             | -0.88010955   |
| qf1_loss                | 0.00019775485 |
| qf2_loss                | 0.0002830827  |
| time_elapsed            | 228           |
| total timesteps         | 32210         |
| value_loss              | 0.00062883494 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.001865472   |
| ent_coef_loss           | -2.5496192    |
| entropy                 | 1.0748658     |
| episodes                | 84            |
| fps                     | 141           |
| mean 100 episode reward | -1.1          |
| n_updates               | 33870         |
| policy_loss             | -0.9468343    |
| qf1_loss                | 0.0034401359  |
| qf2_loss                | 0.004478755   |
| time_elapsed            | 240           |
| total timesteps         | 33970         |
| value_loss              | 0.00060410297 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.001856149   |
| ent_coef_loss           | 2.6240907     |
| entropy                 | 1.0959504     |
| episodes                | 88            |
| fps                     | 141           |
| mean 100 episode reward | -1.1          |
| n_updates               | 35630         |
| policy_loss             | -0.73313177   |
| qf1_loss                | 0.00019994593 |
| qf2_loss                | 0.00020867761 |
| time_elapsed            | 253           |
| total timesteps         | 35730         |
| value_loss              | 0.0003661056  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.001430176   |
| ent_coef_loss           | 1.5416168     |
| entropy                 | 0.9699701     |
| episodes                | 92            |
| fps                     | 141           |
| mean 100 episode reward | -1.1          |
| n_updates               | 37390         |
| policy_loss             | -0.656765     |
| qf1_loss                | 0.000396949   |
| qf2_loss                | 0.00040931333 |
| time_elapsed            | 265           |
| total timesteps         | 37490         |
| value_loss              | 0.0017520611  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0014902762  |
| ent_coef_loss           | -1.7040912    |
| entropy                 | 1.1333178     |
| episodes                | 96            |
| fps                     | 141           |
| mean 100 episode reward | -1.2          |
| n_updates               | 38768         |
| policy_loss             | -0.65308416   |
| qf1_loss                | 0.00052764174 |
| qf2_loss                | 0.00040404114 |
| time_elapsed            | 274           |
| total timesteps         | 38868         |
| value_loss              | 0.0011316071  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0014505412  |
| ent_coef_loss           | -3.7941842    |
| entropy                 | 1.3186954     |
| episodes                | 100           |
| fps                     | 141           |
| mean 100 episode reward | -1.2          |
| n_updates               | 40459         |
| policy_loss             | -0.5557924    |
| qf1_loss                | 0.0004115834  |
| qf2_loss                | 0.00030108244 |
| time_elapsed            | 286           |
| total timesteps         | 40559         |
| value_loss              | 0.0010641904  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.001175746   |
| ent_coef_loss           | -2.1647568    |
| entropy                 | 1.1458242     |
| episodes                | 104           |
| fps                     | 141           |
| mean 100 episode reward | -1.2          |
| n_updates               | 41919         |
| policy_loss             | -0.43394917   |
| qf1_loss                | 0.00033924423 |
| qf2_loss                | 0.00030961825 |
| time_elapsed            | 297           |
| total timesteps         | 42019         |
| value_loss              | 0.0004272327  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0010281949  |
| ent_coef_loss           | -1.7847688    |
| entropy                 | 1.1570511     |
| episodes                | 108           |
| fps                     | 141           |
| mean 100 episode reward | -1.2          |
| n_updates               | 43679         |
| policy_loss             | -0.36490345   |
| qf1_loss                | 0.0018839033  |
| qf2_loss                | 0.0018083069  |
| time_elapsed            | 309           |
| total timesteps         | 43779         |
| value_loss              | 0.00029473915 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0010590492  |
| ent_coef_loss           | 2.4665072     |
| entropy                 | 1.3061528     |
| episodes                | 112           |
| fps                     | 141           |
| mean 100 episode reward | -1.2          |
| n_updates               | 45439         |
| policy_loss             | -0.36748862   |
| qf1_loss                | 0.00010177088 |
| qf2_loss                | 0.00018798064 |
| time_elapsed            | 322           |
| total timesteps         | 45539         |
| value_loss              | 0.0003500642  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.001054239   |
| ent_coef_loss           | -2.7744343    |
| entropy                 | 1.2554953     |
| episodes                | 116           |
| fps                     | 140           |
| mean 100 episode reward | -1.2          |
| n_updates               | 47031         |
| policy_loss             | -0.26943934   |
| qf1_loss                | 4.8378486e-05 |
| qf2_loss                | 8.132051e-05  |
| time_elapsed            | 334           |
| total timesteps         | 47131         |
| value_loss              | 0.00020712372 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0007964316  |
| ent_coef_loss           | -0.95119166   |
| entropy                 | 1.0737337     |
| episodes                | 120           |
| fps                     | 140           |
| mean 100 episode reward | -1.2          |
| n_updates               | 48663         |
| policy_loss             | -0.2855353    |
| qf1_loss                | 0.00013626658 |
| qf2_loss                | 0.00020679872 |
| time_elapsed            | 346           |
| total timesteps         | 48763         |
| value_loss              | 0.00045270502 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00077868334 |
| ent_coef_loss           | -2.4013567    |
| entropy                 | 1.0863008     |
| episodes                | 124           |
| fps                     | 140           |
| mean 100 episode reward | -1.2          |
| n_updates               | 50423         |
| policy_loss             | -0.25492114   |
| qf1_loss                | 9.885653e-05  |
| qf2_loss                | 6.0288967e-05 |
| time_elapsed            | 359           |
| total timesteps         | 50523         |
| value_loss              | 0.00016875043 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.001          |
| ent_coef                | 0.00084417977  |
| ent_coef_loss           | -1.1579784     |
| entropy                 | 1.3770026      |
| episodes                | 128            |
| fps                     | 140            |
| mean 100 episode reward | -1.1           |
| n_updates               | 52096          |
| policy_loss             | -0.14799628    |
| qf1_loss                | 0.000102544705 |
| qf2_loss                | 0.00014036444  |
| time_elapsed            | 370            |
| total timesteps         | 52196          |
| value_loss              | 0.00035478536  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0008055957  |
| ent_coef_loss           | -2.755306     |
| entropy                 | 1.2839141     |
| episodes                | 132           |
| fps                     | 140           |
| mean 100 episode reward | -1.1          |
| n_updates               | 53626         |
| policy_loss             | -0.14313968   |
| qf1_loss                | 7.640517e-05  |
| qf2_loss                | 5.823209e-05  |
| time_elapsed            | 382           |
| total timesteps         | 53726         |
| value_loss              | 0.00018275896 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0008042884  |
| ent_coef_loss           | -3.396214     |
| entropy                 | 1.3248887     |
| episodes                | 136           |
| fps                     | 140           |
| mean 100 episode reward | -1            |
| n_updates               | 55351         |
| policy_loss             | -0.13460048   |
| qf1_loss                | 0.00014557524 |
| qf2_loss                | 0.00015194585 |
| time_elapsed            | 394           |
| total timesteps         | 55451         |
| value_loss              | 8.198825e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00067049544 |
| ent_coef_loss           | -1.6859641    |
| entropy                 | 1.268385      |
| episodes                | 140           |
| fps                     | 140           |
| mean 100 episode reward | -1            |
| n_updates               | 56806         |
| policy_loss             | -0.10455013   |
| qf1_loss                | 3.905161e-05  |
| qf2_loss                | 5.3129872e-05 |
| time_elapsed            | 404           |
| total timesteps         | 56906         |
| value_loss              | 0.0002350366  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00065019284 |
| ent_coef_loss           | -4.667559     |
| entropy                 | 1.0497785     |
| episodes                | 144           |
| fps                     | 140           |
| mean 100 episode reward | -1            |
| n_updates               | 58232         |
| policy_loss             | -0.09076394   |
| qf1_loss                | 8.023679e-05  |
| qf2_loss                | 6.559935e-05  |
| time_elapsed            | 414           |
| total timesteps         | 58332         |
| value_loss              | 0.00013203784 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00057442224 |
| ent_coef_loss           | 1.3836404     |
| entropy                 | 1.2038653     |
| episodes                | 148           |
| fps                     | 141           |
| mean 100 episode reward | -1            |
| n_updates               | 59992         |
| policy_loss             | -0.068096034  |
| qf1_loss                | 4.3385953e-05 |
| qf2_loss                | 7.01423e-05   |
| time_elapsed            | 425           |
| total timesteps         | 60092         |
| value_loss              | 6.683881e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005190804  |
| ent_coef_loss           | -3.2254055    |
| entropy                 | 1.3015383     |
| episodes                | 152           |
| fps                     | 140           |
| mean 100 episode reward | -1.1          |
| n_updates               | 61706         |
| policy_loss             | -0.06178105   |
| qf1_loss                | 5.7407495e-05 |
| qf2_loss                | 4.7441055e-05 |
| time_elapsed            | 439           |
| total timesteps         | 61806         |
| value_loss              | 7.985775e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005176925  |
| ent_coef_loss           | -3.5822484    |
| entropy                 | 1.3514693     |
| episodes                | 156           |
| fps                     | 139           |
| mean 100 episode reward | -1.1          |
| n_updates               | 63466         |
| policy_loss             | -0.03934685   |
| qf1_loss                | 0.00039971687 |
| qf2_loss                | 0.00033699034 |
| time_elapsed            | 455           |
| total timesteps         | 63566         |
| value_loss              | 5.832244e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005145139  |
| ent_coef_loss           | 0.47538358    |
| entropy                 | 1.1682132     |
| episodes                | 160           |
| fps                     | 138           |
| mean 100 episode reward | -1.1          |
| n_updates               | 65226         |
| policy_loss             | 0.0011285485  |
| qf1_loss                | 4.0453087e-05 |
| qf2_loss                | 5.2592244e-05 |
| time_elapsed            | 472           |
| total timesteps         | 65326         |
| value_loss              | 4.800752e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004270914  |
| ent_coef_loss           | -0.13251019   |
| entropy                 | 1.195169      |
| episodes                | 164           |
| fps                     | 137           |
| mean 100 episode reward | -1.2          |
| n_updates               | 66986         |
| policy_loss             | 0.014513001   |
| qf1_loss                | 0.00015260451 |
| qf2_loss                | 6.0141258e-05 |
| time_elapsed            | 488           |
| total timesteps         | 67086         |
| value_loss              | 0.0001672564  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00046259924 |
| ent_coef_loss           | 1.102284      |
| entropy                 | 0.9246566     |
| episodes                | 168           |
| fps                     | 136           |
| mean 100 episode reward | -1.1          |
| n_updates               | 68418         |
| policy_loss             | 0.0108984895  |
| qf1_loss                | 4.165589e-05  |
| qf2_loss                | 7.219758e-05  |
| time_elapsed            | 501           |
| total timesteps         | 68518         |
| value_loss              | 0.00018554922 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004353041  |
| ent_coef_loss           | -0.16583884   |
| entropy                 | 0.8440745     |
| episodes                | 172           |
| fps                     | 135           |
| mean 100 episode reward | -1.1          |
| n_updates               | 70178         |
| policy_loss             | -0.010494817  |
| qf1_loss                | 4.8122474e-05 |
| qf2_loss                | 5.1778137e-05 |
| time_elapsed            | 516           |
| total timesteps         | 70278         |
| value_loss              | 4.447368e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00042036895 |
| ent_coef_loss           | 0.5734288     |
| entropy                 | 0.64182925    |
| episodes                | 176           |
| fps                     | 135           |
| mean 100 episode reward | -1.1          |
| n_updates               | 71824         |
| policy_loss             | -0.009726269  |
| qf1_loss                | 2.803558e-05  |
| qf2_loss                | 4.735439e-05  |
| time_elapsed            | 531           |
| total timesteps         | 71924         |
| value_loss              | 7.769698e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004404878  |
| ent_coef_loss           | -3.9817822    |
| entropy                 | 0.89168745    |
| episodes                | 180           |
| fps                     | 134           |
| mean 100 episode reward | -1.1          |
| n_updates               | 73584         |
| policy_loss             | 0.0031364893  |
| qf1_loss                | 3.0478881e-05 |
| qf2_loss                | 0.00013817076 |
| time_elapsed            | 547           |
| total timesteps         | 73684         |
| value_loss              | 6.761628e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004218305  |
| ent_coef_loss           | -4.230842     |
| entropy                 | 0.8050082     |
| episodes                | 184           |
| fps                     | 134           |
| mean 100 episode reward | -1.1          |
| n_updates               | 75060         |
| policy_loss             | 0.0235875     |
| qf1_loss                | 6.8909765e-05 |
| qf2_loss                | 5.3750504e-05 |
| time_elapsed            | 560           |
| total timesteps         | 75160         |
| value_loss              | 8.1877646e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00043513475 |
| ent_coef_loss           | -2.2575917    |
| entropy                 | 1.1748067     |
| episodes                | 188           |
| fps                     | 133           |
| mean 100 episode reward | -1.1          |
| n_updates               | 76820         |
| policy_loss             | 0.024289496   |
| qf1_loss                | 3.4534733e-05 |
| qf2_loss                | 5.14543e-05   |
| time_elapsed            | 576           |
| total timesteps         | 76920         |
| value_loss              | 8.530264e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00040581924 |
| ent_coef_loss           | -2.657628     |
| entropy                 | 0.89029914    |
| episodes                | 192           |
| fps                     | 132           |
| mean 100 episode reward | -0.9          |
| n_updates               | 78497         |
| policy_loss             | 0.015200378   |
| qf1_loss                | 5.3627904e-05 |
| qf2_loss                | 4.6643847e-05 |
| time_elapsed            | 591           |
| total timesteps         | 78597         |
| value_loss              | 9.358833e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00040659943 |
| ent_coef_loss           | -4.1937094    |
| entropy                 | 1.3332276     |
| episodes                | 196           |
| fps                     | 132           |
| mean 100 episode reward | -0.9          |
| n_updates               | 80065         |
| policy_loss             | 0.021825032   |
| qf1_loss                | 2.9420251e-05 |
| qf2_loss                | 6.445205e-05  |
| time_elapsed            | 605           |
| total timesteps         | 80165         |
| value_loss              | 5.419073e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004389886  |
| ent_coef_loss           | -0.10239786   |
| entropy                 | 0.9484388     |
| episodes                | 200           |
| fps                     | 131           |
| mean 100 episode reward | -1            |
| n_updates               | 81698         |
| policy_loss             | 0.02081449    |
| qf1_loss                | 8.8878776e-05 |
| qf2_loss                | 9.1120164e-05 |
| time_elapsed            | 619           |
| total timesteps         | 81798         |
| value_loss              | 8.527287e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00044448127 |
| ent_coef_loss           | -2.0559187    |
| entropy                 | 1.0030844     |
| episodes                | 204           |
| fps                     | 131           |
| mean 100 episode reward | -1.1          |
| n_updates               | 83458         |
| policy_loss             | 0.0508097     |
| qf1_loss                | 2.0342799e-05 |
| qf2_loss                | 1.9357976e-05 |
| time_elapsed            | 635           |
| total timesteps         | 83558         |
| value_loss              | 5.3170177e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00042364452 |
| ent_coef_loss           | -4.255315     |
| entropy                 | 0.85181534    |
| episodes                | 208           |
| fps                     | 131           |
| mean 100 episode reward | -1.1          |
| n_updates               | 84632         |
| policy_loss             | 0.05318449    |
| qf1_loss                | 0.0019696755  |
| qf2_loss                | 0.0018782127  |
| time_elapsed            | 646           |
| total timesteps         | 84732         |
| value_loss              | 0.00030881987 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00044487586 |
| ent_coef_loss           | -2.9412186    |
| entropy                 | 1.321789      |
| episodes                | 212           |
| fps                     | 130           |
| mean 100 episode reward | -1.2          |
| n_updates               | 86124         |
| policy_loss             | 0.064913824   |
| qf1_loss                | 3.8461083e-05 |
| qf2_loss                | 4.276561e-05  |
| time_elapsed            | 659           |
| total timesteps         | 86224         |
| value_loss              | 7.8125406e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00049066375 |
| ent_coef_loss           | 1.3833165     |
| entropy                 | 1.2301619     |
| episodes                | 216           |
| fps                     | 130           |
| mean 100 episode reward | -1.1          |
| n_updates               | 87611         |
| policy_loss             | 0.055392317   |
| qf1_loss                | 8.582601e-05  |
| qf2_loss                | 5.6983787e-05 |
| time_elapsed            | 673           |
| total timesteps         | 87711         |
| value_loss              | 8.506873e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00041484236 |
| ent_coef_loss           | -4.6594133    |
| entropy                 | 1.0176327     |
| episodes                | 220           |
| fps                     | 129           |
| mean 100 episode reward | -1.1          |
| n_updates               | 89092         |
| policy_loss             | 0.084432036   |
| qf1_loss                | 3.495096e-05  |
| qf2_loss                | 2.8618093e-05 |
| time_elapsed            | 686           |
| total timesteps         | 89192         |
| value_loss              | 6.834106e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00042652196 |
| ent_coef_loss           | 4.811211      |
| entropy                 | 0.9740164     |
| episodes                | 224           |
| fps                     | 129           |
| mean 100 episode reward | -1.1          |
| n_updates               | 90575         |
| policy_loss             | 0.077231616   |
| qf1_loss                | 7.314458e-05  |
| qf2_loss                | 9.924102e-05  |
| time_elapsed            | 699           |
| total timesteps         | 90675         |
| value_loss              | 8.8722605e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00045920286 |
| ent_coef_loss           | 2.0106802     |
| entropy                 | 1.1856813     |
| episodes                | 228           |
| fps                     | 129           |
| mean 100 episode reward | -1.1          |
| n_updates               | 91963         |
| policy_loss             | 0.112177625   |
| qf1_loss                | 4.451822e-05  |
| qf2_loss                | 8.0290134e-05 |
| time_elapsed            | 712           |
| total timesteps         | 92063         |
| value_loss              | 0.00018921713 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00048160457 |
| ent_coef_loss           | -2.169798     |
| entropy                 | 1.0874898     |
| episodes                | 232           |
| fps                     | 128           |
| mean 100 episode reward | -1.2          |
| n_updates               | 93634         |
| policy_loss             | 0.098656      |
| qf1_loss                | 3.890443e-05  |
| qf2_loss                | 3.5637735e-05 |
| time_elapsed            | 727           |
| total timesteps         | 93734         |
| value_loss              | 5.5163986e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.001          |
| ent_coef                | 0.0004823501   |
| ent_coef_loss           | -2.07125       |
| entropy                 | 1.2180821      |
| episodes                | 236            |
| fps                     | 128            |
| mean 100 episode reward | -1.2           |
| n_updates               | 95394          |
| policy_loss             | 0.10017894     |
| qf1_loss                | 0.00019479587  |
| qf2_loss                | 0.000114626106 |
| time_elapsed            | 743            |
| total timesteps         | 95494          |
| value_loss              | 5.4190292e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004751732  |
| ent_coef_loss           | -1.1210744    |
| entropy                 | 1.0781491     |
| episodes                | 240           |
| fps                     | 128           |
| mean 100 episode reward | -1.3          |
| n_updates               | 96892         |
| policy_loss             | 0.09929052    |
| qf1_loss                | 0.0001342601  |
| qf2_loss                | 0.0003051328  |
| time_elapsed            | 756           |
| total timesteps         | 96992         |
| value_loss              | 9.7963595e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00055401056 |
| ent_coef_loss           | -1.1746781    |
| entropy                 | 1.1405637     |
| episodes                | 244           |
| fps                     | 127           |
| mean 100 episode reward | -1.4          |
| n_updates               | 98295         |
| policy_loss             | 0.11470717    |
| qf1_loss                | 0.0001533514  |
| qf2_loss                | 8.875647e-05  |
| time_elapsed            | 769           |
| total timesteps         | 98395         |
| value_loss              | 0.00026745675 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005160515  |
| ent_coef_loss           | -1.3771265    |
| entropy                 | 1.2523575     |
| episodes                | 248           |
| fps                     | 127           |
| mean 100 episode reward | -1.4          |
| n_updates               | 99807         |
| policy_loss             | 0.1070815     |
| qf1_loss                | 0.00036084856 |
| qf2_loss                | 0.00028018074 |
| time_elapsed            | 782           |
| total timesteps         | 99907         |
| value_loss              | 0.00014371888 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004987322  |
| ent_coef_loss           | 3.020803      |
| entropy                 | 0.90303975    |
| episodes                | 252           |
| fps                     | 127           |
| mean 100 episode reward | -1.4          |
| n_updates               | 101294        |
| policy_loss             | 0.12367996    |
| qf1_loss                | 0.00020034179 |
| qf2_loss                | 5.4067903e-05 |
| time_elapsed            | 796           |
| total timesteps         | 101394        |
| value_loss              | 9.307025e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005338531  |
| ent_coef_loss           | -0.80418026   |
| entropy                 | 0.98524094    |
| episodes                | 256           |
| fps                     | 127           |
| mean 100 episode reward | -1.4          |
| n_updates               | 103054        |
| policy_loss             | 0.100789726   |
| qf1_loss                | 5.1028244e-05 |
| qf2_loss                | 0.00015626164 |
| time_elapsed            | 812           |
| total timesteps         | 103154        |
| value_loss              | 0.00010271525 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00061227224 |
| ent_coef_loss           | 1.2461327     |
| entropy                 | 1.2081652     |
| episodes                | 260           |
| fps                     | 126           |
| mean 100 episode reward | -1.4          |
| n_updates               | 104067        |
| policy_loss             | 0.102938205   |
| qf1_loss                | 6.0104063e-05 |
| qf2_loss                | 3.0933916e-05 |
| time_elapsed            | 821           |
| total timesteps         | 104167        |
| value_loss              | 0.00013653334 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00057116355 |
| ent_coef_loss           | 3.3359253     |
| entropy                 | 1.185437      |
| episodes                | 264           |
| fps                     | 126           |
| mean 100 episode reward | -1.5          |
| n_updates               | 105521        |
| policy_loss             | 0.11918184    |
| qf1_loss                | 0.00012408047 |
| qf2_loss                | 0.00010060324 |
| time_elapsed            | 834           |
| total timesteps         | 105621        |
| value_loss              | 0.00024335054 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00057289127 |
| ent_coef_loss           | -1.8518136    |
| entropy                 | 1.4773636     |
| episodes                | 268           |
| fps                     | 126           |
| mean 100 episode reward | -1.5          |
| n_updates               | 107043        |
| policy_loss             | 0.15183607    |
| qf1_loss                | 0.00013519637 |
| qf2_loss                | 8.914429e-05  |
| time_elapsed            | 847           |
| total timesteps         | 107143        |
| value_loss              | 0.00013357805 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005640793  |
| ent_coef_loss           | 0.405554      |
| entropy                 | 1.0971515     |
| episodes                | 272           |
| fps                     | 126           |
| mean 100 episode reward | -1.5          |
| n_updates               | 108803        |
| policy_loss             | 0.14952956    |
| qf1_loss                | 4.9603666e-05 |
| qf2_loss                | 2.7626182e-05 |
| time_elapsed            | 863           |
| total timesteps         | 108903        |
| value_loss              | 7.5126896e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00049987144 |
| ent_coef_loss           | 1.2486947     |
| entropy                 | 1.2497648     |
| episodes                | 276           |
| fps                     | 125           |
| mean 100 episode reward | -1.4          |
| n_updates               | 110284        |
| policy_loss             | 0.14111969    |
| qf1_loss                | 6.648992e-05  |
| qf2_loss                | 6.6549066e-05 |
| time_elapsed            | 877           |
| total timesteps         | 110384        |
| value_loss              | 7.19874e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005829419  |
| ent_coef_loss           | -2.561696     |
| entropy                 | 1.229946      |
| episodes                | 280           |
| fps                     | 125           |
| mean 100 episode reward | -1.5          |
| n_updates               | 111936        |
| policy_loss             | 0.097658284   |
| qf1_loss                | 0.00032766134 |
| qf2_loss                | 0.00034882932 |
| time_elapsed            | 892           |
| total timesteps         | 112036        |
| value_loss              | 8.6840686e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00056615204 |
| ent_coef_loss           | -1.1656104    |
| entropy                 | 1.1189275     |
| episodes                | 284           |
| fps                     | 125           |
| mean 100 episode reward | -1.6          |
| n_updates               | 113696        |
| policy_loss             | 0.15252794    |
| qf1_loss                | 0.0005982121  |
| qf2_loss                | 0.00025863966 |
| time_elapsed            | 908           |
| total timesteps         | 113796        |
| value_loss              | 0.00018964875 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00058426097 |
| ent_coef_loss           | 0.4477325     |
| entropy                 | 1.2857411     |
| episodes                | 288           |
| fps                     | 124           |
| mean 100 episode reward | -1.6          |
| n_updates               | 115456        |
| policy_loss             | 0.12843886    |
| qf1_loss                | 0.0001276565  |
| qf2_loss                | 0.00018256292 |
| time_elapsed            | 926           |
| total timesteps         | 115556        |
| value_loss              | 0.00012376352 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005381905  |
| ent_coef_loss           | -1.242557     |
| entropy                 | 0.9731839     |
| episodes                | 292           |
| fps                     | 124           |
| mean 100 episode reward | -1.7          |
| n_updates               | 117018        |
| policy_loss             | 0.110309586   |
| qf1_loss                | 4.8298753e-05 |
| qf2_loss                | 0.00010192437 |
| time_elapsed            | 941           |
| total timesteps         | 117118        |
| value_loss              | 0.00014224689 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00059507386 |
| ent_coef_loss           | -3.9159694    |
| entropy                 | 1.0235925     |
| episodes                | 296           |
| fps                     | 124           |
| mean 100 episode reward | -1.7          |
| n_updates               | 118525        |
| policy_loss             | 0.17022084    |
| qf1_loss                | 0.00010648445 |
| qf2_loss                | 7.954487e-05  |
| time_elapsed            | 955           |
| total timesteps         | 118625        |
| value_loss              | 0.00034068373 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00056945276 |
| ent_coef_loss           | -1.3775936    |
| entropy                 | 1.0630225     |
| episodes                | 300           |
| fps                     | 123           |
| mean 100 episode reward | -1.7          |
| n_updates               | 120213        |
| policy_loss             | 0.13987291    |
| qf1_loss                | 5.7190075e-05 |
| qf2_loss                | 5.1286806e-05 |
| time_elapsed            | 971           |
| total timesteps         | 120313        |
| value_loss              | 9.125997e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006415487  |
| ent_coef_loss           | 2.698123      |
| entropy                 | 0.8777034     |
| episodes                | 304           |
| fps                     | 123           |
| mean 100 episode reward | -1.5          |
| n_updates               | 121973        |
| policy_loss             | 0.18448287    |
| qf1_loss                | 4.9548267e-05 |
| qf2_loss                | 6.208186e-05  |
| time_elapsed            | 988           |
| total timesteps         | 122073        |
| value_loss              | 0.00012829712 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0005740397 |
| ent_coef_loss           | 1.8740302    |
| entropy                 | 1.0351393    |
| episodes                | 308          |
| fps                     | 123          |
| mean 100 episode reward | -1.5         |
| n_updates               | 123401       |
| policy_loss             | 0.2084549    |
| qf1_loss                | 9.638886e-05 |
| qf2_loss                | 6.73104e-05  |
| time_elapsed            | 1002         |
| total timesteps         | 123501       |
| value_loss              | 8.955707e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005799407  |
| ent_coef_loss           | -3.704136     |
| entropy                 | 1.0312667     |
| episodes                | 312           |
| fps                     | 122           |
| mean 100 episode reward | -1.4          |
| n_updates               | 125161        |
| policy_loss             | 0.13943604    |
| qf1_loss                | 0.00015736243 |
| qf2_loss                | 6.394917e-05  |
| time_elapsed            | 1018          |
| total timesteps         | 125261        |
| value_loss              | 0.00017252692 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00062291074 |
| ent_coef_loss           | 1.3362076     |
| entropy                 | 1.055887      |
| episodes                | 316           |
| fps                     | 122           |
| mean 100 episode reward | -1.4          |
| n_updates               | 126921        |
| policy_loss             | 0.16064268    |
| qf1_loss                | 0.00015351459 |
| qf2_loss                | 7.5897784e-05 |
| time_elapsed            | 1035          |
| total timesteps         | 127021        |
| value_loss              | 0.00033604642 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005733676  |
| ent_coef_loss           | -2.3029711    |
| entropy                 | 1.0469371     |
| episodes                | 320           |
| fps                     | 122           |
| mean 100 episode reward | -1.4          |
| n_updates               | 128681        |
| policy_loss             | 0.13385877    |
| qf1_loss                | 6.6062e-05    |
| qf2_loss                | 6.609693e-05  |
| time_elapsed            | 1052          |
| total timesteps         | 128781        |
| value_loss              | 9.4135474e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00057553593 |
| ent_coef_loss           | -3.4104493    |
| entropy                 | 1.1781447     |
| episodes                | 324           |
| fps                     | 122           |
| mean 100 episode reward | -1.4          |
| n_updates               | 129847        |
| policy_loss             | 0.15579769    |
| qf1_loss                | 2.3921548e-05 |
| qf2_loss                | 0.00044200354 |
| time_elapsed            | 1063          |
| total timesteps         | 129947        |
| value_loss              | 0.00044055475 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006146129  |
| ent_coef_loss           | -2.9024303    |
| entropy                 | 1.2514956     |
| episodes                | 328           |
| fps                     | 121           |
| mean 100 episode reward | -1.4          |
| n_updates               | 131603        |
| policy_loss             | 0.16979478    |
| qf1_loss                | 7.929727e-05  |
| qf2_loss                | 7.9111065e-05 |
| time_elapsed            | 1080          |
| total timesteps         | 131703        |
| value_loss              | 8.1013306e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0006585319 |
| ent_coef_loss           | -1.0894945   |
| entropy                 | 1.20909      |
| episodes                | 332          |
| fps                     | 121          |
| mean 100 episode reward | -1.4         |
| n_updates               | 133363       |
| policy_loss             | 0.12476784   |
| qf1_loss                | 7.993242e-05 |
| qf2_loss                | 9.815757e-05 |
| time_elapsed            | 1097         |
| total timesteps         | 133463       |
| value_loss              | 8.475376e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006167087  |
| ent_coef_loss           | -1.0516105    |
| entropy                 | 1.06933       |
| episodes                | 336           |
| fps                     | 121           |
| mean 100 episode reward | -1.4          |
| n_updates               | 134972        |
| policy_loss             | 0.13733661    |
| qf1_loss                | 4.0488638e-05 |
| qf2_loss                | 5.252965e-05  |
| time_elapsed            | 1112          |
| total timesteps         | 135072        |
| value_loss              | 0.00010356313 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00062228134 |
| ent_coef_loss           | 2.3095868     |
| entropy                 | 0.98770946    |
| episodes                | 340           |
| fps                     | 121           |
| mean 100 episode reward | -1.3          |
| n_updates               | 136732        |
| policy_loss             | 0.12998934    |
| qf1_loss                | 0.00010008346 |
| qf2_loss                | 4.8190617e-05 |
| time_elapsed            | 1128          |
| total timesteps         | 136832        |
| value_loss              | 6.254565e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005754476  |
| ent_coef_loss           | 0.38096136    |
| entropy                 | 1.102824      |
| episodes                | 344           |
| fps                     | 121           |
| mean 100 episode reward | -1.2          |
| n_updates               | 138150        |
| policy_loss             | 0.17287257    |
| qf1_loss                | 7.468389e-05  |
| qf2_loss                | 4.5913213e-05 |
| time_elapsed            | 1141          |
| total timesteps         | 138250        |
| value_loss              | 5.539711e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005832102  |
| ent_coef_loss           | -0.12222701   |
| entropy                 | 1.2131326     |
| episodes                | 348           |
| fps                     | 120           |
| mean 100 episode reward | -1.2          |
| n_updates               | 139910        |
| policy_loss             | 0.18835014    |
| qf1_loss                | 0.00011334181 |
| qf2_loss                | 0.00036209117 |
| time_elapsed            | 1158          |
| total timesteps         | 140010        |
| value_loss              | 8.1112725e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006412588  |
| ent_coef_loss           | -2.5078387    |
| entropy                 | 1.1327529     |
| episodes                | 352           |
| fps                     | 120           |
| mean 100 episode reward | -1.2          |
| n_updates               | 141350        |
| policy_loss             | 0.13289788    |
| qf1_loss                | 7.582167e-05  |
| qf2_loss                | 5.4375872e-05 |
| time_elapsed            | 1171          |
| total timesteps         | 141450        |
| value_loss              | 0.00015114123 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006038676  |
| ent_coef_loss           | 3.2539678     |
| entropy                 | 1.0840831     |
| episodes                | 356           |
| fps                     | 120           |
| mean 100 episode reward | -1.2          |
| n_updates               | 143110        |
| policy_loss             | 0.17477155    |
| qf1_loss                | 8.966269e-05  |
| qf2_loss                | 4.8916165e-05 |
| time_elapsed            | 1188          |
| total timesteps         | 143210        |
| value_loss              | 0.00011525415 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006821202  |
| ent_coef_loss           | 5.7415385     |
| entropy                 | 1.4126829     |
| episodes                | 360           |
| fps                     | 120           |
| mean 100 episode reward | -1.3          |
| n_updates               | 144870        |
| policy_loss             | 0.24311516    |
| qf1_loss                | 6.4478685e-05 |
| qf2_loss                | 7.98135e-05   |
| time_elapsed            | 1204          |
| total timesteps         | 144970        |
| value_loss              | 0.00020933853 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00056028774 |
| ent_coef_loss           | 1.7441204     |
| entropy                 | 1.0180931     |
| episodes                | 364           |
| fps                     | 120           |
| mean 100 episode reward | -1.2          |
| n_updates               | 146261        |
| policy_loss             | 0.17771885    |
| qf1_loss                | 3.6933998e-05 |
| qf2_loss                | 5.5052882e-05 |
| time_elapsed            | 1217          |
| total timesteps         | 146361        |
| value_loss              | 0.00014856656 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00055260066 |
| ent_coef_loss           | 2.7301793     |
| entropy                 | 0.9845848     |
| episodes                | 368           |
| fps                     | 120           |
| mean 100 episode reward | -1.3          |
| n_updates               | 147620        |
| policy_loss             | 0.1562663     |
| qf1_loss                | 0.00016673152 |
| qf2_loss                | 0.00018664323 |
| time_elapsed            | 1229          |
| total timesteps         | 147720        |
| value_loss              | 6.0563652e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00062531355 |
| ent_coef_loss           | -0.3407243    |
| entropy                 | 1.2877984     |
| episodes                | 372           |
| fps                     | 120           |
| mean 100 episode reward | -1.3          |
| n_updates               | 149036        |
| policy_loss             | 0.1524339     |
| qf1_loss                | 3.5637975e-05 |
| qf2_loss                | 2.4027568e-05 |
| time_elapsed            | 1242          |
| total timesteps         | 149136        |
| value_loss              | 4.3920933e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00064757426 |
| ent_coef_loss           | 4.59626       |
| entropy                 | 1.055018      |
| episodes                | 376           |
| fps                     | 119           |
| mean 100 episode reward | -1.3          |
| n_updates               | 150463        |
| policy_loss             | 0.15932804    |
| qf1_loss                | 8.104023e-05  |
| qf2_loss                | 7.7735414e-05 |
| time_elapsed            | 1255          |
| total timesteps         | 150563        |
| value_loss              | 0.0003046455  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006254209  |
| ent_coef_loss           | -3.2089436    |
| entropy                 | 1.0431232     |
| episodes                | 380           |
| fps                     | 119           |
| mean 100 episode reward | -1.2          |
| n_updates               | 152041        |
| policy_loss             | 0.19530815    |
| qf1_loss                | 0.00016455237 |
| qf2_loss                | 8.7245855e-05 |
| time_elapsed            | 1269          |
| total timesteps         | 152141        |
| value_loss              | 0.00014744521 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006343793  |
| ent_coef_loss           | -0.33466363   |
| entropy                 | 1.2457708     |
| episodes                | 384           |
| fps                     | 119           |
| mean 100 episode reward | -1.3          |
| n_updates               | 152740        |
| policy_loss             | 0.18632942    |
| qf1_loss                | 0.00018667964 |
| qf2_loss                | 6.107167e-05  |
| time_elapsed            | 1275          |
| total timesteps         | 152840        |
| value_loss              | 6.361379e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006298034  |
| ent_coef_loss           | 0.9496667     |
| entropy                 | 0.97000384    |
| episodes                | 388           |
| fps                     | 119           |
| mean 100 episode reward | -1.3          |
| n_updates               | 154088        |
| policy_loss             | 0.20931432    |
| qf1_loss                | 0.00017203488 |
| qf2_loss                | 0.0002113705  |
| time_elapsed            | 1288          |
| total timesteps         | 154188        |
| value_loss              | 0.00020488442 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00065858307 |
| ent_coef_loss           | 0.9820123     |
| entropy                 | 0.9958207     |
| episodes                | 392           |
| fps                     | 119           |
| mean 100 episode reward | -1.3          |
| n_updates               | 155722        |
| policy_loss             | 0.15929085    |
| qf1_loss                | 0.00012251837 |
| qf2_loss                | 8.361877e-05  |
| time_elapsed            | 1302          |
| total timesteps         | 155822        |
| value_loss              | 0.00049629447 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00065373    |
| ent_coef_loss           | 6.8088512     |
| entropy                 | 0.95837104    |
| episodes                | 396           |
| fps                     | 119           |
| mean 100 episode reward | -1.3          |
| n_updates               | 157243        |
| policy_loss             | 0.18245624    |
| qf1_loss                | 0.00028635733 |
| qf2_loss                | 0.00015533101 |
| time_elapsed            | 1316          |
| total timesteps         | 157343        |
| value_loss              | 0.0002141369  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00063470093 |
| ent_coef_loss           | -2.460155     |
| entropy                 | 1.0364625     |
| episodes                | 400           |
| fps                     | 119           |
| mean 100 episode reward | -1.2          |
| n_updates               | 158388        |
| policy_loss             | 0.1569365     |
| qf1_loss                | 0.00021458259 |
| qf2_loss                | 0.00023789564 |
| time_elapsed            | 1326          |
| total timesteps         | 158488        |
| value_loss              | 0.00027189663 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.001          |
| ent_coef                | 0.00063720054  |
| ent_coef_loss           | -2.5205145     |
| entropy                 | 1.0955966      |
| episodes                | 404            |
| fps                     | 119            |
| mean 100 episode reward | -1.3           |
| n_updates               | 160148         |
| policy_loss             | 0.21043392     |
| qf1_loss                | 0.000100732366 |
| qf2_loss                | 0.00014947834  |
| time_elapsed            | 1342           |
| total timesteps         | 160248         |
| value_loss              | 0.000119058626 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00069140265 |
| ent_coef_loss           | -0.93124455   |
| entropy                 | 1.1919103     |
| episodes                | 408           |
| fps                     | 119           |
| mean 100 episode reward | -1.3          |
| n_updates               | 161908        |
| policy_loss             | 0.23533632    |
| qf1_loss                | 0.00014335946 |
| qf2_loss                | 0.00050671597 |
| time_elapsed            | 1358          |
| total timesteps         | 162008        |
| value_loss              | 0.00016603484 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.001          |
| ent_coef                | 0.0007015603   |
| ent_coef_loss           | -4.0029063     |
| entropy                 | 0.94350135     |
| episodes                | 412            |
| fps                     | 119            |
| mean 100 episode reward | -1.4           |
| n_updates               | 163487         |
| policy_loss             | 0.19980441     |
| qf1_loss                | 0.000103030536 |
| qf2_loss                | 0.00012957872  |
| time_elapsed            | 1372           |
| total timesteps         | 163587         |
| value_loss              | 0.00018440424  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0007014877  |
| ent_coef_loss           | 4.812542      |
| entropy                 | 1.1872718     |
| episodes                | 416           |
| fps                     | 119           |
| mean 100 episode reward | -1.5          |
| n_updates               | 165247        |
| policy_loss             | 0.22919013    |
| qf1_loss                | 0.0008092285  |
| qf2_loss                | 0.00030986586 |
| time_elapsed            | 1388          |
| total timesteps         | 165347        |
| value_loss              | 0.00021855035 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006848105  |
| ent_coef_loss           | -3.3176355    |
| entropy                 | 1.2249565     |
| episodes                | 420           |
| fps                     | 118           |
| mean 100 episode reward | -1.5          |
| n_updates               | 166862        |
| policy_loss             | 0.17550424    |
| qf1_loss                | 0.00017180448 |
| qf2_loss                | 0.00015011421 |
| time_elapsed            | 1403          |
| total timesteps         | 166962        |
| value_loss              | 0.00013353812 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0006838368 |
| ent_coef_loss           | 1.3890347    |
| entropy                 | 1.0060239    |
| episodes                | 424          |
| fps                     | 118          |
| mean 100 episode reward | -1.5         |
| n_updates               | 168342       |
| policy_loss             | 0.23743269   |
| qf1_loss                | 6.790819e-05 |
| qf2_loss                | 9.341468e-05 |
| time_elapsed            | 1416         |
| total timesteps         | 168442       |
| value_loss              | 9.316234e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00061280705 |
| ent_coef_loss           | -1.0169706    |
| entropy                 | 0.875368      |
| episodes                | 428           |
| fps                     | 118           |
| mean 100 episode reward | -1.6          |
| n_updates               | 170102        |
| policy_loss             | 0.21608454    |
| qf1_loss                | 9.455207e-05  |
| qf2_loss                | 0.00020975794 |
| time_elapsed            | 1432          |
| total timesteps         | 170202        |
| value_loss              | 0.00012792181 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.000650807   |
| ent_coef_loss           | -3.6957455    |
| entropy                 | 1.124752      |
| episodes                | 432           |
| fps                     | 118           |
| mean 100 episode reward | -1.4          |
| n_updates               | 171862        |
| policy_loss             | 0.2103621     |
| qf1_loss                | 0.00029355657 |
| qf2_loss                | 0.00032153702 |
| time_elapsed            | 1448          |
| total timesteps         | 171962        |
| value_loss              | 0.00019570855 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.001          |
| ent_coef                | 0.00057052745  |
| ent_coef_loss           | 1.9979849      |
| entropy                 | 1.0428084      |
| episodes                | 436            |
| fps                     | 118            |
| mean 100 episode reward | -1.4           |
| n_updates               | 173622         |
| policy_loss             | 0.22600605     |
| qf1_loss                | 8.9503985e-05  |
| qf2_loss                | 4.852651e-05   |
| time_elapsed            | 1464           |
| total timesteps         | 173722         |
| value_loss              | 0.000102040896 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00066073146 |
| ent_coef_loss           | 3.1900866     |
| entropy                 | 1.0530378     |
| episodes                | 440           |
| fps                     | 118           |
| mean 100 episode reward | -1.5          |
| n_updates               | 175269        |
| policy_loss             | 0.21770263    |
| qf1_loss                | 7.701879e-05  |
| qf2_loss                | 5.678396e-05  |
| time_elapsed            | 1479          |
| total timesteps         | 175369        |
| value_loss              | 7.465622e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0007003233  |
| ent_coef_loss           | 0.6933532     |
| entropy                 | 1.0979762     |
| episodes                | 444           |
| fps                     | 118           |
| mean 100 episode reward | -1.5          |
| n_updates               | 176871        |
| policy_loss             | 0.19238117    |
| qf1_loss                | 9.675361e-05  |
| qf2_loss                | 0.00010538659 |
| time_elapsed            | 1493          |
| total timesteps         | 176971        |
| value_loss              | 0.00012533714 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0006358563 |
| ent_coef_loss           | -2.4643862   |
| entropy                 | 1.0483224    |
| episodes                | 448          |
| fps                     | 118          |
| mean 100 episode reward | -1.4         |
| n_updates               | 178631       |
| policy_loss             | 0.23975858   |
| qf1_loss                | 5.360585e-05 |
| qf2_loss                | 7.084785e-05 |
| time_elapsed            | 1509         |
| total timesteps         | 178731       |
| value_loss              | 9.47815e-05  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00065402495 |
| ent_coef_loss           | 0.04131201    |
| entropy                 | 1.0833287     |
| episodes                | 452           |
| fps                     | 118           |
| mean 100 episode reward | -1.5          |
| n_updates               | 180138        |
| policy_loss             | 0.22915119    |
| qf1_loss                | 0.00016907393 |
| qf2_loss                | 0.00014007965 |
| time_elapsed            | 1523          |
| total timesteps         | 180238        |
| value_loss              | 0.00010468734 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00062210066 |
| ent_coef_loss           | -1.2203689    |
| entropy                 | 1.0539151     |
| episodes                | 456           |
| fps                     | 118           |
| mean 100 episode reward | -1.4          |
| n_updates               | 181898        |
| policy_loss             | 0.26598412    |
| qf1_loss                | 8.699744e-05  |
| qf2_loss                | 4.8992988e-05 |
| time_elapsed            | 1539          |
| total timesteps         | 181998        |
| value_loss              | 0.00055958855 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006357553  |
| ent_coef_loss           | 1.3785326     |
| entropy                 | 0.9199295     |
| episodes                | 460           |
| fps                     | 118           |
| mean 100 episode reward | -1.3          |
| n_updates               | 183658        |
| policy_loss             | 0.24300541    |
| qf1_loss                | 6.0487364e-05 |
| qf2_loss                | 9.9701e-05    |
| time_elapsed            | 1555          |
| total timesteps         | 183758        |
| value_loss              | 0.00013486852 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00065124343 |
| ent_coef_loss           | 1.4277279     |
| entropy                 | 1.1267607     |
| episodes                | 464           |
| fps                     | 118           |
| mean 100 episode reward | -1.3          |
| n_updates               | 184776        |
| policy_loss             | 0.21022084    |
| qf1_loss                | 4.31846e-05   |
| qf2_loss                | 6.486893e-05  |
| time_elapsed            | 1565          |
| total timesteps         | 184876        |
| value_loss              | 8.734647e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00058711605 |
| ent_coef_loss           | 2.5454698     |
| entropy                 | 1.1240959     |
| episodes                | 468           |
| fps                     | 118           |
| mean 100 episode reward | -1.3          |
| n_updates               | 186419        |
| policy_loss             | 0.20291829    |
| qf1_loss                | 0.00010072047 |
| qf2_loss                | 4.749444e-05  |
| time_elapsed            | 1580          |
| total timesteps         | 186519        |
| value_loss              | 5.0546772e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00062704325 |
| ent_coef_loss           | -2.7394598    |
| entropy                 | 0.9980031     |
| episodes                | 472           |
| fps                     | 117           |
| mean 100 episode reward | -1.3          |
| n_updates               | 188179        |
| policy_loss             | 0.249268      |
| qf1_loss                | 5.8925063e-05 |
| qf2_loss                | 9.4016985e-05 |
| time_elapsed            | 1596          |
| total timesteps         | 188279        |
| value_loss              | 0.00010129905 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006451207  |
| ent_coef_loss           | -0.5224707    |
| entropy                 | 0.99034804    |
| episodes                | 476           |
| fps                     | 117           |
| mean 100 episode reward | -1.2          |
| n_updates               | 189725        |
| policy_loss             | 0.21144047    |
| qf1_loss                | 3.808234e-05  |
| qf2_loss                | 5.1869494e-05 |
| time_elapsed            | 1610          |
| total timesteps         | 189825        |
| value_loss              | 8.960944e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006181979  |
| ent_coef_loss           | -3.5953856    |
| entropy                 | 1.0909187     |
| episodes                | 480           |
| fps                     | 117           |
| mean 100 episode reward | -1.2          |
| n_updates               | 191157        |
| policy_loss             | 0.19030148    |
| qf1_loss                | 0.0001115824  |
| qf2_loss                | 0.0001058628  |
| time_elapsed            | 1623          |
| total timesteps         | 191257        |
| value_loss              | 0.00015708776 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00062661374 |
| ent_coef_loss           | -4.2245083    |
| entropy                 | 1.0018655     |
| episodes                | 484           |
| fps                     | 117           |
| mean 100 episode reward | -1.1          |
| n_updates               | 192917        |
| policy_loss             | 0.24913102    |
| qf1_loss                | 5.267554e-05  |
| qf2_loss                | 0.00015030027 |
| time_elapsed            | 1639          |
| total timesteps         | 193017        |
| value_loss              | 0.00029603275 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005475807  |
| ent_coef_loss           | 0.5283167     |
| entropy                 | 0.89319694    |
| episodes                | 488           |
| fps                     | 117           |
| mean 100 episode reward | -1.1          |
| n_updates               | 194408        |
| policy_loss             | 0.22866356    |
| qf1_loss                | 0.00020389166 |
| qf2_loss                | 0.00016887888 |
| time_elapsed            | 1652          |
| total timesteps         | 194508        |
| value_loss              | 0.00010348202 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.001          |
| ent_coef                | 0.0005293257   |
| ent_coef_loss           | -1.2605677     |
| entropy                 | 0.8919847      |
| episodes                | 492            |
| fps                     | 117            |
| mean 100 episode reward | -1.2           |
| n_updates               | 195902         |
| policy_loss             | 0.22727251     |
| qf1_loss                | 8.470268e-05   |
| qf2_loss                | 7.584528e-05   |
| time_elapsed            | 1666           |
| total timesteps         | 196002         |
| value_loss              | 0.000102447746 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005157047  |
| ent_coef_loss           | -1.8624383    |
| entropy                 | 0.7471074     |
| episodes                | 496           |
| fps                     | 117           |
| mean 100 episode reward | -1.2          |
| n_updates               | 197662        |
| policy_loss             | 0.22398645    |
| qf1_loss                | 0.00013271847 |
| qf2_loss                | 9.570015e-05  |
| time_elapsed            | 1682          |
| total timesteps         | 197762        |
| value_loss              | 0.00012949378 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005162179  |
| ent_coef_loss           | 0.7916219     |
| entropy                 | 0.86458015    |
| episodes                | 500           |
| fps                     | 117           |
| mean 100 episode reward | -1.2          |
| n_updates               | 199422        |
| policy_loss             | 0.22014488    |
| qf1_loss                | 6.0772956e-05 |
| qf2_loss                | 9.5504714e-05 |
| time_elapsed            | 1698          |
| total timesteps         | 199522        |
| value_loss              | 5.4584445e-05 |
-------------------------------------------
>>>>> End testing <<<<< energy:_-0.01__slack:_-0.0005
Final weights saved at:  /home/patrick/tensorboard_logs/sac_energy:_-0.01__slack:_-0.0005/stable_baselines.pkl
TEST COMMAND: python3 py3_learning.py --test --weights  /home/patrick/tensorboard_logs/sac_energy:_-0.01__slack:_-0.0005/stable_baselines.pkl
Starting test with params: {'energy': -0.0005, 'slack': -0.001}
Namespace(draw_screen=False, env_config='configs/env.config', policy='multi_human_rl', policy_config='configs/policy.config', test=False, train_config='configs/train.config', weights=None)
Gym environment created.
COLLISION PENALTY -0.25
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.3287684     |
| ent_coef_loss           | -3.6751165    |
| entropy                 | 2.62015       |
| episodes                | 4             |
| fps                     | 113           |
| mean 100 episode reward | -2.1          |
| n_updates               | 1113          |
| policy_loss             | -3.8702445    |
| qf1_loss                | 0.00074991223 |
| qf2_loss                | 0.0008950544  |
| time_elapsed            | 10            |
| total timesteps         | 1213          |
| value_loss              | 0.005410862   |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.057441488  |
| ent_coef_loss           | -9.228792    |
| entropy                 | 2.638987     |
| episodes                | 8            |
| fps                     | 112          |
| mean 100 episode reward | -2.1         |
| n_updates               | 2873         |
| policy_loss             | -4.804668    |
| qf1_loss                | 0.003482467  |
| qf2_loss                | 0.0013016979 |
| time_elapsed            | 26           |
| total timesteps         | 2973         |
| value_loss              | 0.024349641  |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.01879802   |
| ent_coef_loss           | -11.075736   |
| entropy                 | 2.617695     |
| episodes                | 12           |
| fps                     | 111          |
| mean 100 episode reward | -2.2         |
| n_updates               | 4066         |
| policy_loss             | -4.6580076   |
| qf1_loss                | 0.10502606   |
| qf2_loss                | 0.10926586   |
| time_elapsed            | 37           |
| total timesteps         | 4166         |
| value_loss              | 0.0021270732 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0062497524 |
| ent_coef_loss           | -4.9350905   |
| entropy                 | 1.6179457    |
| episodes                | 16           |
| fps                     | 111          |
| mean 100 episode reward | -2           |
| n_updates               | 5826         |
| policy_loss             | -4.307515    |
| qf1_loss                | 0.0030751424 |
| qf2_loss                | 0.0033788523 |
| time_elapsed            | 53           |
| total timesteps         | 5926         |
| value_loss              | 0.006363821  |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0043090135 |
| ent_coef_loss           | 5.6176877    |
| entropy                 | 1.427687     |
| episodes                | 20           |
| fps                     | 111          |
| mean 100 episode reward | -1.9         |
| n_updates               | 7052         |
| policy_loss             | -3.9074063   |
| qf1_loss                | 0.0017053128 |
| qf2_loss                | 0.001949087  |
| time_elapsed            | 64           |
| total timesteps         | 7152         |
| value_loss              | 0.002578551  |
------------------------------------------
-----------------------------------------
| current_lr              | 0.001       |
| ent_coef                | 0.004183551 |
| ent_coef_loss           | -4.1340814  |
| entropy                 | 1.1335917   |
| episodes                | 24          |
| fps                     | 111         |
| mean 100 episode reward | -2.4        |
| n_updates               | 8344        |
| policy_loss             | -3.7345257  |
| qf1_loss                | 0.00654272  |
| qf2_loss                | 0.005945909 |
| time_elapsed            | 75          |
| total timesteps         | 8444        |
| value_loss              | 0.011448067 |
-----------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.003869772   |
| ent_coef_loss           | 4.7566934     |
| entropy                 | 1.1340458     |
| episodes                | 28            |
| fps                     | 110           |
| mean 100 episode reward | -2.5          |
| n_updates               | 9952          |
| policy_loss             | -3.1253207    |
| qf1_loss                | 0.00087010476 |
| qf2_loss                | 0.0010631518  |
| time_elapsed            | 90            |
| total timesteps         | 10052         |
| value_loss              | 0.0018278913  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0032948127 |
| ent_coef_loss           | 0.9071912    |
| entropy                 | 0.9016869    |
| episodes                | 32           |
| fps                     | 110          |
| mean 100 episode reward | -2.4         |
| n_updates               | 11198        |
| policy_loss             | -2.9910378   |
| qf1_loss                | 0.0016967384 |
| qf2_loss                | 0.002770396  |
| time_elapsed            | 101          |
| total timesteps         | 11298        |
| value_loss              | 0.006486962  |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.003185418  |
| ent_coef_loss           | 1.1214635    |
| entropy                 | 1.5361891    |
| episodes                | 36           |
| fps                     | 110          |
| mean 100 episode reward | -2.3         |
| n_updates               | 12359        |
| policy_loss             | -2.8912048   |
| qf1_loss                | 0.042452663  |
| qf2_loss                | 0.04069036   |
| time_elapsed            | 112          |
| total timesteps         | 12459        |
| value_loss              | 0.0039249863 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0025649043  |
| ent_coef_loss           | -2.6210427    |
| entropy                 | 0.84558475    |
| episodes                | 40            |
| fps                     | 110           |
| mean 100 episode reward | -2.2          |
| n_updates               | 13853         |
| policy_loss             | -2.6082568    |
| qf1_loss                | 0.00041746782 |
| qf2_loss                | 0.0015467627  |
| time_elapsed            | 125           |
| total timesteps         | 13953         |
| value_loss              | 0.0011606659  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00209587    |
| ent_coef_loss           | -1.5167793    |
| entropy                 | 0.7107792     |
| episodes                | 44            |
| fps                     | 110           |
| mean 100 episode reward | -2.1          |
| n_updates               | 15342         |
| policy_loss             | -2.3000946    |
| qf1_loss                | 0.00051353895 |
| qf2_loss                | 0.0003773528  |
| time_elapsed            | 139           |
| total timesteps         | 15442         |
| value_loss              | 0.000597461   |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0018832812 |
| ent_coef_loss           | 2.0639005    |
| entropy                 | 0.9938983    |
| episodes                | 48           |
| fps                     | 110          |
| mean 100 episode reward | -2.1         |
| n_updates               | 17102        |
| policy_loss             | -2.1055758   |
| qf1_loss                | 0.0005593851 |
| qf2_loss                | 0.0005310102 |
| time_elapsed            | 155          |
| total timesteps         | 17202        |
| value_loss              | 0.0017927571 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0017372587  |
| ent_coef_loss           | -2.6542838    |
| entropy                 | 0.82644033    |
| episodes                | 52            |
| fps                     | 110           |
| mean 100 episode reward | -2.2          |
| n_updates               | 18862         |
| policy_loss             | -1.651082     |
| qf1_loss                | 0.0002922984  |
| qf2_loss                | 0.00023489413 |
| time_elapsed            | 170           |
| total timesteps         | 18962         |
| value_loss              | 0.0008448862  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.002147318  |
| ent_coef_loss           | -4.7632895   |
| entropy                 | 1.052305     |
| episodes                | 56           |
| fps                     | 110          |
| mean 100 episode reward | -2.1         |
| n_updates               | 20225        |
| policy_loss             | -1.5804216   |
| qf1_loss                | 0.0007687293 |
| qf2_loss                | 0.0012717806 |
| time_elapsed            | 183          |
| total timesteps         | 20325        |
| value_loss              | 0.0010553057 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0018384133 |
| ent_coef_loss           | -1.1911489   |
| entropy                 | 0.6570052    |
| episodes                | 60           |
| fps                     | 110          |
| mean 100 episode reward | -2.2         |
| n_updates               | 21736        |
| policy_loss             | -1.4224433   |
| qf1_loss                | 0.0038223448 |
| qf2_loss                | 0.0038363626 |
| time_elapsed            | 196          |
| total timesteps         | 21836        |
| value_loss              | 0.0005966867 |
------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0018938462 |
| ent_coef_loss           | 1.0684879    |
| entropy                 | 0.78798604   |
| episodes                | 64           |
| fps                     | 110          |
| mean 100 episode reward | -2.2         |
| n_updates               | 23093        |
| policy_loss             | -1.3620231   |
| qf1_loss                | 0.0007298768 |
| qf2_loss                | 0.0012280283 |
| time_elapsed            | 209          |
| total timesteps         | 23193        |
| value_loss              | 0.0005487321 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.001706013   |
| ent_coef_loss           | 0.6187607     |
| entropy                 | 0.8953559     |
| episodes                | 68            |
| fps                     | 110           |
| mean 100 episode reward | -2.2          |
| n_updates               | 24439         |
| policy_loss             | -1.1588091    |
| qf1_loss                | 0.00092894014 |
| qf2_loss                | 0.00039843627 |
| time_elapsed            | 221           |
| total timesteps         | 24539         |
| value_loss              | 0.00055685925 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0017070847  |
| ent_coef_loss           | -0.22832763   |
| entropy                 | 0.8774254     |
| episodes                | 72            |
| fps                     | 110           |
| mean 100 episode reward | -2.3          |
| n_updates               | 25727         |
| policy_loss             | -0.9486503    |
| qf1_loss                | 0.00033430866 |
| qf2_loss                | 0.00034855353 |
| time_elapsed            | 233           |
| total timesteps         | 25827         |
| value_loss              | 0.00085565203 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0018111329  |
| ent_coef_loss           | 2.296177      |
| entropy                 | 1.2504332     |
| episodes                | 76            |
| fps                     | 110           |
| mean 100 episode reward | -2.2          |
| n_updates               | 27344         |
| policy_loss             | -0.7773091    |
| qf1_loss                | 0.00033428997 |
| qf2_loss                | 0.00031120307 |
| time_elapsed            | 247           |
| total timesteps         | 27444         |
| value_loss              | 0.00039040577 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.001775983   |
| ent_coef_loss           | 1.889039      |
| entropy                 | 1.0358953     |
| episodes                | 80            |
| fps                     | 110           |
| mean 100 episode reward | -2.1          |
| n_updates               | 28412         |
| policy_loss             | -0.8465992    |
| qf1_loss                | 0.0009672586  |
| qf2_loss                | 0.00095438916 |
| time_elapsed            | 257           |
| total timesteps         | 28512         |
| value_loss              | 0.0004387517  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0014302244  |
| ent_coef_loss           | -2.7252707    |
| entropy                 | 1.2152483     |
| episodes                | 84            |
| fps                     | 110           |
| mean 100 episode reward | -2.1          |
| n_updates               | 30172         |
| policy_loss             | -0.659593     |
| qf1_loss                | 0.00039441738 |
| qf2_loss                | 0.00037281652 |
| time_elapsed            | 273           |
| total timesteps         | 30272         |
| value_loss              | 0.0005580479  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.001214613   |
| ent_coef_loss           | -2.0963857    |
| entropy                 | 0.998533      |
| episodes                | 88            |
| fps                     | 110           |
| mean 100 episode reward | -2.1          |
| n_updates               | 31656         |
| policy_loss             | -0.5866976    |
| qf1_loss                | 0.00021347699 |
| qf2_loss                | 0.00014186838 |
| time_elapsed            | 286           |
| total timesteps         | 31756         |
| value_loss              | 0.0003381344  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0012860915  |
| ent_coef_loss           | 1.5867862     |
| entropy                 | 1.0755458     |
| episodes                | 92            |
| fps                     | 110           |
| mean 100 episode reward | -2.1          |
| n_updates               | 33224         |
| policy_loss             | -0.51281965   |
| qf1_loss                | 0.00018829634 |
| qf2_loss                | 0.00017268443 |
| time_elapsed            | 300           |
| total timesteps         | 33324         |
| value_loss              | 0.00041907417 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.001        |
| ent_coef                | 0.0012148314 |
| ent_coef_loss           | 0.28306806   |
| entropy                 | 1.2713256    |
| episodes                | 96           |
| fps                     | 110          |
| mean 100 episode reward | -2.1         |
| n_updates               | 34298        |
| policy_loss             | -0.4011423   |
| qf1_loss                | 0.0016736977 |
| qf2_loss                | 0.0016271301 |
| time_elapsed            | 310          |
| total timesteps         | 34398        |
| value_loss              | 0.0003782845 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0012773725  |
| ent_coef_loss           | 1.5120124     |
| entropy                 | 1.1814929     |
| episodes                | 100           |
| fps                     | 110           |
| mean 100 episode reward | -2            |
| n_updates               | 35910         |
| policy_loss             | -0.26869392   |
| qf1_loss                | 0.0003442763  |
| qf2_loss                | 0.00047022844 |
| time_elapsed            | 325           |
| total timesteps         | 36010         |
| value_loss              | 0.0002902074  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.001128891   |
| ent_coef_loss           | 0.28478622    |
| entropy                 | 1.1871648     |
| episodes                | 104           |
| fps                     | 110           |
| mean 100 episode reward | -2            |
| n_updates               | 37494         |
| policy_loss             | -0.28556904   |
| qf1_loss                | 0.00018230437 |
| qf2_loss                | 0.0001862698  |
| time_elapsed            | 339           |
| total timesteps         | 37594         |
| value_loss              | 0.00029956218 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0010701992  |
| ent_coef_loss           | -3.8811412    |
| entropy                 | 1.1692492     |
| episodes                | 108           |
| fps                     | 110           |
| mean 100 episode reward | -2            |
| n_updates               | 39254         |
| policy_loss             | -0.234605     |
| qf1_loss                | 6.703532e-05  |
| qf2_loss                | 8.885465e-05  |
| time_elapsed            | 355           |
| total timesteps         | 39354         |
| value_loss              | 0.00019588377 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0009807147  |
| ent_coef_loss           | -2.8924587    |
| entropy                 | 1.3227948     |
| episodes                | 112           |
| fps                     | 110           |
| mean 100 episode reward | -2            |
| n_updates               | 40869         |
| policy_loss             | -0.15850374   |
| qf1_loss                | 0.000131721   |
| qf2_loss                | 7.570573e-05  |
| time_elapsed            | 369           |
| total timesteps         | 40969         |
| value_loss              | 0.00032998828 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0008179699  |
| ent_coef_loss           | 4.315752      |
| entropy                 | 0.9993781     |
| episodes                | 116           |
| fps                     | 110           |
| mean 100 episode reward | -2            |
| n_updates               | 42553         |
| policy_loss             | -0.0074670278 |
| qf1_loss                | 9.560438e-05  |
| qf2_loss                | 8.535372e-05  |
| time_elapsed            | 384           |
| total timesteps         | 42653         |
| value_loss              | 0.00014843735 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00077390013 |
| ent_coef_loss           | -1.0609131    |
| entropy                 | 1.1423306     |
| episodes                | 120           |
| fps                     | 110           |
| mean 100 episode reward | -2.1          |
| n_updates               | 44313         |
| policy_loss             | 0.010883316   |
| qf1_loss                | 0.00087414775 |
| qf2_loss                | 0.0008175432  |
| time_elapsed            | 400           |
| total timesteps         | 44413         |
| value_loss              | 0.00023730249 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00062229176 |
| ent_coef_loss           | 1.4495331     |
| entropy                 | 1.0303674     |
| episodes                | 124           |
| fps                     | 110           |
| mean 100 episode reward | -1.9          |
| n_updates               | 45962         |
| policy_loss             | 0.018136535   |
| qf1_loss                | 0.00012509584 |
| qf2_loss                | 0.00010816171 |
| time_elapsed            | 415           |
| total timesteps         | 46062         |
| value_loss              | 0.00017792432 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005782201  |
| ent_coef_loss           | -2.3401997    |
| entropy                 | 0.7742183     |
| episodes                | 128           |
| fps                     | 110           |
| mean 100 episode reward | -1.9          |
| n_updates               | 47722         |
| policy_loss             | 0.044776283   |
| qf1_loss                | 0.0001231227  |
| qf2_loss                | 0.00012360301 |
| time_elapsed            | 431           |
| total timesteps         | 47822         |
| value_loss              | 0.00016485984 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0006385163  |
| ent_coef_loss           | -4.446816     |
| entropy                 | 1.1281981     |
| episodes                | 132           |
| fps                     | 110           |
| mean 100 episode reward | -1.8          |
| n_updates               | 49482         |
| policy_loss             | 0.06448065    |
| qf1_loss                | 0.00017686565 |
| qf2_loss                | 9.341948e-05  |
| time_elapsed            | 447           |
| total timesteps         | 49582         |
| value_loss              | 8.3462735e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00055852294 |
| ent_coef_loss           | -4.372798     |
| entropy                 | 0.97234976    |
| episodes                | 136           |
| fps                     | 110           |
| mean 100 episode reward | -1.8          |
| n_updates               | 51242         |
| policy_loss             | 0.08484995    |
| qf1_loss                | 5.139452e-05  |
| qf2_loss                | 5.3201955e-05 |
| time_elapsed            | 463           |
| total timesteps         | 51342         |
| value_loss              | 7.2283336e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005005035  |
| ent_coef_loss           | 1.771309      |
| entropy                 | 0.6821779     |
| episodes                | 140           |
| fps                     | 110           |
| mean 100 episode reward | -1.8          |
| n_updates               | 52134         |
| policy_loss             | 0.08924927    |
| qf1_loss                | 0.00011762287 |
| qf2_loss                | 0.00016302361 |
| time_elapsed            | 471           |
| total timesteps         | 52234         |
| value_loss              | 0.0002669944  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004827454  |
| ent_coef_loss           | -0.5076225    |
| entropy                 | 0.78614694    |
| episodes                | 144           |
| fps                     | 110           |
| mean 100 episode reward | -1.9          |
| n_updates               | 53894         |
| policy_loss             | 0.13229083    |
| qf1_loss                | 9.3971204e-05 |
| qf2_loss                | 5.9202e-05    |
| time_elapsed            | 488           |
| total timesteps         | 53994         |
| value_loss              | 0.00015859894 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00047708576 |
| ent_coef_loss           | 4.411502      |
| entropy                 | 0.9893906     |
| episodes                | 148           |
| fps                     | 110           |
| mean 100 episode reward | -1.8          |
| n_updates               | 55341         |
| policy_loss             | 0.17875001    |
| qf1_loss                | 0.00011711307 |
| qf2_loss                | 8.440296e-05  |
| time_elapsed            | 501           |
| total timesteps         | 55441         |
| value_loss              | 0.00021213232 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0005109122  |
| ent_coef_loss           | -2.7946022    |
| entropy                 | 0.9225801     |
| episodes                | 152           |
| fps                     | 110           |
| mean 100 episode reward | -1.8          |
| n_updates               | 57101         |
| policy_loss             | 0.18863317    |
| qf1_loss                | 9.54743e-05   |
| qf2_loss                | 6.176014e-05  |
| time_elapsed            | 517           |
| total timesteps         | 57201         |
| value_loss              | 0.00014550111 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00044478232 |
| ent_coef_loss           | -2.2419856    |
| entropy                 | 0.88141257    |
| episodes                | 156           |
| fps                     | 110           |
| mean 100 episode reward | -1.7          |
| n_updates               | 58861         |
| policy_loss             | 0.14199486    |
| qf1_loss                | 8.001852e-05  |
| qf2_loss                | 7.8030906e-05 |
| time_elapsed            | 533           |
| total timesteps         | 58961         |
| value_loss              | 0.00012780569 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00044818575 |
| ent_coef_loss           | -3.4967732    |
| entropy                 | 0.96473813    |
| episodes                | 160           |
| fps                     | 110           |
| mean 100 episode reward | -1.6          |
| n_updates               | 60413         |
| policy_loss             | 0.18370382    |
| qf1_loss                | 8.936283e-05  |
| qf2_loss                | 5.9388844e-05 |
| time_elapsed            | 547           |
| total timesteps         | 60513         |
| value_loss              | 0.00010063869 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004190241  |
| ent_coef_loss           | 4.2228894     |
| entropy                 | 1.0138084     |
| episodes                | 164           |
| fps                     | 110           |
| mean 100 episode reward | -1.5          |
| n_updates               | 62173         |
| policy_loss             | 0.19981305    |
| qf1_loss                | 0.0009407863  |
| qf2_loss                | 0.001236946   |
| time_elapsed            | 563           |
| total timesteps         | 62273         |
| value_loss              | 0.00014404044 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00044886436 |
| ent_coef_loss           | 0.63516223    |
| entropy                 | 1.1123636     |
| episodes                | 168           |
| fps                     | 110           |
| mean 100 episode reward | -1.5          |
| n_updates               | 63933         |
| policy_loss             | 0.21213886    |
| qf1_loss                | 0.00014625995 |
| qf2_loss                | 9.628206e-05  |
| time_elapsed            | 579           |
| total timesteps         | 64033         |
| value_loss              | 0.00019002009 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0003920551  |
| ent_coef_loss           | 1.0079063     |
| entropy                 | 0.7382059     |
| episodes                | 172           |
| fps                     | 110           |
| mean 100 episode reward | -1.4          |
| n_updates               | 64990         |
| policy_loss             | 0.20896333    |
| qf1_loss                | 7.0502254e-05 |
| qf2_loss                | 5.588414e-05  |
| time_elapsed            | 588           |
| total timesteps         | 65090         |
| value_loss              | 8.677003e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0003969831  |
| ent_coef_loss           | -4.4675407    |
| entropy                 | 1.0829358     |
| episodes                | 176           |
| fps                     | 110           |
| mean 100 episode reward | -1.5          |
| n_updates               | 66750         |
| policy_loss             | 0.21179642    |
| qf1_loss                | 0.00032181127 |
| qf2_loss                | 0.00028643248 |
| time_elapsed            | 604           |
| total timesteps         | 66850         |
| value_loss              | 5.7006175e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0003651053  |
| ent_coef_loss           | 1.0153729     |
| entropy                 | 0.94435775    |
| episodes                | 180           |
| fps                     | 110           |
| mean 100 episode reward | -1.5          |
| n_updates               | 68510         |
| policy_loss             | 0.22226262    |
| qf1_loss                | 5.5145003e-05 |
| qf2_loss                | 6.8767185e-05 |
| time_elapsed            | 620           |
| total timesteps         | 68610         |
| value_loss              | 0.0001088548  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00036849178 |
| ent_coef_loss           | 0.248451      |
| entropy                 | 0.7806129     |
| episodes                | 184           |
| fps                     | 110           |
| mean 100 episode reward | -1.4          |
| n_updates               | 70010         |
| policy_loss             | 0.22557583    |
| qf1_loss                | 4.0373172e-05 |
| qf2_loss                | 2.9334731e-05 |
| time_elapsed            | 634           |
| total timesteps         | 70110         |
| value_loss              | 9.8688906e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00035947163 |
| ent_coef_loss           | -1.345962     |
| entropy                 | 0.81134725    |
| episodes                | 188           |
| fps                     | 110           |
| mean 100 episode reward | -1.4          |
| n_updates               | 71622         |
| policy_loss             | 0.20995161    |
| qf1_loss                | 4.4813994e-05 |
| qf2_loss                | 3.4747387e-05 |
| time_elapsed            | 648           |
| total timesteps         | 71722         |
| value_loss              | 6.574114e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00033598722 |
| ent_coef_loss           | -0.5498886    |
| entropy                 | 0.6412269     |
| episodes                | 192           |
| fps                     | 110           |
| mean 100 episode reward | -1.4          |
| n_updates               | 73382         |
| policy_loss             | 0.20331566    |
| qf1_loss                | 0.0001123678  |
| qf2_loss                | 9.9853656e-05 |
| time_elapsed            | 664           |
| total timesteps         | 73482         |
| value_loss              | 6.926432e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0003363168  |
| ent_coef_loss           | -4.1650386    |
| entropy                 | 1.0785123     |
| episodes                | 196           |
| fps                     | 110           |
| mean 100 episode reward | -1.3          |
| n_updates               | 74963         |
| policy_loss             | 0.17084584    |
| qf1_loss                | 5.539349e-05  |
| qf2_loss                | 4.0961917e-05 |
| time_elapsed            | 679           |
| total timesteps         | 75063         |
| value_loss              | 6.832224e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00037977405 |
| ent_coef_loss           | -2.865872     |
| entropy                 | 1.0212181     |
| episodes                | 200           |
| fps                     | 110           |
| mean 100 episode reward | -1.4          |
| n_updates               | 76426         |
| policy_loss             | 0.17507356    |
| qf1_loss                | 9.968766e-05  |
| qf2_loss                | 7.910593e-05  |
| time_elapsed            | 692           |
| total timesteps         | 76526         |
| value_loss              | 0.00015434397 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00040866932 |
| ent_coef_loss           | 0.6264057     |
| entropy                 | 0.75952995    |
| episodes                | 204           |
| fps                     | 110           |
| mean 100 episode reward | -1.4          |
| n_updates               | 77917         |
| policy_loss             | 0.20558032    |
| qf1_loss                | 9.867513e-05  |
| qf2_loss                | 8.182663e-05  |
| time_elapsed            | 705           |
| total timesteps         | 78017         |
| value_loss              | 0.00012745374 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004128469  |
| ent_coef_loss           | -3.7088444    |
| entropy                 | 1.1691769     |
| episodes                | 208           |
| fps                     | 110           |
| mean 100 episode reward | -1.4          |
| n_updates               | 78801         |
| policy_loss             | 0.157074      |
| qf1_loss                | 2.8038494e-05 |
| qf2_loss                | 3.1558404e-05 |
| time_elapsed            | 714           |
| total timesteps         | 78901         |
| value_loss              | 4.3366566e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0003489264  |
| ent_coef_loss           | 2.4440973     |
| entropy                 | 0.7348832     |
| episodes                | 212           |
| fps                     | 110           |
| mean 100 episode reward | -1.4          |
| n_updates               | 80561         |
| policy_loss             | 0.2099784     |
| qf1_loss                | 5.79576e-05   |
| qf2_loss                | 5.0088656e-05 |
| time_elapsed            | 730           |
| total timesteps         | 80661         |
| value_loss              | 0.00013453868 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00037059523 |
| ent_coef_loss           | 0.7914264     |
| entropy                 | 0.9002279     |
| episodes                | 216           |
| fps                     | 110           |
| mean 100 episode reward | -1.3          |
| n_updates               | 82030         |
| policy_loss             | 0.17285112    |
| qf1_loss                | 0.0002743577  |
| qf2_loss                | 0.00015532444 |
| time_elapsed            | 743           |
| total timesteps         | 82130         |
| value_loss              | 0.00019945343 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00042384292 |
| ent_coef_loss           | -0.32297015   |
| entropy                 | 0.67340004    |
| episodes                | 220           |
| fps                     | 110           |
| mean 100 episode reward | -1.3          |
| n_updates               | 83214         |
| policy_loss             | 0.20629048    |
| qf1_loss                | 4.8749083e-05 |
| qf2_loss                | 7.2781724e-05 |
| time_elapsed            | 754           |
| total timesteps         | 83314         |
| value_loss              | 7.551357e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00034633372 |
| ent_coef_loss           | 2.473995      |
| entropy                 | 0.60679734    |
| episodes                | 224           |
| fps                     | 110           |
| mean 100 episode reward | -1.2          |
| n_updates               | 84974         |
| policy_loss             | 0.21226117    |
| qf1_loss                | 6.584258e-05  |
| qf2_loss                | 6.1236344e-05 |
| time_elapsed            | 770           |
| total timesteps         | 85074         |
| value_loss              | 0.00010564969 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004229302  |
| ent_coef_loss           | -3.745491     |
| entropy                 | 1.0772132     |
| episodes                | 228           |
| fps                     | 110           |
| mean 100 episode reward | -1.2          |
| n_updates               | 86734         |
| policy_loss             | 0.1470006     |
| qf1_loss                | 0.00010548528 |
| qf2_loss                | 2.9126015e-05 |
| time_elapsed            | 786           |
| total timesteps         | 86834         |
| value_loss              | 5.1279316e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0003613278  |
| ent_coef_loss           | 0.8736758     |
| entropy                 | 1.2618303     |
| episodes                | 232           |
| fps                     | 110           |
| mean 100 episode reward | -1.2          |
| n_updates               | 88155         |
| policy_loss             | 0.18676233    |
| qf1_loss                | 0.0002073091  |
| qf2_loss                | 0.00030554834 |
| time_elapsed            | 799           |
| total timesteps         | 88255         |
| value_loss              | 0.00011670515 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00037906156 |
| ent_coef_loss           | -5.4146967    |
| entropy                 | 0.9796306     |
| episodes                | 236           |
| fps                     | 110           |
| mean 100 episode reward | -1.2          |
| n_updates               | 89863         |
| policy_loss             | 0.16051924    |
| qf1_loss                | 3.4344484e-05 |
| qf2_loss                | 2.2517084e-05 |
| time_elapsed            | 814           |
| total timesteps         | 89963         |
| value_loss              | 6.773586e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00044635497 |
| ent_coef_loss           | -0.3997836    |
| entropy                 | 0.73941964    |
| episodes                | 240           |
| fps                     | 110           |
| mean 100 episode reward | -1.2          |
| n_updates               | 91623         |
| policy_loss             | 0.17251234    |
| qf1_loss                | 6.205622e-05  |
| qf2_loss                | 3.378871e-05  |
| time_elapsed            | 831           |
| total timesteps         | 91723         |
| value_loss              | 5.6671895e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00043130157 |
| ent_coef_loss           | -0.97663814   |
| entropy                 | 0.87687504    |
| episodes                | 244           |
| fps                     | 110           |
| mean 100 episode reward | -1.1          |
| n_updates               | 92704         |
| policy_loss             | 0.1659807     |
| qf1_loss                | 2.9881574e-05 |
| qf2_loss                | 3.4617115e-05 |
| time_elapsed            | 842           |
| total timesteps         | 92804         |
| value_loss              | 7.185199e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00038767772 |
| ent_coef_loss           | 6.286848      |
| entropy                 | 0.80187273    |
| episodes                | 248           |
| fps                     | 110           |
| mean 100 episode reward | -1.1          |
| n_updates               | 94464         |
| policy_loss             | 0.1689103     |
| qf1_loss                | 6.227923e-05  |
| qf2_loss                | 6.5937085e-05 |
| time_elapsed            | 858           |
| total timesteps         | 94564         |
| value_loss              | 5.6784804e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00033079606 |
| ent_coef_loss           | -0.5994383    |
| entropy                 | 0.80539525    |
| episodes                | 252           |
| fps                     | 110           |
| mean 100 episode reward | -1.1          |
| n_updates               | 96126         |
| policy_loss             | 0.14976195    |
| qf1_loss                | 5.184987e-05  |
| qf2_loss                | 4.2441286e-05 |
| time_elapsed            | 874           |
| total timesteps         | 96226         |
| value_loss              | 6.863597e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00038824102 |
| ent_coef_loss           | 0.35919487    |
| entropy                 | 0.8727598     |
| episodes                | 256           |
| fps                     | 109           |
| mean 100 episode reward | -1.1          |
| n_updates               | 97594         |
| policy_loss             | 0.13218181    |
| qf1_loss                | 0.00041413694 |
| qf2_loss                | 0.0004158431  |
| time_elapsed            | 888           |
| total timesteps         | 97694         |
| value_loss              | 4.3694705e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00038111792 |
| ent_coef_loss           | 0.4269693     |
| entropy                 | 0.9469237     |
| episodes                | 260           |
| fps                     | 109           |
| mean 100 episode reward | -1.1          |
| n_updates               | 99354         |
| policy_loss             | 0.17050777    |
| qf1_loss                | 6.5728396e-05 |
| qf2_loss                | 5.6271387e-05 |
| time_elapsed            | 905           |
| total timesteps         | 99454         |
| value_loss              | 0.00010997877 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.000353758   |
| ent_coef_loss           | -2.591494     |
| entropy                 | 0.77530956    |
| episodes                | 264           |
| fps                     | 109           |
| mean 100 episode reward | -1.2          |
| n_updates               | 100823        |
| policy_loss             | 0.16892715    |
| qf1_loss                | 0.00024171159 |
| qf2_loss                | 0.00027916214 |
| time_elapsed            | 919           |
| total timesteps         | 100923        |
| value_loss              | 0.0001407112  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00033394707 |
| ent_coef_loss           | -3.1323516    |
| entropy                 | 0.83652246    |
| episodes                | 268           |
| fps                     | 109           |
| mean 100 episode reward | -1.1          |
| n_updates               | 102583        |
| policy_loss             | 0.16930124    |
| qf1_loss                | 7.718386e-05  |
| qf2_loss                | 5.5534536e-05 |
| time_elapsed            | 936           |
| total timesteps         | 102683        |
| value_loss              | 5.805373e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00032939046 |
| ent_coef_loss           | 1.5314809     |
| entropy                 | 0.83867794    |
| episodes                | 272           |
| fps                     | 109           |
| mean 100 episode reward | -1.2          |
| n_updates               | 103931        |
| policy_loss             | 0.14698154    |
| qf1_loss                | 2.8840836e-05 |
| qf2_loss                | 4.3454056e-05 |
| time_elapsed            | 949           |
| total timesteps         | 104031        |
| value_loss              | 0.00015198291 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00033707023 |
| ent_coef_loss           | 3.7311554     |
| entropy                 | 0.5708977     |
| episodes                | 276           |
| fps                     | 109           |
| mean 100 episode reward | -1.2          |
| n_updates               | 105582        |
| policy_loss             | 0.19620916    |
| qf1_loss                | 7.9419144e-05 |
| qf2_loss                | 7.111997e-05  |
| time_elapsed            | 964           |
| total timesteps         | 105682        |
| value_loss              | 6.379542e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00038760784 |
| ent_coef_loss           | -5.7242184    |
| entropy                 | 0.57197857    |
| episodes                | 280           |
| fps                     | 109           |
| mean 100 episode reward | -1.2          |
| n_updates               | 107052        |
| policy_loss             | 0.14347997    |
| qf1_loss                | 2.3904333e-05 |
| qf2_loss                | 3.5493227e-05 |
| time_elapsed            | 978           |
| total timesteps         | 107152        |
| value_loss              | 4.7348134e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00040404534 |
| ent_coef_loss           | -1.265597     |
| entropy                 | 0.6830827     |
| episodes                | 284           |
| fps                     | 109           |
| mean 100 episode reward | -1.2          |
| n_updates               | 108812        |
| policy_loss             | 0.13568357    |
| qf1_loss                | 6.6054505e-05 |
| qf2_loss                | 6.0148708e-05 |
| time_elapsed            | 996           |
| total timesteps         | 108912        |
| value_loss              | 5.482299e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00041189697 |
| ent_coef_loss           | 2.2635581     |
| entropy                 | 0.77447426    |
| episodes                | 288           |
| fps                     | 109           |
| mean 100 episode reward | -1.2          |
| n_updates               | 110056        |
| policy_loss             | 0.17212456    |
| qf1_loss                | 0.00014920397 |
| qf2_loss                | 0.00016885248 |
| time_elapsed            | 1008          |
| total timesteps         | 110156        |
| value_loss              | 6.822198e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.001          |
| ent_coef                | 0.00043622355  |
| ent_coef_loss           | 3.325055       |
| entropy                 | 0.8953825      |
| episodes                | 292            |
| fps                     | 109            |
| mean 100 episode reward | -1.2           |
| n_updates               | 111816         |
| policy_loss             | 0.14726205     |
| qf1_loss                | 9.00107e-05    |
| qf2_loss                | 8.7148044e-05  |
| time_elapsed            | 1024           |
| total timesteps         | 111916         |
| value_loss              | 0.000107812855 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00038886542 |
| ent_coef_loss           | 2.7409542     |
| entropy                 | 0.8907782     |
| episodes                | 296           |
| fps                     | 109           |
| mean 100 episode reward | -1.1          |
| n_updates               | 113576        |
| policy_loss             | 0.1354457     |
| qf1_loss                | 2.7372227e-05 |
| qf2_loss                | 2.3399532e-05 |
| time_elapsed            | 1041          |
| total timesteps         | 113676        |
| value_loss              | 3.9451945e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.000371581   |
| ent_coef_loss           | 5.51428       |
| entropy                 | 0.8988339     |
| episodes                | 300           |
| fps                     | 109           |
| mean 100 episode reward | -1.2          |
| n_updates               | 114909        |
| policy_loss             | 0.15535927    |
| qf1_loss                | 0.00011735264 |
| qf2_loss                | 4.8017733e-05 |
| time_elapsed            | 1054          |
| total timesteps         | 115009        |
| value_loss              | 8.207222e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.00041677195 |
| ent_coef_loss           | 4.603425      |
| entropy                 | 0.91748387    |
| episodes                | 304           |
| fps                     | 109           |
| mean 100 episode reward | -1.2          |
| n_updates               | 116610        |
| policy_loss             | 0.16192472    |
| qf1_loss                | 6.5176464e-05 |
| qf2_loss                | 6.354637e-05  |
| time_elapsed            | 1069          |
| total timesteps         | 116710        |
| value_loss              | 0.0001417728  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004852534  |
| ent_coef_loss           | -3.059498     |
| entropy                 | 0.79037255    |
| episodes                | 308           |
| fps                     | 109           |
| mean 100 episode reward | -1.1          |
| n_updates               | 118368        |
| policy_loss             | 0.11822052    |
| qf1_loss                | 0.00013535202 |
| qf2_loss                | 0.00011547926 |
| time_elapsed            | 1086          |
| total timesteps         | 118468        |
| value_loss              | 8.226228e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004342012  |
| ent_coef_loss           | 4.676056      |
| entropy                 | 0.7262603     |
| episodes                | 312           |
| fps                     | 109           |
| mean 100 episode reward | -1.1          |
| n_updates               | 120128        |
| policy_loss             | 0.1881583     |
| qf1_loss                | 0.003341279   |
| qf2_loss                | 0.0033533475  |
| time_elapsed            | 1102          |
| total timesteps         | 120228        |
| value_loss              | 0.00011106281 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.001         |
| ent_coef                | 0.0004867168  |
| ent_coef_loss           | -3.2203565    |
| entropy                 | 0.82636887    |
| episodes                | 316           |
| fps                     | 108           |
| mean 100 episode reward | -1.2          |
| n_updates               | 121888        |
| policy_loss             | 0.13172287    |
| qf1_loss                | 2.0929136e-05 |
| qf2_loss                | 2.3279208e-05 |
| time_elapsed            | 1119          |
| total timesteps         | 121988        |
| value_loss              | 2.2962251e-05 |
-------------------------------------------
