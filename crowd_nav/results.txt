pygame 1.9.6
Hello from the pygame community. https://www.pygame.org/contribute.html
Loading chipmunk for Linux (64bit) [/usr/local/lib/python3.5/dist-packages/pymunk/libchipmunk.so]
Namespace(env_config='configs/env.config', policy='multi_human_rl', policy_config='configs/policy.config', pre_train=False, test=False, train_config='configs/train.config', visualize=False, weights=None)
Gym environment created.
----------------------------------------
| current_lr              | 0.0001     |
| ent_coef                | 0.6382308  |
| ent_coef_loss           | -1.4842896 |
| entropy                 | 2.6740704  |
| episodes                | 10         |
| fps                     | 207        |
| mean 100 episode reward | -2.5       |
| n_updates               | 4492       |
| policy_loss             | -19.118935 |
| qf1_loss                | 1.497148   |
| qf2_loss                | 1.5031333  |
| time_elapsed            | 22         |
| total timesteps         | 4592       |
| value_loss              | 0.07249573 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0001     |
| ent_coef                | 0.4220787  |
| ent_coef_loss           | -2.8264184 |
| entropy                 | 2.6127794  |
| episodes                | 20         |
| fps                     | 210        |
| mean 100 episode reward | -1.9       |
| n_updates               | 8639       |
| policy_loss             | -26.321362 |
| qf1_loss                | 0.08892191 |
| qf2_loss                | 0.08762003 |
| time_elapsed            | 41         |
| total timesteps         | 8739       |
| value_loss              | 0.09561289 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0001      |
| ent_coef                | 0.27493325  |
| ent_coef_loss           | -4.117475   |
| entropy                 | 2.476617    |
| episodes                | 30          |
| fps                     | 211         |
| mean 100 episode reward | -1.8        |
| n_updates               | 12950       |
| policy_loss             | -27.0038    |
| qf1_loss                | 0.07237731  |
| qf2_loss                | 0.071760766 |
| time_elapsed            | 61          |
| total timesteps         | 13050       |
| value_loss              | 0.22265834  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0001      |
| ent_coef                | 0.17891847  |
| ent_coef_loss           | -5.0823536  |
| entropy                 | 2.3757024   |
| episodes                | 40          |
| fps                     | 211         |
| mean 100 episode reward | -1.9        |
| n_updates               | 17297       |
| policy_loss             | -25.211128  |
| qf1_loss                | 0.15616475  |
| qf2_loss                | 0.15800038  |
| time_elapsed            | 82          |
| total timesteps         | 17397       |
| value_loss              | 0.047464974 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0001      |
| ent_coef                | 0.11463987  |
| ent_coef_loss           | -5.966339   |
| entropy                 | 2.13421     |
| episodes                | 50          |
| fps                     | 208         |
| mean 100 episode reward | -1.8        |
| n_updates               | 21816       |
| policy_loss             | -22.311848  |
| qf1_loss                | 0.0600454   |
| qf2_loss                | 0.063339844 |
| time_elapsed            | 105         |
| total timesteps         | 21916       |
| value_loss              | 0.035609894 |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0001     |
| ent_coef                | 0.07341287 |
| ent_coef_loss           | -6.3298078 |
| entropy                 | 2.255755   |
| episodes                | 60         |
| fps                     | 207        |
| mean 100 episode reward | -1.8       |
| n_updates               | 26360      |
| policy_loss             | -18.82872  |
| qf1_loss                | 3.2362518  |
| qf2_loss                | 3.425486   |
| time_elapsed            | 127        |
| total timesteps         | 26460      |
| value_loss              | 0.05789791 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0001      |
| ent_coef                | 0.05324745  |
| ent_coef_loss           | -6.8187094  |
| entropy                 | 2.1034708   |
| episodes                | 70          |
| fps                     | 207         |
| mean 100 episode reward | -1.8        |
| n_updates               | 29654       |
| policy_loss             | -16.93577   |
| qf1_loss                | 0.030763637 |
| qf2_loss                | 0.022318367 |
| time_elapsed            | 143         |
| total timesteps         | 29754       |
| value_loss              | 0.014305697 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0001      |
| ent_coef                | 0.031802602 |
| ent_coef_loss           | -7.61024    |
| entropy                 | 2.0798268   |
| episodes                | 80          |
| fps                     | 206         |
| mean 100 episode reward | -1.9        |
| n_updates               | 34964       |
| policy_loss             | -12.983469  |
| qf1_loss                | 0.017393114 |
| qf2_loss                | 0.024665004 |
| time_elapsed            | 169         |
| total timesteps         | 35064       |
| value_loss              | 0.01081434  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0001      |
| ent_coef                | 0.0175083   |
| ent_coef_loss           | -6.8340235  |
| entropy                 | 1.8844268   |
| episodes                | 90          |
| fps                     | 204         |
| mean 100 episode reward | -1.9        |
| n_updates               | 41317       |
| policy_loss             | -9.604949   |
| qf1_loss                | 0.017395338 |
| qf2_loss                | 0.023392443 |
| time_elapsed            | 202         |
| total timesteps         | 41417       |
| value_loss              | 0.010018388 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.01068885   |
| ent_coef_loss           | -2.1913283   |
| entropy                 | 1.4182096    |
| episodes                | 100          |
| fps                     | 204          |
| mean 100 episode reward | -1.9         |
| n_updates               | 47125        |
| policy_loss             | -7.1404567   |
| qf1_loss                | 0.008446169  |
| qf2_loss                | 0.00945556   |
| time_elapsed            | 230          |
| total timesteps         | 47225        |
| value_loss              | 0.0074693123 |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0001      |
| ent_coef                | 0.008960206 |
| ent_coef_loss           | -1.6552278  |
| entropy                 | 1.399303    |
| episodes                | 110         |
| fps                     | 203         |
| mean 100 episode reward | -1.6        |
| n_updates               | 51381       |
| policy_loss             | -6.368783   |
| qf1_loss                | 0.023401879 |
| qf2_loss                | 0.018026087 |
| time_elapsed            | 252         |
| total timesteps         | 51481       |
| value_loss              | 0.005279556 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0065822173 |
| ent_coef_loss           | -2.0451427   |
| entropy                 | 1.2018002    |
| episodes                | 120          |
| fps                     | 203          |
| mean 100 episode reward | -1.5         |
| n_updates               | 58105        |
| policy_loss             | -4.439882    |
| qf1_loss                | 0.050290093  |
| qf2_loss                | 0.06284522   |
| time_elapsed            | 286          |
| total timesteps         | 58205        |
| value_loss              | 0.0036632633 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.005707035  |
| ent_coef_loss           | -4.827145    |
| entropy                 | 1.2934678    |
| episodes                | 130          |
| fps                     | 203          |
| mean 100 episode reward | -1.5         |
| n_updates               | 65266        |
| policy_loss             | -3.4985769   |
| qf1_loss                | 0.0031275474 |
| qf2_loss                | 0.0028686693 |
| time_elapsed            | 321          |
| total timesteps         | 65366        |
| value_loss              | 0.003380585  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.004524528  |
| ent_coef_loss           | 1.5121005    |
| entropy                 | 0.9865854    |
| episodes                | 140          |
| fps                     | 203          |
| mean 100 episode reward | -1.4         |
| n_updates               | 71101        |
| policy_loss             | -2.5440977   |
| qf1_loss                | 0.0035169006 |
| qf2_loss                | 0.0061097927 |
| time_elapsed            | 350          |
| total timesteps         | 71201        |
| value_loss              | 0.002464967  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.004417147  |
| ent_coef_loss           | 2.7108588    |
| entropy                 | 1.3505514    |
| episodes                | 150          |
| fps                     | 202          |
| mean 100 episode reward | -1.5         |
| n_updates               | 76736        |
| policy_loss             | -1.8928087   |
| qf1_loss                | 0.003359732  |
| qf2_loss                | 0.0032580253 |
| time_elapsed            | 378          |
| total timesteps         | 76836        |
| value_loss              | 0.0015098245 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0036504632 |
| ent_coef_loss           | -1.8345261   |
| entropy                 | 1.4192879    |
| episodes                | 160          |
| fps                     | 202          |
| mean 100 episode reward | -1.7         |
| n_updates               | 81373        |
| policy_loss             | -1.5031459   |
| qf1_loss                | 0.018159086  |
| qf2_loss                | 0.01695157   |
| time_elapsed            | 402          |
| total timesteps         | 81473        |
| value_loss              | 0.0016300688 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.002814115   |
| ent_coef_loss           | 0.36185586    |
| entropy                 | 1.2877817     |
| episodes                | 170           |
| fps                     | 202           |
| mean 100 episode reward | -1.6          |
| n_updates               | 87679         |
| policy_loss             | -1.0002135    |
| qf1_loss                | 0.0012604271  |
| qf2_loss                | 0.0010970656  |
| time_elapsed            | 433           |
| total timesteps         | 87779         |
| value_loss              | 0.00075882324 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.002636514   |
| ent_coef_loss           | -0.5410514    |
| entropy                 | 1.1123486     |
| episodes                | 180           |
| fps                     | 202           |
| mean 100 episode reward | -1.5          |
| n_updates               | 91083         |
| policy_loss             | -0.7575214    |
| qf1_loss                | 0.00083621324 |
| qf2_loss                | 0.0012684584  |
| time_elapsed            | 449           |
| total timesteps         | 91183         |
| value_loss              | 0.0006932097  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0019211005 |
| ent_coef_loss           | 0.28479636   |
| entropy                 | 0.8441366    |
| episodes                | 190          |
| fps                     | 202          |
| mean 100 episode reward | -1.4         |
| n_updates               | 96423        |
| policy_loss             | -0.53523684  |
| qf1_loss                | 0.001746102  |
| qf2_loss                | 0.0018324642 |
| time_elapsed            | 476          |
| total timesteps         | 96523        |
| value_loss              | 0.000546776  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0016239854 |
| ent_coef_loss           | -0.43024504  |
| entropy                 | 0.78307974   |
| episodes                | 200          |
| fps                     | 202          |
| mean 100 episode reward | -1.3         |
| n_updates               | 100894       |
| policy_loss             | -0.3369538   |
| qf1_loss                | 0.001564212  |
| qf2_loss                | 0.0021552264 |
| time_elapsed            | 499          |
| total timesteps         | 100994       |
| value_loss              | 0.0008127813 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0014569227 |
| ent_coef_loss           | 0.9726506    |
| entropy                 | 0.7111796    |
| episodes                | 210          |
| fps                     | 202          |
| mean 100 episode reward | -1.5         |
| n_updates               | 106534       |
| policy_loss             | -0.2087828   |
| qf1_loss                | 0.0009957015 |
| qf2_loss                | 0.0009432575 |
| time_elapsed            | 527          |
| total timesteps         | 106634       |
| value_loss              | 0.0007599478 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001235407   |
| ent_coef_loss           | 0.15848935    |
| entropy                 | 0.8015587     |
| episodes                | 220           |
| fps                     | 202           |
| mean 100 episode reward | -1.6          |
| n_updates               | 111474        |
| policy_loss             | 0.122906715   |
| qf1_loss                | 0.00016865204 |
| qf2_loss                | 0.00025683333 |
| time_elapsed            | 551           |
| total timesteps         | 111574        |
| value_loss              | 0.00032476775 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001079292   |
| ent_coef_loss           | -0.079558134  |
| entropy                 | 0.67056143    |
| episodes                | 230           |
| fps                     | 201           |
| mean 100 episode reward | -1.7          |
| n_updates               | 117578        |
| policy_loss             | 0.13946848    |
| qf1_loss                | 0.007132421   |
| qf2_loss                | 0.00650516    |
| time_elapsed            | 582           |
| total timesteps         | 117678        |
| value_loss              | 0.00053692027 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00089098426 |
| ent_coef_loss           | -3.0305338    |
| entropy                 | 0.63258964    |
| episodes                | 240           |
| fps                     | 201           |
| mean 100 episode reward | -1.6          |
| n_updates               | 123039        |
| policy_loss             | 0.19410986    |
| qf1_loss                | 0.00020140244 |
| qf2_loss                | 0.00021484848 |
| time_elapsed            | 609           |
| total timesteps         | 123139        |
| value_loss              | 0.00013558919 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0008660487 |
| ent_coef_loss           | -1.1062332   |
| entropy                 | 0.26164722   |
| episodes                | 250          |
| fps                     | 201          |
| mean 100 episode reward | -1.4         |
| n_updates               | 128101       |
| policy_loss             | 0.19943705   |
| qf1_loss                | 0.0026272878 |
| qf2_loss                | 0.0010949769 |
| time_elapsed            | 635          |
| total timesteps         | 128201       |
| value_loss              | 0.0002390852 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007452955  |
| ent_coef_loss           | -2.5629478    |
| entropy                 | 0.21069612    |
| episodes                | 260           |
| fps                     | 201           |
| mean 100 episode reward | -1.1          |
| n_updates               | 134615        |
| policy_loss             | 0.1743645     |
| qf1_loss                | 0.00033458526 |
| qf2_loss                | 0.00025456276 |
| time_elapsed            | 667           |
| total timesteps         | 134715        |
| value_loss              | 0.00022020293 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007142153  |
| ent_coef_loss           | 2.5445652     |
| entropy                 | 0.2922132     |
| episodes                | 270           |
| fps                     | 201           |
| mean 100 episode reward | -1            |
| n_updates               | 141074        |
| policy_loss             | 0.14683393    |
| qf1_loss                | 0.00021142105 |
| qf2_loss                | 0.00021521638 |
| time_elapsed            | 699           |
| total timesteps         | 141174        |
| value_loss              | 0.00013211396 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0006910084  |
| ent_coef_loss           | 1.1421041     |
| entropy                 | 0.3142959     |
| episodes                | 280           |
| fps                     | 201           |
| mean 100 episode reward | -1            |
| n_updates               | 145613        |
| policy_loss             | 0.17221935    |
| qf1_loss                | 0.00010671806 |
| qf2_loss                | 0.00010038861 |
| time_elapsed            | 721           |
| total timesteps         | 145713        |
| value_loss              | 8.841946e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007115374  |
| ent_coef_loss           | 0.98330057    |
| entropy                 | 0.29065198    |
| episodes                | 290           |
| fps                     | 201           |
| mean 100 episode reward | -1            |
| n_updates               | 151838        |
| policy_loss             | 0.16274676    |
| qf1_loss                | 0.00025002565 |
| qf2_loss                | 0.00028892382 |
| time_elapsed            | 752           |
| total timesteps         | 151938        |
| value_loss              | 9.393298e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007479717  |
| ent_coef_loss           | -0.5637518    |
| entropy                 | 0.5022688     |
| episodes                | 300           |
| fps                     | 202           |
| mean 100 episode reward | -0.9          |
| n_updates               | 157930        |
| policy_loss             | 0.13495748    |
| qf1_loss                | 0.00018765804 |
| qf2_loss                | 0.00010988649 |
| time_elapsed            | 782           |
| total timesteps         | 158030        |
| value_loss              | 8.794556e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007702583  |
| ent_coef_loss           | -1.2401402    |
| entropy                 | 0.4574566     |
| episodes                | 310           |
| fps                     | 202           |
| mean 100 episode reward | -0.7          |
| n_updates               | 161330        |
| policy_loss             | 0.13160063    |
| qf1_loss                | 0.00011060688 |
| qf2_loss                | 9.70972e-05   |
| time_elapsed            | 798           |
| total timesteps         | 161430        |
| value_loss              | 0.00012282075 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00076932414 |
| ent_coef_loss           | -3.7351673    |
| entropy                 | 0.5622885     |
| episodes                | 320           |
| fps                     | 201           |
| mean 100 episode reward | -0.7          |
| n_updates               | 166250        |
| policy_loss             | 0.11338404    |
| qf1_loss                | 0.00014660126 |
| qf2_loss                | 0.00011203793 |
| time_elapsed            | 823           |
| total timesteps         | 166350        |
| value_loss              | 6.6117165e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007276493  |
| ent_coef_loss           | 1.2113667     |
| entropy                 | 0.41441682    |
| episodes                | 330           |
| fps                     | 201           |
| mean 100 episode reward | -0.5          |
| n_updates               | 171868        |
| policy_loss             | 0.111385144   |
| qf1_loss                | 0.00010366121 |
| qf2_loss                | 8.541164e-05  |
| time_elapsed            | 852           |
| total timesteps         | 171968        |
| value_loss              | 8.5219755e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00077599386 |
| ent_coef_loss           | 1.0875561     |
| entropy                 | 0.5232749     |
| episodes                | 340           |
| fps                     | 201           |
| mean 100 episode reward | -0.5          |
| n_updates               | 176149        |
| policy_loss             | 0.12576377    |
| qf1_loss                | 0.00025746407 |
| qf2_loss                | 0.00025131996 |
| time_elapsed            | 873           |
| total timesteps         | 176249        |
| value_loss              | 9.3914874e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007892569  |
| ent_coef_loss           | -0.8260316    |
| entropy                 | 0.5628691     |
| episodes                | 350           |
| fps                     | 201           |
| mean 100 episode reward | -0.4          |
| n_updates               | 181136        |
| policy_loss             | 0.08828246    |
| qf1_loss                | 0.00021032253 |
| qf2_loss                | 0.00022350506 |
| time_elapsed            | 897           |
| total timesteps         | 181236        |
| value_loss              | 0.00014163862 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000826012   |
| ent_coef_loss           | -0.79637635   |
| entropy                 | 0.71466887    |
| episodes                | 360           |
| fps                     | 202           |
| mean 100 episode reward | -0.4          |
| n_updates               | 187465        |
| policy_loss             | 0.06277187    |
| qf1_loss                | 0.00013127466 |
| qf2_loss                | 0.00016677352 |
| time_elapsed            | 928           |
| total timesteps         | 187565        |
| value_loss              | 9.657754e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00086165435 |
| ent_coef_loss           | 1.5586814     |
| entropy                 | 0.68766165    |
| episodes                | 370           |
| fps                     | 202           |
| mean 100 episode reward | -0.4          |
| n_updates               | 192116        |
| policy_loss             | 0.07531851    |
| qf1_loss                | 0.00031271318 |
| qf2_loss                | 0.00034970712 |
| time_elapsed            | 951           |
| total timesteps         | 192216        |
| value_loss              | 8.170151e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008650288  |
| ent_coef_loss           | 0.7597561     |
| entropy                 | 0.6149667     |
| episodes                | 380           |
| fps                     | 201           |
| mean 100 episode reward | -0.3          |
| n_updates               | 196034        |
| policy_loss             | 0.075752914   |
| qf1_loss                | 0.00014569571 |
| qf2_loss                | 0.0002249589  |
| time_elapsed            | 971           |
| total timesteps         | 196134        |
| value_loss              | 8.7711785e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008835246  |
| ent_coef_loss           | 7.60346       |
| entropy                 | 0.85558844    |
| episodes                | 390           |
| fps                     | 201           |
| mean 100 episode reward | -0.4          |
| n_updates               | 200434        |
| policy_loss             | 0.11994602    |
| qf1_loss                | 0.00011055467 |
| qf2_loss                | 0.00011418412 |
| time_elapsed            | 993           |
| total timesteps         | 200534        |
| value_loss              | 0.00010084662 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009008552  |
| ent_coef_loss           | 0.5726607     |
| entropy                 | 0.81625706    |
| episodes                | 400           |
| fps                     | 201           |
| mean 100 episode reward | -0.5          |
| n_updates               | 203098        |
| policy_loss             | 0.08900209    |
| qf1_loss                | 0.00016360034 |
| qf2_loss                | 0.00015490653 |
| time_elapsed            | 1007          |
| total timesteps         | 203198        |
| value_loss              | 0.000106403   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009279652  |
| ent_coef_loss           | 0.21207023    |
| entropy                 | 0.71928227    |
| episodes                | 410           |
| fps                     | 201           |
| mean 100 episode reward | -0.4          |
| n_updates               | 208342        |
| policy_loss             | 0.08470948    |
| qf1_loss                | 0.00013020032 |
| qf2_loss                | 0.00014712522 |
| time_elapsed            | 1033          |
| total timesteps         | 208442        |
| value_loss              | 8.078541e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009153318  |
| ent_coef_loss           | -1.1561098    |
| entropy                 | 0.71853554    |
| episodes                | 420           |
| fps                     | 201           |
| mean 100 episode reward | -0.3          |
| n_updates               | 211694        |
| policy_loss             | 0.03559632    |
| qf1_loss                | 0.0003512893  |
| qf2_loss                | 0.0001746063  |
| time_elapsed            | 1049          |
| total timesteps         | 211794        |
| value_loss              | 0.00015535794 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00088889897 |
| ent_coef_loss           | 1.1476669     |
| entropy                 | 0.6330063     |
| episodes                | 430           |
| fps                     | 201           |
| mean 100 episode reward | -0.3          |
| n_updates               | 215961        |
| policy_loss             | 0.002356716   |
| qf1_loss                | 0.00014133265 |
| qf2_loss                | 0.00016405477 |
| time_elapsed            | 1070          |
| total timesteps         | 216061        |
| value_loss              | 0.00011293674 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0008807274   |
| ent_coef_loss           | 1.1993866      |
| entropy                 | 0.6612087      |
| episodes                | 440            |
| fps                     | 201            |
| mean 100 episode reward | -0.3           |
| n_updates               | 219023         |
| policy_loss             | 0.012701286    |
| qf1_loss                | 0.00014193461  |
| qf2_loss                | 0.00025599444  |
| time_elapsed            | 1086           |
| total timesteps         | 219123         |
| value_loss              | 0.000117094925 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008435255  |
| ent_coef_loss           | -2.1457014    |
| entropy                 | 0.6765913     |
| episodes                | 450           |
| fps                     | 201           |
| mean 100 episode reward | -0.5          |
| n_updates               | 222125        |
| policy_loss             | 0.04250942    |
| qf1_loss                | 0.00012820293 |
| qf2_loss                | 0.00014164519 |
| time_elapsed            | 1101          |
| total timesteps         | 222225        |
| value_loss              | 0.00022862869 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00081683527 |
| ent_coef_loss           | 3.1138449     |
| entropy                 | 0.8056214     |
| episodes                | 460           |
| fps                     | 201           |
| mean 100 episode reward | -0.4          |
| n_updates               | 227725        |
| policy_loss             | 0.030008886   |
| qf1_loss                | 0.0001346535  |
| qf2_loss                | 9.523362e-05  |
| time_elapsed            | 1129          |
| total timesteps         | 227825        |
| value_loss              | 0.0001233455  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007786377  |
| ent_coef_loss           | 0.8839469     |
| entropy                 | 0.4132588     |
| episodes                | 470           |
| fps                     | 201           |
| mean 100 episode reward | -0.4          |
| n_updates               | 232020        |
| policy_loss             | 0.016717685   |
| qf1_loss                | 0.00040630164 |
| qf2_loss                | 0.00026220662 |
| time_elapsed            | 1151          |
| total timesteps         | 232120        |
| value_loss              | 0.00015239931 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007797579  |
| ent_coef_loss           | -2.5927558    |
| entropy                 | 0.381648      |
| episodes                | 480           |
| fps                     | 201           |
| mean 100 episode reward | -0.3          |
| n_updates               | 236022        |
| policy_loss             | 0.017993882   |
| qf1_loss                | 0.00025167153 |
| qf2_loss                | 0.00018728865 |
| time_elapsed            | 1170          |
| total timesteps         | 236122        |
| value_loss              | 0.00013905737 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000823223   |
| ent_coef_loss           | -0.921553     |
| entropy                 | 0.7306687     |
| episodes                | 490           |
| fps                     | 201           |
| mean 100 episode reward | -0.2          |
| n_updates               | 239326        |
| policy_loss             | 0.10804959    |
| qf1_loss                | 0.00030437327 |
| qf2_loss                | 0.00018413409 |
| time_elapsed            | 1187          |
| total timesteps         | 239426        |
| value_loss              | 0.00022994043 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00086505484 |
| ent_coef_loss           | 1.2922758     |
| entropy                 | 0.61449945    |
| episodes                | 500           |
| fps                     | 201           |
| mean 100 episode reward | -0.1          |
| n_updates               | 242587        |
| policy_loss             | 0.092546776   |
| qf1_loss                | 0.00031912455 |
| qf2_loss                | 0.00024309267 |
| time_elapsed            | 1203          |
| total timesteps         | 242687        |
| value_loss              | 0.00025445683 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008613409  |
| ent_coef_loss           | 1.7119739     |
| entropy                 | 0.7171979     |
| episodes                | 510           |
| fps                     | 201           |
| mean 100 episode reward | -0.1          |
| n_updates               | 245998        |
| policy_loss             | 0.05047169    |
| qf1_loss                | 0.00031020836 |
| qf2_loss                | 0.00044048115 |
| time_elapsed            | 1220          |
| total timesteps         | 246098        |
| value_loss              | 0.00013636932 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008500582  |
| ent_coef_loss           | 0.047662854   |
| entropy                 | 0.6602754     |
| episodes                | 520           |
| fps                     | 201           |
| mean 100 episode reward | 0             |
| n_updates               | 249246        |
| policy_loss             | 0.09663295    |
| qf1_loss                | 0.00023205976 |
| qf2_loss                | 0.00021032008 |
| time_elapsed            | 1236          |
| total timesteps         | 249346        |
| value_loss              | 0.00016530167 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008964967  |
| ent_coef_loss           | -1.7970688    |
| entropy                 | 0.71960294    |
| episodes                | 530           |
| fps                     | 201           |
| mean 100 episode reward | 0             |
| n_updates               | 252105        |
| policy_loss             | 0.026119918   |
| qf1_loss                | 0.000198671   |
| qf2_loss                | 0.00029336664 |
| time_elapsed            | 1250          |
| total timesteps         | 252205        |
| value_loss              | 0.00018767106 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008933666  |
| ent_coef_loss           | -0.2759936    |
| entropy                 | 0.65804136    |
| episodes                | 540           |
| fps                     | 201           |
| mean 100 episode reward | 0.2           |
| n_updates               | 255357        |
| policy_loss             | 0.038377784   |
| qf1_loss                | 0.0004235102  |
| qf2_loss                | 0.00033528035 |
| time_elapsed            | 1267          |
| total timesteps         | 255457        |
| value_loss              | 0.00019077215 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00089849957  |
| ent_coef_loss           | -0.25703013    |
| entropy                 | 0.6521249      |
| episodes                | 550            |
| fps                     | 201            |
| mean 100 episode reward | 0.3            |
| n_updates               | 261145         |
| policy_loss             | -0.00040509267 |
| qf1_loss                | 0.000109280416 |
| qf2_loss                | 0.00017511581  |
| time_elapsed            | 1295           |
| total timesteps         | 261245         |
| value_loss              | 0.0001236382   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00091756834 |
| ent_coef_loss           | -3.7048814    |
| entropy                 | 0.67257774    |
| episodes                | 560           |
| fps                     | 201           |
| mean 100 episode reward | 0.4           |
| n_updates               | 265178        |
| policy_loss             | 0.010623311   |
| qf1_loss                | 0.00017185828 |
| qf2_loss                | 0.00015845426 |
| time_elapsed            | 1315          |
| total timesteps         | 265278        |
| value_loss              | 7.0649476e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009109085  |
| ent_coef_loss           | 0.5137484     |
| entropy                 | 0.81429315    |
| episodes                | 570           |
| fps                     | 201           |
| mean 100 episode reward | 0.5           |
| n_updates               | 268842        |
| policy_loss             | 0.10750762    |
| qf1_loss                | 0.00047705672 |
| qf2_loss                | 0.00035845872 |
| time_elapsed            | 1334          |
| total timesteps         | 268942        |
| value_loss              | 0.000285151   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00093171804 |
| ent_coef_loss           | -0.22332942   |
| entropy                 | 0.7572682     |
| episodes                | 580           |
| fps                     | 201           |
| mean 100 episode reward | 0.4           |
| n_updates               | 272459        |
| policy_loss             | 0.012223831   |
| qf1_loss                | 0.00037832002 |
| qf2_loss                | 0.00027998484 |
| time_elapsed            | 1351          |
| total timesteps         | 272559        |
| value_loss              | 0.00017033062 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00093221886 |
| ent_coef_loss           | -1.7426054    |
| entropy                 | 0.82593685    |
| episodes                | 590           |
| fps                     | 201           |
| mean 100 episode reward | 0.5           |
| n_updates               | 275354        |
| policy_loss             | 0.025190655   |
| qf1_loss                | 0.00023069889 |
| qf2_loss                | 0.00016740669 |
| time_elapsed            | 1366          |
| total timesteps         | 275454        |
| value_loss              | 0.00022908057 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00089450687 |
| ent_coef_loss           | -0.82650346   |
| entropy                 | 0.7977563     |
| episodes                | 600           |
| fps                     | 201           |
| mean 100 episode reward | 0.5           |
| n_updates               | 279385        |
| policy_loss             | -0.003955796  |
| qf1_loss                | 0.0003095463  |
| qf2_loss                | 0.00016331143 |
| time_elapsed            | 1386          |
| total timesteps         | 279485        |
| value_loss              | 0.00020511192 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00090256473  |
| ent_coef_loss           | -4.0644875     |
| entropy                 | 0.80670244     |
| episodes                | 610            |
| fps                     | 201            |
| mean 100 episode reward | 0.5            |
| n_updates               | 282433         |
| policy_loss             | -0.05777827    |
| qf1_loss                | 0.00015105517  |
| qf2_loss                | 0.00016030633  |
| time_elapsed            | 1401           |
| total timesteps         | 282533         |
| value_loss              | 0.000109696135 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009226274  |
| ent_coef_loss           | 2.0311227     |
| entropy                 | 0.8996204     |
| episodes                | 620           |
| fps                     | 201           |
| mean 100 episode reward | 0.4           |
| n_updates               | 285769        |
| policy_loss             | 0.0022035616  |
| qf1_loss                | 0.00027142707 |
| qf2_loss                | 0.00029841607 |
| time_elapsed            | 1418          |
| total timesteps         | 285869        |
| value_loss              | 0.00015206171 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008892919  |
| ent_coef_loss           | 1.0030204     |
| entropy                 | 0.80431646    |
| episodes                | 630           |
| fps                     | 201           |
| mean 100 episode reward | 0.4           |
| n_updates               | 289602        |
| policy_loss             | 0.070299365   |
| qf1_loss                | 0.00021309168 |
| qf2_loss                | 0.00024772176 |
| time_elapsed            | 1436          |
| total timesteps         | 289702        |
| value_loss              | 0.00029227504 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00088586635 |
| ent_coef_loss           | 0.13895726    |
| entropy                 | 0.7699963     |
| episodes                | 640           |
| fps                     | 201           |
| mean 100 episode reward | 0.3           |
| n_updates               | 293310        |
| policy_loss             | -0.010645038  |
| qf1_loss                | 0.00029720046 |
| qf2_loss                | 0.0001261065  |
| time_elapsed            | 1455          |
| total timesteps         | 293410        |
| value_loss              | 0.00015204196 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008659933  |
| ent_coef_loss           | 5.343069      |
| entropy                 | 0.97044754    |
| episodes                | 650           |
| fps                     | 201           |
| mean 100 episode reward | 0.4           |
| n_updates               | 296638        |
| policy_loss             | 0.081944406   |
| qf1_loss                | 0.0004686001  |
| qf2_loss                | 0.00068671856 |
| time_elapsed            | 1471          |
| total timesteps         | 296738        |
| value_loss              | 0.00036290442 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009040801  |
| ent_coef_loss           | -3.3723862    |
| entropy                 | 0.88536185    |
| episodes                | 660           |
| fps                     | 201           |
| mean 100 episode reward | 0.3           |
| n_updates               | 301575        |
| policy_loss             | 0.047045566   |
| qf1_loss                | 0.0007341028  |
| qf2_loss                | 0.00052211375 |
| time_elapsed            | 1496          |
| total timesteps         | 301675        |
| value_loss              | 0.00016733723 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009377338  |
| ent_coef_loss           | -0.3163802    |
| entropy                 | 0.8849611     |
| episodes                | 670           |
| fps                     | 201           |
| mean 100 episode reward | 0.4           |
| n_updates               | 305488        |
| policy_loss             | -0.06660679   |
| qf1_loss                | 0.00024141118 |
| qf2_loss                | 0.0002543555  |
| time_elapsed            | 1516          |
| total timesteps         | 305588        |
| value_loss              | 9.841743e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009654411  |
| ent_coef_loss           | 1.4846715     |
| entropy                 | 0.8291137     |
| episodes                | 680           |
| fps                     | 201           |
| mean 100 episode reward | 0.5           |
| n_updates               | 308382        |
| policy_loss             | 0.011777444   |
| qf1_loss                | 0.0002385068  |
| qf2_loss                | 0.0002517142  |
| time_elapsed            | 1530          |
| total timesteps         | 308482        |
| value_loss              | 0.00021578895 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009414421  |
| ent_coef_loss           | 3.0639465     |
| entropy                 | 0.812325      |
| episodes                | 690           |
| fps                     | 201           |
| mean 100 episode reward | 0.6           |
| n_updates               | 311579        |
| policy_loss             | 0.015577315   |
| qf1_loss                | 0.00027900035 |
| qf2_loss                | 0.0002459282  |
| time_elapsed            | 1546          |
| total timesteps         | 311679        |
| value_loss              | 0.00036029963 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009223815  |
| ent_coef_loss           | -0.47683728   |
| entropy                 | 0.8029104     |
| episodes                | 700           |
| fps                     | 201           |
| mean 100 episode reward | 0.6           |
| n_updates               | 316319        |
| policy_loss             | -0.003577585  |
| qf1_loss                | 0.00019385005 |
| qf2_loss                | 0.00012649425 |
| time_elapsed            | 1569          |
| total timesteps         | 316419        |
| value_loss              | 9.802662e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00088688364 |
| ent_coef_loss           | 1.4948213     |
| entropy                 | 0.7752115     |
| episodes                | 710           |
| fps                     | 201           |
| mean 100 episode reward | 0.7           |
| n_updates               | 321266        |
| policy_loss             | 0.00058848946 |
| qf1_loss                | 0.0038997387  |
| qf2_loss                | 0.0037148823  |
| time_elapsed            | 1594          |
| total timesteps         | 321366        |
| value_loss              | 0.00022637274 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00088996434  |
| ent_coef_loss           | 2.119273       |
| entropy                 | 0.74411994     |
| episodes                | 720            |
| fps                     | 201            |
| mean 100 episode reward | 0.7            |
| n_updates               | 325752         |
| policy_loss             | -0.104208946   |
| qf1_loss                | 0.00016036932  |
| qf2_loss                | 0.00018589896  |
| time_elapsed            | 1616           |
| total timesteps         | 325852         |
| value_loss              | 0.000112877446 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008989598  |
| ent_coef_loss           | -2.638023     |
| entropy                 | 0.902877      |
| episodes                | 730           |
| fps                     | 201           |
| mean 100 episode reward | 0.7           |
| n_updates               | 328841        |
| policy_loss             | -0.085118696  |
| qf1_loss                | 0.00014427447 |
| qf2_loss                | 0.00024773637 |
| time_elapsed            | 1632          |
| total timesteps         | 328941        |
| value_loss              | 0.00016859776 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008870063  |
| ent_coef_loss           | -0.790724     |
| entropy                 | 0.8766987     |
| episodes                | 740           |
| fps                     | 201           |
| mean 100 episode reward | 0.7           |
| n_updates               | 332673        |
| policy_loss             | -0.028593875  |
| qf1_loss                | 0.00020422025 |
| qf2_loss                | 0.0002384622  |
| time_elapsed            | 1651          |
| total timesteps         | 332773        |
| value_loss              | 0.00022570661 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00086631917 |
| ent_coef_loss           | -0.32669282   |
| entropy                 | 0.8817115     |
| episodes                | 750           |
| fps                     | 201           |
| mean 100 episode reward | 0.8           |
| n_updates               | 336236        |
| policy_loss             | -0.089348495  |
| qf1_loss                | 0.0001151801  |
| qf2_loss                | 0.00017739495 |
| time_elapsed            | 1668          |
| total timesteps         | 336336        |
| value_loss              | 0.00016459633 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008687972  |
| ent_coef_loss           | -1.1142563    |
| entropy                 | 0.8243013     |
| episodes                | 760           |
| fps                     | 201           |
| mean 100 episode reward | 0.9           |
| n_updates               | 339436        |
| policy_loss             | -0.13846779   |
| qf1_loss                | 0.0009774778  |
| qf2_loss                | 0.0009783529  |
| time_elapsed            | 1685          |
| total timesteps         | 339536        |
| value_loss              | 0.00013620997 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008609052  |
| ent_coef_loss           | -1.9259156    |
| entropy                 | 0.96842045    |
| episodes                | 770           |
| fps                     | 201           |
| mean 100 episode reward | 0.8           |
| n_updates               | 342299        |
| policy_loss             | -0.037903022  |
| qf1_loss                | 0.00022409477 |
| qf2_loss                | 0.00020368607 |
| time_elapsed            | 1699          |
| total timesteps         | 342399        |
| value_loss              | 0.0001646533  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008628031  |
| ent_coef_loss           | -0.43635505   |
| entropy                 | 0.9451885     |
| episodes                | 780           |
| fps                     | 201           |
| mean 100 episode reward | 1             |
| n_updates               | 345530        |
| policy_loss             | -0.019731168  |
| qf1_loss                | 0.00019568848 |
| qf2_loss                | 0.00019753404 |
| time_elapsed            | 1716          |
| total timesteps         | 345630        |
| value_loss              | 0.00016540391 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000863343   |
| ent_coef_loss           | -2.738388     |
| entropy                 | 0.78890216    |
| episodes                | 790           |
| fps                     | 201           |
| mean 100 episode reward | 1             |
| n_updates               | 348700        |
| policy_loss             | -0.112599894  |
| qf1_loss                | 0.00018692475 |
| qf2_loss                | 0.00024140668 |
| time_elapsed            | 1731          |
| total timesteps         | 348800        |
| value_loss              | 0.0001196723  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00085927296 |
| ent_coef_loss           | 1.4410603     |
| entropy                 | 0.96434635    |
| episodes                | 800           |
| fps                     | 201           |
| mean 100 episode reward | 1             |
| n_updates               | 350860        |
| policy_loss             | -0.014648833  |
| qf1_loss                | 0.00020475587 |
| qf2_loss                | 0.0004090167  |
| time_elapsed            | 1742          |
| total timesteps         | 350960        |
| value_loss              | 0.00016832282 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00087714865 |
| ent_coef_loss           | 0.046207786   |
| entropy                 | 0.9359916     |
| episodes                | 810           |
| fps                     | 201           |
| mean 100 episode reward | 1             |
| n_updates               | 354400        |
| policy_loss             | -0.04262851   |
| qf1_loss                | 0.001514815   |
| qf2_loss                | 0.0012983363  |
| time_elapsed            | 1759          |
| total timesteps         | 354500        |
| value_loss              | 9.2324946e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.000887104  |
| ent_coef_loss           | -4.6016793   |
| entropy                 | 1.0195906    |
| episodes                | 820          |
| fps                     | 201          |
| mean 100 episode reward | 1            |
| n_updates               | 356391       |
| policy_loss             | -0.018920504 |
| qf1_loss                | 0.00535999   |
| qf2_loss                | 0.005563247  |
| time_elapsed            | 1770         |
| total timesteps         | 356491       |
| value_loss              | 0.0002389461 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008400847  |
| ent_coef_loss           | 1.2607617     |
| entropy                 | 0.9482169     |
| episodes                | 830           |
| fps                     | 201           |
| mean 100 episode reward | 1.1           |
| n_updates               | 359515        |
| policy_loss             | -0.09104206   |
| qf1_loss                | 0.0004508055  |
| qf2_loss                | 0.00037441944 |
| time_elapsed            | 1785          |
| total timesteps         | 359615        |
| value_loss              | 0.00014726864 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008495489  |
| ent_coef_loss           | -2.8928242    |
| entropy                 | 0.7980516     |
| episodes                | 840           |
| fps                     | 201           |
| mean 100 episode reward | 1.2           |
| n_updates               | 362471        |
| policy_loss             | -0.110600464  |
| qf1_loss                | 0.00018416674 |
| qf2_loss                | 0.0003091428  |
| time_elapsed            | 1800          |
| total timesteps         | 362571        |
| value_loss              | 0.00014675234 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0008422068 |
| ent_coef_loss           | -3.4215379   |
| entropy                 | 0.7948734    |
| episodes                | 850          |
| fps                     | 201          |
| mean 100 episode reward | 1.2          |
| n_updates               | 365234       |
| policy_loss             | -0.08845177  |
| qf1_loss                | 0.0005945756 |
| qf2_loss                | 0.000385741  |
| time_elapsed            | 1814         |
| total timesteps         | 365334       |
| value_loss              | 0.0003406895 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008541824  |
| ent_coef_loss           | -0.073052585  |
| entropy                 | 0.9342245     |
| episodes                | 860           |
| fps                     | 201           |
| mean 100 episode reward | 1.1           |
| n_updates               | 367489        |
| policy_loss             | -0.0511273    |
| qf1_loss                | 0.00021686188 |
| qf2_loss                | 0.00022946074 |
| time_elapsed            | 1825          |
| total timesteps         | 367589        |
| value_loss              | 0.00018851446 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008504093  |
| ent_coef_loss           | 0.7229471     |
| entropy                 | 1.1116822     |
| episodes                | 870           |
| fps                     | 201           |
| mean 100 episode reward | 1.1           |
| n_updates               | 369763        |
| policy_loss             | -0.073312216  |
| qf1_loss                | 0.00023475703 |
| qf2_loss                | 0.0002515695  |
| time_elapsed            | 1837          |
| total timesteps         | 369863        |
| value_loss              | 0.00023535364 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00085075776 |
| ent_coef_loss           | -0.33926484   |
| entropy                 | 0.8113067     |
| episodes                | 880           |
| fps                     | 201           |
| mean 100 episode reward | 1.1           |
| n_updates               | 373354        |
| policy_loss             | -0.19724534   |
| qf1_loss                | 0.00017321852 |
| qf2_loss                | 0.00021775921 |
| time_elapsed            | 1854          |
| total timesteps         | 373454        |
| value_loss              | 0.00022141714 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00085310533 |
| ent_coef_loss           | 2.362877      |
| entropy                 | 1.0774475     |
| episodes                | 890           |
| fps                     | 201           |
| mean 100 episode reward | 1.1           |
| n_updates               | 375796        |
| policy_loss             | -0.053669922  |
| qf1_loss                | 0.00020074156 |
| qf2_loss                | 0.00022201173 |
| time_elapsed            | 1866          |
| total timesteps         | 375896        |
| value_loss              | 0.00017582739 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008612358  |
| ent_coef_loss           | -1.3941168    |
| entropy                 | 0.9928079     |
| episodes                | 900           |
| fps                     | 201           |
| mean 100 episode reward | 1             |
| n_updates               | 378893        |
| policy_loss             | -0.09843151   |
| qf1_loss                | 0.00030528108 |
| qf2_loss                | 0.0003017384  |
| time_elapsed            | 1882          |
| total timesteps         | 378993        |
| value_loss              | 0.00023235434 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008559356  |
| ent_coef_loss           | -0.47996265   |
| entropy                 | 0.9143286     |
| episodes                | 910           |
| fps                     | 201           |
| mean 100 episode reward | 1.1           |
| n_updates               | 381475        |
| policy_loss             | -0.13874327   |
| qf1_loss                | 0.0013156349  |
| qf2_loss                | 0.0012380206  |
| time_elapsed            | 1895          |
| total timesteps         | 381575        |
| value_loss              | 0.00011576606 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008573768  |
| ent_coef_loss           | -0.52500844   |
| entropy                 | 0.8675053     |
| episodes                | 920           |
| fps                     | 201           |
| mean 100 episode reward | 1.1           |
| n_updates               | 383823        |
| policy_loss             | -0.16780257   |
| qf1_loss                | 0.0010352221  |
| qf2_loss                | 0.0009769736  |
| time_elapsed            | 1907          |
| total timesteps         | 383923        |
| value_loss              | 0.00031310116 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0008384163   |
| ent_coef_loss           | 0.985487       |
| entropy                 | 0.9967891      |
| episodes                | 930            |
| fps                     | 201            |
| mean 100 episode reward | 1.1            |
| n_updates               | 386486         |
| policy_loss             | -0.13200796    |
| qf1_loss                | 0.00028536306  |
| qf2_loss                | 0.00011129726  |
| time_elapsed            | 1920           |
| total timesteps         | 386586         |
| value_loss              | 0.000108089276 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008266255  |
| ent_coef_loss           | 1.7071834     |
| entropy                 | 0.99840283    |
| episodes                | 940           |
| fps                     | 201           |
| mean 100 episode reward | 1             |
| n_updates               | 389348        |
| policy_loss             | -0.105796024  |
| qf1_loss                | 0.00020698467 |
| qf2_loss                | 0.00024993112 |
| time_elapsed            | 1935          |
| total timesteps         | 389448        |
| value_loss              | 0.00020491508 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000822763   |
| ent_coef_loss           | -1.6129183    |
| entropy                 | 0.9336252     |
| episodes                | 950           |
| fps                     | 201           |
| mean 100 episode reward | 1             |
| n_updates               | 392067        |
| policy_loss             | -0.20934498   |
| qf1_loss                | 0.00091877155 |
| qf2_loss                | 0.00084468134 |
| time_elapsed            | 1948          |
| total timesteps         | 392167        |
| value_loss              | 0.00017839571 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008152209  |
| ent_coef_loss           | -4.7146854    |
| entropy                 | 0.92803323    |
| episodes                | 960           |
| fps                     | 201           |
| mean 100 episode reward | 0.9           |
| n_updates               | 394114        |
| policy_loss             | -0.16014907   |
| qf1_loss                | 0.00029170804 |
| qf2_loss                | 0.00036230433 |
| time_elapsed            | 1959          |
| total timesteps         | 394214        |
| value_loss              | 0.00014945917 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00083041616 |
| ent_coef_loss           | -0.85564256   |
| entropy                 | 0.975582      |
| episodes                | 970           |
| fps                     | 201           |
| mean 100 episode reward | 0.9           |
| n_updates               | 396293        |
| policy_loss             | -0.25781608   |
| qf1_loss                | 0.00015394176 |
| qf2_loss                | 0.00021658103 |
| time_elapsed            | 1969          |
| total timesteps         | 396393        |
| value_loss              | 0.00012363761 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008266247  |
| ent_coef_loss           | 1.5089804     |
| entropy                 | 1.0617052     |
| episodes                | 980           |
| fps                     | 201           |
| mean 100 episode reward | 0.9           |
| n_updates               | 398506        |
| policy_loss             | -0.106455386  |
| qf1_loss                | 0.00032400287 |
| qf2_loss                | 0.0003374988  |
| time_elapsed            | 1981          |
| total timesteps         | 398606        |
| value_loss              | 0.00024354516 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008131295  |
| ent_coef_loss           | 0.3010744     |
| entropy                 | 0.93632007    |
| episodes                | 990           |
| fps                     | 201           |
| mean 100 episode reward | 0.8           |
| n_updates               | 400868        |
| policy_loss             | -0.14331812   |
| qf1_loss                | 0.00029855288 |
| qf2_loss                | 0.00016398207 |
| time_elapsed            | 1993          |
| total timesteps         | 400968        |
| value_loss              | 0.00011292032 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008195343  |
| ent_coef_loss           | -2.4777267    |
| entropy                 | 1.0802717     |
| episodes                | 1000          |
| fps                     | 201           |
| mean 100 episode reward | 0.8           |
| n_updates               | 403170        |
| policy_loss             | -0.1990841    |
| qf1_loss                | 0.0010089125  |
| qf2_loss                | 0.0011572305  |
| time_elapsed            | 2005          |
| total timesteps         | 403270        |
| value_loss              | 0.00013328163 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00082527776 |
| ent_coef_loss           | 2.250393      |
| entropy                 | 1.0420278     |
| episodes                | 1010          |
| fps                     | 201           |
| mean 100 episode reward | 0.8           |
| n_updates               | 405597        |
| policy_loss             | -0.11418581   |
| qf1_loss                | 0.0002848902  |
| qf2_loss                | 0.00018719092 |
| time_elapsed            | 2017          |
| total timesteps         | 405697        |
| value_loss              | 0.00023842085 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008133695  |
| ent_coef_loss           | -0.7352364    |
| entropy                 | 1.0672572     |
| episodes                | 1020          |
| fps                     | 201           |
| mean 100 episode reward | 0.9           |
| n_updates               | 408491        |
| policy_loss             | -0.044355366  |
| qf1_loss                | 0.00041270387 |
| qf2_loss                | 0.00030231592 |
| time_elapsed            | 2031          |
| total timesteps         | 408591        |
| value_loss              | 0.00022583922 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008530797  |
| ent_coef_loss           | 2.1451952     |
| entropy                 | 1.0264019     |
| episodes                | 1030          |
| fps                     | 201           |
| mean 100 episode reward | 0.8           |
| n_updates               | 411221        |
| policy_loss             | -0.20460586   |
| qf1_loss                | 0.0003109232  |
| qf2_loss                | 0.00019999943 |
| time_elapsed            | 2045          |
| total timesteps         | 411321        |
| value_loss              | 0.00012234614 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00087459804 |
| ent_coef_loss           | 2.2623763     |
| entropy                 | 1.1726909     |
| episodes                | 1040          |
| fps                     | 201           |
| mean 100 episode reward | 0.8           |
| n_updates               | 413480        |
| policy_loss             | -0.1980162    |
| qf1_loss                | 0.00023548272 |
| qf2_loss                | 0.00016170941 |
| time_elapsed            | 2057          |
| total timesteps         | 413580        |
| value_loss              | 0.00012580362 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008690992  |
| ent_coef_loss           | 1.5432782     |
| entropy                 | 1.1479754     |
| episodes                | 1050          |
| fps                     | 200           |
| mean 100 episode reward | 0.8           |
| n_updates               | 415360        |
| policy_loss             | -0.11121275   |
| qf1_loss                | 0.00024233482 |
| qf2_loss                | 0.0002880089  |
| time_elapsed            | 2067          |
| total timesteps         | 415460        |
| value_loss              | 0.00026176847 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008735015  |
| ent_coef_loss           | -0.5221369    |
| entropy                 | 1.1724386     |
| episodes                | 1060          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 417887        |
| policy_loss             | -0.15768006   |
| qf1_loss                | 0.00033094498 |
| qf2_loss                | 0.00026742686 |
| time_elapsed            | 2080          |
| total timesteps         | 417987        |
| value_loss              | 0.00012148147 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0008576904 |
| ent_coef_loss           | -0.9751634   |
| entropy                 | 1.0885406    |
| episodes                | 1070         |
| fps                     | 200          |
| mean 100 episode reward | 0.9          |
| n_updates               | 420155       |
| policy_loss             | -0.25006226  |
| qf1_loss                | 0.0011095246 |
| qf2_loss                | 0.001125627  |
| time_elapsed            | 2090         |
| total timesteps         | 420255       |
| value_loss              | 0.0002323077 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00084807316 |
| ent_coef_loss           | -2.2712297    |
| entropy                 | 1.0619751     |
| episodes                | 1080          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 422479        |
| policy_loss             | -0.13067141   |
| qf1_loss                | 0.00034088007 |
| qf2_loss                | 0.00057072914 |
| time_elapsed            | 2102          |
| total timesteps         | 422579        |
| value_loss              | 0.0001354543  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00088160095 |
| ent_coef_loss           | 0.24986932    |
| entropy                 | 1.146352      |
| episodes                | 1090          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 424840        |
| policy_loss             | -0.21782842   |
| qf1_loss                | 0.00097432046 |
| qf2_loss                | 0.00085866195 |
| time_elapsed            | 2114          |
| total timesteps         | 424940        |
| value_loss              | 0.00020010027 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00086609164 |
| ent_coef_loss           | 0.3738935     |
| entropy                 | 1.2229755     |
| episodes                | 1100          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 427000        |
| policy_loss             | -0.20320322   |
| qf1_loss                | 0.00021012675 |
| qf2_loss                | 0.00011014447 |
| time_elapsed            | 2124          |
| total timesteps         | 427100        |
| value_loss              | 0.00030507267 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008581809  |
| ent_coef_loss           | 1.5001088     |
| entropy                 | 1.1784382     |
| episodes                | 1110          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 429211        |
| policy_loss             | -0.14049287   |
| qf1_loss                | 0.00024128766 |
| qf2_loss                | 0.00020561332 |
| time_elapsed            | 2136          |
| total timesteps         | 429311        |
| value_loss              | 0.00028684345 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008696037  |
| ent_coef_loss           | -1.3194566    |
| entropy                 | 1.2212994     |
| episodes                | 1120          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 431696        |
| policy_loss             | -0.18304595   |
| qf1_loss                | 0.00015681342 |
| qf2_loss                | 0.00010774555 |
| time_elapsed            | 2148          |
| total timesteps         | 431796        |
| value_loss              | 0.00011993806 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008602856  |
| ent_coef_loss           | -2.809498     |
| entropy                 | 1.2047573     |
| episodes                | 1130          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 434105        |
| policy_loss             | -0.18461543   |
| qf1_loss                | 0.00044659115 |
| qf2_loss                | 0.0002216101  |
| time_elapsed            | 2161          |
| total timesteps         | 434205        |
| value_loss              | 0.00023149356 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008585947  |
| ent_coef_loss           | 1.9296293     |
| entropy                 | 1.1323149     |
| episodes                | 1140          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 436263        |
| policy_loss             | -0.23226586   |
| qf1_loss                | 0.00013032455 |
| qf2_loss                | 0.00014852607 |
| time_elapsed            | 2171          |
| total timesteps         | 436363        |
| value_loss              | 0.00016715011 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0008456063 |
| ent_coef_loss           | 0.90778464   |
| entropy                 | 1.2126243    |
| episodes                | 1150         |
| fps                     | 200          |
| mean 100 episode reward | 1.1          |
| n_updates               | 438503       |
| policy_loss             | -0.20625454  |
| qf1_loss                | 0.0002476617 |
| qf2_loss                | 0.0002454259 |
| time_elapsed            | 2182         |
| total timesteps         | 438603       |
| value_loss              | 0.0003598609 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00083942036 |
| ent_coef_loss           | 1.2740498     |
| entropy                 | 1.1974213     |
| episodes                | 1160          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 440685        |
| policy_loss             | -0.28889453   |
| qf1_loss                | 0.00024546142 |
| qf2_loss                | 0.00012086226 |
| time_elapsed            | 2194          |
| total timesteps         | 440785        |
| value_loss              | 8.761874e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008417917  |
| ent_coef_loss           | 0.06925696    |
| entropy                 | 1.2331895     |
| episodes                | 1170          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 443328        |
| policy_loss             | -0.20557106   |
| qf1_loss                | 0.0007635003  |
| qf2_loss                | 0.0003491628  |
| time_elapsed            | 2206          |
| total timesteps         | 443428        |
| value_loss              | 0.00051090843 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008407174  |
| ent_coef_loss           | 0.86407036    |
| entropy                 | 1.1748619     |
| episodes                | 1180          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 445370        |
| policy_loss             | -0.26258415   |
| qf1_loss                | 0.00027902782 |
| qf2_loss                | 0.00017445582 |
| time_elapsed            | 2216          |
| total timesteps         | 445470        |
| value_loss              | 0.00022486    |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008613179  |
| ent_coef_loss           | 3.2267852     |
| entropy                 | 1.2070289     |
| episodes                | 1190          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 447527        |
| policy_loss             | -0.2079584    |
| qf1_loss                | 0.0013207613  |
| qf2_loss                | 0.0013748133  |
| time_elapsed            | 2227          |
| total timesteps         | 447627        |
| value_loss              | 0.00013627615 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00084973406  |
| ent_coef_loss           | -0.71867895    |
| entropy                 | 1.2163508      |
| episodes                | 1200           |
| fps                     | 200            |
| mean 100 episode reward | 1.2            |
| n_updates               | 449847         |
| policy_loss             | -0.28424385    |
| qf1_loss                | 0.00019143245  |
| qf2_loss                | 0.00026160324  |
| time_elapsed            | 2239           |
| total timesteps         | 449947         |
| value_loss              | 0.000114652335 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008404328  |
| ent_coef_loss           | -3.0874357    |
| entropy                 | 1.2310615     |
| episodes                | 1210          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 452455        |
| policy_loss             | -0.2435889    |
| qf1_loss                | 0.0002770308  |
| qf2_loss                | 0.00021539346 |
| time_elapsed            | 2252          |
| total timesteps         | 452555        |
| value_loss              | 0.00020101567 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00083966734 |
| ent_coef_loss           | -0.4920001    |
| entropy                 | 1.3040189     |
| episodes                | 1220          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 454814        |
| policy_loss             | -0.19834322   |
| qf1_loss                | 0.0003246301  |
| qf2_loss                | 0.0003184239  |
| time_elapsed            | 2264          |
| total timesteps         | 454914        |
| value_loss              | 0.00025191857 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008203025  |
| ent_coef_loss           | -0.6462381    |
| entropy                 | 1.3082564     |
| episodes                | 1230          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 456857        |
| policy_loss             | -0.20342523   |
| qf1_loss                | 0.00022966725 |
| qf2_loss                | 0.0002640683  |
| time_elapsed            | 2274          |
| total timesteps         | 456957        |
| value_loss              | 0.00037088338 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008238847  |
| ent_coef_loss           | 0.8790579     |
| entropy                 | 1.303279      |
| episodes                | 1240          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 459034        |
| policy_loss             | -0.33409524   |
| qf1_loss                | 0.00012323586 |
| qf2_loss                | 0.00017954136 |
| time_elapsed            | 2285          |
| total timesteps         | 459134        |
| value_loss              | 0.00018172403 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00084621826 |
| ent_coef_loss           | -2.602894     |
| entropy                 | 1.2627788     |
| episodes                | 1250          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 461125        |
| policy_loss             | -0.21064971   |
| qf1_loss                | 0.00033859257 |
| qf2_loss                | 0.00031927327 |
| time_elapsed            | 2295          |
| total timesteps         | 461225        |
| value_loss              | 0.0001967435  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00084371096 |
| ent_coef_loss           | 1.0733972     |
| entropy                 | 1.3035533     |
| episodes                | 1260          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 463563        |
| policy_loss             | -0.22530457   |
| qf1_loss                | 0.00014411681 |
| qf2_loss                | 0.00017972104 |
| time_elapsed            | 2308          |
| total timesteps         | 463663        |
| value_loss              | 0.00020090873 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00082083116 |
| ent_coef_loss           | 0.9606375     |
| entropy                 | 1.2551168     |
| episodes                | 1270          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 466268        |
| policy_loss             | -0.12423043   |
| qf1_loss                | 0.00019060742 |
| qf2_loss                | 0.00026178433 |
| time_elapsed            | 2322          |
| total timesteps         | 466368        |
| value_loss              | 0.00033134184 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008379243  |
| ent_coef_loss           | -2.8486598    |
| entropy                 | 1.3022249     |
| episodes                | 1280          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 468848        |
| policy_loss             | -0.20262669   |
| qf1_loss                | 0.00031888194 |
| qf2_loss                | 0.00033803718 |
| time_elapsed            | 2335          |
| total timesteps         | 468948        |
| value_loss              | 0.00014427883 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000834342   |
| ent_coef_loss           | -0.98701894   |
| entropy                 | 1.2615337     |
| episodes                | 1290          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 471381        |
| policy_loss             | -0.36893937   |
| qf1_loss                | 0.0002316783  |
| qf2_loss                | 0.00011505078 |
| time_elapsed            | 2347          |
| total timesteps         | 471481        |
| value_loss              | 0.00024024458 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00080404914 |
| ent_coef_loss           | -0.96729726   |
| entropy                 | 1.3656971     |
| episodes                | 1300          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 473813        |
| policy_loss             | -0.2362692    |
| qf1_loss                | 0.0023678038  |
| qf2_loss                | 0.0024369126  |
| time_elapsed            | 2359          |
| total timesteps         | 473913        |
| value_loss              | 0.00013006195 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008195851  |
| ent_coef_loss           | -1.0388246    |
| entropy                 | 1.2269666     |
| episodes                | 1310          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 475411        |
| policy_loss             | -0.297595     |
| qf1_loss                | 0.00012272611 |
| qf2_loss                | 9.9906305e-05 |
| time_elapsed            | 2368          |
| total timesteps         | 475511        |
| value_loss              | 0.00022965859 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008276186  |
| ent_coef_loss           | -2.901232     |
| entropy                 | 1.2468932     |
| episodes                | 1320          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 477115        |
| policy_loss             | -0.29465583   |
| qf1_loss                | 0.00028146862 |
| qf2_loss                | 0.00016099    |
| time_elapsed            | 2376          |
| total timesteps         | 477215        |
| value_loss              | 0.000279253   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008136131  |
| ent_coef_loss           | -2.3708193    |
| entropy                 | 1.2036561     |
| episodes                | 1330          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 479487        |
| policy_loss             | -0.23024955   |
| qf1_loss                | 0.00023295287 |
| qf2_loss                | 0.00024326424 |
| time_elapsed            | 2388          |
| total timesteps         | 479587        |
| value_loss              | 0.00019082354 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008201449  |
| ent_coef_loss           | 1.470763      |
| entropy                 | 1.2817727     |
| episodes                | 1340          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 482155        |
| policy_loss             | -0.19265476   |
| qf1_loss                | 0.00025843244 |
| qf2_loss                | 0.0003419355  |
| time_elapsed            | 2401          |
| total timesteps         | 482255        |
| value_loss              | 0.00024336886 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008265348  |
| ent_coef_loss           | -0.62056285   |
| entropy                 | 1.3245044     |
| episodes                | 1350          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 484795        |
| policy_loss             | -0.15045461   |
| qf1_loss                | 0.0005388516  |
| qf2_loss                | 0.00065006694 |
| time_elapsed            | 2414          |
| total timesteps         | 484895        |
| value_loss              | 0.00023744887 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00084552367 |
| ent_coef_loss           | -3.4721854    |
| entropy                 | 1.3913927     |
| episodes                | 1360          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 487587        |
| policy_loss             | -0.18846095   |
| qf1_loss                | 0.00019965606 |
| qf2_loss                | 0.00028103119 |
| time_elapsed            | 2428          |
| total timesteps         | 487687        |
| value_loss              | 0.0002946266  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00084384816 |
| ent_coef_loss           | 1.1104977     |
| entropy                 | 1.335551      |
| episodes                | 1370          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 490269        |
| policy_loss             | -0.15534982   |
| qf1_loss                | 0.00028218457 |
| qf2_loss                | 0.0003064291  |
| time_elapsed            | 2442          |
| total timesteps         | 490369        |
| value_loss              | 0.00016959145 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008101085  |
| ent_coef_loss           | -1.3152711    |
| entropy                 | 1.3075964     |
| episodes                | 1380          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 492241        |
| policy_loss             | -0.23615462   |
| qf1_loss                | 0.00012879187 |
| qf2_loss                | 0.00030174907 |
| time_elapsed            | 2451          |
| total timesteps         | 492341        |
| value_loss              | 0.00026223887 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007694702  |
| ent_coef_loss           | -1.3680047    |
| entropy                 | 1.0731356     |
| episodes                | 1390          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 494505        |
| policy_loss             | -0.23961592   |
| qf1_loss                | 0.0002931335  |
| qf2_loss                | 0.0002953672  |
| time_elapsed            | 2462          |
| total timesteps         | 494605        |
| value_loss              | 0.00047676382 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00077213487 |
| ent_coef_loss           | 2.5583048     |
| entropy                 | 1.2265774     |
| episodes                | 1400          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 496408        |
| policy_loss             | -0.1725049    |
| qf1_loss                | 0.0032810818  |
| qf2_loss                | 0.00226121    |
| time_elapsed            | 2472          |
| total timesteps         | 496508        |
| value_loss              | 0.00035679067 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00074477756 |
| ent_coef_loss           | -2.2112453    |
| entropy                 | 1.2547112     |
| episodes                | 1410          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 498758        |
| policy_loss             | -0.26524955   |
| qf1_loss                | 0.0006707714  |
| qf2_loss                | 0.0005460287  |
| time_elapsed            | 2483          |
| total timesteps         | 498858        |
| value_loss              | 0.00019091986 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007348542  |
| ent_coef_loss           | 3.1325185     |
| entropy                 | 1.3217216     |
| episodes                | 1420          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 500671        |
| policy_loss             | -0.21859291   |
| qf1_loss                | 0.00025377268 |
| qf2_loss                | 0.0002856131  |
| time_elapsed            | 2493          |
| total timesteps         | 500771        |
| value_loss              | 0.00023262468 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000745099   |
| ent_coef_loss           | 0.27051896    |
| entropy                 | 1.2760099     |
| episodes                | 1430          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 502936        |
| policy_loss             | -0.18451783   |
| qf1_loss                | 0.0003785105  |
| qf2_loss                | 0.00029779453 |
| time_elapsed            | 2505          |
| total timesteps         | 503036        |
| value_loss              | 0.00023904422 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007610751  |
| ent_coef_loss           | 3.074449      |
| entropy                 | 1.2524667     |
| episodes                | 1440          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 504841        |
| policy_loss             | -0.19856161   |
| qf1_loss                | 0.0004142719  |
| qf2_loss                | 0.00036881946 |
| time_elapsed            | 2514          |
| total timesteps         | 504941        |
| value_loss              | 0.00016307727 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00076285255 |
| ent_coef_loss           | -0.80287975   |
| entropy                 | 1.2569717     |
| episodes                | 1450          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 506560        |
| policy_loss             | -0.2796114    |
| qf1_loss                | 0.00019190898 |
| qf2_loss                | 0.0001937444  |
| time_elapsed            | 2523          |
| total timesteps         | 506660        |
| value_loss              | 9.292546e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00076382695 |
| ent_coef_loss           | 2.936876      |
| entropy                 | 1.3151426     |
| episodes                | 1460          |
| fps                     | 200           |
| mean 100 episode reward | 0.8           |
| n_updates               | 508430        |
| policy_loss             | -0.21092594   |
| qf1_loss                | 0.00032777357 |
| qf2_loss                | 0.0001668708  |
| time_elapsed            | 2532          |
| total timesteps         | 508530        |
| value_loss              | 0.0001603007  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007553346  |
| ent_coef_loss           | 2.2533913     |
| entropy                 | 1.3405403     |
| episodes                | 1470          |
| fps                     | 200           |
| mean 100 episode reward | 0.8           |
| n_updates               | 510357        |
| policy_loss             | -0.19436276   |
| qf1_loss                | 0.00024023379 |
| qf2_loss                | 0.0002895812  |
| time_elapsed            | 2542          |
| total timesteps         | 510457        |
| value_loss              | 0.00018560232 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0007524598 |
| ent_coef_loss           | -4.3087006   |
| entropy                 | 1.2087893    |
| episodes                | 1480         |
| fps                     | 200          |
| mean 100 episode reward | 0.8          |
| n_updates               | 512588       |
| policy_loss             | -0.25374067  |
| qf1_loss                | 0.0038586096 |
| qf2_loss                | 0.004447358  |
| time_elapsed            | 2553         |
| total timesteps         | 512688       |
| value_loss              | 0.000378606  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00075369724 |
| ent_coef_loss           | -0.2092607    |
| entropy                 | 1.2810929     |
| episodes                | 1490          |
| fps                     | 200           |
| mean 100 episode reward | 0.6           |
| n_updates               | 514172        |
| policy_loss             | -0.3106589    |
| qf1_loss                | 0.0003951198  |
| qf2_loss                | 0.00036323018 |
| time_elapsed            | 2562          |
| total timesteps         | 514272        |
| value_loss              | 0.00035994773 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000793439   |
| ent_coef_loss           | 1.7053374     |
| entropy                 | 1.3263597     |
| episodes                | 1500          |
| fps                     | 200           |
| mean 100 episode reward | 0.7           |
| n_updates               | 516679        |
| policy_loss             | -0.23053247   |
| qf1_loss                | 0.00030071766 |
| qf2_loss                | 0.00041271048 |
| time_elapsed            | 2574          |
| total timesteps         | 516779        |
| value_loss              | 0.00026930773 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007721684  |
| ent_coef_loss           | 1.3729715     |
| entropy                 | 1.29177       |
| episodes                | 1510          |
| fps                     | 200           |
| mean 100 episode reward | 0.7           |
| n_updates               | 518749        |
| policy_loss             | -0.23176235   |
| qf1_loss                | 0.00033239595 |
| qf2_loss                | 0.00050772505 |
| time_elapsed            | 2584          |
| total timesteps         | 518849        |
| value_loss              | 0.00016937364 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007830387  |
| ent_coef_loss           | -3.4030235    |
| entropy                 | 1.269503      |
| episodes                | 1520          |
| fps                     | 200           |
| mean 100 episode reward | 0.7           |
| n_updates               | 520996        |
| policy_loss             | -0.27570993   |
| qf1_loss                | 0.00029866677 |
| qf2_loss                | 0.0002294453  |
| time_elapsed            | 2595          |
| total timesteps         | 521096        |
| value_loss              | 0.00014816354 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007914106  |
| ent_coef_loss           | -1.9576054    |
| entropy                 | 1.3819733     |
| episodes                | 1530          |
| fps                     | 200           |
| mean 100 episode reward | 0.8           |
| n_updates               | 523224        |
| policy_loss             | -0.34821224   |
| qf1_loss                | 0.0002053308  |
| qf2_loss                | 0.00020537645 |
| time_elapsed            | 2606          |
| total timesteps         | 523324        |
| value_loss              | 0.00014166685 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007973401  |
| ent_coef_loss           | -0.39403933   |
| entropy                 | 1.3439031     |
| episodes                | 1540          |
| fps                     | 200           |
| mean 100 episode reward | 0.8           |
| n_updates               | 525364        |
| policy_loss             | -0.28300428   |
| qf1_loss                | 0.00017547674 |
| qf2_loss                | 0.00015297158 |
| time_elapsed            | 2617          |
| total timesteps         | 525464        |
| value_loss              | 0.00013217337 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007635611  |
| ent_coef_loss           | -1.9741619    |
| entropy                 | 1.3195409     |
| episodes                | 1550          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 527737        |
| policy_loss             | -0.17207265   |
| qf1_loss                | 0.0003023247  |
| qf2_loss                | 0.00025913317 |
| time_elapsed            | 2629          |
| total timesteps         | 527837        |
| value_loss              | 0.00019859635 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00077344227 |
| ent_coef_loss           | -0.46477208   |
| entropy                 | 1.2797801     |
| episodes                | 1560          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 530129        |
| policy_loss             | -0.21425518   |
| qf1_loss                | 0.000679672   |
| qf2_loss                | 0.0006982673  |
| time_elapsed            | 2641          |
| total timesteps         | 530229        |
| value_loss              | 0.00021188478 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00079159066 |
| ent_coef_loss           | -1.0085988    |
| entropy                 | 1.3780842     |
| episodes                | 1570          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 532393        |
| policy_loss             | -0.19419634   |
| qf1_loss                | 0.00038579496 |
| qf2_loss                | 0.0004989885  |
| time_elapsed            | 2652          |
| total timesteps         | 532493        |
| value_loss              | 0.00019581534 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00076395913 |
| ent_coef_loss           | -1.9438373    |
| entropy                 | 1.3056722     |
| episodes                | 1580          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 534585        |
| policy_loss             | -0.3467427    |
| qf1_loss                | 0.00037445658 |
| qf2_loss                | 0.00034091098 |
| time_elapsed            | 2662          |
| total timesteps         | 534685        |
| value_loss              | 0.00017437036 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007562035  |
| ent_coef_loss           | 0.76056546    |
| entropy                 | 1.3006151     |
| episodes                | 1590          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 536951        |
| policy_loss             | -0.26470238   |
| qf1_loss                | 0.00021577088 |
| qf2_loss                | 0.0001581398  |
| time_elapsed            | 2675          |
| total timesteps         | 537051        |
| value_loss              | 0.0001440385  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00073906867 |
| ent_coef_loss           | 2.1287096     |
| entropy                 | 1.3024235     |
| episodes                | 1600          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 539368        |
| policy_loss             | -0.2648907    |
| qf1_loss                | 0.00021820451 |
| qf2_loss                | 0.00021791425 |
| time_elapsed            | 2686          |
| total timesteps         | 539468        |
| value_loss              | 0.00024291986 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007346177  |
| ent_coef_loss           | -3.7871       |
| entropy                 | 1.3017094     |
| episodes                | 1610          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 541299        |
| policy_loss             | -0.18968782   |
| qf1_loss                | 0.00045728084 |
| qf2_loss                | 0.00023653891 |
| time_elapsed            | 2695          |
| total timesteps         | 541399        |
| value_loss              | 0.00018516665 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00073300325 |
| ent_coef_loss           | 1.2082        |
| entropy                 | 1.3362606     |
| episodes                | 1620          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 543257        |
| policy_loss             | -0.22892787   |
| qf1_loss                | 0.00039401767 |
| qf2_loss                | 0.0004192022  |
| time_elapsed            | 2706          |
| total timesteps         | 543357        |
| value_loss              | 0.00019754573 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007304036  |
| ent_coef_loss           | -1.2845569    |
| entropy                 | 1.255012      |
| episodes                | 1630          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 545400        |
| policy_loss             | -0.210051     |
| qf1_loss                | 0.0006077193  |
| qf2_loss                | 0.00037460416 |
| time_elapsed            | 2716          |
| total timesteps         | 545500        |
| value_loss              | 0.0002491714  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007384462  |
| ent_coef_loss           | -0.07809186   |
| entropy                 | 1.4224349     |
| episodes                | 1640          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 547652        |
| policy_loss             | -0.0914384    |
| qf1_loss                | 0.00027082884 |
| qf2_loss                | 0.00024401014 |
| time_elapsed            | 2728          |
| total timesteps         | 547752        |
| value_loss              | 0.0002538652  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007474904  |
| ent_coef_loss           | 1.7524326     |
| entropy                 | 1.4086888     |
| episodes                | 1650          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 549428        |
| policy_loss             | -0.22522473   |
| qf1_loss                | 0.00031786104 |
| qf2_loss                | 0.00033931618 |
| time_elapsed            | 2737          |
| total timesteps         | 549528        |
| value_loss              | 0.00020292599 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007478223  |
| ent_coef_loss           | 1.8578081     |
| entropy                 | 1.4440827     |
| episodes                | 1660          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 551945        |
| policy_loss             | -0.15191886   |
| qf1_loss                | 0.00036980645 |
| qf2_loss                | 0.0002929578  |
| time_elapsed            | 2749          |
| total timesteps         | 552045        |
| value_loss              | 0.0002062778  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00078528817 |
| ent_coef_loss           | -1.1504059    |
| entropy                 | 1.4664631     |
| episodes                | 1670          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 554079        |
| policy_loss             | -0.15609732   |
| qf1_loss                | 0.0005131151  |
| qf2_loss                | 0.0005674377  |
| time_elapsed            | 2760          |
| total timesteps         | 554179        |
| value_loss              | 0.0002585033  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00078926556 |
| ent_coef_loss           | 0.0684267     |
| entropy                 | 1.4789848     |
| episodes                | 1680          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 556099        |
| policy_loss             | -0.1586566    |
| qf1_loss                | 0.00026363938 |
| qf2_loss                | 0.00021292224 |
| time_elapsed            | 2771          |
| total timesteps         | 556199        |
| value_loss              | 0.00020142287 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008078888  |
| ent_coef_loss           | 0.72918487    |
| entropy                 | 1.4512951     |
| episodes                | 1690          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 558485        |
| policy_loss             | -0.2076293    |
| qf1_loss                | 0.00025323863 |
| qf2_loss                | 0.00021213201 |
| time_elapsed            | 2782          |
| total timesteps         | 558585        |
| value_loss              | 0.00022919032 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00081710215 |
| ent_coef_loss           | -0.41682658   |
| entropy                 | 1.3941259     |
| episodes                | 1700          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 560840        |
| policy_loss             | -0.23325895   |
| qf1_loss                | 0.00070834724 |
| qf2_loss                | 0.00065741775 |
| time_elapsed            | 2794          |
| total timesteps         | 560940        |
| value_loss              | 0.00021160774 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008479547  |
| ent_coef_loss           | 2.7568526     |
| entropy                 | 1.4558439     |
| episodes                | 1710          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 563150        |
| policy_loss             | -0.12330447   |
| qf1_loss                | 0.00088213827 |
| qf2_loss                | 0.0007042144  |
| time_elapsed            | 2806          |
| total timesteps         | 563250        |
| value_loss              | 0.00056106056 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00084019924 |
| ent_coef_loss           | -1.6876299    |
| entropy                 | 1.3918581     |
| episodes                | 1720          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 564814        |
| policy_loss             | -0.21831438   |
| qf1_loss                | 0.00024260313 |
| qf2_loss                | 0.00022445156 |
| time_elapsed            | 2814          |
| total timesteps         | 564914        |
| value_loss              | 0.00014768756 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008261881  |
| ent_coef_loss           | -2.7348297    |
| entropy                 | 1.3749878     |
| episodes                | 1730          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 566921        |
| policy_loss             | -0.2502593    |
| qf1_loss                | 0.00022782151 |
| qf2_loss                | 0.00030931094 |
| time_elapsed            | 2825          |
| total timesteps         | 567021        |
| value_loss              | 0.000428086   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008278238  |
| ent_coef_loss           | -0.8833904    |
| entropy                 | 1.4760983     |
| episodes                | 1740          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 568726        |
| policy_loss             | -0.19874328   |
| qf1_loss                | 0.0002017     |
| qf2_loss                | 0.00031988416 |
| time_elapsed            | 2834          |
| total timesteps         | 568826        |
| value_loss              | 0.00015855621 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00082652457 |
| ent_coef_loss           | 1.2669773     |
| entropy                 | 1.554148      |
| episodes                | 1750          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 570387        |
| policy_loss             | -0.23093244   |
| qf1_loss                | 0.00055986084 |
| qf2_loss                | 0.000507965   |
| time_elapsed            | 2842          |
| total timesteps         | 570487        |
| value_loss              | 0.00031918398 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008473157  |
| ent_coef_loss           | 0.8084974     |
| entropy                 | 1.4879692     |
| episodes                | 1760          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 572487        |
| policy_loss             | -0.20817864   |
| qf1_loss                | 0.0002904462  |
| qf2_loss                | 0.0003214602  |
| time_elapsed            | 2853          |
| total timesteps         | 572587        |
| value_loss              | 0.00019797406 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008267875  |
| ent_coef_loss           | 2.0786676     |
| entropy                 | 1.5173452     |
| episodes                | 1770          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 574377        |
| policy_loss             | -0.28324962   |
| qf1_loss                | 0.00019478478 |
| qf2_loss                | 0.00028625154 |
| time_elapsed            | 2862          |
| total timesteps         | 574477        |
| value_loss              | 0.0002525699  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00083796907 |
| ent_coef_loss           | 0.5640031     |
| entropy                 | 1.4528098     |
| episodes                | 1780          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 576612        |
| policy_loss             | -0.19370748   |
| qf1_loss                | 0.00029347546 |
| qf2_loss                | 0.0005314069  |
| time_elapsed            | 2873          |
| total timesteps         | 576712        |
| value_loss              | 0.00043900084 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00081941625 |
| ent_coef_loss           | -0.21313792   |
| entropy                 | 1.4112293     |
| episodes                | 1790          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 579445        |
| policy_loss             | -0.13001393   |
| qf1_loss                | 0.0002968894  |
| qf2_loss                | 0.00022691367 |
| time_elapsed            | 2888          |
| total timesteps         | 579545        |
| value_loss              | 0.0002044813  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008043873  |
| ent_coef_loss           | 1.9083565     |
| entropy                 | 1.3804277     |
| episodes                | 1800          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 581480        |
| policy_loss             | -0.194457     |
| qf1_loss                | 0.00042824712 |
| qf2_loss                | 0.0002442846  |
| time_elapsed            | 2898          |
| total timesteps         | 581580        |
| value_loss              | 0.00036389142 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00081197097 |
| ent_coef_loss           | -4.098604     |
| entropy                 | 1.3571725     |
| episodes                | 1810          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 583517        |
| policy_loss             | -0.3896473    |
| qf1_loss                | 0.0006772025  |
| qf2_loss                | 0.0007945638  |
| time_elapsed            | 2908          |
| total timesteps         | 583617        |
| value_loss              | 0.00026273174 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007925885  |
| ent_coef_loss           | -1.947137     |
| entropy                 | 1.2959011     |
| episodes                | 1820          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 585645        |
| policy_loss             | -0.2849716    |
| qf1_loss                | 0.0004459414  |
| qf2_loss                | 0.00037669478 |
| time_elapsed            | 2919          |
| total timesteps         | 585745        |
| value_loss              | 0.0002822552  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00078593695 |
| ent_coef_loss           | -3.3377266    |
| entropy                 | 1.3568597     |
| episodes                | 1830          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 587896        |
| policy_loss             | -0.29581997   |
| qf1_loss                | 0.00023608108 |
| qf2_loss                | 0.00024329015 |
| time_elapsed            | 2930          |
| total timesteps         | 587996        |
| value_loss              | 0.00016921126 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00080847845 |
| ent_coef_loss           | 0.35096574    |
| entropy                 | 1.3008043     |
| episodes                | 1840          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 589856        |
| policy_loss             | -0.29123437   |
| qf1_loss                | 0.00030414693 |
| qf2_loss                | 0.00025936164 |
| time_elapsed            | 2940          |
| total timesteps         | 589956        |
| value_loss              | 0.00023724324 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008021646  |
| ent_coef_loss           | -0.05953899   |
| entropy                 | 1.3844621     |
| episodes                | 1850          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 592265        |
| policy_loss             | -0.18816103   |
| qf1_loss                | 0.00040464295 |
| qf2_loss                | 0.0005061548  |
| time_elapsed            | 2953          |
| total timesteps         | 592365        |
| value_loss              | 0.00015970081 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00080368994 |
| ent_coef_loss           | -0.4355827    |
| entropy                 | 1.4479908     |
| episodes                | 1860          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 594146        |
| policy_loss             | -0.15897089   |
| qf1_loss                | 0.0001916249  |
| qf2_loss                | 0.00031507976 |
| time_elapsed            | 2962          |
| total timesteps         | 594246        |
| value_loss              | 0.00022437269 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00082473055 |
| ent_coef_loss           | 2.7145302     |
| entropy                 | 1.4269986     |
| episodes                | 1870          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 596262        |
| policy_loss             | -0.20428364   |
| qf1_loss                | 0.00020333887 |
| qf2_loss                | 0.00023592384 |
| time_elapsed            | 2973          |
| total timesteps         | 596362        |
| value_loss              | 0.00027652318 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00084157975 |
| ent_coef_loss           | -0.27246153   |
| entropy                 | 1.508677      |
| episodes                | 1880          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 598234        |
| policy_loss             | -0.20793235   |
| qf1_loss                | 0.00032167253 |
| qf2_loss                | 0.00031614947 |
| time_elapsed            | 2982          |
| total timesteps         | 598334        |
| value_loss              | 0.00024110993 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008082699  |
| ent_coef_loss           | 1.5213051     |
| entropy                 | 1.5260819     |
| episodes                | 1890          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 600304        |
| policy_loss             | -0.2594393    |
| qf1_loss                | 0.00023291566 |
| qf2_loss                | 0.00029075283 |
| time_elapsed            | 2992          |
| total timesteps         | 600404        |
| value_loss              | 0.00024164238 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00080351485 |
| ent_coef_loss           | -2.411989     |
| entropy                 | 1.3771615     |
| episodes                | 1900          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 602319        |
| policy_loss             | -0.20310034   |
| qf1_loss                | 0.0002788407  |
| qf2_loss                | 0.00029531616 |
| time_elapsed            | 3003          |
| total timesteps         | 602419        |
| value_loss              | 0.00026763853 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007915484  |
| ent_coef_loss           | -2.160386     |
| entropy                 | 1.3822367     |
| episodes                | 1910          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 604455        |
| policy_loss             | -0.31435785   |
| qf1_loss                | 0.00035899115 |
| qf2_loss                | 0.00034392482 |
| time_elapsed            | 3014          |
| total timesteps         | 604555        |
| value_loss              | 0.00024647836 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00078194315 |
| ent_coef_loss           | -1.0059947    |
| entropy                 | 1.4516661     |
| episodes                | 1920          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 606095        |
| policy_loss             | -0.121990025  |
| qf1_loss                | 0.00022395347 |
| qf2_loss                | 0.00024603718 |
| time_elapsed            | 3021          |
| total timesteps         | 606195        |
| value_loss              | 0.00017491623 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00079721166 |
| ent_coef_loss           | -1.1486455    |
| entropy                 | 1.3729872     |
| episodes                | 1930          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 608065        |
| policy_loss             | -0.28514147   |
| qf1_loss                | 0.00014020753 |
| qf2_loss                | 0.00014255225 |
| time_elapsed            | 3031          |
| total timesteps         | 608165        |
| value_loss              | 9.938865e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008142034  |
| ent_coef_loss           | 1.8816609     |
| entropy                 | 1.4143155     |
| episodes                | 1940          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 609893        |
| policy_loss             | -0.3103251    |
| qf1_loss                | 0.000223804   |
| qf2_loss                | 0.00016131254 |
| time_elapsed            | 3041          |
| total timesteps         | 609993        |
| value_loss              | 8.7261724e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00081547356 |
| ent_coef_loss           | -1.3740673    |
| entropy                 | 1.4938385     |
| episodes                | 1950          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 611899        |
| policy_loss             | -0.17167452   |
| qf1_loss                | 0.0004374164  |
| qf2_loss                | 0.00040693436 |
| time_elapsed            | 3050          |
| total timesteps         | 611999        |
| value_loss              | 0.00020907866 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00080717413 |
| ent_coef_loss           | 2.7791872     |
| entropy                 | 1.3210156     |
| episodes                | 1960          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 613817        |
| policy_loss             | -0.2903378    |
| qf1_loss                | 0.0009578398  |
| qf2_loss                | 0.00088896934 |
| time_elapsed            | 3060          |
| total timesteps         | 613917        |
| value_loss              | 0.0001282181  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008175628  |
| ent_coef_loss           | 2.1044228     |
| entropy                 | 1.3769159     |
| episodes                | 1970          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 615890        |
| policy_loss             | -0.31660548   |
| qf1_loss                | 0.00041392358 |
| qf2_loss                | 0.00051328016 |
| time_elapsed            | 3071          |
| total timesteps         | 615990        |
| value_loss              | 0.00021054145 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008248564  |
| ent_coef_loss           | -3.99138      |
| entropy                 | 1.3796794     |
| episodes                | 1980          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 617687        |
| policy_loss             | -0.10519886   |
| qf1_loss                | 0.00051097706 |
| qf2_loss                | 0.00035844918 |
| time_elapsed            | 3079          |
| total timesteps         | 617787        |
| value_loss              | 0.0003095894  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00081864727 |
| ent_coef_loss           | 0.54913986    |
| entropy                 | 1.3719064     |
| episodes                | 1990          |
| fps                     | 200           |
| mean 100 episode reward | 0.8           |
| n_updates               | 619108        |
| policy_loss             | -0.04430989   |
| qf1_loss                | 0.00066470064 |
| qf2_loss                | 0.000387069   |
| time_elapsed            | 3087          |
| total timesteps         | 619208        |
| value_loss              | 0.00032796722 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00079403963 |
| ent_coef_loss           | -2.2315636    |
| entropy                 | 1.448417      |
| episodes                | 2000          |
| fps                     | 200           |
| mean 100 episode reward | 0.8           |
| n_updates               | 621078        |
| policy_loss             | -0.18991432   |
| qf1_loss                | 0.00042117297 |
| qf2_loss                | 0.0003272416  |
| time_elapsed            | 3097          |
| total timesteps         | 621178        |
| value_loss              | 0.0002981974  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00079573086 |
| ent_coef_loss           | 1.4144187     |
| entropy                 | 1.3609188     |
| episodes                | 2010          |
| fps                     | 200           |
| mean 100 episode reward | 0.8           |
| n_updates               | 623253        |
| policy_loss             | -0.20882156   |
| qf1_loss                | 0.00033999933 |
| qf2_loss                | 0.00019728843 |
| time_elapsed            | 3108          |
| total timesteps         | 623353        |
| value_loss              | 0.00019013586 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00079571264 |
| ent_coef_loss           | -1.3158844    |
| entropy                 | 1.3855871     |
| episodes                | 2020          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 625439        |
| policy_loss             | -0.20074792   |
| qf1_loss                | 0.00047959038 |
| qf2_loss                | 0.0006359555  |
| time_elapsed            | 3119          |
| total timesteps         | 625539        |
| value_loss              | 0.00032573374 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008023999  |
| ent_coef_loss           | 1.3423048     |
| entropy                 | 1.3704941     |
| episodes                | 2030          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 627404        |
| policy_loss             | -0.12430942   |
| qf1_loss                | 0.00036474958 |
| qf2_loss                | 0.00039679086 |
| time_elapsed            | 3130          |
| total timesteps         | 627504        |
| value_loss              | 0.00018091481 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00079967536 |
| ent_coef_loss           | 3.7178338     |
| entropy                 | 1.38551       |
| episodes                | 2040          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 629409        |
| policy_loss             | -0.10868554   |
| qf1_loss                | 0.00064521097 |
| qf2_loss                | 0.00033474033 |
| time_elapsed            | 3139          |
| total timesteps         | 629509        |
| value_loss              | 0.00045152544 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00081112736 |
| ent_coef_loss           | 1.4617281     |
| entropy                 | 1.3194863     |
| episodes                | 2050          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 631581        |
| policy_loss             | -0.096209794  |
| qf1_loss                | 0.0004798312  |
| qf2_loss                | 0.00029778632 |
| time_elapsed            | 3151          |
| total timesteps         | 631681        |
| value_loss              | 0.00047188508 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008184849  |
| ent_coef_loss           | -2.5988338    |
| entropy                 | 1.4034154     |
| episodes                | 2060          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 633814        |
| policy_loss             | -0.28395307   |
| qf1_loss                | 0.0003895269  |
| qf2_loss                | 0.00044361013 |
| time_elapsed            | 3162          |
| total timesteps         | 633914        |
| value_loss              | 0.00022452715 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00084585877 |
| ent_coef_loss           | 1.6237044     |
| entropy                 | 1.3636094     |
| episodes                | 2070          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 636091        |
| policy_loss             | -0.22824275   |
| qf1_loss                | 0.00034947705 |
| qf2_loss                | 0.00034050836 |
| time_elapsed            | 3173          |
| total timesteps         | 636191        |
| value_loss              | 0.0004058716  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00085850916 |
| ent_coef_loss           | -0.07199144   |
| entropy                 | 1.3471444     |
| episodes                | 2080          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 638086        |
| policy_loss             | -0.11280492   |
| qf1_loss                | 0.00032593912 |
| qf2_loss                | 0.00032648956 |
| time_elapsed            | 3184          |
| total timesteps         | 638186        |
| value_loss              | 0.00050995604 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000872366   |
| ent_coef_loss           | 0.9665616     |
| entropy                 | 1.342875      |
| episodes                | 2090          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 640318        |
| policy_loss             | -0.18387371   |
| qf1_loss                | 0.00021300641 |
| qf2_loss                | 0.0004143378  |
| time_elapsed            | 3195          |
| total timesteps         | 640418        |
| value_loss              | 0.0002473049  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008194073  |
| ent_coef_loss           | -0.35541123   |
| entropy                 | 1.334821      |
| episodes                | 2100          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 642462        |
| policy_loss             | -0.17303278   |
| qf1_loss                | 0.00023957688 |
| qf2_loss                | 0.00034760352 |
| time_elapsed            | 3205          |
| total timesteps         | 642562        |
| value_loss              | 0.00015492132 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007995567  |
| ent_coef_loss           | 0.561684      |
| entropy                 | 1.4245749     |
| episodes                | 2110          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 644597        |
| policy_loss             | -0.19221514   |
| qf1_loss                | 0.00034029398 |
| qf2_loss                | 0.00034083542 |
| time_elapsed            | 3217          |
| total timesteps         | 644697        |
| value_loss              | 0.0002125497  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00079656835 |
| ent_coef_loss           | -1.7032354    |
| entropy                 | 1.3798542     |
| episodes                | 2120          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 646758        |
| policy_loss             | -0.2692633    |
| qf1_loss                | 0.0003660411  |
| qf2_loss                | 0.00052335334 |
| time_elapsed            | 3227          |
| total timesteps         | 646858        |
| value_loss              | 0.00027596334 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008209603  |
| ent_coef_loss           | -1.1573509    |
| entropy                 | 1.3946676     |
| episodes                | 2130          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 648829        |
| policy_loss             | -0.23038113   |
| qf1_loss                | 0.00024520367 |
| qf2_loss                | 0.0002583685  |
| time_elapsed            | 3238          |
| total timesteps         | 648929        |
| value_loss              | 0.00023382084 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008189479  |
| ent_coef_loss           | -5.8435864    |
| entropy                 | 1.3808823     |
| episodes                | 2140          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 650765        |
| policy_loss             | -0.3598417    |
| qf1_loss                | 0.0001647382  |
| qf2_loss                | 0.00015866145 |
| time_elapsed            | 3248          |
| total timesteps         | 650865        |
| value_loss              | 0.00014267984 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00080718065 |
| ent_coef_loss           | 0.23297775    |
| entropy                 | 1.4879253     |
| episodes                | 2150          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 652848        |
| policy_loss             | -0.17855912   |
| qf1_loss                | 0.0004001777  |
| qf2_loss                | 0.0007530883  |
| time_elapsed            | 3258          |
| total timesteps         | 652948        |
| value_loss              | 0.00047166704 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00082453905 |
| ent_coef_loss           | -2.4782183    |
| entropy                 | 1.415736      |
| episodes                | 2160          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 655144        |
| policy_loss             | -0.23552538   |
| qf1_loss                | 0.00037656593 |
| qf2_loss                | 0.00023989257 |
| time_elapsed            | 3269          |
| total timesteps         | 655244        |
| value_loss              | 0.00023735981 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000815168   |
| ent_coef_loss           | 0.022462726   |
| entropy                 | 1.3982227     |
| episodes                | 2170          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 657212        |
| policy_loss             | -0.2800991    |
| qf1_loss                | 0.00027337263 |
| qf2_loss                | 0.00034419599 |
| time_elapsed            | 3280          |
| total timesteps         | 657312        |
| value_loss              | 0.00019268977 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008358994  |
| ent_coef_loss           | -1.8319752    |
| entropy                 | 1.4677734     |
| episodes                | 2180          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 659024        |
| policy_loss             | -0.2639838    |
| qf1_loss                | 0.0006596863  |
| qf2_loss                | 0.0008349578  |
| time_elapsed            | 3288          |
| total timesteps         | 659124        |
| value_loss              | 0.00025922753 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008522735  |
| ent_coef_loss           | 1.9262862     |
| entropy                 | 1.3831685     |
| episodes                | 2190          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 660823        |
| policy_loss             | -0.3252449    |
| qf1_loss                | 0.00053682877 |
| qf2_loss                | 0.00068258843 |
| time_elapsed            | 3297          |
| total timesteps         | 660923        |
| value_loss              | 0.00026442364 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008806489  |
| ent_coef_loss           | 2.862177      |
| entropy                 | 1.5691334     |
| episodes                | 2200          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 662988        |
| policy_loss             | -0.21496648   |
| qf1_loss                | 0.00018638594 |
| qf2_loss                | 0.00027658074 |
| time_elapsed            | 3308          |
| total timesteps         | 663088        |
| value_loss              | 0.00022373277 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008994847  |
| ent_coef_loss           | 1.8843684     |
| entropy                 | 1.4277049     |
| episodes                | 2210          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 664785        |
| policy_loss             | -0.20649906   |
| qf1_loss                | 0.00032889168 |
| qf2_loss                | 0.00035141938 |
| time_elapsed            | 3318          |
| total timesteps         | 664885        |
| value_loss              | 0.0002610996  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00091695035 |
| ent_coef_loss           | -4.4459167    |
| entropy                 | 1.4744345     |
| episodes                | 2220          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 666734        |
| policy_loss             | -0.33709526   |
| qf1_loss                | 0.0001643354  |
| qf2_loss                | 0.00012063829 |
| time_elapsed            | 3328          |
| total timesteps         | 666834        |
| value_loss              | 0.00010946715 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00092542573 |
| ent_coef_loss           | 1.6636252     |
| entropy                 | 1.5394992     |
| episodes                | 2230          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 668685        |
| policy_loss             | -0.19218582   |
| qf1_loss                | 0.0016179907  |
| qf2_loss                | 0.0010640309  |
| time_elapsed            | 3338          |
| total timesteps         | 668785        |
| value_loss              | 0.0001946003  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009166898  |
| ent_coef_loss           | -3.2705007    |
| entropy                 | 1.4786221     |
| episodes                | 2240          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 670730        |
| policy_loss             | -0.33784252   |
| qf1_loss                | 0.0005033005  |
| qf2_loss                | 0.0006687852  |
| time_elapsed            | 3348          |
| total timesteps         | 670830        |
| value_loss              | 0.00015409585 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009142173  |
| ent_coef_loss           | 1.7381653     |
| entropy                 | 1.5662981     |
| episodes                | 2250          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 672611        |
| policy_loss             | -0.14544475   |
| qf1_loss                | 0.0003601112  |
| qf2_loss                | 0.00040716925 |
| time_elapsed            | 3357          |
| total timesteps         | 672711        |
| value_loss              | 0.00035207032 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009075026  |
| ent_coef_loss           | 1.2593772     |
| entropy                 | 1.5557009     |
| episodes                | 2260          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 674708        |
| policy_loss             | -0.18049245   |
| qf1_loss                | 0.0003075093  |
| qf2_loss                | 0.00024230474 |
| time_elapsed            | 3368          |
| total timesteps         | 674808        |
| value_loss              | 0.0003381365  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009139554  |
| ent_coef_loss           | 3.2575898     |
| entropy                 | 1.4863322     |
| episodes                | 2270          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 676617        |
| policy_loss             | -0.23938814   |
| qf1_loss                | 0.000616095   |
| qf2_loss                | 0.00038155002 |
| time_elapsed            | 3377          |
| total timesteps         | 676717        |
| value_loss              | 0.0002550098  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.000901888  |
| ent_coef_loss           | -0.23837292  |
| entropy                 | 1.5131214    |
| episodes                | 2280         |
| fps                     | 200          |
| mean 100 episode reward | 1.2          |
| n_updates               | 678831       |
| policy_loss             | -0.31265262  |
| qf1_loss                | 0.0002461283 |
| qf2_loss                | 0.0001665428 |
| time_elapsed            | 3388         |
| total timesteps         | 678931       |
| value_loss              | 0.0001936262 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00089339726 |
| ent_coef_loss           | -0.5693042    |
| entropy                 | 1.6361291     |
| episodes                | 2290          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 680823        |
| policy_loss             | -0.14109667   |
| qf1_loss                | 9.355738e-05  |
| qf2_loss                | 0.00021440124 |
| time_elapsed            | 3398          |
| total timesteps         | 680923        |
| value_loss              | 0.00014332574 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00090605364 |
| ent_coef_loss           | 0.6385891     |
| entropy                 | 1.5550765     |
| episodes                | 2300          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 683260        |
| policy_loss             | -0.17201035   |
| qf1_loss                | 0.00022867674 |
| qf2_loss                | 0.00029478688 |
| time_elapsed            | 3410          |
| total timesteps         | 683360        |
| value_loss              | 0.00025933178 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00089273293 |
| ent_coef_loss           | -1.9844261    |
| entropy                 | 1.5335786     |
| episodes                | 2310          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 685290        |
| policy_loss             | -0.22552103   |
| qf1_loss                | 0.0002529739  |
| qf2_loss                | 0.00030632218 |
| time_elapsed            | 3421          |
| total timesteps         | 685390        |
| value_loss              | 0.00027113076 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008669556  |
| ent_coef_loss           | 1.54037       |
| entropy                 | 1.546385      |
| episodes                | 2320          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 687064        |
| policy_loss             | -0.22811526   |
| qf1_loss                | 0.00042456377 |
| qf2_loss                | 0.00030643452 |
| time_elapsed            | 3430          |
| total timesteps         | 687164        |
| value_loss              | 0.0002579253  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008728965  |
| ent_coef_loss           | -0.7605933    |
| entropy                 | 1.5587146     |
| episodes                | 2330          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 689117        |
| policy_loss             | -0.28753686   |
| qf1_loss                | 0.00048972433 |
| qf2_loss                | 0.00045718445 |
| time_elapsed            | 3440          |
| total timesteps         | 689217        |
| value_loss              | 0.00013584165 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00088910793 |
| ent_coef_loss           | 0.97250056    |
| entropy                 | 1.4654448     |
| episodes                | 2340          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 691597        |
| policy_loss             | -0.1784955    |
| qf1_loss                | 0.00038648897 |
| qf2_loss                | 0.00037437008 |
| time_elapsed            | 3453          |
| total timesteps         | 691697        |
| value_loss              | 0.00059491646 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00091166457 |
| ent_coef_loss           | 2.217702      |
| entropy                 | 1.6064177     |
| episodes                | 2350          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 693833        |
| policy_loss             | -0.1651009    |
| qf1_loss                | 0.00049638236 |
| qf2_loss                | 0.00048824673 |
| time_elapsed            | 3465          |
| total timesteps         | 693933        |
| value_loss              | 0.0006937132  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009258367  |
| ent_coef_loss           | -0.559644     |
| entropy                 | 1.5985328     |
| episodes                | 2360          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 695821        |
| policy_loss             | -0.34189665   |
| qf1_loss                | 0.00032878827 |
| qf2_loss                | 0.00021975301 |
| time_elapsed            | 3474          |
| total timesteps         | 695921        |
| value_loss              | 0.00031471578 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008917646  |
| ent_coef_loss           | 0.8181226     |
| entropy                 | 1.5207107     |
| episodes                | 2370          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 697964        |
| policy_loss             | -0.18162222   |
| qf1_loss                | 0.00074968    |
| qf2_loss                | 0.0010208808  |
| time_elapsed            | 3486          |
| total timesteps         | 698064        |
| value_loss              | 0.00014782618 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00088351534 |
| ent_coef_loss           | 2.9668524     |
| entropy                 | 1.6379156     |
| episodes                | 2380          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 699812        |
| policy_loss             | -0.16561973   |
| qf1_loss                | 0.00028489102 |
| qf2_loss                | 0.00022267574 |
| time_elapsed            | 3495          |
| total timesteps         | 699912        |
| value_loss              | 0.00016780102 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008705044  |
| ent_coef_loss           | -3.3479466    |
| entropy                 | 1.4971793     |
| episodes                | 2390          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 701731        |
| policy_loss             | -0.20551711   |
| qf1_loss                | 0.0005729297  |
| qf2_loss                | 0.00082240877 |
| time_elapsed            | 3504          |
| total timesteps         | 701831        |
| value_loss              | 0.00025827944 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008675581  |
| ent_coef_loss           | -1.2865666    |
| entropy                 | 1.5475936     |
| episodes                | 2400          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 703446        |
| policy_loss             | -0.19646977   |
| qf1_loss                | 0.0002901267  |
| qf2_loss                | 0.00023590508 |
| time_elapsed            | 3513          |
| total timesteps         | 703546        |
| value_loss              | 0.00016667806 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.000847544  |
| ent_coef_loss           | -1.5010462   |
| entropy                 | 1.5079651    |
| episodes                | 2410         |
| fps                     | 200          |
| mean 100 episode reward | 1.1          |
| n_updates               | 705393       |
| policy_loss             | -0.29775697  |
| qf1_loss                | 0.0005464456 |
| qf2_loss                | 0.0002287963 |
| time_elapsed            | 3523         |
| total timesteps         | 705493       |
| value_loss              | 0.0005410182 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00085035583 |
| ent_coef_loss           | -0.010927677  |
| entropy                 | 1.3771105     |
| episodes                | 2420          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 706831        |
| policy_loss             | -0.04230367   |
| qf1_loss                | 0.0007879939  |
| qf2_loss                | 0.00057700044 |
| time_elapsed            | 3530          |
| total timesteps         | 706931        |
| value_loss              | 0.0003808893  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008656445  |
| ent_coef_loss           | -0.78045326   |
| entropy                 | 1.5056052     |
| episodes                | 2430          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 708965        |
| policy_loss             | -0.3177073    |
| qf1_loss                | 0.00035175146 |
| qf2_loss                | 0.00029466746 |
| time_elapsed            | 3541          |
| total timesteps         | 709065        |
| value_loss              | 0.0002221771  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00089397386 |
| ent_coef_loss           | 1.1183207     |
| entropy                 | 1.5790709     |
| episodes                | 2440          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 711149        |
| policy_loss             | -0.33895475   |
| qf1_loss                | 0.00044625028 |
| qf2_loss                | 0.00024176453 |
| time_elapsed            | 3552          |
| total timesteps         | 711249        |
| value_loss              | 0.00017568396 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00089790806 |
| ent_coef_loss           | 3.0735795     |
| entropy                 | 1.5211338     |
| episodes                | 2450          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 713066        |
| policy_loss             | -0.23454931   |
| qf1_loss                | 0.00032683567 |
| qf2_loss                | 0.0004289573  |
| time_elapsed            | 3561          |
| total timesteps         | 713166        |
| value_loss              | 0.00023656139 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00092179497 |
| ent_coef_loss           | -0.69345194   |
| entropy                 | 1.5790906     |
| episodes                | 2460          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 714917        |
| policy_loss             | -0.30957413   |
| qf1_loss                | 0.00033481815 |
| qf2_loss                | 0.00015575779 |
| time_elapsed            | 3571          |
| total timesteps         | 715017        |
| value_loss              | 0.00021130616 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009638804  |
| ent_coef_loss           | 1.4241328     |
| entropy                 | 1.545551      |
| episodes                | 2470          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 716739        |
| policy_loss             | -0.26692468   |
| qf1_loss                | 0.00030064088 |
| qf2_loss                | 0.00025191484 |
| time_elapsed            | 3580          |
| total timesteps         | 716839        |
| value_loss              | 0.00027544287 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00094764086 |
| ent_coef_loss           | -1.8605003    |
| entropy                 | 1.460845      |
| episodes                | 2480          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 718966        |
| policy_loss             | -0.32409436   |
| qf1_loss                | 0.00018893054 |
| qf2_loss                | 0.00025868992 |
| time_elapsed            | 3591          |
| total timesteps         | 719066        |
| value_loss              | 0.00018977595 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00092756486 |
| ent_coef_loss           | 1.1836746     |
| entropy                 | 1.588026      |
| episodes                | 2490          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 720634        |
| policy_loss             | -0.2643356    |
| qf1_loss                | 0.00042051062 |
| qf2_loss                | 0.00021032621 |
| time_elapsed            | 3600          |
| total timesteps         | 720734        |
| value_loss              | 0.00032319932 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009503446  |
| ent_coef_loss           | -0.9139689    |
| entropy                 | 1.5441285     |
| episodes                | 2500          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 722141        |
| policy_loss             | -0.24873629   |
| qf1_loss                | 0.00021557923 |
| qf2_loss                | 0.00025234907 |
| time_elapsed            | 3607          |
| total timesteps         | 722241        |
| value_loss              | 0.00034475015 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00095443544 |
| ent_coef_loss           | -0.76000273   |
| entropy                 | 1.5683905     |
| episodes                | 2510          |
| fps                     | 200           |
| mean 100 episode reward | 0.8           |
| n_updates               | 724152        |
| policy_loss             | -0.29342493   |
| qf1_loss                | 0.00013811472 |
| qf2_loss                | 0.00019631277 |
| time_elapsed            | 3617          |
| total timesteps         | 724252        |
| value_loss              | 0.00017153527 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009750284  |
| ent_coef_loss           | 0.9450017     |
| entropy                 | 1.5840275     |
| episodes                | 2520          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 726689        |
| policy_loss             | -0.28440654   |
| qf1_loss                | 0.00021711556 |
| qf2_loss                | 8.036806e-05  |
| time_elapsed            | 3630          |
| total timesteps         | 726789        |
| value_loss              | 0.0002409025  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009915694  |
| ent_coef_loss           | 1.9269352     |
| entropy                 | 1.5442859     |
| episodes                | 2530          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 728502        |
| policy_loss             | -0.23588604   |
| qf1_loss                | 0.00024270109 |
| qf2_loss                | 0.00017697463 |
| time_elapsed            | 3639          |
| total timesteps         | 728602        |
| value_loss              | 0.0001166526  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0010009536  |
| ent_coef_loss           | 1.4549749     |
| entropy                 | 1.5343761     |
| episodes                | 2540          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 730491        |
| policy_loss             | -0.15109968   |
| qf1_loss                | 0.0003846556  |
| qf2_loss                | 0.0004699104  |
| time_elapsed            | 3648          |
| total timesteps         | 730591        |
| value_loss              | 0.00029126095 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0010023926  |
| ent_coef_loss           | 0.8002867     |
| entropy                 | 1.5907913     |
| episodes                | 2550          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 732249        |
| policy_loss             | -0.22791724   |
| qf1_loss                | 0.00026342316 |
| qf2_loss                | 0.000269687   |
| time_elapsed            | 3657          |
| total timesteps         | 732349        |
| value_loss              | 0.0003513183  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0010003676   |
| ent_coef_loss           | 0.4364367      |
| entropy                 | 1.5394654      |
| episodes                | 2560           |
| fps                     | 200            |
| mean 100 episode reward | 0.9            |
| n_updates               | 734407         |
| policy_loss             | -0.2380712     |
| qf1_loss                | 0.00019630056  |
| qf2_loss                | 0.00016128886  |
| time_elapsed            | 3668           |
| total timesteps         | 734507         |
| value_loss              | 0.000119821576 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001012358   |
| ent_coef_loss           | -0.063696265  |
| entropy                 | 1.5394619     |
| episodes                | 2570          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 736122        |
| policy_loss             | -0.21116854   |
| qf1_loss                | 0.00020484065 |
| qf2_loss                | 0.00016056774 |
| time_elapsed            | 3676          |
| total timesteps         | 736222        |
| value_loss              | 0.00016584029 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009792049  |
| ent_coef_loss           | -0.4794265    |
| entropy                 | 1.5958977     |
| episodes                | 2580          |
| fps                     | 200           |
| mean 100 episode reward | 0.9           |
| n_updates               | 738143        |
| policy_loss             | -0.20777124   |
| qf1_loss                | 0.00015022735 |
| qf2_loss                | 0.000194761   |
| time_elapsed            | 3686          |
| total timesteps         | 738243        |
| value_loss              | 9.8578166e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001001889   |
| ent_coef_loss           | -2.722743     |
| entropy                 | 1.6062002     |
| episodes                | 2590          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 740291        |
| policy_loss             | -0.26563507   |
| qf1_loss                | 0.00018341717 |
| qf2_loss                | 0.00013360777 |
| time_elapsed            | 3697          |
| total timesteps         | 740391        |
| value_loss              | 0.00021938604 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0010218474  |
| ent_coef_loss           | -0.010973543  |
| entropy                 | 1.5789199     |
| episodes                | 2600          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 742454        |
| policy_loss             | -0.22236808   |
| qf1_loss                | 0.0001965398  |
| qf2_loss                | 0.00023347286 |
| time_elapsed            | 3708          |
| total timesteps         | 742554        |
| value_loss              | 0.00017471565 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0010331676  |
| ent_coef_loss           | -2.8848414    |
| entropy                 | 1.5768859     |
| episodes                | 2610          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 744458        |
| policy_loss             | -0.28930405   |
| qf1_loss                | 0.00016448725 |
| qf2_loss                | 0.00018829662 |
| time_elapsed            | 3718          |
| total timesteps         | 744558        |
| value_loss              | 0.00019772539 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0010118749  |
| ent_coef_loss           | -1.3944566    |
| entropy                 | 1.5183469     |
| episodes                | 2620          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 746534        |
| policy_loss             | -0.33754256   |
| qf1_loss                | 0.00031424992 |
| qf2_loss                | 0.00027387467 |
| time_elapsed            | 3728          |
| total timesteps         | 746634        |
| value_loss              | 0.00011235857 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009921171  |
| ent_coef_loss           | 2.0341964     |
| entropy                 | 1.5999413     |
| episodes                | 2630          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 748444        |
| policy_loss             | -0.21563604   |
| qf1_loss                | 0.00018953028 |
| qf2_loss                | 0.00026231623 |
| time_elapsed            | 3738          |
| total timesteps         | 748544        |
| value_loss              | 0.00029728614 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009952467  |
| ent_coef_loss           | -1.8339295    |
| entropy                 | 1.6270866     |
| episodes                | 2640          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 750656        |
| policy_loss             | -0.23057939   |
| qf1_loss                | 0.00034155993 |
| qf2_loss                | 0.00047505664 |
| time_elapsed            | 3749          |
| total timesteps         | 750756        |
| value_loss              | 0.0003198309  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009730252  |
| ent_coef_loss           | -0.86164856   |
| entropy                 | 1.6660287     |
| episodes                | 2650          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 752690        |
| policy_loss             | -0.22679906   |
| qf1_loss                | 0.0002631802  |
| qf2_loss                | 0.00015386692 |
| time_elapsed            | 3759          |
| total timesteps         | 752790        |
| value_loss              | 0.0003064646  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009860905  |
| ent_coef_loss           | -0.10126817   |
| entropy                 | 1.6231585     |
| episodes                | 2660          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 754491        |
| policy_loss             | -0.26799434   |
| qf1_loss                | 0.00016349612 |
| qf2_loss                | 0.00018187502 |
| time_elapsed            | 3767          |
| total timesteps         | 754591        |
| value_loss              | 0.00017110605 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0010122136  |
| ent_coef_loss           | 2.1733656     |
| entropy                 | 1.5503073     |
| episodes                | 2670          |
| fps                     | 200           |
| mean 100 episode reward | 1.4           |
| n_updates               | 756642        |
| policy_loss             | -0.25118083   |
| qf1_loss                | 0.00021582568 |
| qf2_loss                | 0.0002769794  |
| time_elapsed            | 3778          |
| total timesteps         | 756742        |
| value_loss              | 0.00027290653 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00101024    |
| ent_coef_loss           | -3.0460787    |
| entropy                 | 1.6232417     |
| episodes                | 2680          |
| fps                     | 200           |
| mean 100 episode reward | 1.4           |
| n_updates               | 758400        |
| policy_loss             | -0.21403897   |
| qf1_loss                | 0.0010421567  |
| qf2_loss                | 0.0010623365  |
| time_elapsed            | 3787          |
| total timesteps         | 758500        |
| value_loss              | 0.00018834532 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000966884   |
| ent_coef_loss           | -2.5748494    |
| entropy                 | 1.6041334     |
| episodes                | 2690          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 760265        |
| policy_loss             | -0.26220042   |
| qf1_loss                | 0.00025098122 |
| qf2_loss                | 0.00033353548 |
| time_elapsed            | 3796          |
| total timesteps         | 760365        |
| value_loss              | 0.00016860526 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00090607785 |
| ent_coef_loss           | 1.7911888     |
| entropy                 | 1.5526698     |
| episodes                | 2700          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 762382        |
| policy_loss             | -0.22687024   |
| qf1_loss                | 0.00015179247 |
| qf2_loss                | 0.00015770484 |
| time_elapsed            | 3806          |
| total timesteps         | 762482        |
| value_loss              | 0.0004063583  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00090853265 |
| ent_coef_loss           | 2.1804953     |
| entropy                 | 1.5985144     |
| episodes                | 2710          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 764724        |
| policy_loss             | -0.1726341    |
| qf1_loss                | 0.00025638388 |
| qf2_loss                | 0.00021567527 |
| time_elapsed            | 3819          |
| total timesteps         | 764824        |
| value_loss              | 0.00013883637 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009491201  |
| ent_coef_loss           | 0.7327574     |
| entropy                 | 1.6520158     |
| episodes                | 2720          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 766948        |
| policy_loss             | -0.1564787    |
| qf1_loss                | 0.0001882599  |
| qf2_loss                | 0.00022736436 |
| time_elapsed            | 3830          |
| total timesteps         | 767048        |
| value_loss              | 0.00016063686 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009806054  |
| ent_coef_loss           | -0.99893296   |
| entropy                 | 1.6066132     |
| episodes                | 2730          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 768984        |
| policy_loss             | -0.29772043   |
| qf1_loss                | 0.00043922104 |
| qf2_loss                | 0.0003745989  |
| time_elapsed            | 3840          |
| total timesteps         | 769084        |
| value_loss              | 0.00022490123 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009461441  |
| ent_coef_loss           | -2.5665069    |
| entropy                 | 1.5852907     |
| episodes                | 2740          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 771019        |
| policy_loss             | -0.22470951   |
| qf1_loss                | 0.00021616087 |
| qf2_loss                | 0.00028505956 |
| time_elapsed            | 3851          |
| total timesteps         | 771119        |
| value_loss              | 0.00022116749 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00094212743 |
| ent_coef_loss           | 3.250554      |
| entropy                 | 1.5591922     |
| episodes                | 2750          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 772957        |
| policy_loss             | -0.25655293   |
| qf1_loss                | 0.00026276204 |
| qf2_loss                | 0.0002394899  |
| time_elapsed            | 3860          |
| total timesteps         | 773057        |
| value_loss              | 0.00028608297 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00095514435 |
| ent_coef_loss           | 1.7856817     |
| entropy                 | 1.5854754     |
| episodes                | 2760          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 775129        |
| policy_loss             | -0.33261174   |
| qf1_loss                | 0.00019591389 |
| qf2_loss                | 0.00023370612 |
| time_elapsed            | 3871          |
| total timesteps         | 775229        |
| value_loss              | 0.00012141591 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009681255  |
| ent_coef_loss           | 1.3345442     |
| entropy                 | 1.68478       |
| episodes                | 2770          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 777176        |
| policy_loss             | -0.2174892    |
| qf1_loss                | 0.00023119443 |
| qf2_loss                | 0.00021089497 |
| time_elapsed            | 3882          |
| total timesteps         | 777276        |
| value_loss              | 0.00013141693 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00093240244 |
| ent_coef_loss           | 0.47814566    |
| entropy                 | 1.6238399     |
| episodes                | 2780          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 779266        |
| policy_loss             | -0.31469992   |
| qf1_loss                | 0.00012567363 |
| qf2_loss                | 0.0002037329  |
| time_elapsed            | 3892          |
| total timesteps         | 779366        |
| value_loss              | 0.00011058496 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00093340426 |
| ent_coef_loss           | 1.0609417     |
| entropy                 | 1.6353334     |
| episodes                | 2790          |
| fps                     | 200           |
| mean 100 episode reward | 1.4           |
| n_updates               | 781210        |
| policy_loss             | -0.15890947   |
| qf1_loss                | 0.00013265219 |
| qf2_loss                | 0.00016200576 |
| time_elapsed            | 3902          |
| total timesteps         | 781310        |
| value_loss              | 0.00016222027 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000938088   |
| ent_coef_loss           | -1.4788971    |
| entropy                 | 1.555031      |
| episodes                | 2800          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 783257        |
| policy_loss             | -0.2694815    |
| qf1_loss                | 0.00032800023 |
| qf2_loss                | 0.0002816738  |
| time_elapsed            | 3913          |
| total timesteps         | 783357        |
| value_loss              | 0.0002092402  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009279405  |
| ent_coef_loss           | 3.4877386     |
| entropy                 | 1.4654348     |
| episodes                | 2810          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 785176        |
| policy_loss             | -0.2839598    |
| qf1_loss                | 0.00016992007 |
| qf2_loss                | 0.00013117191 |
| time_elapsed            | 3922          |
| total timesteps         | 785276        |
| value_loss              | 0.00020395692 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009398337  |
| ent_coef_loss           | 0.06376797    |
| entropy                 | 1.5943127     |
| episodes                | 2820          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 787078        |
| policy_loss             | -0.199543     |
| qf1_loss                | 0.000271663   |
| qf2_loss                | 0.0004661026  |
| time_elapsed            | 3932          |
| total timesteps         | 787178        |
| value_loss              | 0.00030783942 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00092539133 |
| ent_coef_loss           | 2.4834588     |
| entropy                 | 1.6807096     |
| episodes                | 2830          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 789184        |
| policy_loss             | -0.29532695   |
| qf1_loss                | 0.00024189203 |
| qf2_loss                | 0.00041183457 |
| time_elapsed            | 3943          |
| total timesteps         | 789284        |
| value_loss              | 0.00024128333 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009124644  |
| ent_coef_loss           | -0.7745267    |
| entropy                 | 1.5489235     |
| episodes                | 2840          |
| fps                     | 200           |
| mean 100 episode reward | 1.4           |
| n_updates               | 791183        |
| policy_loss             | -0.294837     |
| qf1_loss                | 0.0002356958  |
| qf2_loss                | 0.0002455736  |
| time_elapsed            | 3953          |
| total timesteps         | 791283        |
| value_loss              | 0.00016552584 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008906746  |
| ent_coef_loss           | 3.736504      |
| entropy                 | 1.5827663     |
| episodes                | 2850          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 793056        |
| policy_loss             | -0.123080045  |
| qf1_loss                | 0.0002906233  |
| qf2_loss                | 0.00066030177 |
| time_elapsed            | 3962          |
| total timesteps         | 793156        |
| value_loss              | 0.0003993165  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000895117   |
| ent_coef_loss           | -0.327641     |
| entropy                 | 1.6168752     |
| episodes                | 2860          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 795197        |
| policy_loss             | -0.2345508    |
| qf1_loss                | 0.0003937107  |
| qf2_loss                | 0.00044132175 |
| time_elapsed            | 3973          |
| total timesteps         | 795297        |
| value_loss              | 0.00017082738 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00090463855 |
| ent_coef_loss           | 2.0012405     |
| entropy                 | 1.595514      |
| episodes                | 2870          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 797185        |
| policy_loss             | -0.24885789   |
| qf1_loss                | 0.00022484682 |
| qf2_loss                | 0.00029494188 |
| time_elapsed            | 3982          |
| total timesteps         | 797285        |
| value_loss              | 0.00029193517 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008933193  |
| ent_coef_loss           | 0.74671596    |
| entropy                 | 1.5325637     |
| episodes                | 2880          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 799180        |
| policy_loss             | -0.28958178   |
| qf1_loss                | 0.00020446954 |
| qf2_loss                | 0.00019445    |
| time_elapsed            | 3993          |
| total timesteps         | 799280        |
| value_loss              | 0.0001437167  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00089545426 |
| ent_coef_loss           | -4.907062     |
| entropy                 | 1.5822192     |
| episodes                | 2890          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 801347        |
| policy_loss             | -0.33360747   |
| qf1_loss                | 0.00017230223 |
| qf2_loss                | 0.00013539982 |
| time_elapsed            | 4004          |
| total timesteps         | 801447        |
| value_loss              | 0.00010250357 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000915238   |
| ent_coef_loss           | 1.8625517     |
| entropy                 | 1.6469254     |
| episodes                | 2900          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 803085        |
| policy_loss             | -0.21529244   |
| qf1_loss                | 0.00019332764 |
| qf2_loss                | 0.0001903334  |
| time_elapsed            | 4012          |
| total timesteps         | 803185        |
| value_loss              | 0.00015108963 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00092346896 |
| ent_coef_loss           | 2.314923      |
| entropy                 | 1.5465325     |
| episodes                | 2910          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 805110        |
| policy_loss             | -0.27004224   |
| qf1_loss                | 0.0003299759  |
| qf2_loss                | 0.00027502642 |
| time_elapsed            | 4022          |
| total timesteps         | 805210        |
| value_loss              | 0.00010971345 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00092469656 |
| ent_coef_loss           | -3.0009146    |
| entropy                 | 1.4978511     |
| episodes                | 2920          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 806690        |
| policy_loss             | -0.37013185   |
| qf1_loss                | 0.00022853745 |
| qf2_loss                | 0.00015679281 |
| time_elapsed            | 4030          |
| total timesteps         | 806790        |
| value_loss              | 0.00021672162 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009385676  |
| ent_coef_loss           | -1.7118422    |
| entropy                 | 1.5680146     |
| episodes                | 2930          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 808887        |
| policy_loss             | -0.39095423   |
| qf1_loss                | 0.00015142978 |
| qf2_loss                | 8.430892e-05  |
| time_elapsed            | 4041          |
| total timesteps         | 808987        |
| value_loss              | 7.91317e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00096005434 |
| ent_coef_loss           | -1.559851     |
| entropy                 | 1.5034289     |
| episodes                | 2940          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 811272        |
| policy_loss             | -0.26275486   |
| qf1_loss                | 0.00015535197 |
| qf2_loss                | 0.0002535138  |
| time_elapsed            | 4053          |
| total timesteps         | 811372        |
| value_loss              | 0.00013479355 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0010003285  |
| ent_coef_loss           | 0.76405585    |
| entropy                 | 1.6178997     |
| episodes                | 2950          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 813323        |
| policy_loss             | -0.18736371   |
| qf1_loss                | 0.00045074825 |
| qf2_loss                | 0.00046902717 |
| time_elapsed            | 4064          |
| total timesteps         | 813423        |
| value_loss              | 0.0002397288  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009855677  |
| ent_coef_loss           | -0.28186578   |
| entropy                 | 1.6563187     |
| episodes                | 2960          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 815141        |
| policy_loss             | -0.26539096   |
| qf1_loss                | 0.00034086942 |
| qf2_loss                | 0.00029059118 |
| time_elapsed            | 4072          |
| total timesteps         | 815241        |
| value_loss              | 0.00017089712 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009807661  |
| ent_coef_loss           | 1.0429862     |
| entropy                 | 1.5734154     |
| episodes                | 2970          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 816764        |
| policy_loss             | -0.29971242   |
| qf1_loss                | 0.00017698706 |
| qf2_loss                | 0.0002064016  |
| time_elapsed            | 4081          |
| total timesteps         | 816864        |
| value_loss              | 0.0001387607  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00094831304 |
| ent_coef_loss           | -1.8676608    |
| entropy                 | 1.6550782     |
| episodes                | 2980          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 818681        |
| policy_loss             | -0.30025613   |
| qf1_loss                | 0.00025384245 |
| qf2_loss                | 0.00014052998 |
| time_elapsed            | 4091          |
| total timesteps         | 818781        |
| value_loss              | 0.00019301444 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00095300114 |
| ent_coef_loss           | -0.3083787    |
| entropy                 | 1.6461949     |
| episodes                | 2990          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 820298        |
| policy_loss             | -0.29531878   |
| qf1_loss                | 0.00033465572 |
| qf2_loss                | 0.00042824406 |
| time_elapsed            | 4099          |
| total timesteps         | 820398        |
| value_loss              | 0.00020158949 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00097168755 |
| ent_coef_loss           | -0.6977179    |
| entropy                 | 1.6048324     |
| episodes                | 3000          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 822278        |
| policy_loss             | -0.2588114    |
| qf1_loss                | 0.00023494288 |
| qf2_loss                | 0.00010168856 |
| time_elapsed            | 4109          |
| total timesteps         | 822378        |
| value_loss              | 0.00016066633 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009707438  |
| ent_coef_loss           | 1.5806943     |
| entropy                 | 1.5701702     |
| episodes                | 3010          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 824491        |
| policy_loss             | -0.23890656   |
| qf1_loss                | 0.0003759637  |
| qf2_loss                | 0.0002141811  |
| time_elapsed            | 4121          |
| total timesteps         | 824591        |
| value_loss              | 0.00026050833 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000969058   |
| ent_coef_loss           | 2.0211914     |
| entropy                 | 1.652853      |
| episodes                | 3020          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 826614        |
| policy_loss             | -0.24856323   |
| qf1_loss                | 0.0003018058  |
| qf2_loss                | 0.00024320849 |
| time_elapsed            | 4131          |
| total timesteps         | 826714        |
| value_loss              | 0.00017802138 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00093578716 |
| ent_coef_loss           | -4.801051     |
| entropy                 | 1.5952773     |
| episodes                | 3030          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 828501        |
| policy_loss             | -0.25519627   |
| qf1_loss                | 0.00024565597 |
| qf2_loss                | 0.00044384462 |
| time_elapsed            | 4140          |
| total timesteps         | 828601        |
| value_loss              | 0.00015328999 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00091592735 |
| ent_coef_loss           | 0.7395712     |
| entropy                 | 1.6563972     |
| episodes                | 3040          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 830627        |
| policy_loss             | -0.2786742    |
| qf1_loss                | 0.00020876326 |
| qf2_loss                | 0.000247341   |
| time_elapsed            | 4151          |
| total timesteps         | 830727        |
| value_loss              | 0.00022291392 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009280422  |
| ent_coef_loss           | 0.5657352     |
| entropy                 | 1.6223916     |
| episodes                | 3050          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 833123        |
| policy_loss             | -0.21014176   |
| qf1_loss                | 0.00014556243 |
| qf2_loss                | 0.00024813402 |
| time_elapsed            | 4163          |
| total timesteps         | 833223        |
| value_loss              | 0.00017871772 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009052077  |
| ent_coef_loss           | -2.7648187    |
| entropy                 | 1.6383758     |
| episodes                | 3060          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 835046        |
| policy_loss             | -0.2772897    |
| qf1_loss                | 0.0002117497  |
| qf2_loss                | 0.00018465874 |
| time_elapsed            | 4173          |
| total timesteps         | 835146        |
| value_loss              | 0.00024354471 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009302903  |
| ent_coef_loss           | -4.60757      |
| entropy                 | 1.6486679     |
| episodes                | 3070          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 837472        |
| policy_loss             | -0.3189361    |
| qf1_loss                | 0.00012071485 |
| qf2_loss                | 0.00016393527 |
| time_elapsed            | 4186          |
| total timesteps         | 837572        |
| value_loss              | 8.9947134e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00094910787 |
| ent_coef_loss           | 0.8247606     |
| entropy                 | 1.5721691     |
| episodes                | 3080          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 839049        |
| policy_loss             | -0.28065282   |
| qf1_loss                | 0.0014795823  |
| qf2_loss                | 0.0018831965  |
| time_elapsed            | 4193          |
| total timesteps         | 839149        |
| value_loss              | 0.00020966274 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00095142645 |
| ent_coef_loss           | 1.0580446     |
| entropy                 | 1.6012477     |
| episodes                | 3090          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 841095        |
| policy_loss             | -0.28629285   |
| qf1_loss                | 0.00039593517 |
| qf2_loss                | 0.0004428211  |
| time_elapsed            | 4204          |
| total timesteps         | 841195        |
| value_loss              | 0.00015652651 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00094564795 |
| ent_coef_loss           | 0.33389324    |
| entropy                 | 1.6643305     |
| episodes                | 3100          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 842929        |
| policy_loss             | -0.25688726   |
| qf1_loss                | 0.000302639   |
| qf2_loss                | 0.00028465095 |
| time_elapsed            | 4213          |
| total timesteps         | 843029        |
| value_loss              | 0.00015610288 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0009452264   |
| ent_coef_loss           | -3.065802      |
| entropy                 | 1.6126187      |
| episodes                | 3110           |
| fps                     | 200            |
| mean 100 episode reward | 1.1            |
| n_updates               | 845083         |
| policy_loss             | -0.26773995    |
| qf1_loss                | 0.00019283227  |
| qf2_loss                | 0.00012918592  |
| time_elapsed            | 4224           |
| total timesteps         | 845183         |
| value_loss              | 0.000114374605 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00094389863 |
| ent_coef_loss           | 4.2564297     |
| entropy                 | 1.6518133     |
| episodes                | 3120          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 847161        |
| policy_loss             | -0.2011402    |
| qf1_loss                | 0.00018748158 |
| qf2_loss                | 0.00013970635 |
| time_elapsed            | 4234          |
| total timesteps         | 847261        |
| value_loss              | 0.00012482662 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00095981173 |
| ent_coef_loss           | -1.2388344    |
| entropy                 | 1.6010754     |
| episodes                | 3130          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 849267        |
| policy_loss             | -0.36551404   |
| qf1_loss                | 0.00014609337 |
| qf2_loss                | 7.934071e-05  |
| time_elapsed            | 4245          |
| total timesteps         | 849367        |
| value_loss              | 0.00014374751 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009581756  |
| ent_coef_loss           | -1.2096364    |
| entropy                 | 1.6444144     |
| episodes                | 3140          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 851133        |
| policy_loss             | -0.29374987   |
| qf1_loss                | 0.0006804355  |
| qf2_loss                | 0.00053630583 |
| time_elapsed            | 4254          |
| total timesteps         | 851233        |
| value_loss              | 0.00012930325 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009727863  |
| ent_coef_loss           | 0.5401461     |
| entropy                 | 1.6203611     |
| episodes                | 3150          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 853142        |
| policy_loss             | -0.20727243   |
| qf1_loss                | 0.00025227887 |
| qf2_loss                | 0.00021727642 |
| time_elapsed            | 4264          |
| total timesteps         | 853242        |
| value_loss              | 0.00023555031 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009718539  |
| ent_coef_loss           | 1.1744549     |
| entropy                 | 1.5940999     |
| episodes                | 3160          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 855416        |
| policy_loss             | -0.2668906    |
| qf1_loss                | 0.0001624949  |
| qf2_loss                | 0.00015834997 |
| time_elapsed            | 4275          |
| total timesteps         | 855516        |
| value_loss              | 7.87632e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009682936  |
| ent_coef_loss           | 0.2921718     |
| entropy                 | 1.5906072     |
| episodes                | 3170          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 857347        |
| policy_loss             | -0.41017187   |
| qf1_loss                | 0.00012054737 |
| qf2_loss                | 0.00010123862 |
| time_elapsed            | 4285          |
| total timesteps         | 857447        |
| value_loss              | 0.00011415128 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009537067  |
| ent_coef_loss           | 0.49399912    |
| entropy                 | 1.5847437     |
| episodes                | 3180          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 858918        |
| policy_loss             | -0.26881656   |
| qf1_loss                | 0.00015245425 |
| qf2_loss                | 9.3757015e-05 |
| time_elapsed            | 4293          |
| total timesteps         | 859018        |
| value_loss              | 0.00015645959 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009449623  |
| ent_coef_loss           | 0.8845494     |
| entropy                 | 1.5687897     |
| episodes                | 3190          |
| fps                     | 200           |
| mean 100 episode reward | 1.3           |
| n_updates               | 861382        |
| policy_loss             | -0.28959507   |
| qf1_loss                | 0.00037699862 |
| qf2_loss                | 0.00044608157 |
| time_elapsed            | 4305          |
| total timesteps         | 861482        |
| value_loss              | 9.227361e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00094326196 |
| ent_coef_loss           | -1.4485568    |
| entropy                 | 1.5859557     |
| episodes                | 3200          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 863321        |
| policy_loss             | -0.21510644   |
| qf1_loss                | 0.00036329095 |
| qf2_loss                | 0.00029519259 |
| time_elapsed            | 4315          |
| total timesteps         | 863421        |
| value_loss              | 0.0002215082  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009338107  |
| ent_coef_loss           | 0.6669202     |
| entropy                 | 1.5209205     |
| episodes                | 3210          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 865327        |
| policy_loss             | -0.28081676   |
| qf1_loss                | 0.00021396417 |
| qf2_loss                | 0.00016052685 |
| time_elapsed            | 4325          |
| total timesteps         | 865427        |
| value_loss              | 0.00032570743 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009149081  |
| ent_coef_loss           | 0.18113649    |
| entropy                 | 1.5292583     |
| episodes                | 3220          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 867224        |
| policy_loss             | -0.26336968   |
| qf1_loss                | 0.00021429724 |
| qf2_loss                | 0.00023164244 |
| time_elapsed            | 4334          |
| total timesteps         | 867324        |
| value_loss              | 0.00014293494 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009127094  |
| ent_coef_loss           | -2.1826606    |
| entropy                 | 1.5897578     |
| episodes                | 3230          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 869325        |
| policy_loss             | -0.30301145   |
| qf1_loss                | 0.00016314277 |
| qf2_loss                | 0.000208096   |
| time_elapsed            | 4345          |
| total timesteps         | 869425        |
| value_loss              | 9.001371e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00092314184 |
| ent_coef_loss           | -1.2715721    |
| entropy                 | 1.6014392     |
| episodes                | 3240          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 871146        |
| policy_loss             | -0.22729945   |
| qf1_loss                | 0.00024596436 |
| qf2_loss                | 0.00033127726 |
| time_elapsed            | 4354          |
| total timesteps         | 871246        |
| value_loss              | 0.00012954055 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009132078  |
| ent_coef_loss           | 1.1694906     |
| entropy                 | 1.5533824     |
| episodes                | 3250          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 872947        |
| policy_loss             | -0.17166895   |
| qf1_loss                | 0.000281371   |
| qf2_loss                | 0.00025287116 |
| time_elapsed            | 4364          |
| total timesteps         | 873047        |
| value_loss              | 0.00018255589 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00091377017 |
| ent_coef_loss           | -3.9433947    |
| entropy                 | 1.614764      |
| episodes                | 3260          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 874951        |
| policy_loss             | -0.29704088   |
| qf1_loss                | 0.0002583673  |
| qf2_loss                | 0.00020815493 |
| time_elapsed            | 4373          |
| total timesteps         | 875051        |
| value_loss              | 0.00011821273 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00090801856 |
| ent_coef_loss           | 2.4804654     |
| entropy                 | 1.5747827     |
| episodes                | 3270          |
| fps                     | 200           |
| mean 100 episode reward | 1             |
| n_updates               | 876769        |
| policy_loss             | -0.31561565   |
| qf1_loss                | 0.00016306681 |
| qf2_loss                | 0.00029777823 |
| time_elapsed            | 4382          |
| total timesteps         | 876869        |
| value_loss              | 0.00018953875 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009119089  |
| ent_coef_loss           | 1.448059      |
| entropy                 | 1.6340648     |
| episodes                | 3280          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 878823        |
| policy_loss             | -0.16142286   |
| qf1_loss                | 0.0002636481  |
| qf2_loss                | 0.00018609053 |
| time_elapsed            | 4392          |
| total timesteps         | 878923        |
| value_loss              | 0.00023160681 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00092235644 |
| ent_coef_loss           | 1.9135747     |
| entropy                 | 1.6436683     |
| episodes                | 3290          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 880870        |
| policy_loss             | -0.25902128   |
| qf1_loss                | 0.00031715026 |
| qf2_loss                | 0.00037918467 |
| time_elapsed            | 4402          |
| total timesteps         | 880970        |
| value_loss              | 0.0002638711  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000929795   |
| ent_coef_loss           | -1.428115     |
| entropy                 | 1.6258649     |
| episodes                | 3300          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 882594        |
| policy_loss             | -0.27001595   |
| qf1_loss                | 0.00013275999 |
| qf2_loss                | 0.00016086058 |
| time_elapsed            | 4411          |
| total timesteps         | 882694        |
| value_loss              | 0.0001873727  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008821312  |
| ent_coef_loss           | -2.5853205    |
| entropy                 | 1.5508928     |
| episodes                | 3310          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 884489        |
| policy_loss             | -0.36513877   |
| qf1_loss                | 0.0001258484  |
| qf2_loss                | 0.00013779876 |
| time_elapsed            | 4420          |
| total timesteps         | 884589        |
| value_loss              | 0.00016762265 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00087236846 |
| ent_coef_loss           | 1.4165454     |
| entropy                 | 1.5566683     |
| episodes                | 3320          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 886457        |
| policy_loss             | -0.22466503   |
| qf1_loss                | 0.00015589429 |
| qf2_loss                | 0.00012625047 |
| time_elapsed            | 4430          |
| total timesteps         | 886557        |
| value_loss              | 0.0001265139  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00089598086 |
| ent_coef_loss           | 0.3523587     |
| entropy                 | 1.5695709     |
| episodes                | 3330          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 888338        |
| policy_loss             | -0.22134209   |
| qf1_loss                | 0.00029413303 |
| qf2_loss                | 0.00044815746 |
| time_elapsed            | 4440          |
| total timesteps         | 888438        |
| value_loss              | 0.00032968193 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00089757034 |
| ent_coef_loss           | -1.7723815    |
| entropy                 | 1.5950028     |
| episodes                | 3340          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 890487        |
| policy_loss             | -0.26858488   |
| qf1_loss                | 0.00044520939 |
| qf2_loss                | 0.0003251828  |
| time_elapsed            | 4451          |
| total timesteps         | 890587        |
| value_loss              | 0.00043308624 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008845363  |
| ent_coef_loss           | -0.6389091    |
| entropy                 | 1.5562639     |
| episodes                | 3350          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 892308        |
| policy_loss             | -0.2539433    |
| qf1_loss                | 0.00046208408 |
| qf2_loss                | 0.0003176621  |
| time_elapsed            | 4459          |
| total timesteps         | 892408        |
| value_loss              | 0.00035509333 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000884962   |
| ent_coef_loss           | 1.6194274     |
| entropy                 | 1.5909064     |
| episodes                | 3360          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 894994        |
| policy_loss             | -0.3360733    |
| qf1_loss                | 0.00014078313 |
| qf2_loss                | 0.00014679521 |
| time_elapsed            | 4473          |
| total timesteps         | 895094        |
| value_loss              | 0.00014017435 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008650049  |
| ent_coef_loss           | -2.371406     |
| entropy                 | 1.5446886     |
| episodes                | 3370          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 897103        |
| policy_loss             | -0.24408646   |
| qf1_loss                | 0.00024334494 |
| qf2_loss                | 0.00031433097 |
| time_elapsed            | 4484          |
| total timesteps         | 897203        |
| value_loss              | 0.00017780853 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008791816  |
| ent_coef_loss           | -2.4862165    |
| entropy                 | 1.5786037     |
| episodes                | 3380          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 898972        |
| policy_loss             | -0.23361482   |
| qf1_loss                | 0.00014828521 |
| qf2_loss                | 0.00011745782 |
| time_elapsed            | 4493          |
| total timesteps         | 899072        |
| value_loss              | 0.00010852034 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008836409  |
| ent_coef_loss           | -0.33495706   |
| entropy                 | 1.5585669     |
| episodes                | 3390          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 900826        |
| policy_loss             | -0.30334175   |
| qf1_loss                | 0.00042610825 |
| qf2_loss                | 0.00036587648 |
| time_elapsed            | 4503          |
| total timesteps         | 900926        |
| value_loss              | 0.00020354151 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00087831635 |
| ent_coef_loss           | 0.9164681     |
| entropy                 | 1.5309894     |
| episodes                | 3400          |
| fps                     | 200           |
| mean 100 episode reward | 1.1           |
| n_updates               | 903040        |
| policy_loss             | -0.37023723   |
| qf1_loss                | 0.00014520786 |
| qf2_loss                | 0.00015129603 |
| time_elapsed            | 4515          |
| total timesteps         | 903140        |
| value_loss              | 0.00013397534 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00089787296 |
| ent_coef_loss           | 5.13104       |
| entropy                 | 1.597182      |
| episodes                | 3410          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 904935        |
| policy_loss             | -0.21985398   |
| qf1_loss                | 0.00016093583 |
| qf2_loss                | 0.00029316847 |
| time_elapsed            | 4524          |
| total timesteps         | 905035        |
| value_loss              | 0.00023488651 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00093096885 |
| ent_coef_loss           | 0.8209032     |
| entropy                 | 1.611373      |
| episodes                | 3420          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 906500        |
| policy_loss             | -0.27643326   |
| qf1_loss                | 0.00023002652 |
| qf2_loss                | 0.00024694097 |
| time_elapsed            | 4532          |
| total timesteps         | 906600        |
| value_loss              | 0.00017428449 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00092856056 |
| ent_coef_loss           | -2.2113533    |
| entropy                 | 1.6035819     |
| episodes                | 3430          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 908555        |
| policy_loss             | -0.37288314   |
| qf1_loss                | 0.00012561401 |
| qf2_loss                | 0.00017735476 |
| time_elapsed            | 4543          |
| total timesteps         | 908655        |
| value_loss              | 0.00016847061 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009162069  |
| ent_coef_loss           | 0.2903722     |
| entropy                 | 1.676199      |
| episodes                | 3440          |
| fps                     | 200           |
| mean 100 episode reward | 1.2           |
| n_updates               | 910406        |
| policy_loss             | -0.27286738   |
| qf1_loss                | 0.00010738192 |
| qf2_loss                | 0.00016596614 |
| time_elapsed            | 4552          |
| total timesteps         | 910506        |
| value_loss              | 0.00025054553 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009208518  |
| ent_coef_loss           | 0.7767755     |
| entropy                 | 1.5947214     |
| episodes                | 3450          |
| fps                     | 199           |
| mean 100 episode reward | 1.1           |
| n_updates               | 912455        |
| policy_loss             | -0.34764615   |
| qf1_loss                | 0.00026369406 |
| qf2_loss                | 0.00019197416 |
| time_elapsed            | 4563          |
| total timesteps         | 912555        |
| value_loss              | 0.00018591079 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00090904656 |
| ent_coef_loss           | 0.73381       |
| entropy                 | 1.6135719     |
| episodes                | 3460          |
| fps                     | 199           |
| mean 100 episode reward | 1.1           |
| n_updates               | 914550        |
| policy_loss             | -0.24557175   |
| qf1_loss                | 0.00021964031 |
| qf2_loss                | 0.00022412563 |
| time_elapsed            | 4574          |
| total timesteps         | 914650        |
| value_loss              | 0.0002176638  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009094624  |
| ent_coef_loss           | -1.1506871    |
| entropy                 | 1.5649018     |
| episodes                | 3470          |
| fps                     | 199           |
| mean 100 episode reward | 1.1           |
| n_updates               | 916577        |
| policy_loss             | -0.22294581   |
| qf1_loss                | 0.00033602602 |
| qf2_loss                | 0.00026731627 |
| time_elapsed            | 4583          |
| total timesteps         | 916677        |
| value_loss              | 0.00032034513 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00092543766 |
| ent_coef_loss           | -0.13066572   |
| entropy                 | 1.5526209     |
| episodes                | 3480          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 918722        |
| policy_loss             | -0.26141703   |
| qf1_loss                | 0.00023001127 |
| qf2_loss                | 0.0002731605  |
| time_elapsed            | 4594          |
| total timesteps         | 918822        |
| value_loss              | 0.00019320825 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00093780574 |
| ent_coef_loss           | -1.546582     |
| entropy                 | 1.6747906     |
| episodes                | 3490          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 920462        |
| policy_loss             | -0.3077075    |
| qf1_loss                | 0.00020307463 |
| qf2_loss                | 0.0002270283  |
| time_elapsed            | 4603          |
| total timesteps         | 920562        |
| value_loss              | 0.0001983823  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00095148635  |
| ent_coef_loss           | -2.676889      |
| entropy                 | 1.6245916      |
| episodes                | 3500           |
| fps                     | 199            |
| mean 100 episode reward | 1.2            |
| n_updates               | 922495         |
| policy_loss             | -0.33428252    |
| qf1_loss                | 0.00015066729  |
| qf2_loss                | 0.00012975496  |
| time_elapsed            | 4613           |
| total timesteps         | 922595         |
| value_loss              | 0.000113744674 |
--------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00093325693  |
| ent_coef_loss           | 2.3682637      |
| entropy                 | 1.6676356      |
| episodes                | 3510           |
| fps                     | 199            |
| mean 100 episode reward | 1.2            |
| n_updates               | 924541         |
| policy_loss             | -0.28191608    |
| qf1_loss                | 7.714362e-05   |
| qf2_loss                | 0.00024007336  |
| time_elapsed            | 4624           |
| total timesteps         | 924641         |
| value_loss              | 0.000117258525 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009534252  |
| ent_coef_loss           | 2.0872388     |
| entropy                 | 1.6272972     |
| episodes                | 3520          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 926679        |
| policy_loss             | -0.33829445   |
| qf1_loss                | 0.00021044462 |
| qf2_loss                | 0.00017827778 |
| time_elapsed            | 4635          |
| total timesteps         | 926779        |
| value_loss              | 0.0001528174  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00094967557 |
| ent_coef_loss           | -3.1744814    |
| entropy                 | 1.6326181     |
| episodes                | 3530          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 928633        |
| policy_loss             | -0.40365902   |
| qf1_loss                | 0.00014397185 |
| qf2_loss                | 0.00016233581 |
| time_elapsed            | 4644          |
| total timesteps         | 928733        |
| value_loss              | 0.0001900979  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009337711  |
| ent_coef_loss           | 1.8554542     |
| entropy                 | 1.62517       |
| episodes                | 3540          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 930689        |
| policy_loss             | -0.24774891   |
| qf1_loss                | 0.00025629188 |
| qf2_loss                | 0.00022553197 |
| time_elapsed            | 4655          |
| total timesteps         | 930789        |
| value_loss              | 0.00032601733 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00090696185  |
| ent_coef_loss           | -0.2983091     |
| entropy                 | 1.6787689      |
| episodes                | 3550           |
| fps                     | 199            |
| mean 100 episode reward | 1.4            |
| n_updates               | 932668         |
| policy_loss             | -0.30724245    |
| qf1_loss                | 0.00019393023  |
| qf2_loss                | 0.00018082408  |
| time_elapsed            | 4665           |
| total timesteps         | 932768         |
| value_loss              | 0.000121086385 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000878223   |
| ent_coef_loss           | 1.6277692     |
| entropy                 | 1.6573205     |
| episodes                | 3560          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 934608        |
| policy_loss             | -0.23319566   |
| qf1_loss                | 0.00016077903 |
| qf2_loss                | 0.00019314955 |
| time_elapsed            | 4674          |
| total timesteps         | 934708        |
| value_loss              | 9.719476e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0008889464   |
| ent_coef_loss           | -0.061743498   |
| entropy                 | 1.622638       |
| episodes                | 3570           |
| fps                     | 199            |
| mean 100 episode reward | 1.3            |
| n_updates               | 936313         |
| policy_loss             | -0.29302165    |
| qf1_loss                | 0.00025422862  |
| qf2_loss                | 0.00019932774  |
| time_elapsed            | 4683           |
| total timesteps         | 936413         |
| value_loss              | 0.000118998134 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00090387923 |
| ent_coef_loss           | -2.5852098    |
| entropy                 | 1.5565375     |
| episodes                | 3580          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 938368        |
| policy_loss             | -0.3711071    |
| qf1_loss                | 0.00056217326 |
| qf2_loss                | 0.0008410507  |
| time_elapsed            | 4694          |
| total timesteps         | 938468        |
| value_loss              | 0.00018375408 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008918199  |
| ent_coef_loss           | -1.6737664    |
| entropy                 | 1.6456583     |
| episodes                | 3590          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 940439        |
| policy_loss             | -0.2807545    |
| qf1_loss                | 0.00013788135 |
| qf2_loss                | 9.80347e-05   |
| time_elapsed            | 4703          |
| total timesteps         | 940539        |
| value_loss              | 9.8578086e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008820799  |
| ent_coef_loss           | -0.4941321    |
| entropy                 | 1.6287944     |
| episodes                | 3600          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 942394        |
| policy_loss             | -0.4171742    |
| qf1_loss                | 0.00023590686 |
| qf2_loss                | 0.00014844857 |
| time_elapsed            | 4713          |
| total timesteps         | 942494        |
| value_loss              | 0.00012540421 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009155662  |
| ent_coef_loss           | -0.4237998    |
| entropy                 | 1.6194817     |
| episodes                | 3610          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 944350        |
| policy_loss             | -0.35253468   |
| qf1_loss                | 0.00023333199 |
| qf2_loss                | 0.00016288826 |
| time_elapsed            | 4723          |
| total timesteps         | 944450        |
| value_loss              | 0.00010673124 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00088629813 |
| ent_coef_loss           | 0.7858553     |
| entropy                 | 1.6122077     |
| episodes                | 3620          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 946503        |
| policy_loss             | -0.29486668   |
| qf1_loss                | 0.0002982695  |
| qf2_loss                | 0.00028494687 |
| time_elapsed            | 4734          |
| total timesteps         | 946603        |
| value_loss              | 0.00015532957 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00088783103 |
| ent_coef_loss           | -0.13623941   |
| entropy                 | 1.5926404     |
| episodes                | 3630          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 948524        |
| policy_loss             | -0.28774744   |
| qf1_loss                | 0.00021713562 |
| qf2_loss                | 0.00015502927 |
| time_elapsed            | 4744          |
| total timesteps         | 948624        |
| value_loss              | 0.00019034401 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00089611375 |
| ent_coef_loss           | 2.9772573     |
| entropy                 | 1.6193818     |
| episodes                | 3640          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 950706        |
| policy_loss             | -0.22592676   |
| qf1_loss                | 0.00014082159 |
| qf2_loss                | 0.00023515959 |
| time_elapsed            | 4755          |
| total timesteps         | 950806        |
| value_loss              | 0.00020763112 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009079999  |
| ent_coef_loss           | 3.6391273     |
| entropy                 | 1.624923      |
| episodes                | 3650          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 952535        |
| policy_loss             | -0.24448478   |
| qf1_loss                | 0.00027742345 |
| qf2_loss                | 0.00021383315 |
| time_elapsed            | 4764          |
| total timesteps         | 952635        |
| value_loss              | 0.00021794831 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009049198  |
| ent_coef_loss           | -1.2501739    |
| entropy                 | 1.5921504     |
| episodes                | 3660          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 954387        |
| policy_loss             | -0.43315178   |
| qf1_loss                | 0.00016713204 |
| qf2_loss                | 0.00014223815 |
| time_elapsed            | 4773          |
| total timesteps         | 954487        |
| value_loss              | 6.631922e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008664741  |
| ent_coef_loss           | -1.7617869    |
| entropy                 | 1.5836233     |
| episodes                | 3670          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 956480        |
| policy_loss             | -0.38609394   |
| qf1_loss                | 0.00020708475 |
| qf2_loss                | 0.00012874886 |
| time_elapsed            | 4784          |
| total timesteps         | 956580        |
| value_loss              | 9.681543e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00085949956 |
| ent_coef_loss           | 4.774575      |
| entropy                 | 1.5604546     |
| episodes                | 3680          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 958333        |
| policy_loss             | -0.2545907    |
| qf1_loss                | 0.00017847653 |
| qf2_loss                | 0.0002176562  |
| time_elapsed            | 4793          |
| total timesteps         | 958433        |
| value_loss              | 0.00019798338 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00085535547  |
| ent_coef_loss           | 0.48666823     |
| entropy                 | 1.6146438      |
| episodes                | 3690           |
| fps                     | 199            |
| mean 100 episode reward | 1.2            |
| n_updates               | 960191         |
| policy_loss             | -0.33549732    |
| qf1_loss                | 0.000120473414 |
| qf2_loss                | 0.00021173911  |
| time_elapsed            | 4802           |
| total timesteps         | 960291         |
| value_loss              | 0.0001888649   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008786653  |
| ent_coef_loss           | -0.41296744   |
| entropy                 | 1.6161575     |
| episodes                | 3700          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 962347        |
| policy_loss             | -0.32632935   |
| qf1_loss                | 0.0001203663  |
| qf2_loss                | 0.00013993931 |
| time_elapsed            | 4813          |
| total timesteps         | 962447        |
| value_loss              | 0.00015149056 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009068035  |
| ent_coef_loss           | -1.2279238    |
| entropy                 | 1.6132472     |
| episodes                | 3710          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 964215        |
| policy_loss             | -0.29599273   |
| qf1_loss                | 0.00014225132 |
| qf2_loss                | 0.00015902643 |
| time_elapsed            | 4821          |
| total timesteps         | 964315        |
| value_loss              | 0.0001753204  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00087192265 |
| ent_coef_loss           | -1.6595888    |
| entropy                 | 1.5799321     |
| episodes                | 3720          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 966280        |
| policy_loss             | -0.31671143   |
| qf1_loss                | 0.00017932711 |
| qf2_loss                | 0.00011418574 |
| time_elapsed            | 4832          |
| total timesteps         | 966380        |
| value_loss              | 0.00012890049 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008816985  |
| ent_coef_loss           | -4.708254     |
| entropy                 | 1.6044128     |
| episodes                | 3730          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 968300        |
| policy_loss             | -0.32902104   |
| qf1_loss                | 0.0002077042  |
| qf2_loss                | 0.00028432405 |
| time_elapsed            | 4843          |
| total timesteps         | 968400        |
| value_loss              | 0.00020921571 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008805091  |
| ent_coef_loss           | -0.7514062    |
| entropy                 | 1.5973804     |
| episodes                | 3740          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 970241        |
| policy_loss             | -0.29688704   |
| qf1_loss                | 0.00024545053 |
| qf2_loss                | 0.0002499827  |
| time_elapsed            | 4852          |
| total timesteps         | 970341        |
| value_loss              | 0.00022817418 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009020059  |
| ent_coef_loss           | 2.54916       |
| entropy                 | 1.6298506     |
| episodes                | 3750          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 972084        |
| policy_loss             | -0.3013189    |
| qf1_loss                | 0.00013953308 |
| qf2_loss                | 0.00018722427 |
| time_elapsed            | 4861          |
| total timesteps         | 972184        |
| value_loss              | 0.00014538717 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00089278445 |
| ent_coef_loss           | 1.3908834     |
| entropy                 | 1.6859832     |
| episodes                | 3760          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 974101        |
| policy_loss             | -0.4541034    |
| qf1_loss                | 9.8092896e-05 |
| qf2_loss                | 0.00017982742 |
| time_elapsed            | 4872          |
| total timesteps         | 974201        |
| value_loss              | 0.0001442227  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00089842547 |
| ent_coef_loss           | 0.20742106    |
| entropy                 | 1.5852813     |
| episodes                | 3770          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 976025        |
| policy_loss             | -0.37367278   |
| qf1_loss                | 8.576954e-05  |
| qf2_loss                | 0.00012614785 |
| time_elapsed            | 4881          |
| total timesteps         | 976125        |
| value_loss              | 7.528436e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.000889753  |
| ent_coef_loss           | -0.8148277   |
| entropy                 | 1.6356348    |
| episodes                | 3780         |
| fps                     | 199          |
| mean 100 episode reward | 1.4          |
| n_updates               | 978087       |
| policy_loss             | -0.27461475  |
| qf1_loss                | 0.000434511  |
| qf2_loss                | 0.0002434919 |
| time_elapsed            | 4891         |
| total timesteps         | 978187       |
| value_loss              | 0.0003046688 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00089957647 |
| ent_coef_loss           | 1.4259534     |
| entropy                 | 1.7155565     |
| episodes                | 3790          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 979973        |
| policy_loss             | -0.27461034   |
| qf1_loss                | 0.00025961502 |
| qf2_loss                | 0.0002924159  |
| time_elapsed            | 4901          |
| total timesteps         | 980073        |
| value_loss              | 0.0002281144  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00089708425 |
| ent_coef_loss           | -2.6915102    |
| entropy                 | 1.6429863     |
| episodes                | 3800          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 982056        |
| policy_loss             | -0.41897482   |
| qf1_loss                | 0.00021809601 |
| qf2_loss                | 0.00020996726 |
| time_elapsed            | 4911          |
| total timesteps         | 982156        |
| value_loss              | 0.00011089032 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008917633  |
| ent_coef_loss           | -0.9685716    |
| entropy                 | 1.6394724     |
| episodes                | 3810          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 983870        |
| policy_loss             | -0.2835487    |
| qf1_loss                | 0.00023606246 |
| qf2_loss                | 0.00011128934 |
| time_elapsed            | 4920          |
| total timesteps         | 983970        |
| value_loss              | 0.00018146526 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00088995753 |
| ent_coef_loss           | 0.71549654    |
| entropy                 | 1.6227324     |
| episodes                | 3820          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 985889        |
| policy_loss             | -0.3203386    |
| qf1_loss                | 0.00013354828 |
| qf2_loss                | 0.00016639737 |
| time_elapsed            | 4931          |
| total timesteps         | 985989        |
| value_loss              | 0.0001744816  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008513904  |
| ent_coef_loss           | -1.6897459    |
| entropy                 | 1.6607966     |
| episodes                | 3830          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 987917        |
| policy_loss             | -0.32098007   |
| qf1_loss                | 0.00015051241 |
| qf2_loss                | 0.00014896182 |
| time_elapsed            | 4940          |
| total timesteps         | 988017        |
| value_loss              | 0.00011757644 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008072596  |
| ent_coef_loss           | 3.7545707     |
| entropy                 | 1.5937138     |
| episodes                | 3840          |
| fps                     | 199           |
| mean 100 episode reward | 1.5           |
| n_updates               | 990097        |
| policy_loss             | -0.26952082   |
| qf1_loss                | 0.00012629217 |
| qf2_loss                | 0.00010224541 |
| time_elapsed            | 4952          |
| total timesteps         | 990197        |
| value_loss              | 0.00022494093 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00079119066 |
| ent_coef_loss           | 1.9290788     |
| entropy                 | 1.5833774     |
| episodes                | 3850          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 992074        |
| policy_loss             | -0.28597865   |
| qf1_loss                | 0.0001576251  |
| qf2_loss                | 9.711488e-05  |
| time_elapsed            | 4962          |
| total timesteps         | 992174        |
| value_loss              | 0.00023472527 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007863471  |
| ent_coef_loss           | 3.8424144     |
| entropy                 | 1.5671178     |
| episodes                | 3860          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 994194        |
| policy_loss             | -0.3236633    |
| qf1_loss                | 9.3478906e-05 |
| qf2_loss                | 0.0001178754  |
| time_elapsed            | 4972          |
| total timesteps         | 994294        |
| value_loss              | 9.892063e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00080176536 |
| ent_coef_loss           | -1.4235785    |
| entropy                 | 1.5833807     |
| episodes                | 3870          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 996054        |
| policy_loss             | -0.40769178   |
| qf1_loss                | 0.00011387325 |
| qf2_loss                | 0.000110225   |
| time_elapsed            | 4981          |
| total timesteps         | 996154        |
| value_loss              | 0.00013987151 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00080583815  |
| ent_coef_loss           | -1.3651595     |
| entropy                 | 1.5083425      |
| episodes                | 3880           |
| fps                     | 199            |
| mean 100 episode reward | 1.4            |
| n_updates               | 997943         |
| policy_loss             | -0.44704157    |
| qf1_loss                | 0.000107204614 |
| qf2_loss                | 0.00013385189  |
| time_elapsed            | 4991           |
| total timesteps         | 998043         |
| value_loss              | 0.0001534386   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008009836  |
| ent_coef_loss           | -1.3270437    |
| entropy                 | 1.5105643     |
| episodes                | 3890          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 999897        |
| policy_loss             | -0.3122462    |
| qf1_loss                | 0.0002147331  |
| qf2_loss                | 0.00023744468 |
| time_elapsed            | 5000          |
| total timesteps         | 999997        |
| value_loss              | 0.00019433099 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00075233495 |
| ent_coef_loss           | 0.74004304    |
| entropy                 | 1.5353663     |
| episodes                | 3900          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1001877       |
| policy_loss             | -0.3291968    |
| qf1_loss                | 0.00016003278 |
| qf2_loss                | 0.0002274311  |
| time_elapsed            | 5011          |
| total timesteps         | 1001977       |
| value_loss              | 9.628393e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00072589715 |
| ent_coef_loss           | 1.1422876     |
| entropy                 | 1.5197209     |
| episodes                | 3910          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1003968       |
| policy_loss             | -0.25869805   |
| qf1_loss                | 0.00022659237 |
| qf2_loss                | 0.00017138639 |
| time_elapsed            | 5021          |
| total timesteps         | 1004068       |
| value_loss              | 0.00023092805 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00074995775  |
| ent_coef_loss           | 1.9918551      |
| entropy                 | 1.5481417      |
| episodes                | 3920           |
| fps                     | 199            |
| mean 100 episode reward | 1.3            |
| n_updates               | 1005583        |
| policy_loss             | -0.36491197    |
| qf1_loss                | 0.00015548397  |
| qf2_loss                | 0.000106047824 |
| time_elapsed            | 5029           |
| total timesteps         | 1005683        |
| value_loss              | 0.00018657546  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007546286  |
| ent_coef_loss           | -1.7877398    |
| entropy                 | 1.4867216     |
| episodes                | 3930          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1007522       |
| policy_loss             | -0.35455596   |
| qf1_loss                | 0.00015374948 |
| qf2_loss                | 0.00033530645 |
| time_elapsed            | 5038          |
| total timesteps         | 1007622       |
| value_loss              | 0.00017068523 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007409314  |
| ent_coef_loss           | 0.35544473    |
| entropy                 | 1.5302159     |
| episodes                | 3940          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1009664       |
| policy_loss             | -0.3539638    |
| qf1_loss                | 0.00031663972 |
| qf2_loss                | 0.00012263874 |
| time_elapsed            | 5050          |
| total timesteps         | 1009764       |
| value_loss              | 0.00022370185 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00076431915 |
| ent_coef_loss           | -1.2904669    |
| entropy                 | 1.5065515     |
| episodes                | 3950          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1011760       |
| policy_loss             | -0.30497718   |
| qf1_loss                | 0.009262273   |
| qf2_loss                | 0.009773073   |
| time_elapsed            | 5059          |
| total timesteps         | 1011860       |
| value_loss              | 0.00031569722 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007969695  |
| ent_coef_loss           | -0.020645976  |
| entropy                 | 1.4768478     |
| episodes                | 3960          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1013610       |
| policy_loss             | -0.40947706   |
| qf1_loss                | 0.00015738365 |
| qf2_loss                | 0.00017273874 |
| time_elapsed            | 5069          |
| total timesteps         | 1013710       |
| value_loss              | 0.00019065685 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008044698  |
| ent_coef_loss           | -0.13438916   |
| entropy                 | 1.4882851     |
| episodes                | 3970          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1015702       |
| policy_loss             | -0.37125367   |
| qf1_loss                | 0.00013933388 |
| qf2_loss                | 0.00012122078 |
| time_elapsed            | 5080          |
| total timesteps         | 1015802       |
| value_loss              | 0.00012928025 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000798362   |
| ent_coef_loss           | -0.51433015   |
| entropy                 | 1.4715183     |
| episodes                | 3980          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1017779       |
| policy_loss             | -0.36196765   |
| qf1_loss                | 0.00018353102 |
| qf2_loss                | 0.00019844204 |
| time_elapsed            | 5090          |
| total timesteps         | 1017879       |
| value_loss              | 0.00013040935 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007978186  |
| ent_coef_loss           | 3.7218666     |
| entropy                 | 1.4981683     |
| episodes                | 3990          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1019631       |
| policy_loss             | -0.3591586    |
| qf1_loss                | 0.00023898958 |
| qf2_loss                | 0.00030824816 |
| time_elapsed            | 5100          |
| total timesteps         | 1019731       |
| value_loss              | 0.00016701817 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00080667087 |
| ent_coef_loss           | -0.023542285  |
| entropy                 | 1.5341084     |
| episodes                | 4000          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1021342       |
| policy_loss             | -0.31459945   |
| qf1_loss                | 0.00015244636 |
| qf2_loss                | 0.00010247054 |
| time_elapsed            | 5109          |
| total timesteps         | 1021442       |
| value_loss              | 0.00018326176 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00079155667 |
| ent_coef_loss           | -1.0223484    |
| entropy                 | 1.4891338     |
| episodes                | 4010          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1023387       |
| policy_loss             | -0.34045574   |
| qf1_loss                | 0.00027742377 |
| qf2_loss                | 0.0002442424  |
| time_elapsed            | 5119          |
| total timesteps         | 1023487       |
| value_loss              | 0.00017842278 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007722582  |
| ent_coef_loss           | 1.9742393     |
| entropy                 | 1.534321      |
| episodes                | 4020          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1025475       |
| policy_loss             | -0.3260165    |
| qf1_loss                | 0.0001996669  |
| qf2_loss                | 0.00017966126 |
| time_elapsed            | 5130          |
| total timesteps         | 1025575       |
| value_loss              | 0.00014945572 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00077078    |
| ent_coef_loss           | -2.0144107    |
| entropy                 | 1.4812926     |
| episodes                | 4030          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1027497       |
| policy_loss             | -0.41729254   |
| qf1_loss                | 9.1605136e-05 |
| qf2_loss                | 0.0001385909  |
| time_elapsed            | 5140          |
| total timesteps         | 1027597       |
| value_loss              | 0.00010573382 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007699135  |
| ent_coef_loss           | -2.9460602    |
| entropy                 | 1.507213      |
| episodes                | 4040          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1030123       |
| policy_loss             | -0.32357544   |
| qf1_loss                | 0.00017183722 |
| qf2_loss                | 0.00028940794 |
| time_elapsed            | 5153          |
| total timesteps         | 1030223       |
| value_loss              | 0.00015823488 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00082157826 |
| ent_coef_loss           | 1.2166374     |
| entropy                 | 1.5104046     |
| episodes                | 4050          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1032764       |
| policy_loss             | -0.22978747   |
| qf1_loss                | 0.0002532269  |
| qf2_loss                | 0.00021674931 |
| time_elapsed            | 5166          |
| total timesteps         | 1032864       |
| value_loss              | 0.00020448689 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008121019  |
| ent_coef_loss           | 1.6129969     |
| entropy                 | 1.5538738     |
| episodes                | 4060          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1034892       |
| policy_loss             | -0.32746992   |
| qf1_loss                | 0.00021354423 |
| qf2_loss                | 0.00023495969 |
| time_elapsed            | 5176          |
| total timesteps         | 1034992       |
| value_loss              | 0.00018470109 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008295601  |
| ent_coef_loss           | 0.9940871     |
| entropy                 | 1.5222064     |
| episodes                | 4070          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1036852       |
| policy_loss             | -0.3676836    |
| qf1_loss                | 0.00015406011 |
| qf2_loss                | 0.00017173143 |
| time_elapsed            | 5187          |
| total timesteps         | 1036952       |
| value_loss              | 0.00010025111 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00084852503 |
| ent_coef_loss           | -1.11521      |
| entropy                 | 1.5728787     |
| episodes                | 4080          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1039227       |
| policy_loss             | -0.40577272   |
| qf1_loss                | 0.0002432731  |
| qf2_loss                | 0.0002511657  |
| time_elapsed            | 5199          |
| total timesteps         | 1039327       |
| value_loss              | 0.000162262   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00088193145 |
| ent_coef_loss           | 0.4327767     |
| entropy                 | 1.538451      |
| episodes                | 4090          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1041322       |
| policy_loss             | -0.42578143   |
| qf1_loss                | 0.00012976801 |
| qf2_loss                | 0.00023206054 |
| time_elapsed            | 5209          |
| total timesteps         | 1041422       |
| value_loss              | 0.00015397079 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00090771593 |
| ent_coef_loss           | 1.568179      |
| entropy                 | 1.5141098     |
| episodes                | 4100          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1043232       |
| policy_loss             | -0.33405492   |
| qf1_loss                | 0.0003099733  |
| qf2_loss                | 0.00024284645 |
| time_elapsed            | 5219          |
| total timesteps         | 1043332       |
| value_loss              | 0.00032694373 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00089521264 |
| ent_coef_loss           | -3.178348     |
| entropy                 | 1.6051611     |
| episodes                | 4110          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1045264       |
| policy_loss             | -0.2813699    |
| qf1_loss                | 0.00041424175 |
| qf2_loss                | 0.00042470227 |
| time_elapsed            | 5229          |
| total timesteps         | 1045364       |
| value_loss              | 0.00020729633 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00089315744 |
| ent_coef_loss           | 1.3577663     |
| entropy                 | 1.5321447     |
| episodes                | 4120          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1047283       |
| policy_loss             | -0.38152227   |
| qf1_loss                | 0.00013037611 |
| qf2_loss                | 0.00013537754 |
| time_elapsed            | 5239          |
| total timesteps         | 1047383       |
| value_loss              | 0.00013784457 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00087777915 |
| ent_coef_loss           | -1.346725     |
| entropy                 | 1.5262988     |
| episodes                | 4130          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1049337       |
| policy_loss             | -0.30726147   |
| qf1_loss                | 0.00014523757 |
| qf2_loss                | 0.00016485638 |
| time_elapsed            | 5249          |
| total timesteps         | 1049437       |
| value_loss              | 0.00016204975 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00089220953  |
| ent_coef_loss           | 2.3806272      |
| entropy                 | 1.5414002      |
| episodes                | 4140           |
| fps                     | 199            |
| mean 100 episode reward | 1.4            |
| n_updates               | 1051312        |
| policy_loss             | -0.31168032    |
| qf1_loss                | 0.00020247359  |
| qf2_loss                | 0.0001888363   |
| time_elapsed            | 5260           |
| total timesteps         | 1051412        |
| value_loss              | 0.000107049564 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000889454   |
| ent_coef_loss           | 2.0070634     |
| entropy                 | 1.5795267     |
| episodes                | 4150          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1053286       |
| policy_loss             | -0.28138363   |
| qf1_loss                | 0.0001873272  |
| qf2_loss                | 0.00013420395 |
| time_elapsed            | 5269          |
| total timesteps         | 1053386       |
| value_loss              | 0.00013393222 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00088363583 |
| ent_coef_loss           | -1.8477073    |
| entropy                 | 1.5533993     |
| episodes                | 4160          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1055090       |
| policy_loss             | -0.31629673   |
| qf1_loss                | 0.0001337663  |
| qf2_loss                | 0.00018376112 |
| time_elapsed            | 5278          |
| total timesteps         | 1055190       |
| value_loss              | 0.00019905862 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000894718   |
| ent_coef_loss           | -0.33555388   |
| entropy                 | 1.5581244     |
| episodes                | 4170          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1056908       |
| policy_loss             | -0.29476106   |
| qf1_loss                | 0.00019655662 |
| qf2_loss                | 0.00027035846 |
| time_elapsed            | 5287          |
| total timesteps         | 1057008       |
| value_loss              | 0.00024523085 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009089642  |
| ent_coef_loss           | 0.16057715    |
| entropy                 | 1.5817852     |
| episodes                | 4180          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1058872       |
| policy_loss             | -0.3221134    |
| qf1_loss                | 0.00013444666 |
| qf2_loss                | 9.387711e-05  |
| time_elapsed            | 5297          |
| total timesteps         | 1058972       |
| value_loss              | 0.000146962   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00092935434 |
| ent_coef_loss           | 0.56644285    |
| entropy                 | 1.5564754     |
| episodes                | 4190          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1060690       |
| policy_loss             | -0.39201915   |
| qf1_loss                | 0.00032243377 |
| qf2_loss                | 0.00029199253 |
| time_elapsed            | 5307          |
| total timesteps         | 1060790       |
| value_loss              | 0.0001263446  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00092144037  |
| ent_coef_loss           | 1.2520418      |
| entropy                 | 1.6060548      |
| episodes                | 4200           |
| fps                     | 199            |
| mean 100 episode reward | 1.3            |
| n_updates               | 1062466        |
| policy_loss             | -0.298945      |
| qf1_loss                | 0.00039843653  |
| qf2_loss                | 0.00031437387  |
| time_elapsed            | 5316           |
| total timesteps         | 1062566        |
| value_loss              | 0.000117429154 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000898533   |
| ent_coef_loss           | 0.40770876    |
| entropy                 | 1.5672112     |
| episodes                | 4210          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1064383       |
| policy_loss             | -0.3762139    |
| qf1_loss                | 0.00034873778 |
| qf2_loss                | 0.00024218387 |
| time_elapsed            | 5326          |
| total timesteps         | 1064483       |
| value_loss              | 0.00017536207 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00087276625 |
| ent_coef_loss           | 0.5237847     |
| entropy                 | 1.6297051     |
| episodes                | 4220          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1066211       |
| policy_loss             | -0.32729125   |
| qf1_loss                | 0.00023174594 |
| qf2_loss                | 0.0002571351  |
| time_elapsed            | 5335          |
| total timesteps         | 1066311       |
| value_loss              | 0.00018202499 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00086981396 |
| ent_coef_loss           | -0.21107477   |
| entropy                 | 1.5195253     |
| episodes                | 4230          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1068137       |
| policy_loss             | -0.23486602   |
| qf1_loss                | 0.00029350183 |
| qf2_loss                | 0.00027803358 |
| time_elapsed            | 5345          |
| total timesteps         | 1068237       |
| value_loss              | 0.00027589666 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008448281  |
| ent_coef_loss           | 2.7275224     |
| entropy                 | 1.5899979     |
| episodes                | 4240          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1070191       |
| policy_loss             | -0.34525618   |
| qf1_loss                | 0.00021708521 |
| qf2_loss                | 0.0001597926  |
| time_elapsed            | 5355          |
| total timesteps         | 1070291       |
| value_loss              | 0.00027932558 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0008091669   |
| ent_coef_loss           | 0.7206093      |
| entropy                 | 1.5133872      |
| episodes                | 4250           |
| fps                     | 199            |
| mean 100 episode reward | 1.2            |
| n_updates               | 1071975        |
| policy_loss             | -0.3661374     |
| qf1_loss                | 0.00014874077  |
| qf2_loss                | 0.00013523694  |
| time_elapsed            | 5364           |
| total timesteps         | 1072075        |
| value_loss              | 0.000112978996 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00080113404 |
| ent_coef_loss           | 0.88759077    |
| entropy                 | 1.5413219     |
| episodes                | 4260          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1074015       |
| policy_loss             | -0.4071901    |
| qf1_loss                | 0.0002367128  |
| qf2_loss                | 0.00021799418 |
| time_elapsed            | 5374          |
| total timesteps         | 1074115       |
| value_loss              | 0.0001248809  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0008191678   |
| ent_coef_loss           | -0.9215325     |
| entropy                 | 1.5131768      |
| episodes                | 4270           |
| fps                     | 199            |
| mean 100 episode reward | 1.2            |
| n_updates               | 1075894        |
| policy_loss             | -0.32892093    |
| qf1_loss                | 0.00025857484  |
| qf2_loss                | 0.00020646841  |
| time_elapsed            | 5384           |
| total timesteps         | 1075994        |
| value_loss              | 0.000113045964 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00084141805 |
| ent_coef_loss           | -1.5834665    |
| entropy                 | 1.6194917     |
| episodes                | 4280          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1077891       |
| policy_loss             | -0.33700937   |
| qf1_loss                | 0.00012884283 |
| qf2_loss                | 8.6595304e-05 |
| time_elapsed            | 5393          |
| total timesteps         | 1077991       |
| value_loss              | 0.00012748498 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008192334  |
| ent_coef_loss           | -1.0771724    |
| entropy                 | 1.5853121     |
| episodes                | 4290          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1080019       |
| policy_loss             | -0.37277007   |
| qf1_loss                | 0.00024753864 |
| qf2_loss                | 0.00013458716 |
| time_elapsed            | 5404          |
| total timesteps         | 1080119       |
| value_loss              | 0.0002198868  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007687594  |
| ent_coef_loss           | -1.6231599    |
| entropy                 | 1.5181763     |
| episodes                | 4300          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1081832       |
| policy_loss             | -0.33691907   |
| qf1_loss                | 0.00030854467 |
| qf2_loss                | 0.00012564918 |
| time_elapsed            | 5414          |
| total timesteps         | 1081932       |
| value_loss              | 0.00019037517 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00078188017 |
| ent_coef_loss           | 2.063952      |
| entropy                 | 1.5332451     |
| episodes                | 4310          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1083619       |
| policy_loss             | -0.2641005    |
| qf1_loss                | 0.0006227162  |
| qf2_loss                | 0.00034086168 |
| time_elapsed            | 5422          |
| total timesteps         | 1083719       |
| value_loss              | 0.00026040818 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00079896796 |
| ent_coef_loss           | 0.058753222   |
| entropy                 | 1.5370691     |
| episodes                | 4320          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1085533       |
| policy_loss             | -0.35099465   |
| qf1_loss                | 0.00016150285 |
| qf2_loss                | 8.773555e-05  |
| time_elapsed            | 5432          |
| total timesteps         | 1085633       |
| value_loss              | 0.00019477811 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000817244   |
| ent_coef_loss           | 2.7065227     |
| entropy                 | 1.508088      |
| episodes                | 4330          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1087534       |
| policy_loss             | -0.33028638   |
| qf1_loss                | 0.0005568223  |
| qf2_loss                | 0.00023414992 |
| time_elapsed            | 5442          |
| total timesteps         | 1087634       |
| value_loss              | 0.00017448056 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008529321  |
| ent_coef_loss           | 0.078918636   |
| entropy                 | 1.5677563     |
| episodes                | 4340          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1089605       |
| policy_loss             | -0.36066943   |
| qf1_loss                | 0.0001330458  |
| qf2_loss                | 0.00024774997 |
| time_elapsed            | 5452          |
| total timesteps         | 1089705       |
| value_loss              | 0.00029120938 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00087343407  |
| ent_coef_loss           | -2.7796974     |
| entropy                 | 1.5867281      |
| episodes                | 4350           |
| fps                     | 199            |
| mean 100 episode reward | 1.3            |
| n_updates               | 1091616        |
| policy_loss             | -0.36829558    |
| qf1_loss                | 0.00015583029  |
| qf2_loss                | 0.0002118061   |
| time_elapsed            | 5463           |
| total timesteps         | 1091716        |
| value_loss              | 0.000120543984 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008618257  |
| ent_coef_loss           | -2.6208622    |
| entropy                 | 1.5956751     |
| episodes                | 4360          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1093641       |
| policy_loss             | -0.37212417   |
| qf1_loss                | 0.0003057066  |
| qf2_loss                | 0.00027825276 |
| time_elapsed            | 5473          |
| total timesteps         | 1093741       |
| value_loss              | 6.96824e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008438952  |
| ent_coef_loss           | 1.4430614     |
| entropy                 | 1.5762995     |
| episodes                | 4370          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1095500       |
| policy_loss             | -0.30739477   |
| qf1_loss                | 0.0004116298  |
| qf2_loss                | 0.0003120393  |
| time_elapsed            | 5482          |
| total timesteps         | 1095600       |
| value_loss              | 7.2352064e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00084478175 |
| ent_coef_loss           | 0.9696598     |
| entropy                 | 1.5648894     |
| episodes                | 4380          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1097342       |
| policy_loss             | -0.35004133   |
| qf1_loss                | 0.00045528178 |
| qf2_loss                | 0.00036022282 |
| time_elapsed            | 5491          |
| total timesteps         | 1097442       |
| value_loss              | 0.00016204335 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00084001094 |
| ent_coef_loss           | 3.065095      |
| entropy                 | 1.5866677     |
| episodes                | 4390          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1099161       |
| policy_loss             | -0.24348217   |
| qf1_loss                | 0.0002270831  |
| qf2_loss                | 0.0002849501  |
| time_elapsed            | 5501          |
| total timesteps         | 1099261       |
| value_loss              | 0.00021143319 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00084154366 |
| ent_coef_loss           | -0.65338635   |
| entropy                 | 1.5102172     |
| episodes                | 4400          |
| fps                     | 199           |
| mean 100 episode reward | 1.1           |
| n_updates               | 1100720       |
| policy_loss             | -0.33074397   |
| qf1_loss                | 0.00013137054 |
| qf2_loss                | 0.00010898178 |
| time_elapsed            | 5508          |
| total timesteps         | 1100820       |
| value_loss              | 0.00025220084 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00084470323 |
| ent_coef_loss           | -0.5470679    |
| entropy                 | 1.5163611     |
| episodes                | 4410          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1102724       |
| policy_loss             | -0.33945155   |
| qf1_loss                | 0.00013781928 |
| qf2_loss                | 0.000181568   |
| time_elapsed            | 5518          |
| total timesteps         | 1102824       |
| value_loss              | 8.491872e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00085809536  |
| ent_coef_loss           | 1.6302091      |
| entropy                 | 1.5505064      |
| episodes                | 4420           |
| fps                     | 199            |
| mean 100 episode reward | 1.2            |
| n_updates               | 1104356        |
| policy_loss             | -0.30317417    |
| qf1_loss                | 0.000102887854 |
| qf2_loss                | 0.000113387854 |
| time_elapsed            | 5527           |
| total timesteps         | 1104456        |
| value_loss              | 0.00022716197  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008415846  |
| ent_coef_loss           | -0.98614275   |
| entropy                 | 1.4603474     |
| episodes                | 4430          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1106510       |
| policy_loss             | -0.29680726   |
| qf1_loss                | 0.00019266966 |
| qf2_loss                | 0.0001544377  |
| time_elapsed            | 5537          |
| total timesteps         | 1106610       |
| value_loss              | 0.00030537718 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00082984415 |
| ent_coef_loss           | 2.2016966     |
| entropy                 | 1.4689655     |
| episodes                | 4440          |
| fps                     | 199           |
| mean 100 episode reward | 1.1           |
| n_updates               | 1108541       |
| policy_loss             | -0.31673872   |
| qf1_loss                | 0.00029065728 |
| qf2_loss                | 0.00015281423 |
| time_elapsed            | 5548          |
| total timesteps         | 1108641       |
| value_loss              | 0.00015777636 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008215379  |
| ent_coef_loss           | -0.61275846   |
| entropy                 | 1.4482712     |
| episodes                | 4450          |
| fps                     | 199           |
| mean 100 episode reward | 1.1           |
| n_updates               | 1110272       |
| policy_loss             | -0.33899355   |
| qf1_loss                | 0.0001562334  |
| qf2_loss                | 9.113689e-05  |
| time_elapsed            | 5556          |
| total timesteps         | 1110372       |
| value_loss              | 0.00011741791 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0008239094   |
| ent_coef_loss           | -4.699643      |
| entropy                 | 1.5059159      |
| episodes                | 4460           |
| fps                     | 199            |
| mean 100 episode reward | 1              |
| n_updates               | 1112092        |
| policy_loss             | -0.41115454    |
| qf1_loss                | 0.00013960284  |
| qf2_loss                | 0.00014308492  |
| time_elapsed            | 5565           |
| total timesteps         | 1112192        |
| value_loss              | 0.000104948835 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008288318  |
| ent_coef_loss           | -1.0507216    |
| entropy                 | 1.5134301     |
| episodes                | 4470          |
| fps                     | 199           |
| mean 100 episode reward | 1.1           |
| n_updates               | 1114626       |
| policy_loss             | -0.36312038   |
| qf1_loss                | 0.0014324682  |
| qf2_loss                | 0.0014793199  |
| time_elapsed            | 5578          |
| total timesteps         | 1114726       |
| value_loss              | 0.00016391411 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00084827055 |
| ent_coef_loss           | -1.831314     |
| entropy                 | 1.5340812     |
| episodes                | 4480          |
| fps                     | 199           |
| mean 100 episode reward | 1.1           |
| n_updates               | 1116658       |
| policy_loss             | -0.3838649    |
| qf1_loss                | 0.00018430037 |
| qf2_loss                | 0.00013136843 |
| time_elapsed            | 5588          |
| total timesteps         | 1116758       |
| value_loss              | 0.0002056171  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008488929  |
| ent_coef_loss           | 4.914982      |
| entropy                 | 1.5235484     |
| episodes                | 4490          |
| fps                     | 199           |
| mean 100 episode reward | 1.1           |
| n_updates               | 1118252       |
| policy_loss             | -0.3080178    |
| qf1_loss                | 0.00022597086 |
| qf2_loss                | 0.00013611028 |
| time_elapsed            | 5596          |
| total timesteps         | 1118352       |
| value_loss              | 0.00010872867 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00082110753 |
| ent_coef_loss           | -2.5860324    |
| entropy                 | 1.4812433     |
| episodes                | 4500          |
| fps                     | 199           |
| mean 100 episode reward | 1.1           |
| n_updates               | 1120116       |
| policy_loss             | -0.32939202   |
| qf1_loss                | 0.0004288135  |
| qf2_loss                | 0.0002726199  |
| time_elapsed            | 5606          |
| total timesteps         | 1120216       |
| value_loss              | 0.00027881784 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0008012456 |
| ent_coef_loss           | -0.3678077   |
| entropy                 | 1.4954069    |
| episodes                | 4510         |
| fps                     | 199          |
| mean 100 episode reward | 1.1          |
| n_updates               | 1122800      |
| policy_loss             | -0.36493438  |
| qf1_loss                | 0.008483127  |
| qf2_loss                | 0.007376392  |
| time_elapsed            | 5619         |
| total timesteps         | 1122900      |
| value_loss              | 0.0001534886 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00077889836 |
| ent_coef_loss           | -1.7119243    |
| entropy                 | 1.4343235     |
| episodes                | 4520          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1124896       |
| policy_loss             | -0.3486774    |
| qf1_loss                | 0.00017319457 |
| qf2_loss                | 0.00014786891 |
| time_elapsed            | 5629          |
| total timesteps         | 1124996       |
| value_loss              | 0.00021503799 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008016079  |
| ent_coef_loss           | 1.3096802     |
| entropy                 | 1.4860308     |
| episodes                | 4530          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1126851       |
| policy_loss             | -0.27329475   |
| qf1_loss                | 0.00011006302 |
| qf2_loss                | 0.00029639574 |
| time_elapsed            | 5639          |
| total timesteps         | 1126951       |
| value_loss              | 0.00011584882 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00076789735 |
| ent_coef_loss           | -1.5456095    |
| entropy                 | 1.5210028     |
| episodes                | 4540          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1128947       |
| policy_loss             | -0.3177023    |
| qf1_loss                | 0.0001583025  |
| qf2_loss                | 0.00017784935 |
| time_elapsed            | 5650          |
| total timesteps         | 1129047       |
| value_loss              | 0.00018776799 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0007695707   |
| ent_coef_loss           | -0.9716694     |
| entropy                 | 1.470267       |
| episodes                | 4550           |
| fps                     | 199            |
| mean 100 episode reward | 1.3            |
| n_updates               | 1131046        |
| policy_loss             | -0.35916114    |
| qf1_loss                | 9.617507e-05   |
| qf2_loss                | 9.076419e-05   |
| time_elapsed            | 5660           |
| total timesteps         | 1131146        |
| value_loss              | 0.000106058105 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007565595  |
| ent_coef_loss           | -2.5383584    |
| entropy                 | 1.4547336     |
| episodes                | 4560          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1133647       |
| policy_loss             | -0.39965755   |
| qf1_loss                | 0.00011218527 |
| qf2_loss                | 0.00019225811 |
| time_elapsed            | 5673          |
| total timesteps         | 1133747       |
| value_loss              | 0.00029502553 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007629831  |
| ent_coef_loss           | 2.5879734     |
| entropy                 | 1.4673713     |
| episodes                | 4570          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1135239       |
| policy_loss             | -0.33390608   |
| qf1_loss                | 0.00013322377 |
| qf2_loss                | 0.0001506599  |
| time_elapsed            | 5681          |
| total timesteps         | 1135339       |
| value_loss              | 0.00024063553 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007974078  |
| ent_coef_loss           | -2.435962     |
| entropy                 | 1.5619106     |
| episodes                | 4580          |
| fps                     | 199           |
| mean 100 episode reward | 1.1           |
| n_updates               | 1137000       |
| policy_loss             | -0.3130638    |
| qf1_loss                | 0.00020281403 |
| qf2_loss                | 0.00033401803 |
| time_elapsed            | 5690          |
| total timesteps         | 1137100       |
| value_loss              | 0.00018849017 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00078752043  |
| ent_coef_loss           | 0.7836763      |
| entropy                 | 1.4308689      |
| episodes                | 4590           |
| fps                     | 199            |
| mean 100 episode reward | 1.2            |
| n_updates               | 1139019        |
| policy_loss             | -0.32445586    |
| qf1_loss                | 0.000111741814 |
| qf2_loss                | 0.0002811631   |
| time_elapsed            | 5700           |
| total timesteps         | 1139119        |
| value_loss              | 0.00016829013  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007938042  |
| ent_coef_loss           | 1.4244167     |
| entropy                 | 1.5717471     |
| episodes                | 4600          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1141045       |
| policy_loss             | -0.39688075   |
| qf1_loss                | 0.00021495095 |
| qf2_loss                | 0.00020859137 |
| time_elapsed            | 5711          |
| total timesteps         | 1141145       |
| value_loss              | 0.00017297477 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008418872  |
| ent_coef_loss           | -0.74851155   |
| entropy                 | 1.4585481     |
| episodes                | 4610          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1143030       |
| policy_loss             | -0.29449934   |
| qf1_loss                | 0.00015340158 |
| qf2_loss                | 0.00021965138 |
| time_elapsed            | 5721          |
| total timesteps         | 1143130       |
| value_loss              | 0.0002310322  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008600621  |
| ent_coef_loss           | -1.6309462    |
| entropy                 | 1.546474      |
| episodes                | 4620          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1145064       |
| policy_loss             | -0.328107     |
| qf1_loss                | 0.00027363095 |
| qf2_loss                | 0.00018563517 |
| time_elapsed            | 5731          |
| total timesteps         | 1145164       |
| value_loss              | 0.0003054667  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008219537  |
| ent_coef_loss           | 2.1015017     |
| entropy                 | 1.4394886     |
| episodes                | 4630          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1147073       |
| policy_loss             | -0.37563974   |
| qf1_loss                | 0.00018954213 |
| qf2_loss                | 0.00015047331 |
| time_elapsed            | 5741          |
| total timesteps         | 1147173       |
| value_loss              | 0.00010766339 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007955776  |
| ent_coef_loss           | 2.239124      |
| entropy                 | 1.4797693     |
| episodes                | 4640          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1149260       |
| policy_loss             | -0.3653166    |
| qf1_loss                | 0.00022580681 |
| qf2_loss                | 0.00013512468 |
| time_elapsed            | 5751          |
| total timesteps         | 1149360       |
| value_loss              | 0.00020759215 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007860918  |
| ent_coef_loss           | 0.26358998    |
| entropy                 | 1.5223445     |
| episodes                | 4650          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1151266       |
| policy_loss             | -0.30475384   |
| qf1_loss                | 0.0003058998  |
| qf2_loss                | 0.00042857687 |
| time_elapsed            | 5761          |
| total timesteps         | 1151366       |
| value_loss              | 0.0002107452  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00077455834 |
| ent_coef_loss           | 2.9927044     |
| entropy                 | 1.499152      |
| episodes                | 4660          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1153324       |
| policy_loss             | -0.2943293    |
| qf1_loss                | 0.0001744006  |
| qf2_loss                | 0.00022309012 |
| time_elapsed            | 5772          |
| total timesteps         | 1153424       |
| value_loss              | 9.759827e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007438285  |
| ent_coef_loss           | -0.27719903   |
| entropy                 | 1.4784503     |
| episodes                | 4670          |
| fps                     | 199           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1155418       |
| policy_loss             | -0.2752888    |
| qf1_loss                | 0.00023216402 |
| qf2_loss                | 0.00024281543 |
| time_elapsed            | 5782          |
| total timesteps         | 1155518       |
| value_loss              | 0.00020692064 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000740091   |
| ent_coef_loss           | -0.17941672   |
| entropy                 | 1.5410626     |
| episodes                | 4680          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1157075       |
| policy_loss             | -0.39066935   |
| qf1_loss                | 0.0002348447  |
| qf2_loss                | 0.0003361203  |
| time_elapsed            | 5791          |
| total timesteps         | 1157175       |
| value_loss              | 0.00017309893 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00076523557 |
| ent_coef_loss           | -1.7766525    |
| entropy                 | 1.4788475     |
| episodes                | 4690          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1158924       |
| policy_loss             | -0.34919572   |
| qf1_loss                | 0.00012044876 |
| qf2_loss                | 9.452094e-05  |
| time_elapsed            | 5800          |
| total timesteps         | 1159024       |
| value_loss              | 0.00015433496 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00076872425 |
| ent_coef_loss           | -3.7319534    |
| entropy                 | 1.5520563     |
| episodes                | 4700          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1160771       |
| policy_loss             | -0.48152596   |
| qf1_loss                | 6.044767e-05  |
| qf2_loss                | 8.2120736e-05 |
| time_elapsed            | 5809          |
| total timesteps         | 1160871       |
| value_loss              | 3.8509246e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007441474  |
| ent_coef_loss           | -2.041256     |
| entropy                 | 1.5447757     |
| episodes                | 4710          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1162718       |
| policy_loss             | -0.2664702    |
| qf1_loss                | 0.00016226422 |
| qf2_loss                | 0.00018668768 |
| time_elapsed            | 5818          |
| total timesteps         | 1162818       |
| value_loss              | 0.0003053646  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00072124106 |
| ent_coef_loss           | 0.5295015     |
| entropy                 | 1.418745      |
| episodes                | 4720          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1164870       |
| policy_loss             | -0.3563482    |
| qf1_loss                | 0.00024755567 |
| qf2_loss                | 0.00032888606 |
| time_elapsed            | 5830          |
| total timesteps         | 1164970       |
| value_loss              | 0.00011888998 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007646921  |
| ent_coef_loss           | 4.774706      |
| entropy                 | 1.4979689     |
| episodes                | 4730          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1166855       |
| policy_loss             | -0.3058806    |
| qf1_loss                | 0.00032823405 |
| qf2_loss                | 0.00025580474 |
| time_elapsed            | 5839          |
| total timesteps         | 1166955       |
| value_loss              | 0.00015140639 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00076772674 |
| ent_coef_loss           | 2.8561947     |
| entropy                 | 1.5342438     |
| episodes                | 4740          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1168621       |
| policy_loss             | -0.29509795   |
| qf1_loss                | 0.00021832316 |
| qf2_loss                | 0.00016514244 |
| time_elapsed            | 5849          |
| total timesteps         | 1168721       |
| value_loss              | 7.8898025e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007537447  |
| ent_coef_loss           | -2.636354     |
| entropy                 | 1.4392338     |
| episodes                | 4750          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1170865       |
| policy_loss             | -0.31242663   |
| qf1_loss                | 0.00097260426 |
| qf2_loss                | 0.00082120625 |
| time_elapsed            | 5860          |
| total timesteps         | 1170965       |
| value_loss              | 0.00010047243 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007588675  |
| ent_coef_loss           | 0.42444342    |
| entropy                 | 1.5077956     |
| episodes                | 4760          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1172916       |
| policy_loss             | -0.37577137   |
| qf1_loss                | 0.00013102652 |
| qf2_loss                | 0.00015090287 |
| time_elapsed            | 5870          |
| total timesteps         | 1173016       |
| value_loss              | 0.00015455708 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00075785787 |
| ent_coef_loss           | 0.35493422    |
| entropy                 | 1.4494379     |
| episodes                | 4770          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1174907       |
| policy_loss             | -0.2517479    |
| qf1_loss                | 0.00019319633 |
| qf2_loss                | 0.00020337633 |
| time_elapsed            | 5880          |
| total timesteps         | 1175007       |
| value_loss              | 9.3142604e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00075915124 |
| ent_coef_loss           | -2.2022383    |
| entropy                 | 1.4855522     |
| episodes                | 4780          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1176824       |
| policy_loss             | -0.42242742   |
| qf1_loss                | 8.120291e-05  |
| qf2_loss                | 9.114482e-05  |
| time_elapsed            | 5890          |
| total timesteps         | 1176924       |
| value_loss              | 9.4318195e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0007722111   |
| ent_coef_loss           | -1.9995408     |
| entropy                 | 1.5187011      |
| episodes                | 4790           |
| fps                     | 199            |
| mean 100 episode reward | 1.3            |
| n_updates               | 1178887        |
| policy_loss             | -0.24856962    |
| qf1_loss                | 0.000107007334 |
| qf2_loss                | 0.00019307791  |
| time_elapsed            | 5900           |
| total timesteps         | 1178987        |
| value_loss              | 0.00014553066  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007713378  |
| ent_coef_loss           | 0.3573947     |
| entropy                 | 1.5299926     |
| episodes                | 4800          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1181005       |
| policy_loss             | -0.32275602   |
| qf1_loss                | 0.00025571865 |
| qf2_loss                | 0.00018185924 |
| time_elapsed            | 5911          |
| total timesteps         | 1181105       |
| value_loss              | 0.00039101118 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007988415  |
| ent_coef_loss           | -0.9926939    |
| entropy                 | 1.5566523     |
| episodes                | 4810          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1183123       |
| policy_loss             | -0.3209883    |
| qf1_loss                | 0.00015471381 |
| qf2_loss                | 9.322578e-05  |
| time_elapsed            | 5922          |
| total timesteps         | 1183223       |
| value_loss              | 0.00019132302 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00081182196 |
| ent_coef_loss           | 2.3070323     |
| entropy                 | 1.5455482     |
| episodes                | 4820          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1184762       |
| policy_loss             | -0.324023     |
| qf1_loss                | 0.00017863828 |
| qf2_loss                | 0.0002825433  |
| time_elapsed            | 5930          |
| total timesteps         | 1184862       |
| value_loss              | 0.00013121472 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008338611  |
| ent_coef_loss           | -0.32890058   |
| entropy                 | 1.5477887     |
| episodes                | 4830          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1186623       |
| policy_loss             | -0.31705493   |
| qf1_loss                | 0.00012677956 |
| qf2_loss                | 0.00021285485 |
| time_elapsed            | 5939          |
| total timesteps         | 1186723       |
| value_loss              | 0.00017060974 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00083573005 |
| ent_coef_loss           | 4.315007      |
| entropy                 | 1.479386      |
| episodes                | 4840          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1188729       |
| policy_loss             | -0.24785155   |
| qf1_loss                | 0.0003124918  |
| qf2_loss                | 0.00019643216 |
| time_elapsed            | 5950          |
| total timesteps         | 1188829       |
| value_loss              | 0.00049089734 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00083856424 |
| ent_coef_loss           | -0.41790307   |
| entropy                 | 1.5160351     |
| episodes                | 4850          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1190711       |
| policy_loss             | -0.34315628   |
| qf1_loss                | 0.00013230325 |
| qf2_loss                | 7.709458e-05  |
| time_elapsed            | 5959          |
| total timesteps         | 1190811       |
| value_loss              | 0.00012254657 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00086736993 |
| ent_coef_loss           | 0.76545364    |
| entropy                 | 1.4919488     |
| episodes                | 4860          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1192687       |
| policy_loss             | -0.31459355   |
| qf1_loss                | 0.00017907715 |
| qf2_loss                | 0.00017998941 |
| time_elapsed            | 5969          |
| total timesteps         | 1192787       |
| value_loss              | 0.0002782512  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008585202  |
| ent_coef_loss           | 0.4325196     |
| entropy                 | 1.5131274     |
| episodes                | 4870          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1194639       |
| policy_loss             | -0.38406962   |
| qf1_loss                | 0.00012708388 |
| qf2_loss                | 0.0001306476  |
| time_elapsed            | 5980          |
| total timesteps         | 1194739       |
| value_loss              | 9.3084294e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008544867  |
| ent_coef_loss           | -1.9927611    |
| entropy                 | 1.4926858     |
| episodes                | 4880          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1196470       |
| policy_loss             | -0.287516     |
| qf1_loss                | 0.00061022316 |
| qf2_loss                | 0.00035285405 |
| time_elapsed            | 5989          |
| total timesteps         | 1196570       |
| value_loss              | 0.00027235944 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008681925  |
| ent_coef_loss           | -1.41923      |
| entropy                 | 1.5342057     |
| episodes                | 4890          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1198142       |
| policy_loss             | -0.1586195    |
| qf1_loss                | 0.00036729578 |
| qf2_loss                | 0.00031579833 |
| time_elapsed            | 5997          |
| total timesteps         | 1198242       |
| value_loss              | 0.00023520362 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008716267  |
| ent_coef_loss           | -2.0388308    |
| entropy                 | 1.5288347     |
| episodes                | 4900          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1200045       |
| policy_loss             | -0.37023735   |
| qf1_loss                | 0.00021474819 |
| qf2_loss                | 0.00020399547 |
| time_elapsed            | 6007          |
| total timesteps         | 1200145       |
| value_loss              | 6.557477e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008493941  |
| ent_coef_loss           | -0.187157     |
| entropy                 | 1.5214945     |
| episodes                | 4910          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1202036       |
| policy_loss             | -0.36781204   |
| qf1_loss                | 0.00019049832 |
| qf2_loss                | 0.00011372106 |
| time_elapsed            | 6017          |
| total timesteps         | 1202136       |
| value_loss              | 8.990237e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00082953204 |
| ent_coef_loss           | -1.9764351    |
| entropy                 | 1.528297      |
| episodes                | 4920          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1203867       |
| policy_loss             | -0.3470412    |
| qf1_loss                | 0.00024182606 |
| qf2_loss                | 0.00015302048 |
| time_elapsed            | 6025          |
| total timesteps         | 1203967       |
| value_loss              | 0.000199771   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00083629927 |
| ent_coef_loss           | -1.1100935    |
| entropy                 | 1.5086281     |
| episodes                | 4930          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1205939       |
| policy_loss             | -0.32786947   |
| qf1_loss                | 0.00016937166 |
| qf2_loss                | 0.00016248616 |
| time_elapsed            | 6036          |
| total timesteps         | 1206039       |
| value_loss              | 0.00038270315 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00085245474 |
| ent_coef_loss           | -2.029663     |
| entropy                 | 1.5027385     |
| episodes                | 4940          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1208184       |
| policy_loss             | -0.34812343   |
| qf1_loss                | 0.00018424337 |
| qf2_loss                | 0.0001243009  |
| time_elapsed            | 6047          |
| total timesteps         | 1208284       |
| value_loss              | 0.00012791426 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0008808744 |
| ent_coef_loss           | 1.9605613    |
| entropy                 | 1.5624363    |
| episodes                | 4950         |
| fps                     | 199          |
| mean 100 episode reward | 1.3          |
| n_updates               | 1210355      |
| policy_loss             | -0.37115127  |
| qf1_loss                | 8.587912e-05 |
| qf2_loss                | 7.703035e-05 |
| time_elapsed            | 6058         |
| total timesteps         | 1210455      |
| value_loss              | 9.887332e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00084250927 |
| ent_coef_loss           | 0.3856088     |
| entropy                 | 1.5596699     |
| episodes                | 4960          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1212013       |
| policy_loss             | -0.3692563    |
| qf1_loss                | 0.00027879715 |
| qf2_loss                | 0.00014892998 |
| time_elapsed            | 6066          |
| total timesteps         | 1212113       |
| value_loss              | 7.3667026e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008239271  |
| ent_coef_loss           | 1.0664055     |
| entropy                 | 1.4817536     |
| episodes                | 4970          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1214098       |
| policy_loss             | -0.4352817    |
| qf1_loss                | 0.00039808816 |
| qf2_loss                | 0.00050939264 |
| time_elapsed            | 6076          |
| total timesteps         | 1214198       |
| value_loss              | 0.00011341817 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008008797  |
| ent_coef_loss           | -2.73442      |
| entropy                 | 1.4875283     |
| episodes                | 4980          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1216513       |
| policy_loss             | -0.3450584    |
| qf1_loss                | 0.00021368949 |
| qf2_loss                | 0.00015869581 |
| time_elapsed            | 6089          |
| total timesteps         | 1216613       |
| value_loss              | 0.00014556496 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00076404115 |
| ent_coef_loss           | -3.6462483    |
| entropy                 | 1.5133662     |
| episodes                | 4990          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1218247       |
| policy_loss             | -0.34528184   |
| qf1_loss                | 0.00013708493 |
| qf2_loss                | 0.00025971906 |
| time_elapsed            | 6098          |
| total timesteps         | 1218347       |
| value_loss              | 9.4092175e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007766346  |
| ent_coef_loss           | 2.039032      |
| entropy                 | 1.4985423     |
| episodes                | 5000          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1220411       |
| policy_loss             | -0.39298052   |
| qf1_loss                | 8.945003e-05  |
| qf2_loss                | 0.00011473448 |
| time_elapsed            | 6109          |
| total timesteps         | 1220511       |
| value_loss              | 0.00010561825 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008080637  |
| ent_coef_loss           | 0.20012164    |
| entropy                 | 1.4732871     |
| episodes                | 5010          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1222288       |
| policy_loss             | -0.37063414   |
| qf1_loss                | 0.0006452684  |
| qf2_loss                | 0.0005007733  |
| time_elapsed            | 6118          |
| total timesteps         | 1222388       |
| value_loss              | 0.00034418114 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00079533143 |
| ent_coef_loss           | -1.7818396    |
| entropy                 | 1.4204884     |
| episodes                | 5020          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1224315       |
| policy_loss             | -0.3093415    |
| qf1_loss                | 0.00022636977 |
| qf2_loss                | 0.00024072824 |
| time_elapsed            | 6129          |
| total timesteps         | 1224415       |
| value_loss              | 0.00013914473 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007865935  |
| ent_coef_loss           | -0.5005498    |
| entropy                 | 1.4866161     |
| episodes                | 5030          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1226304       |
| policy_loss             | -0.37002218   |
| qf1_loss                | 7.494164e-05  |
| qf2_loss                | 0.00017619267 |
| time_elapsed            | 6138          |
| total timesteps         | 1226404       |
| value_loss              | 0.0003257123  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00078081165 |
| ent_coef_loss           | -2.0212193    |
| entropy                 | 1.4291333     |
| episodes                | 5040          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1228417       |
| policy_loss             | -0.3471295    |
| qf1_loss                | 0.0053298525  |
| qf2_loss                | 0.0050107148  |
| time_elapsed            | 6149          |
| total timesteps         | 1228517       |
| value_loss              | 0.000188325   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000788341   |
| ent_coef_loss           | 0.47296202    |
| entropy                 | 1.4293327     |
| episodes                | 5050          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1230319       |
| policy_loss             | -0.32407033   |
| qf1_loss                | 0.00044225005 |
| qf2_loss                | 0.0003555041  |
| time_elapsed            | 6159          |
| total timesteps         | 1230419       |
| value_loss              | 0.00015602105 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00077554514 |
| ent_coef_loss           | 2.6586604     |
| entropy                 | 1.5020859     |
| episodes                | 5060          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1232163       |
| policy_loss             | -0.39419907   |
| qf1_loss                | 0.00014536464 |
| qf2_loss                | 9.951799e-05  |
| time_elapsed            | 6168          |
| total timesteps         | 1232263       |
| value_loss              | 9.497954e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007869082  |
| ent_coef_loss           | -0.26680136   |
| entropy                 | 1.4669623     |
| episodes                | 5070          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1234393       |
| policy_loss             | -0.22665007   |
| qf1_loss                | 0.0013848026  |
| qf2_loss                | 0.0012142111  |
| time_elapsed            | 6180          |
| total timesteps         | 1234493       |
| value_loss              | 0.00032808448 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00080952386 |
| ent_coef_loss           | 0.35942313    |
| entropy                 | 1.435461      |
| episodes                | 5080          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1236823       |
| policy_loss             | -0.37095463   |
| qf1_loss                | 0.0001591711  |
| qf2_loss                | 0.00027356308 |
| time_elapsed            | 6193          |
| total timesteps         | 1236923       |
| value_loss              | 0.00015245186 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008302012  |
| ent_coef_loss           | 1.9024295     |
| entropy                 | 1.4816399     |
| episodes                | 5090          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1239319       |
| policy_loss             | -0.32277784   |
| qf1_loss                | 0.00014788008 |
| qf2_loss                | 0.00024782377 |
| time_elapsed            | 6205          |
| total timesteps         | 1239419       |
| value_loss              | 7.973929e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00086517236 |
| ent_coef_loss           | -2.4407635    |
| entropy                 | 1.4910905     |
| episodes                | 5100          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1241383       |
| policy_loss             | -0.3822053    |
| qf1_loss                | 0.00017088096 |
| qf2_loss                | 0.00013152967 |
| time_elapsed            | 6215          |
| total timesteps         | 1241483       |
| value_loss              | 0.00016017603 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008608141  |
| ent_coef_loss           | -0.61392486   |
| entropy                 | 1.4913392     |
| episodes                | 5110          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1243446       |
| policy_loss             | -0.2530329    |
| qf1_loss                | 0.0011781115  |
| qf2_loss                | 0.0011658648  |
| time_elapsed            | 6226          |
| total timesteps         | 1243546       |
| value_loss              | 0.00013752327 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00083998335  |
| ent_coef_loss           | 5.6769795      |
| entropy                 | 1.5137963      |
| episodes                | 5120           |
| fps                     | 199            |
| mean 100 episode reward | 1.3            |
| n_updates               | 1245493        |
| policy_loss             | -0.3173294     |
| qf1_loss                | 0.000118266384 |
| qf2_loss                | 9.30984e-05    |
| time_elapsed            | 6235           |
| total timesteps         | 1245593        |
| value_loss              | 0.000118108284 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008367177  |
| ent_coef_loss           | 2.0729542     |
| entropy                 | 1.4827276     |
| episodes                | 5130          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1247417       |
| policy_loss             | -0.36443287   |
| qf1_loss                | 0.00020369762 |
| qf2_loss                | 0.00024397485 |
| time_elapsed            | 6245          |
| total timesteps         | 1247517       |
| value_loss              | 0.00012563387 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00081400934 |
| ent_coef_loss           | -0.4214995    |
| entropy                 | 1.4287895     |
| episodes                | 5140          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1249482       |
| policy_loss             | -0.31111866   |
| qf1_loss                | 0.00018437285 |
| qf2_loss                | 0.00018117591 |
| time_elapsed            | 6255          |
| total timesteps         | 1249582       |
| value_loss              | 0.00010469947 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00081457273 |
| ent_coef_loss           | 0.31126535    |
| entropy                 | 1.4372382     |
| episodes                | 5150          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1251539       |
| policy_loss             | -0.34475484   |
| qf1_loss                | 0.0001778328  |
| qf2_loss                | 0.00017777635 |
| time_elapsed            | 6265          |
| total timesteps         | 1251639       |
| value_loss              | 0.00015547896 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.000812366    |
| ent_coef_loss           | -0.46079278    |
| entropy                 | 1.4238026      |
| episodes                | 5160           |
| fps                     | 199            |
| mean 100 episode reward | 1.3            |
| n_updates               | 1253526        |
| policy_loss             | -0.404019      |
| qf1_loss                | 0.000109265515 |
| qf2_loss                | 0.00014407618  |
| time_elapsed            | 6276           |
| total timesteps         | 1253626        |
| value_loss              | 0.0003154241   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007976649  |
| ent_coef_loss           | 0.34145996    |
| entropy                 | 1.4806664     |
| episodes                | 5170          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1255522       |
| policy_loss             | -0.377735     |
| qf1_loss                | 8.3473074e-05 |
| qf2_loss                | 6.691493e-05  |
| time_elapsed            | 6286          |
| total timesteps         | 1255622       |
| value_loss              | 5.47549e-05   |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0007970763   |
| ent_coef_loss           | -0.012116939   |
| entropy                 | 1.4406985      |
| episodes                | 5180           |
| fps                     | 199            |
| mean 100 episode reward | 1.4            |
| n_updates               | 1257349        |
| policy_loss             | -0.30779976    |
| qf1_loss                | 0.000121044286 |
| qf2_loss                | 0.00022971087  |
| time_elapsed            | 6295           |
| total timesteps         | 1257449        |
| value_loss              | 0.00020661863  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008150223  |
| ent_coef_loss           | 2.7962751     |
| entropy                 | 1.4824262     |
| episodes                | 5190          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1259307       |
| policy_loss             | -0.37135065   |
| qf1_loss                | 0.00015968957 |
| qf2_loss                | 0.00013614296 |
| time_elapsed            | 6305          |
| total timesteps         | 1259407       |
| value_loss              | 0.00015751614 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008146504  |
| ent_coef_loss           | 0.2812842     |
| entropy                 | 1.4739705     |
| episodes                | 5200          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1261359       |
| policy_loss             | -0.2623339    |
| qf1_loss                | 0.00024691242 |
| qf2_loss                | 0.00014721806 |
| time_elapsed            | 6315          |
| total timesteps         | 1261459       |
| value_loss              | 0.00017109218 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008178954  |
| ent_coef_loss           | -0.77560055   |
| entropy                 | 1.402405      |
| episodes                | 5210          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1263212       |
| policy_loss             | -0.3696283    |
| qf1_loss                | 0.0002861818  |
| qf2_loss                | 0.00041427976 |
| time_elapsed            | 6325          |
| total timesteps         | 1263312       |
| value_loss              | 0.00016162734 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008070244  |
| ent_coef_loss           | 0.87233096    |
| entropy                 | 1.4310546     |
| episodes                | 5220          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1264998       |
| policy_loss             | -0.30198115   |
| qf1_loss                | 0.00019612725 |
| qf2_loss                | 0.00097143074 |
| time_elapsed            | 6334          |
| total timesteps         | 1265098       |
| value_loss              | 0.00035708587 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0008438284 |
| ent_coef_loss           | 2.229981     |
| entropy                 | 1.4783354    |
| episodes                | 5230         |
| fps                     | 199          |
| mean 100 episode reward | 1.3          |
| n_updates               | 1267083      |
| policy_loss             | -0.32986003  |
| qf1_loss                | 0.0006806581 |
| qf2_loss                | 0.0011210358 |
| time_elapsed            | 6345         |
| total timesteps         | 1267183      |
| value_loss              | 0.0001755075 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008626077  |
| ent_coef_loss           | -0.23820055   |
| entropy                 | 1.46822       |
| episodes                | 5240          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1269093       |
| policy_loss             | -0.3191303    |
| qf1_loss                | 0.00012900816 |
| qf2_loss                | 9.657265e-05  |
| time_elapsed            | 6354          |
| total timesteps         | 1269193       |
| value_loss              | 0.0001404241  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00085223245 |
| ent_coef_loss           | -0.07649547   |
| entropy                 | 1.492368      |
| episodes                | 5250          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1271353       |
| policy_loss             | -0.2614543    |
| qf1_loss                | 0.00044040362 |
| qf2_loss                | 0.00023574042 |
| time_elapsed            | 6366          |
| total timesteps         | 1271453       |
| value_loss              | 0.00019555021 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00085757714 |
| ent_coef_loss           | -0.68640643   |
| entropy                 | 1.4784307     |
| episodes                | 5260          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1273379       |
| policy_loss             | -0.26804212   |
| qf1_loss                | 0.00034310727 |
| qf2_loss                | 0.00015212937 |
| time_elapsed            | 6376          |
| total timesteps         | 1273479       |
| value_loss              | 0.00015246417 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008579931  |
| ent_coef_loss           | 2.3526735     |
| entropy                 | 1.4811933     |
| episodes                | 5270          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1275340       |
| policy_loss             | -0.3957255    |
| qf1_loss                | 0.00020418908 |
| qf2_loss                | 0.00017584246 |
| time_elapsed            | 6386          |
| total timesteps         | 1275440       |
| value_loss              | 0.00013546918 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00083718507 |
| ent_coef_loss           | 3.8876965     |
| entropy                 | 1.5471027     |
| episodes                | 5280          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1277607       |
| policy_loss             | -0.24941322   |
| qf1_loss                | 0.00018710017 |
| qf2_loss                | 0.00019391936 |
| time_elapsed            | 6398          |
| total timesteps         | 1277707       |
| value_loss              | 0.00038685638 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00082717673 |
| ent_coef_loss           | 2.4002538     |
| entropy                 | 1.4809661     |
| episodes                | 5290          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1279468       |
| policy_loss             | -0.22111934   |
| qf1_loss                | 0.0018457493  |
| qf2_loss                | 0.0008959456  |
| time_elapsed            | 6407          |
| total timesteps         | 1279568       |
| value_loss              | 0.00018889765 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00082829606 |
| ent_coef_loss           | -0.7157666    |
| entropy                 | 1.5799849     |
| episodes                | 5300          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1281449       |
| policy_loss             | -0.38162208   |
| qf1_loss                | 0.0002283387  |
| qf2_loss                | 0.00022129178 |
| time_elapsed            | 6417          |
| total timesteps         | 1281549       |
| value_loss              | 0.00017363034 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00081308564 |
| ent_coef_loss           | -2.7114427    |
| entropy                 | 1.4742472     |
| episodes                | 5310          |
| fps                     | 199           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1283478       |
| policy_loss             | -0.41803104   |
| qf1_loss                | 0.00011110486 |
| qf2_loss                | 0.00016275581 |
| time_elapsed            | 6427          |
| total timesteps         | 1283578       |
| value_loss              | 0.00010261353 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00079635717 |
| ent_coef_loss           | 1.1201816     |
| entropy                 | 1.4852868     |
| episodes                | 5320          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1285263       |
| policy_loss             | -0.32626867   |
| qf1_loss                | 0.0006132269  |
| qf2_loss                | 0.00030749256 |
| time_elapsed            | 6436          |
| total timesteps         | 1285363       |
| value_loss              | 0.00011140481 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0008161929 |
| ent_coef_loss           | -1.6880808   |
| entropy                 | 1.5248024    |
| episodes                | 5330         |
| fps                     | 199          |
| mean 100 episode reward | 1.4          |
| n_updates               | 1287207      |
| policy_loss             | -0.3764187   |
| qf1_loss                | 7.931134e-05 |
| qf2_loss                | 9.958942e-05 |
| time_elapsed            | 6446         |
| total timesteps         | 1287307      |
| value_loss              | 8.253859e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00080788805 |
| ent_coef_loss           | -1.4037858    |
| entropy                 | 1.460622      |
| episodes                | 5340          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1289342       |
| policy_loss             | -0.40587056   |
| qf1_loss                | 0.00035757924 |
| qf2_loss                | 0.00038196048 |
| time_elapsed            | 6457          |
| total timesteps         | 1289442       |
| value_loss              | 0.00032759644 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008001586  |
| ent_coef_loss           | -2.5274286    |
| entropy                 | 1.5148592     |
| episodes                | 5350          |
| fps                     | 199           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1291340       |
| policy_loss             | -0.41911417   |
| qf1_loss                | 0.00019567451 |
| qf2_loss                | 0.00017972721 |
| time_elapsed            | 6467          |
| total timesteps         | 1291440       |
| value_loss              | 0.00012807878 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007963925  |
| ent_coef_loss           | 3.1947947     |
| entropy                 | 1.3716087     |
| episodes                | 5360          |
| fps                     | 199           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1293438       |
| policy_loss             | -0.26911265   |
| qf1_loss                | 0.0002728388  |
| qf2_loss                | 0.00029003958 |
| time_elapsed            | 6478          |
| total timesteps         | 1293538       |
| value_loss              | 0.00028452725 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008310123  |
| ent_coef_loss           | 1.0298773     |
| entropy                 | 1.498558      |
| episodes                | 5370          |
| fps                     | 199           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1295575       |
| policy_loss             | -0.32188725   |
| qf1_loss                | 0.0004796796  |
| qf2_loss                | 0.0005345848  |
| time_elapsed            | 6489          |
| total timesteps         | 1295675       |
| value_loss              | 0.00015689674 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0008294881   |
| ent_coef_loss           | 2.4724078      |
| entropy                 | 1.5602994      |
| episodes                | 5380           |
| fps                     | 199            |
| mean 100 episode reward | 1.4            |
| n_updates               | 1298137        |
| policy_loss             | -0.2537207     |
| qf1_loss                | 0.000104176885 |
| qf2_loss                | 0.0006595941   |
| time_elapsed            | 6501           |
| total timesteps         | 1298237        |
| value_loss              | 0.0008691383   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008493974  |
| ent_coef_loss           | 1.5821202     |
| entropy                 | 1.5849602     |
| episodes                | 5390          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1300166       |
| policy_loss             | -0.41182092   |
| qf1_loss                | 0.0001327887  |
| qf2_loss                | 9.595946e-05  |
| time_elapsed            | 6512          |
| total timesteps         | 1300266       |
| value_loss              | 0.00019022798 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008648057  |
| ent_coef_loss           | 4.8256197     |
| entropy                 | 1.5494146     |
| episodes                | 5400          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1302314       |
| policy_loss             | -0.32905647   |
| qf1_loss                | 0.00024686242 |
| qf2_loss                | 0.00022008619 |
| time_elapsed            | 6522          |
| total timesteps         | 1302414       |
| value_loss              | 9.3436174e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00089674    |
| ent_coef_loss           | -0.42225158   |
| entropy                 | 1.5233134     |
| episodes                | 5410          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1304363       |
| policy_loss             | -0.2769844    |
| qf1_loss                | 0.00012721072 |
| qf2_loss                | 0.00037622912 |
| time_elapsed            | 6532          |
| total timesteps         | 1304463       |
| value_loss              | 0.00019054906 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008991043  |
| ent_coef_loss           | 2.9137454     |
| entropy                 | 1.508668      |
| episodes                | 5420          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1305917       |
| policy_loss             | -0.26214316   |
| qf1_loss                | 0.0006922608  |
| qf2_loss                | 0.0002833191  |
| time_elapsed            | 6540          |
| total timesteps         | 1306017       |
| value_loss              | 0.00034038295 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00089369935 |
| ent_coef_loss           | -3.3923612    |
| entropy                 | 1.5915482     |
| episodes                | 5430          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1307836       |
| policy_loss             | -0.3036999    |
| qf1_loss                | 0.0006198645  |
| qf2_loss                | 0.000302495   |
| time_elapsed            | 6549          |
| total timesteps         | 1307936       |
| value_loss              | 0.00025412254 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0008984533   |
| ent_coef_loss           | 2.8502903      |
| entropy                 | 1.5319747      |
| episodes                | 5440           |
| fps                     | 199            |
| mean 100 episode reward | 1.3            |
| n_updates               | 1309913        |
| policy_loss             | -0.31175977    |
| qf1_loss                | 0.00026796167  |
| qf2_loss                | 0.0002237878   |
| time_elapsed            | 6559           |
| total timesteps         | 1310013        |
| value_loss              | 0.000110116416 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00086416426 |
| ent_coef_loss           | 1.4451554     |
| entropy                 | 1.6006727     |
| episodes                | 5450          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1311878       |
| policy_loss             | -0.33361495   |
| qf1_loss                | 0.00014152475 |
| qf2_loss                | 9.1176305e-05 |
| time_elapsed            | 6568          |
| total timesteps         | 1311978       |
| value_loss              | 0.00016425007 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00086672866 |
| ent_coef_loss           | 0.16838479    |
| entropy                 | 1.4953811     |
| episodes                | 5460          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1313566       |
| policy_loss             | -0.392856     |
| qf1_loss                | 0.00019127794 |
| qf2_loss                | 0.00018135624 |
| time_elapsed            | 6577          |
| total timesteps         | 1313666       |
| value_loss              | 0.0002025584  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00085107546 |
| ent_coef_loss           | -3.3859377    |
| entropy                 | 1.5618839     |
| episodes                | 5470          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1315418       |
| policy_loss             | -0.345165     |
| qf1_loss                | 0.00043083075 |
| qf2_loss                | 0.0007145413  |
| time_elapsed            | 6586          |
| total timesteps         | 1315518       |
| value_loss              | 0.0001682887  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008429666  |
| ent_coef_loss           | 1.9519333     |
| entropy                 | 1.578547      |
| episodes                | 5480          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1317443       |
| policy_loss             | -0.34417534   |
| qf1_loss                | 0.0002488131  |
| qf2_loss                | 0.00013252365 |
| time_elapsed            | 6596          |
| total timesteps         | 1317543       |
| value_loss              | 9.745282e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008742528  |
| ent_coef_loss           | 2.107335      |
| entropy                 | 1.570822      |
| episodes                | 5490          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1319538       |
| policy_loss             | -0.36965537   |
| qf1_loss                | 0.00013509262 |
| qf2_loss                | 8.977855e-05  |
| time_elapsed            | 6607          |
| total timesteps         | 1319638       |
| value_loss              | 6.1090344e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008895642  |
| ent_coef_loss           | 2.840137      |
| entropy                 | 1.6385357     |
| episodes                | 5500          |
| fps                     | 199           |
| mean 100 episode reward | 1.1           |
| n_updates               | 1321642       |
| policy_loss             | -0.31524634   |
| qf1_loss                | 0.00011614377 |
| qf2_loss                | 0.0002933534  |
| time_elapsed            | 6618          |
| total timesteps         | 1321742       |
| value_loss              | 9.158289e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00092082104 |
| ent_coef_loss           | 1.8831878     |
| entropy                 | 1.5945013     |
| episodes                | 5510          |
| fps                     | 199           |
| mean 100 episode reward | 1.1           |
| n_updates               | 1323726       |
| policy_loss             | -0.33710995   |
| qf1_loss                | 0.0001773747  |
| qf2_loss                | 0.00023079042 |
| time_elapsed            | 6628          |
| total timesteps         | 1323826       |
| value_loss              | 5.8011727e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000937774   |
| ent_coef_loss           | 4.377435      |
| entropy                 | 1.629487      |
| episodes                | 5520          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1325875       |
| policy_loss             | -0.2307692    |
| qf1_loss                | 0.00029297062 |
| qf2_loss                | 0.0004197858  |
| time_elapsed            | 6639          |
| total timesteps         | 1325975       |
| value_loss              | 0.00020141334 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00094348285 |
| ent_coef_loss           | 2.3652155     |
| entropy                 | 1.6358646     |
| episodes                | 5530          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1327806       |
| policy_loss             | -0.3636652    |
| qf1_loss                | 0.0001182087  |
| qf2_loss                | 0.00016170934 |
| time_elapsed            | 6649          |
| total timesteps         | 1327906       |
| value_loss              | 0.00016468398 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009677673  |
| ent_coef_loss           | -1.4066768    |
| entropy                 | 1.6103957     |
| episodes                | 5540          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1329767       |
| policy_loss             | -0.3693998    |
| qf1_loss                | 0.00015057858 |
| qf2_loss                | 0.0002137787  |
| time_elapsed            | 6659          |
| total timesteps         | 1329867       |
| value_loss              | 9.200587e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009729881  |
| ent_coef_loss           | -1.5711904    |
| entropy                 | 1.6551704     |
| episodes                | 5550          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1331805       |
| policy_loss             | -0.35442233   |
| qf1_loss                | 0.00014109806 |
| qf2_loss                | 0.00014614956 |
| time_elapsed            | 6669          |
| total timesteps         | 1331905       |
| value_loss              | 0.0001449013  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009412608  |
| ent_coef_loss           | 0.924134      |
| entropy                 | 1.6594539     |
| episodes                | 5560          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1333842       |
| policy_loss             | -0.32703137   |
| qf1_loss                | 0.000132658   |
| qf2_loss                | 0.00012077428 |
| time_elapsed            | 6679          |
| total timesteps         | 1333942       |
| value_loss              | 0.00014894603 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009157448  |
| ent_coef_loss           | -1.3763673    |
| entropy                 | 1.532792      |
| episodes                | 5570          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1336099       |
| policy_loss             | -0.24196616   |
| qf1_loss                | 0.00014098342 |
| qf2_loss                | 0.00018329249 |
| time_elapsed            | 6690          |
| total timesteps         | 1336199       |
| value_loss              | 9.9834026e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009124861  |
| ent_coef_loss           | -2.5851655    |
| entropy                 | 1.6325338     |
| episodes                | 5580          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1338178       |
| policy_loss             | -0.4368137    |
| qf1_loss                | 0.0002215116  |
| qf2_loss                | 0.00019846986 |
| time_elapsed            | 6701          |
| total timesteps         | 1338278       |
| value_loss              | 0.00013019826 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00090785965 |
| ent_coef_loss           | -2.7054987    |
| entropy                 | 1.5651226     |
| episodes                | 5590          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1340225       |
| policy_loss             | -0.47787124   |
| qf1_loss                | 7.8247016e-05 |
| qf2_loss                | 0.00012149595 |
| time_elapsed            | 6710          |
| total timesteps         | 1340325       |
| value_loss              | 0.00015056973 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009385327  |
| ent_coef_loss           | -3.7190127    |
| entropy                 | 1.5660839     |
| episodes                | 5600          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1342146       |
| policy_loss             | -0.3935827    |
| qf1_loss                | 0.00013040385 |
| qf2_loss                | 0.00010380456 |
| time_elapsed            | 6721          |
| total timesteps         | 1342246       |
| value_loss              | 9.643605e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009408964  |
| ent_coef_loss           | -0.40136227   |
| entropy                 | 1.6262709     |
| episodes                | 5610          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1344075       |
| policy_loss             | -0.3632943    |
| qf1_loss                | 0.0002758632  |
| qf2_loss                | 0.00025442085 |
| time_elapsed            | 6730          |
| total timesteps         | 1344175       |
| value_loss              | 0.00015612891 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0009459898   |
| ent_coef_loss           | -0.4519534     |
| entropy                 | 1.638636       |
| episodes                | 5620           |
| fps                     | 199            |
| mean 100 episode reward | 1.4            |
| n_updates               | 1346093        |
| policy_loss             | -0.37139934    |
| qf1_loss                | 0.00021751455  |
| qf2_loss                | 0.00015741836  |
| time_elapsed            | 6740           |
| total timesteps         | 1346193        |
| value_loss              | 0.000116475276 |
--------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00091549853  |
| ent_coef_loss           | -4.808028      |
| entropy                 | 1.5991918      |
| episodes                | 5630           |
| fps                     | 199            |
| mean 100 episode reward | 1.4            |
| n_updates               | 1348107        |
| policy_loss             | -0.4414937     |
| qf1_loss                | 0.00010513441  |
| qf2_loss                | 0.000105029285 |
| time_elapsed            | 6751           |
| total timesteps         | 1348207        |
| value_loss              | 0.00012508394  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00091480167 |
| ent_coef_loss           | -0.5860352    |
| entropy                 | 1.5282173     |
| episodes                | 5640          |
| fps                     | 199           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1350142       |
| policy_loss             | -0.27106434   |
| qf1_loss                | 0.00071893004 |
| qf2_loss                | 0.0007299911  |
| time_elapsed            | 6761          |
| total timesteps         | 1350242       |
| value_loss              | 0.00031292913 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00093902514 |
| ent_coef_loss           | 1.1801097     |
| entropy                 | 1.5980531     |
| episodes                | 5650          |
| fps                     | 199           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1352170       |
| policy_loss             | -0.39847144   |
| qf1_loss                | 0.0002244536  |
| qf2_loss                | 0.0001700708  |
| time_elapsed            | 6770          |
| total timesteps         | 1352270       |
| value_loss              | 0.00011094043 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00094197737 |
| ent_coef_loss           | -2.437811     |
| entropy                 | 1.6192423     |
| episodes                | 5660          |
| fps                     | 199           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1354100       |
| policy_loss             | -0.38248423   |
| qf1_loss                | 9.281474e-05  |
| qf2_loss                | 0.00010483849 |
| time_elapsed            | 6780          |
| total timesteps         | 1354200       |
| value_loss              | 7.388686e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00091797404 |
| ent_coef_loss           | 0.18519652    |
| entropy                 | 1.6071026     |
| episodes                | 5670          |
| fps                     | 199           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1356119       |
| policy_loss             | -0.35877568   |
| qf1_loss                | 0.00023794263 |
| qf2_loss                | 0.00019887448 |
| time_elapsed            | 6790          |
| total timesteps         | 1356219       |
| value_loss              | 0.00013064887 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00092341215 |
| ent_coef_loss           | -2.731668     |
| entropy                 | 1.6433623     |
| episodes                | 5680          |
| fps                     | 199           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1357947       |
| policy_loss             | -0.24414593   |
| qf1_loss                | 0.00015630006 |
| qf2_loss                | 0.00017256784 |
| time_elapsed            | 6799          |
| total timesteps         | 1358047       |
| value_loss              | 0.00015983896 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009040439  |
| ent_coef_loss           | 2.1457477     |
| entropy                 | 1.5927289     |
| episodes                | 5690          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1359672       |
| policy_loss             | -0.34364367   |
| qf1_loss                | 0.0002808785  |
| qf2_loss                | 0.00040417333 |
| time_elapsed            | 6808          |
| total timesteps         | 1359772       |
| value_loss              | 0.0002211314  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00090642314 |
| ent_coef_loss           | 0.15348727    |
| entropy                 | 1.5977457     |
| episodes                | 5700          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1361662       |
| policy_loss             | -0.4053514    |
| qf1_loss                | 0.00013873598 |
| qf2_loss                | 0.00013452972 |
| time_elapsed            | 6818          |
| total timesteps         | 1361762       |
| value_loss              | 0.00011305748 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00089576305 |
| ent_coef_loss           | -3.3571644    |
| entropy                 | 1.572398      |
| episodes                | 5710          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1363542       |
| policy_loss             | -0.30631772   |
| qf1_loss                | 0.00027078146 |
| qf2_loss                | 0.00021552051 |
| time_elapsed            | 6827          |
| total timesteps         | 1363642       |
| value_loss              | 0.00023140266 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008673099  |
| ent_coef_loss           | 1.441341      |
| entropy                 | 1.5996821     |
| episodes                | 5720          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1365381       |
| policy_loss             | -0.28898883   |
| qf1_loss                | 0.00026746833 |
| qf2_loss                | 0.00034720247 |
| time_elapsed            | 6836          |
| total timesteps         | 1365481       |
| value_loss              | 0.00022709051 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008618894  |
| ent_coef_loss           | -1.8253639    |
| entropy                 | 1.5759791     |
| episodes                | 5730          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1367388       |
| policy_loss             | -0.3231203    |
| qf1_loss                | 0.0004298063  |
| qf2_loss                | 0.00025410962 |
| time_elapsed            | 6847          |
| total timesteps         | 1367488       |
| value_loss              | 0.00040478492 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00083816604 |
| ent_coef_loss           | -1.3525903    |
| entropy                 | 1.6029793     |
| episodes                | 5740          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1369335       |
| policy_loss             | -0.4294231    |
| qf1_loss                | 0.00013609928 |
| qf2_loss                | 0.00010268068 |
| time_elapsed            | 6856          |
| total timesteps         | 1369435       |
| value_loss              | 0.0002806728  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00083827315 |
| ent_coef_loss           | 1.8636208     |
| entropy                 | 1.6013598     |
| episodes                | 5750          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1371298       |
| policy_loss             | -0.30270547   |
| qf1_loss                | 0.00023985383 |
| qf2_loss                | 0.00022972637 |
| time_elapsed            | 6866          |
| total timesteps         | 1371398       |
| value_loss              | 0.0001552141  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000827155   |
| ent_coef_loss           | 0.9176372     |
| entropy                 | 1.5526423     |
| episodes                | 5760          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1373412       |
| policy_loss             | -0.29131114   |
| qf1_loss                | 0.0001615191  |
| qf2_loss                | 0.00026627906 |
| time_elapsed            | 6878          |
| total timesteps         | 1373512       |
| value_loss              | 8.418881e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008370509  |
| ent_coef_loss           | 0.24664873    |
| entropy                 | 1.621857      |
| episodes                | 5770          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1375476       |
| policy_loss             | -0.3646806    |
| qf1_loss                | 9.944773e-05  |
| qf2_loss                | 0.00014503472 |
| time_elapsed            | 6888          |
| total timesteps         | 1375576       |
| value_loss              | 0.00012210687 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008208284  |
| ent_coef_loss           | -2.3213794    |
| entropy                 | 1.6161273     |
| episodes                | 5780          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1377415       |
| policy_loss             | -0.39149177   |
| qf1_loss                | 9.406597e-05  |
| qf2_loss                | 0.00010162796 |
| time_elapsed            | 6898          |
| total timesteps         | 1377515       |
| value_loss              | 8.4926214e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007568106  |
| ent_coef_loss           | 2.945222      |
| entropy                 | 1.5755838     |
| episodes                | 5790          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1379490       |
| policy_loss             | -0.32973012   |
| qf1_loss                | 0.00037392738 |
| qf2_loss                | 0.00029356082 |
| time_elapsed            | 6909          |
| total timesteps         | 1379590       |
| value_loss              | 0.00022816533 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007304659  |
| ent_coef_loss           | 0.8545896     |
| entropy                 | 1.5499389     |
| episodes                | 5800          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1381411       |
| policy_loss             | -0.38698828   |
| qf1_loss                | 0.00046368293 |
| qf2_loss                | 0.0003705385  |
| time_elapsed            | 6918          |
| total timesteps         | 1381511       |
| value_loss              | 0.00020101835 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00074549136 |
| ent_coef_loss           | 3.2060325     |
| entropy                 | 1.4968133     |
| episodes                | 5810          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1383202       |
| policy_loss             | -0.37260243   |
| qf1_loss                | 0.00021754195 |
| qf2_loss                | 0.0002750893  |
| time_elapsed            | 6927          |
| total timesteps         | 1383302       |
| value_loss              | 8.992443e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007890315  |
| ent_coef_loss           | 0.44070765    |
| entropy                 | 1.547682      |
| episodes                | 5820          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1385214       |
| policy_loss             | -0.38225007   |
| qf1_loss                | 0.00024229113 |
| qf2_loss                | 0.00021646616 |
| time_elapsed            | 6938          |
| total timesteps         | 1385314       |
| value_loss              | 8.092087e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008462356  |
| ent_coef_loss           | 0.57813644    |
| entropy                 | 1.5786309     |
| episodes                | 5830          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1387143       |
| policy_loss             | -0.37080133   |
| qf1_loss                | 0.00020339222 |
| qf2_loss                | 0.00012698513 |
| time_elapsed            | 6947          |
| total timesteps         | 1387243       |
| value_loss              | 7.056068e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00086812215 |
| ent_coef_loss           | -1.702347     |
| entropy                 | 1.6124148     |
| episodes                | 5840          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1389746       |
| policy_loss             | -0.3806305    |
| qf1_loss                | 0.00015173196 |
| qf2_loss                | 0.00019069179 |
| time_elapsed            | 6960          |
| total timesteps         | 1389846       |
| value_loss              | 0.00019144024 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009041452  |
| ent_coef_loss           | -0.79144096   |
| entropy                 | 1.6031232     |
| episodes                | 5850          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1391602       |
| policy_loss             | -0.3606437    |
| qf1_loss                | 0.00078475976 |
| qf2_loss                | 0.0003742119  |
| time_elapsed            | 6970          |
| total timesteps         | 1391702       |
| value_loss              | 9.6944044e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00091834046 |
| ent_coef_loss           | -0.16110319   |
| entropy                 | 1.6542993     |
| episodes                | 5860          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1393611       |
| policy_loss             | -0.3217527    |
| qf1_loss                | 0.00044276207 |
| qf2_loss                | 0.00030268022 |
| time_elapsed            | 6979          |
| total timesteps         | 1393711       |
| value_loss              | 0.00022996514 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008709312  |
| ent_coef_loss           | -2.1089206    |
| entropy                 | 1.6049259     |
| episodes                | 5870          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1395445       |
| policy_loss             | -0.32057586   |
| qf1_loss                | 0.0004419947  |
| qf2_loss                | 0.00024326346 |
| time_elapsed            | 6988          |
| total timesteps         | 1395545       |
| value_loss              | 0.00013404197 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00084520446 |
| ent_coef_loss           | 2.5945296     |
| entropy                 | 1.6144062     |
| episodes                | 5880          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1397502       |
| policy_loss             | -0.2782763    |
| qf1_loss                | 0.00023907307 |
| qf2_loss                | 0.00020951516 |
| time_elapsed            | 6999          |
| total timesteps         | 1397602       |
| value_loss              | 0.00024893283 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0008058132   |
| ent_coef_loss           | 3.122582       |
| entropy                 | 1.607831       |
| episodes                | 5890           |
| fps                     | 199            |
| mean 100 episode reward | 1.4            |
| n_updates               | 1399402        |
| policy_loss             | -0.31121108    |
| qf1_loss                | 0.000111123096 |
| qf2_loss                | 0.00013818013  |
| time_elapsed            | 7008           |
| total timesteps         | 1399502        |
| value_loss              | 0.00017586135  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008114949  |
| ent_coef_loss           | 2.4023619     |
| entropy                 | 1.553508      |
| episodes                | 5900          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1401521       |
| policy_loss             | -0.36596036   |
| qf1_loss                | 0.00019379752 |
| qf2_loss                | 0.00022025939 |
| time_elapsed            | 7019          |
| total timesteps         | 1401621       |
| value_loss              | 9.793318e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00083609356 |
| ent_coef_loss           | 1.4477637     |
| entropy                 | 1.5940937     |
| episodes                | 5910          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1403804       |
| policy_loss             | -0.31747591   |
| qf1_loss                | 0.0005247826  |
| qf2_loss                | 0.00031478348 |
| time_elapsed            | 7030          |
| total timesteps         | 1403904       |
| value_loss              | 0.0001230018  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00087187655 |
| ent_coef_loss           | 4.0319624     |
| entropy                 | 1.5959768     |
| episodes                | 5920          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1405387       |
| policy_loss             | -0.2861476    |
| qf1_loss                | 0.00017771743 |
| qf2_loss                | 0.00034254437 |
| time_elapsed            | 7038          |
| total timesteps         | 1405487       |
| value_loss              | 0.00020223152 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00091987045 |
| ent_coef_loss           | -1.3407835    |
| entropy                 | 1.6186366     |
| episodes                | 5930          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1407377       |
| policy_loss             | -0.40746942   |
| qf1_loss                | 0.0002892583  |
| qf2_loss                | 0.00026068074 |
| time_elapsed            | 7048          |
| total timesteps         | 1407477       |
| value_loss              | 0.00010074861 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00092920504 |
| ent_coef_loss           | 0.4882252     |
| entropy                 | 1.565443      |
| episodes                | 5940          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1409259       |
| policy_loss             | -0.32346094   |
| qf1_loss                | 0.00023439486 |
| qf2_loss                | 0.00033011934 |
| time_elapsed            | 7057          |
| total timesteps         | 1409359       |
| value_loss              | 0.00035902404 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009517196  |
| ent_coef_loss           | -4.1487155    |
| entropy                 | 1.6395175     |
| episodes                | 5950          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1411235       |
| policy_loss             | -0.41592523   |
| qf1_loss                | 0.00023936198 |
| qf2_loss                | 0.0001908889  |
| time_elapsed            | 7067          |
| total timesteps         | 1411335       |
| value_loss              | 0.00020294986 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009924194  |
| ent_coef_loss           | -2.626231     |
| entropy                 | 1.6644367     |
| episodes                | 5960          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1413429       |
| policy_loss             | -0.29082358   |
| qf1_loss                | 0.0004098625  |
| qf2_loss                | 0.00035881106 |
| time_elapsed            | 7078          |
| total timesteps         | 1413529       |
| value_loss              | 0.0002421751  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0010153215  |
| ent_coef_loss           | 0.43391424    |
| entropy                 | 1.6558123     |
| episodes                | 5970          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1415473       |
| policy_loss             | -0.3933978    |
| qf1_loss                | 0.00016907851 |
| qf2_loss                | 0.0002292956  |
| time_elapsed            | 7088          |
| total timesteps         | 1415573       |
| value_loss              | 0.00011789391 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009947134  |
| ent_coef_loss           | 1.1585352     |
| entropy                 | 1.6452732     |
| episodes                | 5980          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1417410       |
| policy_loss             | -0.30663237   |
| qf1_loss                | 0.00044183468 |
| qf2_loss                | 0.00033176606 |
| time_elapsed            | 7098          |
| total timesteps         | 1417510       |
| value_loss              | 0.00032114596 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009815883  |
| ent_coef_loss           | 0.7924155     |
| entropy                 | 1.6511168     |
| episodes                | 5990          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1419158       |
| policy_loss             | -0.34057546   |
| qf1_loss                | 0.00021125599 |
| qf2_loss                | 0.00012854756 |
| time_elapsed            | 7107          |
| total timesteps         | 1419258       |
| value_loss              | 0.00013516305 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00095272716 |
| ent_coef_loss           | -1.3139477    |
| entropy                 | 1.5700233     |
| episodes                | 6000          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1421183       |
| policy_loss             | -0.33865213   |
| qf1_loss                | 0.00019996107 |
| qf2_loss                | 0.00016768661 |
| time_elapsed            | 7117          |
| total timesteps         | 1421283       |
| value_loss              | 0.00028162956 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009542148  |
| ent_coef_loss           | -2.388423     |
| entropy                 | 1.6352136     |
| episodes                | 6010          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1423168       |
| policy_loss             | -0.36668026   |
| qf1_loss                | 0.00014043966 |
| qf2_loss                | 0.00013498642 |
| time_elapsed            | 7127          |
| total timesteps         | 1423268       |
| value_loss              | 8.418136e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00093659735  |
| ent_coef_loss           | -1.5674272     |
| entropy                 | 1.6303949      |
| episodes                | 6020           |
| fps                     | 199            |
| mean 100 episode reward | 1.3            |
| n_updates               | 1425708        |
| policy_loss             | -0.2792378     |
| qf1_loss                | 0.00014294294  |
| qf2_loss                | 0.000106481035 |
| time_elapsed            | 7139           |
| total timesteps         | 1425808        |
| value_loss              | 9.4946896e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009188407  |
| ent_coef_loss           | 2.3338585     |
| entropy                 | 1.5972106     |
| episodes                | 6030          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1427689       |
| policy_loss             | -0.28499183   |
| qf1_loss                | 0.00019155585 |
| qf2_loss                | 0.00013379435 |
| time_elapsed            | 7150          |
| total timesteps         | 1427789       |
| value_loss              | 0.00018698857 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00092590996 |
| ent_coef_loss           | -1.0566579    |
| entropy                 | 1.5852091     |
| episodes                | 6040          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1429705       |
| policy_loss             | -0.41282776   |
| qf1_loss                | 0.00012947008 |
| qf2_loss                | 0.00013726272 |
| time_elapsed            | 7159          |
| total timesteps         | 1429805       |
| value_loss              | 0.00016934333 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000948384   |
| ent_coef_loss           | 1.5057673     |
| entropy                 | 1.59603       |
| episodes                | 6050          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1431719       |
| policy_loss             | -0.39679617   |
| qf1_loss                | 0.0002920831  |
| qf2_loss                | 0.00016575227 |
| time_elapsed            | 7170          |
| total timesteps         | 1431819       |
| value_loss              | 0.00022247987 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009642785  |
| ent_coef_loss           | -1.9999577    |
| entropy                 | 1.611362      |
| episodes                | 6060          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1433707       |
| policy_loss             | -0.42220145   |
| qf1_loss                | 0.00014152232 |
| qf2_loss                | 0.00013939396 |
| time_elapsed            | 7180          |
| total timesteps         | 1433807       |
| value_loss              | 0.00014759481 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009453923  |
| ent_coef_loss           | 1.8015665     |
| entropy                 | 1.6229309     |
| episodes                | 6070          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1435602       |
| policy_loss             | -0.2880242    |
| qf1_loss                | 0.00036855295 |
| qf2_loss                | 0.00035011978 |
| time_elapsed            | 7189          |
| total timesteps         | 1435702       |
| value_loss              | 0.00023098636 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009401376  |
| ent_coef_loss           | 0.80911213    |
| entropy                 | 1.603809      |
| episodes                | 6080          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1437509       |
| policy_loss             | -0.31371307   |
| qf1_loss                | 0.00019450879 |
| qf2_loss                | 0.00020568445 |
| time_elapsed            | 7198          |
| total timesteps         | 1437609       |
| value_loss              | 0.00021030389 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00095962273 |
| ent_coef_loss           | 0.8995688     |
| entropy                 | 1.6531577     |
| episodes                | 6090          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1439540       |
| policy_loss             | -0.34295133   |
| qf1_loss                | 0.00013227707 |
| qf2_loss                | 0.00019655828 |
| time_elapsed            | 7209          |
| total timesteps         | 1439640       |
| value_loss              | 0.00021033463 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009986104  |
| ent_coef_loss           | 0.73670805    |
| entropy                 | 1.649491      |
| episodes                | 6100          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1441476       |
| policy_loss             | -0.39266816   |
| qf1_loss                | 0.00022209683 |
| qf2_loss                | 0.00012502447 |
| time_elapsed            | 7218          |
| total timesteps         | 1441576       |
| value_loss              | 5.932118e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009998264  |
| ent_coef_loss           | 1.3602363     |
| entropy                 | 1.6746752     |
| episodes                | 6110          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1443448       |
| policy_loss             | -0.35248828   |
| qf1_loss                | 0.00020695427 |
| qf2_loss                | 0.00010181545 |
| time_elapsed            | 7228          |
| total timesteps         | 1443548       |
| value_loss              | 0.00015918522 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00093441334 |
| ent_coef_loss           | -2.2965562    |
| entropy                 | 1.5797457     |
| episodes                | 6120          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1445422       |
| policy_loss             | -0.2979766    |
| qf1_loss                | 0.0007167577  |
| qf2_loss                | 0.0018338446  |
| time_elapsed            | 7238          |
| total timesteps         | 1445522       |
| value_loss              | 0.00023317055 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00087636267  |
| ent_coef_loss           | 2.1137333      |
| entropy                 | 1.5669298      |
| episodes                | 6130           |
| fps                     | 199            |
| mean 100 episode reward | 1.3            |
| n_updates               | 1447279        |
| policy_loss             | -0.40512517    |
| qf1_loss                | 0.0001027834   |
| qf2_loss                | 0.000119543125 |
| time_elapsed            | 7247           |
| total timesteps         | 1447379        |
| value_loss              | 9.792322e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008623486  |
| ent_coef_loss           | -2.2790363    |
| entropy                 | 1.559131      |
| episodes                | 6140          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1449234       |
| policy_loss             | -0.40035912   |
| qf1_loss                | 0.0001704861  |
| qf2_loss                | 0.00011877646 |
| time_elapsed            | 7257          |
| total timesteps         | 1449334       |
| value_loss              | 0.00011074017 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00086279854 |
| ent_coef_loss           | -0.5546873    |
| entropy                 | 1.5261745     |
| episodes                | 6150          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1451073       |
| policy_loss             | -0.36562783   |
| qf1_loss                | 0.000207355   |
| qf2_loss                | 0.00026883636 |
| time_elapsed            | 7267          |
| total timesteps         | 1451173       |
| value_loss              | 0.00020366044 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008918837  |
| ent_coef_loss           | 3.237835      |
| entropy                 | 1.5666319     |
| episodes                | 6160          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1453147       |
| policy_loss             | -0.30007845   |
| qf1_loss                | 0.005154039   |
| qf2_loss                | 0.004353653   |
| time_elapsed            | 7277          |
| total timesteps         | 1453247       |
| value_loss              | 0.00022077147 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008974253  |
| ent_coef_loss           | 4.0431414     |
| entropy                 | 1.5710199     |
| episodes                | 6170          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1455150       |
| policy_loss             | -0.28780884   |
| qf1_loss                | 0.00018464579 |
| qf2_loss                | 0.0003248654  |
| time_elapsed            | 7286          |
| total timesteps         | 1455250       |
| value_loss              | 0.00026674016 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00090929714  |
| ent_coef_loss           | 1.7382936      |
| entropy                 | 1.5460461      |
| episodes                | 6180           |
| fps                     | 199            |
| mean 100 episode reward | 1.3            |
| n_updates               | 1456815        |
| policy_loss             | -0.31966764    |
| qf1_loss                | 8.5797285e-05  |
| qf2_loss                | 0.00011267025  |
| time_elapsed            | 7295           |
| total timesteps         | 1456915        |
| value_loss              | 0.000103021026 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000913958   |
| ent_coef_loss           | 1.809591      |
| entropy                 | 1.5450768     |
| episodes                | 6190          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1458561       |
| policy_loss             | -0.35953996   |
| qf1_loss                | 0.00019441012 |
| qf2_loss                | 0.00018438237 |
| time_elapsed            | 7304          |
| total timesteps         | 1458661       |
| value_loss              | 0.00013560201 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009266564  |
| ent_coef_loss           | 3.3616781     |
| entropy                 | 1.563667      |
| episodes                | 6200          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1460460       |
| policy_loss             | -0.36584923   |
| qf1_loss                | 0.0002892084  |
| qf2_loss                | 0.00024323499 |
| time_elapsed            | 7312          |
| total timesteps         | 1460560       |
| value_loss              | 0.00015442807 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000936793   |
| ent_coef_loss           | -2.3722725    |
| entropy                 | 1.4930209     |
| episodes                | 6210          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1462469       |
| policy_loss             | -0.40321505   |
| qf1_loss                | 0.00013677057 |
| qf2_loss                | 0.00013329944 |
| time_elapsed            | 7322          |
| total timesteps         | 1462569       |
| value_loss              | 0.00011746607 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009617836  |
| ent_coef_loss           | -0.11090827   |
| entropy                 | 1.5590402     |
| episodes                | 6220          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1464464       |
| policy_loss             | -0.32782623   |
| qf1_loss                | 0.0004419955  |
| qf2_loss                | 0.0003421732  |
| time_elapsed            | 7333          |
| total timesteps         | 1464564       |
| value_loss              | 0.00027266244 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00096763996 |
| ent_coef_loss           | 2.255903      |
| entropy                 | 1.5760896     |
| episodes                | 6230          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1466496       |
| policy_loss             | -0.2782585    |
| qf1_loss                | 0.00017155497 |
| qf2_loss                | 0.0003147763  |
| time_elapsed            | 7343          |
| total timesteps         | 1466596       |
| value_loss              | 0.00041090348 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009366809  |
| ent_coef_loss           | -3.990946     |
| entropy                 | 1.6008197     |
| episodes                | 6240          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1468563       |
| policy_loss             | -0.3611508    |
| qf1_loss                | 0.00020970264 |
| qf2_loss                | 0.00014886873 |
| time_elapsed            | 7354          |
| total timesteps         | 1468663       |
| value_loss              | 0.00017401212 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009592874  |
| ent_coef_loss           | 2.3274426     |
| entropy                 | 1.6087914     |
| episodes                | 6250          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1470344       |
| policy_loss             | -0.27554786   |
| qf1_loss                | 0.0002566396  |
| qf2_loss                | 0.00050710875 |
| time_elapsed            | 7363          |
| total timesteps         | 1470444       |
| value_loss              | 0.00023659653 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00094378163  |
| ent_coef_loss           | 0.47244477     |
| entropy                 | 1.6324043      |
| episodes                | 6260           |
| fps                     | 199            |
| mean 100 episode reward | 1.3            |
| n_updates               | 1472217        |
| policy_loss             | -0.353383      |
| qf1_loss                | 0.00025485124  |
| qf2_loss                | 0.000101200145 |
| time_elapsed            | 7372           |
| total timesteps         | 1472317        |
| value_loss              | 0.0002306553   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00096358027 |
| ent_coef_loss           | -0.078219     |
| entropy                 | 1.6566293     |
| episodes                | 6270          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1474723       |
| policy_loss             | -0.33195573   |
| qf1_loss                | 8.597817e-05  |
| qf2_loss                | 9.9581506e-05 |
| time_elapsed            | 7384          |
| total timesteps         | 1474823       |
| value_loss              | 0.00010425073 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00095468125 |
| ent_coef_loss           | 0.48498273    |
| entropy                 | 1.6250198     |
| episodes                | 6280          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1476514       |
| policy_loss             | -0.31931937   |
| qf1_loss                | 0.000245767   |
| qf2_loss                | 0.00041877496 |
| time_elapsed            | 7393          |
| total timesteps         | 1476614       |
| value_loss              | 0.00011555733 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009866883  |
| ent_coef_loss           | -0.62484705   |
| entropy                 | 1.586703      |
| episodes                | 6290          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1478282       |
| policy_loss             | -0.30672222   |
| qf1_loss                | 0.00019265543 |
| qf2_loss                | 0.00014859185 |
| time_elapsed            | 7401          |
| total timesteps         | 1478382       |
| value_loss              | 9.633796e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000987262   |
| ent_coef_loss           | 2.5997453     |
| entropy                 | 1.5772505     |
| episodes                | 6300          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1480295       |
| policy_loss             | -0.302445     |
| qf1_loss                | 0.00015184004 |
| qf2_loss                | 0.00018750408 |
| time_elapsed            | 7412          |
| total timesteps         | 1480395       |
| value_loss              | 9.254392e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009842232  |
| ent_coef_loss           | 0.062170327   |
| entropy                 | 1.5923083     |
| episodes                | 6310          |
| fps                     | 199           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1482305       |
| policy_loss             | -0.32946318   |
| qf1_loss                | 0.00013336344 |
| qf2_loss                | 0.00017233926 |
| time_elapsed            | 7422          |
| total timesteps         | 1482405       |
| value_loss              | 0.00012704397 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009758945  |
| ent_coef_loss           | -2.7945237    |
| entropy                 | 1.6049234     |
| episodes                | 6320          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1484010       |
| policy_loss             | -0.35246053   |
| qf1_loss                | 0.0005479501  |
| qf2_loss                | 0.00033555905 |
| time_elapsed            | 7430          |
| total timesteps         | 1484110       |
| value_loss              | 0.0005069335  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00097393966 |
| ent_coef_loss           | 0.6935987     |
| entropy                 | 1.5750046     |
| episodes                | 6330          |
| fps                     | 199           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1485934       |
| policy_loss             | -0.39830446   |
| qf1_loss                | 0.00016730864 |
| qf2_loss                | 0.00035072496 |
| time_elapsed            | 7440          |
| total timesteps         | 1486034       |
| value_loss              | 0.00015048066 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00097151013 |
| ent_coef_loss           | 4.1910343     |
| entropy                 | 1.598573      |
| episodes                | 6340          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1488550       |
| policy_loss             | -0.27477813   |
| qf1_loss                | 0.00043774117 |
| qf2_loss                | 0.00016773555 |
| time_elapsed            | 7454          |
| total timesteps         | 1488650       |
| value_loss              | 0.0002727764  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0009701505   |
| ent_coef_loss           | 1.3516877      |
| entropy                 | 1.5882508      |
| episodes                | 6350           |
| fps                     | 199            |
| mean 100 episode reward | 1.3            |
| n_updates               | 1490428        |
| policy_loss             | -0.35456       |
| qf1_loss                | 0.000103014114 |
| qf2_loss                | 9.932115e-05   |
| time_elapsed            | 7463           |
| total timesteps         | 1490528        |
| value_loss              | 0.00010431734  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00097107707 |
| ent_coef_loss           | -3.2441587    |
| entropy                 | 1.627919      |
| episodes                | 6360          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1492460       |
| policy_loss             | -0.33846396   |
| qf1_loss                | 0.00029038865 |
| qf2_loss                | 0.00030660944 |
| time_elapsed            | 7473          |
| total timesteps         | 1492560       |
| value_loss              | 0.0001345239  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009726745  |
| ent_coef_loss           | 0.05597794    |
| entropy                 | 1.5988662     |
| episodes                | 6370          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1495056       |
| policy_loss             | -0.3889714    |
| qf1_loss                | 0.00024961398 |
| qf2_loss                | 0.00017018618 |
| time_elapsed            | 7486          |
| total timesteps         | 1495156       |
| value_loss              | 0.00033821532 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009355101  |
| ent_coef_loss           | 1.1409321     |
| entropy                 | 1.5456386     |
| episodes                | 6380          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1496843       |
| policy_loss             | -0.33127457   |
| qf1_loss                | 0.0002889136  |
| qf2_loss                | 0.00029735034 |
| time_elapsed            | 7495          |
| total timesteps         | 1496943       |
| value_loss              | 0.00025714285 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00095498725 |
| ent_coef_loss           | 0.5504474     |
| entropy                 | 1.529521      |
| episodes                | 6390          |
| fps                     | 199           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1498872       |
| policy_loss             | -0.3074488    |
| qf1_loss                | 0.0002064859  |
| qf2_loss                | 0.00016165884 |
| time_elapsed            | 7505          |
| total timesteps         | 1498972       |
| value_loss              | 0.00023013147 |
-------------------------------------------
>>>>> End testing <<<<< nn_layers:_[256__128__64]__kinematics:_unicycle__learning_trials:_1500000__collision_penalty:_-1.0
Final weights saved at:  /home/admin/tensorboard_logs/sac_3_nn_layers:_[256__128__64]__kinematics:_unicycle__learning_trials:_1500000__collision_penalty:_-1.0/stable_baselines.pkl
TEST COMMAND: python3 py3_learning.py --test --weights  /home/admin/tensorboard_logs/sac_3_nn_layers:_[256__128__64]__kinematics:_unicycle__learning_trials:_1500000__collision_penalty:_-1.0/stable_baselines.pkl --visualize
