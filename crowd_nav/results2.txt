pygame 1.9.6
Hello from the pygame community. https://www.pygame.org/contribute.html
Loading chipmunk for Linux (64bit) [/usr/local/lib/python3.5/dist-packages/pymunk/libchipmunk.so]
Namespace(env_config='configs/env.config', policy='multi_human_rl', policy_config='configs/policy.config', pre_train=False, show_sensors=False, test=False, train_config='configs/train.config', visualize=False, weights=None)
Gym environment created.
-----------------------------------------
| current_lr              | 0.0001      |
| ent_coef                | 0.6140107   |
| ent_coef_loss           | -1.6309707  |
| entropy                 | 2.5962567   |
| episodes                | 10          |
| fps                     | 201         |
| mean 100 episode reward | -0.9        |
| n_updates               | 4880        |
| policy_loss             | -20.993374  |
| qf1_loss                | 2.566255    |
| qf2_loss                | 2.3798935   |
| time_elapsed            | 24          |
| total timesteps         | 4980        |
| value_loss              | 0.037352815 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0001      |
| ent_coef                | 0.293268    |
| ent_coef_loss           | -4.0601616  |
| entropy                 | 2.587199    |
| episodes                | 20          |
| fps                     | 197         |
| mean 100 episode reward | -0.5        |
| n_updates               | 12280       |
| policy_loss             | -28.604174  |
| qf1_loss                | 0.027109865 |
| qf2_loss                | 0.03162524  |
| time_elapsed            | 62          |
| total timesteps         | 12380       |
| value_loss              | 0.041103788 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0001      |
| ent_coef                | 0.17193684  |
| ent_coef_loss           | -5.717535   |
| entropy                 | 2.4761515   |
| episodes                | 30          |
| fps                     | 198         |
| mean 100 episode reward | -0.6        |
| n_updates               | 17638       |
| policy_loss             | -26.6517    |
| qf1_loss                | 0.03752535  |
| qf2_loss                | 0.038921446 |
| time_elapsed            | 89          |
| total timesteps         | 17738       |
| value_loss              | 0.043407008 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0001      |
| ent_coef                | 0.10675736  |
| ent_coef_loss           | -6.7989187  |
| entropy                 | 2.4195266   |
| episodes                | 40          |
| fps                     | 198         |
| mean 100 episode reward | -0.6        |
| n_updates               | 22431       |
| policy_loss             | -23.043365  |
| qf1_loss                | 3.1063535   |
| qf2_loss                | 3.0928068   |
| time_elapsed            | 113         |
| total timesteps         | 22531       |
| value_loss              | 0.014681934 |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0001     |
| ent_coef                | 0.06596474 |
| ent_coef_loss           | -8.28914   |
| entropy                 | 2.279623   |
| episodes                | 50         |
| fps                     | 198        |
| mean 100 episode reward | -0.6       |
| n_updates               | 27277      |
| policy_loss             | -18.42434  |
| qf1_loss                | 2.4469235  |
| qf2_loss                | 2.4853377  |
| time_elapsed            | 137        |
| total timesteps         | 27377      |
| value_loss              | 0.03130804 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0001      |
| ent_coef                | 0.03449488  |
| ent_coef_loss           | -9.504961   |
| entropy                 | 1.8723978   |
| episodes                | 60          |
| fps                     | 198         |
| mean 100 episode reward | -0.7        |
| n_updates               | 33857       |
| policy_loss             | -13.277056  |
| qf1_loss                | 0.007950202 |
| qf2_loss                | 0.009073637 |
| time_elapsed            | 170         |
| total timesteps         | 33957       |
| value_loss              | 0.007798507 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0001      |
| ent_coef                | 0.022473628 |
| ent_coef_loss           | -9.731019   |
| entropy                 | 2.0987      |
| episodes                | 70          |
| fps                     | 198         |
| mean 100 episode reward | -1          |
| n_updates               | 38265       |
| policy_loss             | -10.418476  |
| qf1_loss                | 0.008597154 |
| qf2_loss                | 0.009318793 |
| time_elapsed            | 192         |
| total timesteps         | 38365       |
| value_loss              | 0.009645425 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.013244531  |
| ent_coef_loss           | -7.5178943   |
| entropy                 | 1.9845759    |
| episodes                | 80           |
| fps                     | 198          |
| mean 100 episode reward | -1           |
| n_updates               | 43651        |
| policy_loss             | -7.885213    |
| qf1_loss                | 0.004191609  |
| qf2_loss                | 0.0048445472 |
| time_elapsed            | 219          |
| total timesteps         | 43751        |
| value_loss              | 0.0019894848 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.008042286  |
| ent_coef_loss           | -9.845312    |
| entropy                 | 1.5931067    |
| episodes                | 90           |
| fps                     | 198          |
| mean 100 episode reward | -1           |
| n_updates               | 48903        |
| policy_loss             | -5.7073927   |
| qf1_loss                | 0.0017361885 |
| qf2_loss                | 0.002513035  |
| time_elapsed            | 246          |
| total timesteps         | 49003        |
| value_loss              | 0.0012276745 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0056162705 |
| ent_coef_loss           | -7.604095    |
| entropy                 | 1.5735781    |
| episodes                | 100          |
| fps                     | 199          |
| mean 100 episode reward | -1           |
| n_updates               | 52554        |
| policy_loss             | -4.4475756   |
| qf1_loss                | 0.002949107  |
| qf2_loss                | 0.0032587857 |
| time_elapsed            | 264          |
| total timesteps         | 52654        |
| value_loss              | 0.0010461973 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0034787399  |
| ent_coef_loss           | -6.8629646    |
| entropy                 | 0.6184379     |
| episodes                | 110           |
| fps                     | 199           |
| mean 100 episode reward | -1            |
| n_updates               | 57678         |
| policy_loss             | -3.3083987    |
| qf1_loss                | 0.00079382246 |
| qf2_loss                | 0.0006841465  |
| time_elapsed            | 290           |
| total timesteps         | 57778         |
| value_loss              | 0.00029588316 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0024659599  |
| ent_coef_loss           | -5.9475327    |
| entropy                 | 0.39727485    |
| episodes                | 120           |
| fps                     | 198           |
| mean 100 episode reward | -1.1          |
| n_updates               | 61376         |
| policy_loss             | -2.536042     |
| qf1_loss                | 0.026617685   |
| qf2_loss                | 0.026966969   |
| time_elapsed            | 308           |
| total timesteps         | 61476         |
| value_loss              | 0.00032440532 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016773819  |
| ent_coef_loss           | -6.805964     |
| entropy                 | 0.422437      |
| episodes                | 130           |
| fps                     | 199           |
| mean 100 episode reward | -1.1          |
| n_updates               | 65623         |
| policy_loss             | -1.9391795    |
| qf1_loss                | 0.00074181135 |
| qf2_loss                | 0.0004855256  |
| time_elapsed            | 329           |
| total timesteps         | 65723         |
| value_loss              | 0.00046624884 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014192141  |
| ent_coef_loss           | -7.3696556    |
| entropy                 | 0.12690687    |
| episodes                | 140           |
| fps                     | 199           |
| mean 100 episode reward | -1.2          |
| n_updates               | 67629         |
| policy_loss             | -1.7001128    |
| qf1_loss                | 0.0007332994  |
| qf2_loss                | 0.000740499   |
| time_elapsed            | 340           |
| total timesteps         | 67729         |
| value_loss              | 0.00032959986 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009985266  |
| ent_coef_loss           | 0.3603353     |
| entropy                 | -0.031526305  |
| episodes                | 150           |
| fps                     | 199           |
| mean 100 episode reward | -1.3          |
| n_updates               | 71789         |
| policy_loss             | -1.2137996    |
| qf1_loss                | 0.00074188516 |
| qf2_loss                | 0.00058074866 |
| time_elapsed            | 360           |
| total timesteps         | 71889         |
| value_loss              | 0.0004585897  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00083674246 |
| ent_coef_loss           | -1.9651291    |
| entropy                 | -0.26171654   |
| episodes                | 160           |
| fps                     | 199           |
| mean 100 episode reward | -1.3          |
| n_updates               | 74136         |
| policy_loss             | -1.097148     |
| qf1_loss                | 0.0003564553  |
| qf2_loss                | 0.0003957967  |
| time_elapsed            | 372           |
| total timesteps         | 74236         |
| value_loss              | 0.00013690836 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00063109363 |
| ent_coef_loss           | -2.8171642    |
| entropy                 | -0.5062858    |
| episodes                | 170           |
| fps                     | 199           |
| mean 100 episode reward | -1.1          |
| n_updates               | 79550         |
| policy_loss             | -0.6511248    |
| qf1_loss                | 0.00048404402 |
| qf2_loss                | 0.0004017365  |
| time_elapsed            | 400           |
| total timesteps         | 79650         |
| value_loss              | 0.00037748727 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00056160695 |
| ent_coef_loss           | -2.576299     |
| entropy                 | -0.49666035   |
| episodes                | 180           |
| fps                     | 199           |
| mean 100 episode reward | -1.1          |
| n_updates               | 83268         |
| policy_loss             | -0.51212466   |
| qf1_loss                | 0.0006709258  |
| qf2_loss                | 0.0005213717  |
| time_elapsed            | 418           |
| total timesteps         | 83368         |
| value_loss              | 6.153397e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0004931663 |
| ent_coef_loss           | -2.4485805   |
| entropy                 | -0.34411496  |
| episodes                | 190          |
| fps                     | 199          |
| mean 100 episode reward | -1.1         |
| n_updates               | 88946        |
| policy_loss             | -0.27028346  |
| qf1_loss                | 0.0017358864 |
| qf2_loss                | 0.0015825451 |
| time_elapsed            | 446          |
| total timesteps         | 89046        |
| value_loss              | 4.376231e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0004347152  |
| ent_coef_loss           | -1.9818234    |
| entropy                 | -0.5183153    |
| episodes                | 200           |
| fps                     | 199           |
| mean 100 episode reward | -1.2          |
| n_updates               | 94564         |
| policy_loss             | -0.16571684   |
| qf1_loss                | 0.00020348848 |
| qf2_loss                | 0.00021371213 |
| time_elapsed            | 474           |
| total timesteps         | 94664         |
| value_loss              | 3.1073778e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0004563414  |
| ent_coef_loss           | -0.55949587   |
| entropy                 | -0.32271957   |
| episodes                | 210           |
| fps                     | 199           |
| mean 100 episode reward | -1.2          |
| n_updates               | 100896        |
| policy_loss             | -0.05514612   |
| qf1_loss                | 0.00015033911 |
| qf2_loss                | 0.00016818443 |
| time_elapsed            | 506           |
| total timesteps         | 100996        |
| value_loss              | 6.2324085e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00042835102 |
| ent_coef_loss           | 0.29014874    |
| entropy                 | -0.28913873   |
| episodes                | 220           |
| fps                     | 199           |
| mean 100 episode reward | -1.1          |
| n_updates               | 106980        |
| policy_loss             | 0.02670705    |
| qf1_loss                | 0.0001599903  |
| qf2_loss                | 0.00010021113 |
| time_elapsed            | 536           |
| total timesteps         | 107080        |
| value_loss              | 3.8183705e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0003408226  |
| ent_coef_loss           | 0.05387318    |
| entropy                 | -0.463149     |
| episodes                | 230           |
| fps                     | 199           |
| mean 100 episode reward | -1.1          |
| n_updates               | 113025        |
| policy_loss             | 0.10232191    |
| qf1_loss                | 8.496444e-05  |
| qf2_loss                | 9.348917e-05  |
| time_elapsed            | 567           |
| total timesteps         | 113125        |
| value_loss              | 3.6378708e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0003281448  |
| ent_coef_loss           | 2.2613864     |
| entropy                 | -0.6216514    |
| episodes                | 240           |
| fps                     | 199           |
| mean 100 episode reward | -1            |
| n_updates               | 119200        |
| policy_loss             | 0.1421618     |
| qf1_loss                | 7.061886e-05  |
| qf2_loss                | 7.3027506e-05 |
| time_elapsed            | 599           |
| total timesteps         | 119300        |
| value_loss              | 3.7901496e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0003528784  |
| ent_coef_loss           | 2.1255183     |
| entropy                 | -0.18564186   |
| episodes                | 250           |
| fps                     | 198           |
| mean 100 episode reward | -1            |
| n_updates               | 125017        |
| policy_loss             | 0.15734929    |
| qf1_loss                | 0.00015401785 |
| qf2_loss                | 0.00014577774 |
| time_elapsed            | 629           |
| total timesteps         | 125117        |
| value_loss              | 7.448677e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00033138334 |
| ent_coef_loss           | -1.378412     |
| entropy                 | -0.55891776   |
| episodes                | 260           |
| fps                     | 198           |
| mean 100 episode reward | -0.9          |
| n_updates               | 131805        |
| policy_loss             | 0.18108861    |
| qf1_loss                | 8.456885e-05  |
| qf2_loss                | 0.00011684892 |
| time_elapsed            | 665           |
| total timesteps         | 131905        |
| value_loss              | 4.9715825e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00035663    |
| ent_coef_loss           | -3.805263     |
| entropy                 | -0.28707743   |
| episodes                | 270           |
| fps                     | 198           |
| mean 100 episode reward | -1            |
| n_updates               | 137890        |
| policy_loss             | 0.18369642    |
| qf1_loss                | 0.0001951411  |
| qf2_loss                | 0.00021927604 |
| time_elapsed            | 696           |
| total timesteps         | 137990        |
| value_loss              | 0.00011184576 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00036763915 |
| ent_coef_loss           | -4.072496     |
| entropy                 | -0.40228206   |
| episodes                | 280           |
| fps                     | 198           |
| mean 100 episode reward | -0.9          |
| n_updates               | 142542        |
| policy_loss             | 0.2326029     |
| qf1_loss                | 0.00012157853 |
| qf2_loss                | 9.161444e-05  |
| time_elapsed            | 720           |
| total timesteps         | 142642        |
| value_loss              | 5.363964e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00035912264  |
| ent_coef_loss           | 0.6442728      |
| entropy                 | -0.49947575    |
| episodes                | 290            |
| fps                     | 198            |
| mean 100 episode reward | -0.9           |
| n_updates               | 149942         |
| policy_loss             | 0.24275282     |
| qf1_loss                | 0.000120611745 |
| qf2_loss                | 0.00012371362  |
| time_elapsed            | 757            |
| total timesteps         | 150042         |
| value_loss              | 5.6308327e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00039412972 |
| ent_coef_loss           | -0.50147116   |
| entropy                 | -0.23941661   |
| episodes                | 300           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 156975        |
| policy_loss             | 0.23011844    |
| qf1_loss                | 4.3939843e-05 |
| qf2_loss                | 4.704256e-05  |
| time_elapsed            | 794           |
| total timesteps         | 157075        |
| value_loss              | 4.9412447e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00034746516 |
| ent_coef_loss           | -2.6459744    |
| entropy                 | -0.23490277   |
| episodes                | 310           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 161532        |
| policy_loss             | 0.20338735    |
| qf1_loss                | 3.746194e-05  |
| qf2_loss                | 6.9906666e-05 |
| time_elapsed            | 817           |
| total timesteps         | 161632        |
| value_loss              | 1.8450679e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00030804367 |
| ent_coef_loss           | 2.164299      |
| entropy                 | -0.59005725   |
| episodes                | 320           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 166369        |
| policy_loss             | 0.21810013    |
| qf1_loss                | 0.00014307296 |
| qf2_loss                | 0.00011871302 |
| time_elapsed            | 841           |
| total timesteps         | 166469        |
| value_loss              | 8.933179e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00029726577 |
| ent_coef_loss           | -3.323504     |
| entropy                 | -0.584628     |
| episodes                | 330           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 172056        |
| policy_loss             | 0.20825729    |
| qf1_loss                | 3.351488e-05  |
| qf2_loss                | 5.9063266e-05 |
| time_elapsed            | 869           |
| total timesteps         | 172156        |
| value_loss              | 1.7188373e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00028337882 |
| ent_coef_loss           | 1.632404      |
| entropy                 | -0.6349933    |
| episodes                | 340           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 176910        |
| policy_loss             | 0.23534155    |
| qf1_loss                | 0.00016396053 |
| qf2_loss                | 0.00010355275 |
| time_elapsed            | 895           |
| total timesteps         | 177010        |
| value_loss              | 9.137341e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00030190672 |
| ent_coef_loss           | -2.2166371    |
| entropy                 | -0.50077116   |
| episodes                | 350           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 182954        |
| policy_loss             | 0.17491284    |
| qf1_loss                | 0.00020297198 |
| qf2_loss                | 0.00021523269 |
| time_elapsed            | 926           |
| total timesteps         | 183054        |
| value_loss              | 5.372289e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0003100987  |
| ent_coef_loss           | -0.9563399    |
| entropy                 | -0.5924759    |
| episodes                | 360           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 189589        |
| policy_loss             | 0.19932674    |
| qf1_loss                | 3.478599e-05  |
| qf2_loss                | 4.4245306e-05 |
| time_elapsed            | 961           |
| total timesteps         | 189689        |
| value_loss              | 7.426814e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0002935821  |
| ent_coef_loss           | 0.53587323    |
| entropy                 | -0.74720776   |
| episodes                | 370           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 195105        |
| policy_loss             | 0.16968368    |
| qf1_loss                | 0.00012722948 |
| qf2_loss                | 0.00013504754 |
| time_elapsed            | 988           |
| total timesteps         | 195205        |
| value_loss              | 5.6989826e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00030408488 |
| ent_coef_loss           | 2.6038218     |
| entropy                 | -0.46053845   |
| episodes                | 380           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 201397        |
| policy_loss             | 0.14784008    |
| qf1_loss                | 4.2644842e-05 |
| qf2_loss                | 4.517356e-05  |
| time_elapsed            | 1020          |
| total timesteps         | 201497        |
| value_loss              | 2.8530518e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00036159478 |
| ent_coef_loss           | 1.8516796     |
| entropy                 | -0.2122255    |
| episodes                | 390           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 208307        |
| policy_loss             | 0.18427739    |
| qf1_loss                | 8.6289365e-05 |
| qf2_loss                | 7.535209e-05  |
| time_elapsed            | 1055          |
| total timesteps         | 208407        |
| value_loss              | 4.7587804e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0003677633  |
| ent_coef_loss           | -0.37540483   |
| entropy                 | -0.15238535   |
| episodes                | 400           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 212442        |
| policy_loss             | 0.15173921    |
| qf1_loss                | 5.0384187e-05 |
| qf2_loss                | 7.4874646e-05 |
| time_elapsed            | 1075          |
| total timesteps         | 212542        |
| value_loss              | 3.283855e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00039536695 |
| ent_coef_loss           | -0.106538475  |
| entropy                 | 0.0047019236  |
| episodes                | 410           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 218023        |
| policy_loss             | 0.16504496    |
| qf1_loss                | 7.818786e-05  |
| qf2_loss                | 0.00010171303 |
| time_elapsed            | 1103          |
| total timesteps         | 218123        |
| value_loss              | 4.368498e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0003321142  |
| ent_coef_loss           | -1.9308219    |
| entropy                 | -0.09048901   |
| episodes                | 420           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 225127        |
| policy_loss             | 0.17730126    |
| qf1_loss                | 7.72264e-05   |
| qf2_loss                | 5.9018712e-05 |
| time_elapsed            | 1140          |
| total timesteps         | 225227        |
| value_loss              | 2.386074e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00029786883 |
| ent_coef_loss           | -1.5838547    |
| entropy                 | -0.24995872   |
| episodes                | 430           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 231422        |
| policy_loss             | 0.16100094    |
| qf1_loss                | 2.9702798e-05 |
| qf2_loss                | 3.3605585e-05 |
| time_elapsed            | 1172          |
| total timesteps         | 231522        |
| value_loss              | 2.1030555e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00033580096 |
| ent_coef_loss           | 2.396638      |
| entropy                 | -0.48274353   |
| episodes                | 440           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 238264        |
| policy_loss             | 0.16054794    |
| qf1_loss                | 8.9485366e-05 |
| qf2_loss                | 8.597325e-05  |
| time_elapsed            | 1206          |
| total timesteps         | 238364        |
| value_loss              | 3.69207e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00033470942 |
| ent_coef_loss           | -0.4039143    |
| entropy                 | -0.32536379   |
| episodes                | 450           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 241780        |
| policy_loss             | 0.13968587    |
| qf1_loss                | 2.2450855e-05 |
| qf2_loss                | 1.5581498e-05 |
| time_elapsed            | 1223          |
| total timesteps         | 241880        |
| value_loss              | 1.1813377e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00035309265 |
| ent_coef_loss           | -2.0970318    |
| entropy                 | -0.16885373   |
| episodes                | 460           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 247899        |
| policy_loss             | 0.14382255    |
| qf1_loss                | 3.415671e-05  |
| qf2_loss                | 2.716263e-05  |
| time_elapsed            | 1255          |
| total timesteps         | 247999        |
| value_loss              | 1.7217224e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0003833713  |
| ent_coef_loss           | 2.7607558     |
| entropy                 | -0.014251679  |
| episodes                | 470           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 254202        |
| policy_loss             | 0.16360094    |
| qf1_loss                | 0.0007104491  |
| qf2_loss                | 8.2405764e-05 |
| time_elapsed            | 1287          |
| total timesteps         | 254302        |
| value_loss              | 0.00029178482 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00038972506 |
| ent_coef_loss           | -0.8942872    |
| entropy                 | 0.13367285    |
| episodes                | 480           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 259573        |
| policy_loss             | 0.15648279    |
| qf1_loss                | 0.00020034907 |
| qf2_loss                | 0.00011367705 |
| time_elapsed            | 1314          |
| total timesteps         | 259673        |
| value_loss              | 1.689358e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00034056394 |
| ent_coef_loss           | 3.678448      |
| entropy                 | -0.1160214    |
| episodes                | 490           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 265991        |
| policy_loss             | 0.15767133    |
| qf1_loss                | 8.3303894e-05 |
| qf2_loss                | 3.7681246e-05 |
| time_elapsed            | 1346          |
| total timesteps         | 266091        |
| value_loss              | 5.3051823e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0003309791  |
| ent_coef_loss           | 0.3924802     |
| entropy                 | -0.20365426   |
| episodes                | 500           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 271048        |
| policy_loss             | 0.1144086     |
| qf1_loss                | 2.8857983e-05 |
| qf2_loss                | 2.2122826e-05 |
| time_elapsed            | 1371          |
| total timesteps         | 271148        |
| value_loss              | 1.6222166e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00036658972 |
| ent_coef_loss           | 0.23634613    |
| entropy                 | -0.17740682   |
| episodes                | 510           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 275822        |
| policy_loss             | 0.16130292    |
| qf1_loss                | 0.00012373737 |
| qf2_loss                | 9.599177e-05  |
| time_elapsed            | 1396          |
| total timesteps         | 275922        |
| value_loss              | 2.693998e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0003428171  |
| ent_coef_loss           | 2.3674371     |
| entropy                 | -0.06349791   |
| episodes                | 520           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 280508        |
| policy_loss             | 0.13767986    |
| qf1_loss                | 5.3046846e-05 |
| qf2_loss                | 6.099907e-05  |
| time_elapsed            | 1419          |
| total timesteps         | 280608        |
| value_loss              | 1.0627125e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00036741974 |
| ent_coef_loss           | -2.4941182    |
| entropy                 | -0.26571935   |
| episodes                | 530           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 286559        |
| policy_loss             | 0.15404174    |
| qf1_loss                | 3.8978316e-05 |
| qf2_loss                | 1.7201728e-05 |
| time_elapsed            | 1450          |
| total timesteps         | 286659        |
| value_loss              | 2.825533e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00037719612 |
| ent_coef_loss           | -0.7684876    |
| entropy                 | 0.1891252     |
| episodes                | 540           |
| fps                     | 197           |
| mean 100 episode reward | -0.4          |
| n_updates               | 291485        |
| policy_loss             | 0.131855      |
| qf1_loss                | 4.9423594e-05 |
| qf2_loss                | 5.7166173e-05 |
| time_elapsed            | 1475          |
| total timesteps         | 291585        |
| value_loss              | 3.416115e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00035437153 |
| ent_coef_loss           | 0.5525491     |
| entropy                 | 0.1608665     |
| episodes                | 550           |
| fps                     | 197           |
| mean 100 episode reward | -0.4          |
| n_updates               | 294166        |
| policy_loss             | 0.14139216    |
| qf1_loss                | 9.800599e-05  |
| qf2_loss                | 8.784805e-05  |
| time_elapsed            | 1489          |
| total timesteps         | 294266        |
| value_loss              | 0.0001005269  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00035089458 |
| ent_coef_loss           | 0.32693243    |
| entropy                 | -0.2589562    |
| episodes                | 560           |
| fps                     | 197           |
| mean 100 episode reward | -0.4          |
| n_updates               | 296304        |
| policy_loss             | 0.15427399    |
| qf1_loss                | 0.00010209372 |
| qf2_loss                | 5.026045e-05  |
| time_elapsed            | 1499          |
| total timesteps         | 296404        |
| value_loss              | 4.2311236e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00033472985  |
| ent_coef_loss           | 1.0668519      |
| entropy                 | -0.00061737746 |
| episodes                | 570            |
| fps                     | 197            |
| mean 100 episode reward | -0.4           |
| n_updates               | 300719         |
| policy_loss             | 0.16316095     |
| qf1_loss                | 0.00019625785  |
| qf2_loss                | 9.938741e-05   |
| time_elapsed            | 1522           |
| total timesteps         | 300819         |
| value_loss              | 3.9549544e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00035359088 |
| ent_coef_loss           | -3.8717856    |
| entropy                 | -0.32493383   |
| episodes                | 580           |
| fps                     | 197           |
| mean 100 episode reward | -0.4          |
| n_updates               | 307380        |
| policy_loss             | 0.14540428    |
| qf1_loss                | 2.6293554e-05 |
| qf2_loss                | 2.9372437e-05 |
| time_elapsed            | 1556          |
| total timesteps         | 307480        |
| value_loss              | 2.5642637e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00032828344 |
| ent_coef_loss           | 0.9525416     |
| entropy                 | -0.32601303   |
| episodes                | 590           |
| fps                     | 197           |
| mean 100 episode reward | -0.4          |
| n_updates               | 312877        |
| policy_loss             | 0.1504772     |
| qf1_loss                | 9.5276104e-05 |
| qf2_loss                | 4.972211e-05  |
| time_elapsed            | 1583          |
| total timesteps         | 312977        |
| value_loss              | 4.201896e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00031103342 |
| ent_coef_loss           | -1.9622897    |
| entropy                 | -0.44480604   |
| episodes                | 600           |
| fps                     | 197           |
| mean 100 episode reward | -0.4          |
| n_updates               | 317151        |
| policy_loss             | 0.14435789    |
| qf1_loss                | 2.2465108e-05 |
| qf2_loss                | 2.1820491e-05 |
| time_elapsed            | 1606          |
| total timesteps         | 317251        |
| value_loss              | 2.48093e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00031974766 |
| ent_coef_loss           | -3.5835915    |
| entropy                 | -0.30247265   |
| episodes                | 610           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 320649        |
| policy_loss             | 0.167213      |
| qf1_loss                | 7.8844605e-05 |
| qf2_loss                | 8.47332e-05   |
| time_elapsed            | 1624          |
| total timesteps         | 320749        |
| value_loss              | 8.304053e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00034716888 |
| ent_coef_loss           | -1.5599       |
| entropy                 | -0.2673246    |
| episodes                | 620           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 325316        |
| policy_loss             | 0.119406566   |
| qf1_loss                | 0.000605564   |
| qf2_loss                | 0.00063247414 |
| time_elapsed            | 1647          |
| total timesteps         | 325416        |
| value_loss              | 4.5136192e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000355595   |
| ent_coef_loss           | -0.52963305   |
| entropy                 | -0.19533446   |
| episodes                | 630           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 329021        |
| policy_loss             | 0.107865274   |
| qf1_loss                | 6.027172e-05  |
| qf2_loss                | 6.192241e-05  |
| time_elapsed            | 1666          |
| total timesteps         | 329121        |
| value_loss              | 3.9982348e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00040086854 |
| ent_coef_loss           | -1.2056937    |
| entropy                 | 0.01568422    |
| episodes                | 640           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 333341        |
| policy_loss             | 0.082610056   |
| qf1_loss                | 0.00013587525 |
| qf2_loss                | 0.00014175326 |
| time_elapsed            | 1688          |
| total timesteps         | 333441        |
| value_loss              | 5.4641998e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00043634235 |
| ent_coef_loss           | -2.0239089    |
| entropy                 | 0.047563255   |
| episodes                | 650           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 337517        |
| policy_loss             | 0.07393926    |
| qf1_loss                | 0.00011522902 |
| qf2_loss                | 9.9407036e-05 |
| time_elapsed            | 1709          |
| total timesteps         | 337617        |
| value_loss              | 4.1955616e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00045571275 |
| ent_coef_loss           | -0.68600494   |
| entropy                 | -0.051035754  |
| episodes                | 660           |
| fps                     | 197           |
| mean 100 episode reward | -0.4          |
| n_updates               | 340783        |
| policy_loss             | 0.039287753   |
| qf1_loss                | 8.905154e-05  |
| qf2_loss                | 0.00010220552 |
| time_elapsed            | 1725          |
| total timesteps         | 340883        |
| value_loss              | 2.9192084e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000447021   |
| ent_coef_loss           | -2.7156234    |
| entropy                 | -0.08788474   |
| episodes                | 670           |
| fps                     | 197           |
| mean 100 episode reward | -0.4          |
| n_updates               | 343308        |
| policy_loss             | 0.092198625   |
| qf1_loss                | 9.5010095e-05 |
| qf2_loss                | 0.00011081327 |
| time_elapsed            | 1738          |
| total timesteps         | 343408        |
| value_loss              | 5.196427e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00046421587 |
| ent_coef_loss           | 0.19919735    |
| entropy                 | 0.306628      |
| episodes                | 680           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 345325        |
| policy_loss             | 0.048698787   |
| qf1_loss                | 0.0020210652  |
| qf2_loss                | 0.0021304914  |
| time_elapsed            | 1749          |
| total timesteps         | 345425        |
| value_loss              | 3.0918185e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00047800344 |
| ent_coef_loss           | 2.4505951     |
| entropy                 | 0.18275663    |
| episodes                | 690           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 349961        |
| policy_loss             | 0.07213827    |
| qf1_loss                | 0.00014286868 |
| qf2_loss                | 0.00015882857 |
| time_elapsed            | 1772          |
| total timesteps         | 350061        |
| value_loss              | 0.00016016101 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00044629304 |
| ent_coef_loss           | -2.2994156    |
| entropy                 | -0.09810071   |
| episodes                | 700           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 353342        |
| policy_loss             | 0.08034024    |
| qf1_loss                | 0.00018220328 |
| qf2_loss                | 0.00022299157 |
| time_elapsed            | 1789          |
| total timesteps         | 353442        |
| value_loss              | 5.939629e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00043397892 |
| ent_coef_loss           | 0.43142816    |
| entropy                 | -0.30560738   |
| episodes                | 710           |
| fps                     | 197           |
| mean 100 episode reward | -0.4          |
| n_updates               | 358204        |
| policy_loss             | 0.06763044    |
| qf1_loss                | 0.0073987893  |
| qf2_loss                | 0.006685036   |
| time_elapsed            | 1814          |
| total timesteps         | 358304        |
| value_loss              | 9.0069894e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00044171428 |
| ent_coef_loss           | -1.7021805    |
| entropy                 | -0.085187376  |
| episodes                | 720           |
| fps                     | 197           |
| mean 100 episode reward | -0.3          |
| n_updates               | 362720        |
| policy_loss             | 0.06922688    |
| qf1_loss                | 7.2495204e-05 |
| qf2_loss                | 8.9554276e-05 |
| time_elapsed            | 1837          |
| total timesteps         | 362820        |
| value_loss              | 4.3187494e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0005098387  |
| ent_coef_loss           | 1.784926      |
| entropy                 | -0.03459779   |
| episodes                | 730           |
| fps                     | 197           |
| mean 100 episode reward | -0.3          |
| n_updates               | 366026        |
| policy_loss             | -0.01590322   |
| qf1_loss                | 0.00019696701 |
| qf2_loss                | 0.0002843382  |
| time_elapsed            | 1854          |
| total timesteps         | 366126        |
| value_loss              | 9.72367e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0005481139  |
| ent_coef_loss           | -1.0850064    |
| entropy                 | 0.24528001    |
| episodes                | 740           |
| fps                     | 197           |
| mean 100 episode reward | -0.2          |
| n_updates               | 369871        |
| policy_loss             | 0.051257998   |
| qf1_loss                | 6.5288375e-05 |
| qf2_loss                | 6.445507e-05  |
| time_elapsed            | 1873          |
| total timesteps         | 369971        |
| value_loss              | 3.0209874e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00055213284 |
| ent_coef_loss           | 0.38995087    |
| entropy                 | 0.2888908     |
| episodes                | 750           |
| fps                     | 197           |
| mean 100 episode reward | -0.1          |
| n_updates               | 376365        |
| policy_loss             | 0.07615282    |
| qf1_loss                | 0.00020294984 |
| qf2_loss                | 0.00017733811 |
| time_elapsed            | 1906          |
| total timesteps         | 376465        |
| value_loss              | 0.00010428301 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00055776286 |
| ent_coef_loss           | -2.2379475    |
| entropy                 | 0.15638772    |
| episodes                | 760           |
| fps                     | 197           |
| mean 100 episode reward | -0.1          |
| n_updates               | 382202        |
| policy_loss             | 0.080124654   |
| qf1_loss                | 0.00014385513 |
| qf2_loss                | 0.00014724788 |
| time_elapsed            | 1935          |
| total timesteps         | 382302        |
| value_loss              | 5.7450303e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0005430138  |
| ent_coef_loss           | 3.07375       |
| entropy                 | 0.095295064   |
| episodes                | 770           |
| fps                     | 197           |
| mean 100 episode reward | 0             |
| n_updates               | 386921        |
| policy_loss             | 0.0379482     |
| qf1_loss                | 0.0003418074  |
| qf2_loss                | 0.00045094977 |
| time_elapsed            | 1959          |
| total timesteps         | 387021        |
| value_loss              | 0.00024711018 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00055051554 |
| ent_coef_loss           | 0.79165614    |
| entropy                 | 0.20475438    |
| episodes                | 780           |
| fps                     | 197           |
| mean 100 episode reward | 0.1           |
| n_updates               | 391342        |
| policy_loss             | 0.07767059    |
| qf1_loss                | 0.006605463   |
| qf2_loss                | 0.007073869   |
| time_elapsed            | 1981          |
| total timesteps         | 391442        |
| value_loss              | 7.547179e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0006541987  |
| ent_coef_loss           | 1.5139604     |
| entropy                 | 0.46786758    |
| episodes                | 790           |
| fps                     | 197           |
| mean 100 episode reward | 0.3           |
| n_updates               | 395511        |
| policy_loss             | 0.073620126   |
| qf1_loss                | 0.00014277457 |
| qf2_loss                | 0.00016026237 |
| time_elapsed            | 2003          |
| total timesteps         | 395611        |
| value_loss              | 0.0001457839  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0006787265  |
| ent_coef_loss           | 0.072078586   |
| entropy                 | 0.4047907     |
| episodes                | 800           |
| fps                     | 197           |
| mean 100 episode reward | 0.3           |
| n_updates               | 399692        |
| policy_loss             | 0.12406826    |
| qf1_loss                | 0.00014641999 |
| qf2_loss                | 0.00017256022 |
| time_elapsed            | 2024          |
| total timesteps         | 399792        |
| value_loss              | 0.00020318797 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0006352069  |
| ent_coef_loss           | -2.0991914    |
| entropy                 | 0.4278993     |
| episodes                | 810           |
| fps                     | 197           |
| mean 100 episode reward | 0.3           |
| n_updates               | 405328        |
| policy_loss             | 0.1468056     |
| qf1_loss                | 0.0002582762  |
| qf2_loss                | 0.000126217   |
| time_elapsed            | 2053          |
| total timesteps         | 405428        |
| value_loss              | 0.00022323267 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0006090909  |
| ent_coef_loss           | -1.8053378    |
| entropy                 | 0.26180518    |
| episodes                | 820           |
| fps                     | 197           |
| mean 100 episode reward | 0.3           |
| n_updates               | 411056        |
| policy_loss             | 0.0779957     |
| qf1_loss                | 0.00016546337 |
| qf2_loss                | 0.00022796678 |
| time_elapsed            | 2082          |
| total timesteps         | 411156        |
| value_loss              | 6.270281e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000616914   |
| ent_coef_loss           | 1.3056986     |
| entropy                 | 0.5693867     |
| episodes                | 830           |
| fps                     | 197           |
| mean 100 episode reward | 0.4           |
| n_updates               | 414356        |
| policy_loss             | 0.12679848    |
| qf1_loss                | 0.00056213845 |
| qf2_loss                | 0.00063968974 |
| time_elapsed            | 2098          |
| total timesteps         | 414456        |
| value_loss              | 9.551009e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0006178048  |
| ent_coef_loss           | -2.9387312    |
| entropy                 | 0.5398084     |
| episodes                | 840           |
| fps                     | 197           |
| mean 100 episode reward | 0.3           |
| n_updates               | 417686        |
| policy_loss             | 0.08274701    |
| qf1_loss                | 8.5687105e-05 |
| qf2_loss                | 0.00011116348 |
| time_elapsed            | 2115          |
| total timesteps         | 417786        |
| value_loss              | 4.2395222e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00065747765 |
| ent_coef_loss           | 4.293273      |
| entropy                 | 0.48139358    |
| episodes                | 850           |
| fps                     | 197           |
| mean 100 episode reward | 0.4           |
| n_updates               | 421094        |
| policy_loss             | 0.06549092    |
| qf1_loss                | 0.00028403054 |
| qf2_loss                | 0.00017520467 |
| time_elapsed            | 2132          |
| total timesteps         | 421194        |
| value_loss              | 6.512276e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0006565525  |
| ent_coef_loss           | -0.22557467   |
| entropy                 | 0.5389744     |
| episodes                | 860           |
| fps                     | 197           |
| mean 100 episode reward | 0.4           |
| n_updates               | 426069        |
| policy_loss             | 0.09699891    |
| qf1_loss                | 0.00013585837 |
| qf2_loss                | 0.00014758999 |
| time_elapsed            | 2158          |
| total timesteps         | 426169        |
| value_loss              | 8.3885985e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0006096261  |
| ent_coef_loss           | -1.5608642    |
| entropy                 | 0.52032185    |
| episodes                | 870           |
| fps                     | 197           |
| mean 100 episode reward | 0.3           |
| n_updates               | 431751        |
| policy_loss             | 0.06997259    |
| qf1_loss                | 0.00013999845 |
| qf2_loss                | 0.00012685443 |
| time_elapsed            | 2187          |
| total timesteps         | 431851        |
| value_loss              | 5.0472045e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00056222646 |
| ent_coef_loss           | -1.262911     |
| entropy                 | 0.36867803    |
| episodes                | 880           |
| fps                     | 197           |
| mean 100 episode reward | 0.3           |
| n_updates               | 437621        |
| policy_loss             | 0.018298008   |
| qf1_loss                | 0.0007498363  |
| qf2_loss                | 0.0008444633  |
| time_elapsed            | 2216          |
| total timesteps         | 437721        |
| value_loss              | 0.00015763892 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.000589088    |
| ent_coef_loss           | 0.7846669      |
| entropy                 | 0.5111681      |
| episodes                | 890            |
| fps                     | 197            |
| mean 100 episode reward | 0.2            |
| n_updates               | 442293         |
| policy_loss             | -0.019451506   |
| qf1_loss                | 0.00018697872  |
| qf2_loss                | 0.0001607867   |
| time_elapsed            | 2240           |
| total timesteps         | 442393         |
| value_loss              | 0.000116652445 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0006277035  |
| ent_coef_loss           | 0.23439133    |
| entropy                 | 0.7431473     |
| episodes                | 900           |
| fps                     | 197           |
| mean 100 episode reward | 0.3           |
| n_updates               | 446551        |
| policy_loss             | 0.010373959   |
| qf1_loss                | 0.00016482311 |
| qf2_loss                | 0.00019099674 |
| time_elapsed            | 2262          |
| total timesteps         | 446651        |
| value_loss              | 5.7640274e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00069628464 |
| ent_coef_loss           | -2.2623444    |
| entropy                 | 0.8058007     |
| episodes                | 910           |
| fps                     | 197           |
| mean 100 episode reward | 0.2           |
| n_updates               | 449792        |
| policy_loss             | 0.028703155   |
| qf1_loss                | 0.00016268468 |
| qf2_loss                | 0.00014839642 |
| time_elapsed            | 2278          |
| total timesteps         | 449892        |
| value_loss              | 0.00015813277 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00073641166 |
| ent_coef_loss           | 1.4208579     |
| entropy                 | 0.8538351     |
| episodes                | 920           |
| fps                     | 197           |
| mean 100 episode reward | 0.3           |
| n_updates               | 453225        |
| policy_loss             | -0.012585226  |
| qf1_loss                | 0.000582561   |
| qf2_loss                | 0.0005387105  |
| time_elapsed            | 2296          |
| total timesteps         | 453325        |
| value_loss              | 0.00016405579 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007567864  |
| ent_coef_loss           | -3.393377     |
| entropy                 | 0.9811201     |
| episodes                | 930           |
| fps                     | 197           |
| mean 100 episode reward | 0.3           |
| n_updates               | 456250        |
| policy_loss             | -0.0020091536 |
| qf1_loss                | 0.00018822686 |
| qf2_loss                | 0.00016566552 |
| time_elapsed            | 2312          |
| total timesteps         | 456350        |
| value_loss              | 7.4389405e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0007455557   |
| ent_coef_loss           | -0.9763092     |
| entropy                 | 0.9846351      |
| episodes                | 940            |
| fps                     | 197            |
| mean 100 episode reward | 0.5            |
| n_updates               | 459635         |
| policy_loss             | -0.044490505   |
| qf1_loss                | 0.00011346518  |
| qf2_loss                | 0.00014388768  |
| time_elapsed            | 2329           |
| total timesteps         | 459735         |
| value_loss              | 0.000112209054 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00077181094 |
| ent_coef_loss           | 0.27640426    |
| entropy                 | 1.0114021     |
| episodes                | 950           |
| fps                     | 197           |
| mean 100 episode reward | 0.4           |
| n_updates               | 463189        |
| policy_loss             | 0.005773171   |
| qf1_loss                | 0.00015357826 |
| qf2_loss                | 0.0001223812  |
| time_elapsed            | 2347          |
| total timesteps         | 463289        |
| value_loss              | 5.2474345e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.000778966   |
| ent_coef_loss           | -2.685701     |
| entropy                 | 1.0711209     |
| episodes                | 960           |
| fps                     | 197           |
| mean 100 episode reward | 0.5           |
| n_updates               | 465342        |
| policy_loss             | 0.00063631166 |
| qf1_loss                | 0.00012456012 |
| qf2_loss                | 0.00029184506 |
| time_elapsed            | 2357          |
| total timesteps         | 465442        |
| value_loss              | 5.3241754e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0007664999   |
| ent_coef_loss           | 0.29087877     |
| entropy                 | 0.93414414     |
| episodes                | 970            |
| fps                     | 197            |
| mean 100 episode reward | 0.5            |
| n_updates               | 468052         |
| policy_loss             | -0.008121496   |
| qf1_loss                | 0.00028258603  |
| qf2_loss                | 0.0001471025   |
| time_elapsed            | 2371           |
| total timesteps         | 468152         |
| value_loss              | 0.000105390325 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007315193  |
| ent_coef_loss           | 2.4199207     |
| entropy                 | 0.8362311     |
| episodes                | 980           |
| fps                     | 197           |
| mean 100 episode reward | 0.6           |
| n_updates               | 471008        |
| policy_loss             | -0.064112276  |
| qf1_loss                | 0.00080378976 |
| qf2_loss                | 0.0014133459  |
| time_elapsed            | 2386          |
| total timesteps         | 471108        |
| value_loss              | 5.5000713e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007319624  |
| ent_coef_loss           | -0.27328682   |
| entropy                 | 0.87705046    |
| episodes                | 990           |
| fps                     | 197           |
| mean 100 episode reward | 0.6           |
| n_updates               | 473024        |
| policy_loss             | -0.06713599   |
| qf1_loss                | 0.00016522748 |
| qf2_loss                | 0.00013235005 |
| time_elapsed            | 2396          |
| total timesteps         | 473124        |
| value_loss              | 0.0001402903  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0007473692  |
| ent_coef_loss           | 1.8455117     |
| entropy                 | 0.74056053    |
| episodes                | 1000          |
| fps                     | 197           |
| mean 100 episode reward | 0.7           |
| n_updates               | 475110        |
| policy_loss             | -0.059951775  |
| qf1_loss                | 0.0005729314  |
| qf2_loss                | 0.00054051925 |
| time_elapsed            | 2407          |
| total timesteps         | 475210        |
| value_loss              | 0.00024306355 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00076309044 |
| ent_coef_loss           | 2.7291412     |
| entropy                 | 0.81282794    |
| episodes                | 1010          |
| fps                     | 197           |
| mean 100 episode reward | 0.8           |
| n_updates               | 477494        |
| policy_loss             | -0.11899599   |
| qf1_loss                | 0.00015439832 |
| qf2_loss                | 0.00014598558 |
| time_elapsed            | 2419          |
| total timesteps         | 477594        |
| value_loss              | 8.576439e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00079532614 |
| ent_coef_loss           | 0.19014084    |
| entropy                 | 0.93126017    |
| episodes                | 1020          |
| fps                     | 197           |
| mean 100 episode reward | 0.7           |
| n_updates               | 479774        |
| policy_loss             | -0.025025167  |
| qf1_loss                | 0.00039294703 |
| qf2_loss                | 0.00026432978 |
| time_elapsed            | 2431          |
| total timesteps         | 479874        |
| value_loss              | 6.866679e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008094432  |
| ent_coef_loss           | -0.58287483   |
| entropy                 | 0.7096975     |
| episodes                | 1030          |
| fps                     | 197           |
| mean 100 episode reward | 0.7           |
| n_updates               | 483900        |
| policy_loss             | -0.12288643   |
| qf1_loss                | 0.00016903551 |
| qf2_loss                | 0.00016191034 |
| time_elapsed            | 2452          |
| total timesteps         | 484000        |
| value_loss              | 4.2255197e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008373024  |
| ent_coef_loss           | 1.9165978     |
| entropy                 | 0.7629264     |
| episodes                | 1040          |
| fps                     | 197           |
| mean 100 episode reward | 0.8           |
| n_updates               | 486521        |
| policy_loss             | -0.15277961   |
| qf1_loss                | 0.00014012058 |
| qf2_loss                | 0.00015535265 |
| time_elapsed            | 2465          |
| total timesteps         | 486621        |
| value_loss              | 6.881873e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00083346124 |
| ent_coef_loss           | -1.8866781    |
| entropy                 | 0.8539828     |
| episodes                | 1050          |
| fps                     | 197           |
| mean 100 episode reward | 0.8           |
| n_updates               | 488661        |
| policy_loss             | -0.1106329    |
| qf1_loss                | 0.0001715167  |
| qf2_loss                | 0.00018169385 |
| time_elapsed            | 2476          |
| total timesteps         | 488761        |
| value_loss              | 4.3450134e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008250735  |
| ent_coef_loss           | 2.3270233     |
| entropy                 | 0.7158306     |
| episodes                | 1060          |
| fps                     | 197           |
| mean 100 episode reward | 0.9           |
| n_updates               | 490881        |
| policy_loss             | -0.056084964  |
| qf1_loss                | 0.00024125204 |
| qf2_loss                | 0.00019688722 |
| time_elapsed            | 2487          |
| total timesteps         | 490981        |
| value_loss              | 0.00010454233 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0008922733  |
| ent_coef_loss           | 0.8791028     |
| entropy                 | 0.7411779     |
| episodes                | 1070          |
| fps                     | 197           |
| mean 100 episode reward | 1             |
| n_updates               | 492861        |
| policy_loss             | -0.13809732   |
| qf1_loss                | 0.0003786806  |
| qf2_loss                | 0.000454312   |
| time_elapsed            | 2497          |
| total timesteps         | 492961        |
| value_loss              | 0.00010962794 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009628234  |
| ent_coef_loss           | -1.9810718    |
| entropy                 | 0.82956856    |
| episodes                | 1080          |
| fps                     | 197           |
| mean 100 episode reward | 0.9           |
| n_updates               | 495964        |
| policy_loss             | -0.13133073   |
| qf1_loss                | 0.00031715963 |
| qf2_loss                | 0.00031164172 |
| time_elapsed            | 2513          |
| total timesteps         | 496064        |
| value_loss              | 8.0595484e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009842378  |
| ent_coef_loss           | 1.1669011     |
| entropy                 | 0.9649173     |
| episodes                | 1090          |
| fps                     | 197           |
| mean 100 episode reward | 0.9           |
| n_updates               | 499021        |
| policy_loss             | -0.13019536   |
| qf1_loss                | 0.00057086744 |
| qf2_loss                | 0.0006445404  |
| time_elapsed            | 2528          |
| total timesteps         | 499121        |
| value_loss              | 0.00013316305 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0010001797  |
| ent_coef_loss           | 3.345076      |
| entropy                 | 0.9397281     |
| episodes                | 1100          |
| fps                     | 197           |
| mean 100 episode reward | 0.9           |
| n_updates               | 502210        |
| policy_loss             | -0.17243019   |
| qf1_loss                | 0.00013806722 |
| qf2_loss                | 0.0001621533  |
| time_elapsed            | 2545          |
| total timesteps         | 502310        |
| value_loss              | 0.0001362231  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0009992972  |
| ent_coef_loss           | -0.709221     |
| entropy                 | 0.907532      |
| episodes                | 1110          |
| fps                     | 197           |
| mean 100 episode reward | 0.9           |
| n_updates               | 504892        |
| policy_loss             | -0.18529326   |
| qf1_loss                | 0.0003047199  |
| qf2_loss                | 0.00025249296 |
| time_elapsed            | 2558          |
| total timesteps         | 504992        |
| value_loss              | 0.00017617081 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0010479025  |
| ent_coef_loss           | -0.31394356   |
| entropy                 | 0.99108046    |
| episodes                | 1120          |
| fps                     | 197           |
| mean 100 episode reward | 1             |
| n_updates               | 508152        |
| policy_loss             | -0.11536272   |
| qf1_loss                | 0.00025487127 |
| qf2_loss                | 0.00030253275 |
| time_elapsed            | 2575          |
| total timesteps         | 508252        |
| value_loss              | 0.00013135982 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0010752447  |
| ent_coef_loss           | 2.9499507     |
| entropy                 | 0.9694465     |
| episodes                | 1130          |
| fps                     | 197           |
| mean 100 episode reward | 1             |
| n_updates               | 511108        |
| policy_loss             | -0.20938037   |
| qf1_loss                | 0.000360463   |
| qf2_loss                | 0.0003636973  |
| time_elapsed            | 2590          |
| total timesteps         | 511208        |
| value_loss              | 0.00014095029 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0010878276  |
| ent_coef_loss           | -0.24537826   |
| entropy                 | 0.9979999     |
| episodes                | 1140          |
| fps                     | 197           |
| mean 100 episode reward | 1             |
| n_updates               | 514764        |
| policy_loss             | -0.20755574   |
| qf1_loss                | 0.00017413421 |
| qf2_loss                | 0.00023643325 |
| time_elapsed            | 2609          |
| total timesteps         | 514864        |
| value_loss              | 0.00017528178 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0010555936   |
| ent_coef_loss           | -0.4098863     |
| entropy                 | 0.91417277     |
| episodes                | 1150           |
| fps                     | 197            |
| mean 100 episode reward | 1              |
| n_updates               | 518169         |
| policy_loss             | -0.15052712    |
| qf1_loss                | 0.00035083783  |
| qf2_loss                | 0.00045061443  |
| time_elapsed            | 2626           |
| total timesteps         | 518269         |
| value_loss              | 0.000105543615 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0010460004  |
| ent_coef_loss           | 1.0612769     |
| entropy                 | 0.9776261     |
| episodes                | 1160          |
| fps                     | 197           |
| mean 100 episode reward | 1             |
| n_updates               | 520984        |
| policy_loss             | -0.22711247   |
| qf1_loss                | 0.00021008312 |
| qf2_loss                | 0.00031433295 |
| time_elapsed            | 2640          |
| total timesteps         | 521084        |
| value_loss              | 9.551509e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0010403903  |
| ent_coef_loss           | 2.2014449     |
| entropy                 | 1.0598927     |
| episodes                | 1170          |
| fps                     | 197           |
| mean 100 episode reward | 0.9           |
| n_updates               | 523172        |
| policy_loss             | -0.17547467   |
| qf1_loss                | 0.00030649008 |
| qf2_loss                | 0.00030935678 |
| time_elapsed            | 2651          |
| total timesteps         | 523272        |
| value_loss              | 9.3782044e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001066815   |
| ent_coef_loss           | 2.9080546     |
| entropy                 | 1.1062586     |
| episodes                | 1180          |
| fps                     | 197           |
| mean 100 episode reward | 0.9           |
| n_updates               | 524705        |
| policy_loss             | -0.1717906    |
| qf1_loss                | 0.0005941234  |
| qf2_loss                | 0.00066118233 |
| time_elapsed            | 2658          |
| total timesteps         | 524805        |
| value_loss              | 0.00017947852 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0010856387  |
| ent_coef_loss           | 3.2906833     |
| entropy                 | 0.9375961     |
| episodes                | 1190          |
| fps                     | 197           |
| mean 100 episode reward | 0.8           |
| n_updates               | 527202        |
| policy_loss             | -0.14394706   |
| qf1_loss                | 0.0002337115  |
| qf2_loss                | 0.0002460566  |
| time_elapsed            | 2671          |
| total timesteps         | 527302        |
| value_loss              | 0.00014259259 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001087813   |
| ent_coef_loss           | -0.7863515    |
| entropy                 | 0.8219887     |
| episodes                | 1200          |
| fps                     | 197           |
| mean 100 episode reward | 0.8           |
| n_updates               | 528837        |
| policy_loss             | -0.21604596   |
| qf1_loss                | 0.0003502962  |
| qf2_loss                | 0.00038399908 |
| time_elapsed            | 2679          |
| total timesteps         | 528937        |
| value_loss              | 0.00017750339 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0011012674 |
| ent_coef_loss           | 0.7042606    |
| entropy                 | 0.9958496    |
| episodes                | 1210         |
| fps                     | 197          |
| mean 100 episode reward | 0.8          |
| n_updates               | 531127       |
| policy_loss             | -0.101007946 |
| qf1_loss                | 0.006974326  |
| qf2_loss                | 0.007861626  |
| time_elapsed            | 2691         |
| total timesteps         | 531227       |
| value_loss              | 0.0002413414 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0011491524  |
| ent_coef_loss           | 0.41664195    |
| entropy                 | 0.85494244    |
| episodes                | 1220          |
| fps                     | 197           |
| mean 100 episode reward | 0.8           |
| n_updates               | 533615        |
| policy_loss             | -0.1502194    |
| qf1_loss                | 0.00020261595 |
| qf2_loss                | 0.00030756468 |
| time_elapsed            | 2704          |
| total timesteps         | 533715        |
| value_loss              | 0.00013236093 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0011700664  |
| ent_coef_loss           | -1.218559     |
| entropy                 | 0.88279045    |
| episodes                | 1230          |
| fps                     | 197           |
| mean 100 episode reward | 0.8           |
| n_updates               | 535630        |
| policy_loss             | -0.17897768   |
| qf1_loss                | 0.00035521522 |
| qf2_loss                | 0.00039573413 |
| time_elapsed            | 2713          |
| total timesteps         | 535730        |
| value_loss              | 0.0001356367  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0012107312   |
| ent_coef_loss           | 1.7208631      |
| entropy                 | 1.1631758      |
| episodes                | 1240           |
| fps                     | 197            |
| mean 100 episode reward | 0.8            |
| n_updates               | 538089         |
| policy_loss             | -0.053586714   |
| qf1_loss                | 0.00049335876  |
| qf2_loss                | 0.00039246096  |
| time_elapsed            | 2726           |
| total timesteps         | 538189         |
| value_loss              | 0.000111736896 |
--------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0012449136   |
| ent_coef_loss           | -4.125859      |
| entropy                 | 1.0192745      |
| episodes                | 1250           |
| fps                     | 197            |
| mean 100 episode reward | 0.8            |
| n_updates               | 541180         |
| policy_loss             | -0.14856024    |
| qf1_loss                | 0.0009293748   |
| qf2_loss                | 0.0007749812   |
| time_elapsed            | 2742           |
| total timesteps         | 541280         |
| value_loss              | 0.000102301856 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0012133822  |
| ent_coef_loss           | 2.1446853     |
| entropy                 | 0.99814224    |
| episodes                | 1260          |
| fps                     | 197           |
| mean 100 episode reward | 0.8           |
| n_updates               | 545052        |
| policy_loss             | -0.20167717   |
| qf1_loss                | 0.0004764755  |
| qf2_loss                | 0.00080448063 |
| time_elapsed            | 2761          |
| total timesteps         | 545152        |
| value_loss              | 0.00015459197 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0012416304  |
| ent_coef_loss           | 1.0120525     |
| entropy                 | 1.0807748     |
| episodes                | 1270          |
| fps                     | 197           |
| mean 100 episode reward | 1             |
| n_updates               | 547925        |
| policy_loss             | -0.1152126    |
| qf1_loss                | 0.00025697425 |
| qf2_loss                | 0.00021737581 |
| time_elapsed            | 2775          |
| total timesteps         | 548025        |
| value_loss              | 0.00013704048 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0013600477  |
| ent_coef_loss           | -1.4799547    |
| entropy                 | 0.9985325     |
| episodes                | 1280          |
| fps                     | 197           |
| mean 100 episode reward | 1             |
| n_updates               | 551674        |
| policy_loss             | -0.10392054   |
| qf1_loss                | 0.00029941672 |
| qf2_loss                | 0.00023206024 |
| time_elapsed            | 2795          |
| total timesteps         | 551774        |
| value_loss              | 0.0001789854  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0013888775  |
| ent_coef_loss           | 0.9413179     |
| entropy                 | 1.1859628     |
| episodes                | 1290          |
| fps                     | 197           |
| mean 100 episode reward | 1.1           |
| n_updates               | 553916        |
| policy_loss             | -0.08631853   |
| qf1_loss                | 0.00017184691 |
| qf2_loss                | 0.00019444119 |
| time_elapsed            | 2806          |
| total timesteps         | 554016        |
| value_loss              | 0.00011113403 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001417384   |
| ent_coef_loss           | -0.81313866   |
| entropy                 | 1.1430542     |
| episodes                | 1300          |
| fps                     | 197           |
| mean 100 episode reward | 1.1           |
| n_updates               | 556257        |
| policy_loss             | -0.14630826   |
| qf1_loss                | 0.00019089604 |
| qf2_loss                | 0.00020637928 |
| time_elapsed            | 2818          |
| total timesteps         | 556357        |
| value_loss              | 0.00013442458 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0013680147  |
| ent_coef_loss           | -2.3859336    |
| entropy                 | 1.1158116     |
| episodes                | 1310          |
| fps                     | 197           |
| mean 100 episode reward | 1.2           |
| n_updates               | 558877        |
| policy_loss             | -0.12450816   |
| qf1_loss                | 0.00055729476 |
| qf2_loss                | 0.0005716393  |
| time_elapsed            | 2831          |
| total timesteps         | 558977        |
| value_loss              | 0.00011360945 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0013319136  |
| ent_coef_loss           | -1.2758927    |
| entropy                 | 1.1168052     |
| episodes                | 1320          |
| fps                     | 197           |
| mean 100 episode reward | 1.1           |
| n_updates               | 560779        |
| policy_loss             | -0.18364313   |
| qf1_loss                | 0.001326511   |
| qf2_loss                | 0.0014538221  |
| time_elapsed            | 2841          |
| total timesteps         | 560879        |
| value_loss              | 0.00035798879 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0013918098  |
| ent_coef_loss           | -1.2798834    |
| entropy                 | 1.0874773     |
| episodes                | 1330          |
| fps                     | 197           |
| mean 100 episode reward | 1.2           |
| n_updates               | 562989        |
| policy_loss             | -0.11034901   |
| qf1_loss                | 0.00028415726 |
| qf2_loss                | 0.00038689972 |
| time_elapsed            | 2852          |
| total timesteps         | 563089        |
| value_loss              | 0.00016117544 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014160796  |
| ent_coef_loss           | 0.51918846    |
| entropy                 | 1.195913      |
| episodes                | 1340          |
| fps                     | 197           |
| mean 100 episode reward | 1.2           |
| n_updates               | 565173        |
| policy_loss             | -0.1547405    |
| qf1_loss                | 0.0004108739  |
| qf2_loss                | 0.00038444216 |
| time_elapsed            | 2863          |
| total timesteps         | 565273        |
| value_loss              | 0.00024445867 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014395358  |
| ent_coef_loss           | 1.2744713     |
| entropy                 | 1.1592491     |
| episodes                | 1350          |
| fps                     | 197           |
| mean 100 episode reward | 1.3           |
| n_updates               | 567500        |
| policy_loss             | -0.115018725  |
| qf1_loss                | 0.0002207166  |
| qf2_loss                | 0.00021007072 |
| time_elapsed            | 2875          |
| total timesteps         | 567600        |
| value_loss              | 0.00033183384 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014821363  |
| ent_coef_loss           | 2.239489      |
| entropy                 | 1.1818919     |
| episodes                | 1360          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 569578        |
| policy_loss             | -0.1737628    |
| qf1_loss                | 0.00033770048 |
| qf2_loss                | 0.00026270005 |
| time_elapsed            | 2886          |
| total timesteps         | 569678        |
| value_loss              | 0.00013734451 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014559233  |
| ent_coef_loss           | 0.113761455   |
| entropy                 | 1.2225779     |
| episodes                | 1370          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 571796        |
| policy_loss             | -0.105548516  |
| qf1_loss                | 0.00055296626 |
| qf2_loss                | 0.00035462392 |
| time_elapsed            | 2896          |
| total timesteps         | 571896        |
| value_loss              | 0.00018360073 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014229594  |
| ent_coef_loss           | 0.2545913     |
| entropy                 | 1.2205684     |
| episodes                | 1380          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 573861        |
| policy_loss             | -0.29883027   |
| qf1_loss                | 0.00016498385 |
| qf2_loss                | 0.00022325371 |
| time_elapsed            | 2907          |
| total timesteps         | 573961        |
| value_loss              | 0.00011145786 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0013899442  |
| ent_coef_loss           | -1.1899184    |
| entropy                 | 1.1642336     |
| episodes                | 1390          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 575929        |
| policy_loss             | -0.20691457   |
| qf1_loss                | 0.0008462971  |
| qf2_loss                | 0.0006222958  |
| time_elapsed            | 2918          |
| total timesteps         | 576029        |
| value_loss              | 0.00017232663 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0013825857  |
| ent_coef_loss           | 2.598835      |
| entropy                 | 1.1567788     |
| episodes                | 1400          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 578984        |
| policy_loss             | -0.2729584    |
| qf1_loss                | 0.0031158284  |
| qf2_loss                | 0.0025550746  |
| time_elapsed            | 2933          |
| total timesteps         | 579084        |
| value_loss              | 0.00041402515 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0013727974  |
| ent_coef_loss           | -0.5434595    |
| entropy                 | 1.2058704     |
| episodes                | 1410          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 581027        |
| policy_loss             | -0.18354866   |
| qf1_loss                | 0.00043536563 |
| qf2_loss                | 0.000617835   |
| time_elapsed            | 2943          |
| total timesteps         | 581127        |
| value_loss              | 0.00018176794 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0013753928  |
| ent_coef_loss           | 1.5881189     |
| entropy                 | 1.1494415     |
| episodes                | 1420          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 583944        |
| policy_loss             | -0.27598596   |
| qf1_loss                | 0.00028956833 |
| qf2_loss                | 0.00021275286 |
| time_elapsed            | 2958          |
| total timesteps         | 584044        |
| value_loss              | 0.00014394283 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001390257   |
| ent_coef_loss           | -1.3834643    |
| entropy                 | 1.1270664     |
| episodes                | 1430          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 585586        |
| policy_loss             | -0.20959729   |
| qf1_loss                | 0.00026241012 |
| qf2_loss                | 0.0003598978  |
| time_elapsed            | 2967          |
| total timesteps         | 585686        |
| value_loss              | 0.00016637951 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0014356517   |
| ent_coef_loss           | 0.92886573     |
| entropy                 | 1.190837       |
| episodes                | 1440           |
| fps                     | 197            |
| mean 100 episode reward | 1.4            |
| n_updates               | 587353         |
| policy_loss             | -0.3047666     |
| qf1_loss                | 0.0010340601   |
| qf2_loss                | 0.0010536045   |
| time_elapsed            | 2976           |
| total timesteps         | 587453         |
| value_loss              | 0.000100811085 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014582919  |
| ent_coef_loss           | -1.9096332    |
| entropy                 | 1.2996018     |
| episodes                | 1450          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 589206        |
| policy_loss             | -0.16116805   |
| qf1_loss                | 0.00047800198 |
| qf2_loss                | 0.00066985056 |
| time_elapsed            | 2985          |
| total timesteps         | 589306        |
| value_loss              | 0.00018893543 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014856551  |
| ent_coef_loss           | 2.3243806     |
| entropy                 | 1.2589481     |
| episodes                | 1460          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 591055        |
| policy_loss             | -0.18507469   |
| qf1_loss                | 0.0005107338  |
| qf2_loss                | 0.0003372858  |
| time_elapsed            | 2994          |
| total timesteps         | 591155        |
| value_loss              | 0.00011207843 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015136984  |
| ent_coef_loss           | 0.96147907    |
| entropy                 | 1.2006385     |
| episodes                | 1470          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 592852        |
| policy_loss             | -0.20880222   |
| qf1_loss                | 0.00018783344 |
| qf2_loss                | 0.00031194807 |
| time_elapsed            | 3004          |
| total timesteps         | 592952        |
| value_loss              | 0.00018355598 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015041075  |
| ent_coef_loss           | 1.0139624     |
| entropy                 | 1.2087841     |
| episodes                | 1480          |
| fps                     | 197           |
| mean 100 episode reward | 1.3           |
| n_updates               | 594704        |
| policy_loss             | -0.21701476   |
| qf1_loss                | 0.0001466907  |
| qf2_loss                | 0.00018312954 |
| time_elapsed            | 3014          |
| total timesteps         | 594804        |
| value_loss              | 0.00013771381 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015450807  |
| ent_coef_loss           | -0.16862142   |
| entropy                 | 1.1980369     |
| episodes                | 1490          |
| fps                     | 197           |
| mean 100 episode reward | 1.3           |
| n_updates               | 596762        |
| policy_loss             | -0.23218283   |
| qf1_loss                | 0.00017932375 |
| qf2_loss                | 0.00021003294 |
| time_elapsed            | 3024          |
| total timesteps         | 596862        |
| value_loss              | 0.00012121877 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015402045  |
| ent_coef_loss           | 1.5742321     |
| entropy                 | 1.209794      |
| episodes                | 1500          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 598639        |
| policy_loss             | -0.26981342   |
| qf1_loss                | 0.0002358349  |
| qf2_loss                | 0.00017509857 |
| time_elapsed            | 3033          |
| total timesteps         | 598739        |
| value_loss              | 0.00016098535 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015617759  |
| ent_coef_loss           | 0.67929137    |
| entropy                 | 1.2277879     |
| episodes                | 1510          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 600564        |
| policy_loss             | -0.14331031   |
| qf1_loss                | 0.00015331517 |
| qf2_loss                | 0.00014192474 |
| time_elapsed            | 3043          |
| total timesteps         | 600664        |
| value_loss              | 0.00011615972 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015411521  |
| ent_coef_loss           | -3.0248294    |
| entropy                 | 1.3960719     |
| episodes                | 1520          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 603030        |
| policy_loss             | -0.16806677   |
| qf1_loss                | 0.00025753153 |
| qf2_loss                | 0.00028167263 |
| time_elapsed            | 3056          |
| total timesteps         | 603130        |
| value_loss              | 0.00012960404 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015375686  |
| ent_coef_loss           | 2.1741762     |
| entropy                 | 1.3541348     |
| episodes                | 1530          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 605431        |
| policy_loss             | -0.23710951   |
| qf1_loss                | 0.0004585132  |
| qf2_loss                | 0.00053292105 |
| time_elapsed            | 3068          |
| total timesteps         | 605531        |
| value_loss              | 8.398703e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015319117  |
| ent_coef_loss           | 0.004089713   |
| entropy                 | 1.2725664     |
| episodes                | 1540          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 608263        |
| policy_loss             | -0.19588146   |
| qf1_loss                | 0.00041432978 |
| qf2_loss                | 0.00024665307 |
| time_elapsed            | 3082          |
| total timesteps         | 608363        |
| value_loss              | 9.351582e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015472822  |
| ent_coef_loss           | -0.17344493   |
| entropy                 | 1.1639984     |
| episodes                | 1550          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 610337        |
| policy_loss             | -0.20752251   |
| qf1_loss                | 0.00071449846 |
| qf2_loss                | 0.0007020192  |
| time_elapsed            | 3093          |
| total timesteps         | 610437        |
| value_loss              | 0.00012017316 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015570763  |
| ent_coef_loss           | 0.7322345     |
| entropy                 | 1.2037086     |
| episodes                | 1560          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 612404        |
| policy_loss             | -0.15278484   |
| qf1_loss                | 0.00035442572 |
| qf2_loss                | 0.00035543268 |
| time_elapsed            | 3103          |
| total timesteps         | 612504        |
| value_loss              | 0.00017523016 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016089949  |
| ent_coef_loss           | -1.5740774    |
| entropy                 | 1.275482      |
| episodes                | 1570          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 614824        |
| policy_loss             | -0.15153548   |
| qf1_loss                | 0.00033677876 |
| qf2_loss                | 0.000302375   |
| time_elapsed            | 3116          |
| total timesteps         | 614924        |
| value_loss              | 0.000151511   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016566197  |
| ent_coef_loss           | 0.58037424    |
| entropy                 | 1.2156396     |
| episodes                | 1580          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 616644        |
| policy_loss             | -0.14789572   |
| qf1_loss                | 0.00018895266 |
| qf2_loss                | 0.00020203268 |
| time_elapsed            | 3125          |
| total timesteps         | 616744        |
| value_loss              | 0.00022203183 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0016601846 |
| ent_coef_loss           | 1.2451345    |
| entropy                 | 1.1761997    |
| episodes                | 1590         |
| fps                     | 197          |
| mean 100 episode reward | 1.5          |
| n_updates               | 618538       |
| policy_loss             | -0.29705924  |
| qf1_loss                | 0.0007020672 |
| qf2_loss                | 0.0011080257 |
| time_elapsed            | 3135         |
| total timesteps         | 618638       |
| value_loss              | 0.0002210646 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016775292  |
| ent_coef_loss           | -2.7121868    |
| entropy                 | 1.3191397     |
| episodes                | 1600          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 620263        |
| policy_loss             | -0.14631562   |
| qf1_loss                | 0.0004738886  |
| qf2_loss                | 0.00063028553 |
| time_elapsed            | 3144          |
| total timesteps         | 620363        |
| value_loss              | 0.00019719143 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016920952  |
| ent_coef_loss           | -1.3360415    |
| entropy                 | 1.2344084     |
| episodes                | 1610          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 622084        |
| policy_loss             | -0.20601958   |
| qf1_loss                | 0.00032822634 |
| qf2_loss                | 0.00019348023 |
| time_elapsed            | 3153          |
| total timesteps         | 622184        |
| value_loss              | 0.00021040015 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016639873  |
| ent_coef_loss           | 1.4167683     |
| entropy                 | 1.377352      |
| episodes                | 1620          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 623888        |
| policy_loss             | -0.2033717    |
| qf1_loss                | 0.0005865582  |
| qf2_loss                | 0.00032258756 |
| time_elapsed            | 3162          |
| total timesteps         | 623988        |
| value_loss              | 0.00021300741 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001618833   |
| ent_coef_loss           | -0.032126367  |
| entropy                 | 1.3390684     |
| episodes                | 1630          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 625384        |
| policy_loss             | -0.2394784    |
| qf1_loss                | 0.00027127098 |
| qf2_loss                | 0.00024550938 |
| time_elapsed            | 3170          |
| total timesteps         | 625484        |
| value_loss              | 0.00018295992 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001606662   |
| ent_coef_loss           | 0.4851356     |
| entropy                 | 1.2771462     |
| episodes                | 1640          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 626995        |
| policy_loss             | -0.2514912    |
| qf1_loss                | 0.0005018542  |
| qf2_loss                | 0.00041203812 |
| time_elapsed            | 3177          |
| total timesteps         | 627095        |
| value_loss              | 9.4628325e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015847115  |
| ent_coef_loss           | 0.22228563    |
| entropy                 | 1.4039855     |
| episodes                | 1650          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 628623        |
| policy_loss             | -0.28000575   |
| qf1_loss                | 0.0031469257  |
| qf2_loss                | 0.003103631   |
| time_elapsed            | 3186          |
| total timesteps         | 628723        |
| value_loss              | 0.00016218162 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015951213  |
| ent_coef_loss           | -1.9925071    |
| entropy                 | 1.2356205     |
| episodes                | 1660          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 630267        |
| policy_loss             | -0.20861395   |
| qf1_loss                | 0.00018711525 |
| qf2_loss                | 0.00018540924 |
| time_elapsed            | 3194          |
| total timesteps         | 630367        |
| value_loss              | 0.0001197221  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0016262729   |
| ent_coef_loss           | 1.9405545      |
| entropy                 | 1.2789974      |
| episodes                | 1670           |
| fps                     | 197            |
| mean 100 episode reward | 1.4            |
| n_updates               | 632059         |
| policy_loss             | -0.28584903    |
| qf1_loss                | 0.00025321788  |
| qf2_loss                | 0.00023220136  |
| time_elapsed            | 3204           |
| total timesteps         | 632159         |
| value_loss              | 0.000108461245 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016802984  |
| ent_coef_loss           | 1.809711      |
| entropy                 | 1.3413115     |
| episodes                | 1680          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 633928        |
| policy_loss             | -0.2673146    |
| qf1_loss                | 0.00025637474 |
| qf2_loss                | 0.00021894538 |
| time_elapsed            | 3213          |
| total timesteps         | 634028        |
| value_loss              | 0.00014845032 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017006937  |
| ent_coef_loss           | -0.3929335    |
| entropy                 | 1.3910155     |
| episodes                | 1690          |
| fps                     | 197           |
| mean 100 episode reward | 1.3           |
| n_updates               | 635947        |
| policy_loss             | -0.18899111   |
| qf1_loss                | 0.00018930403 |
| qf2_loss                | 0.00013128381 |
| time_elapsed            | 3223          |
| total timesteps         | 636047        |
| value_loss              | 0.00017886839 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016996115  |
| ent_coef_loss           | -1.0634974    |
| entropy                 | 1.3313872     |
| episodes                | 1700          |
| fps                     | 197           |
| mean 100 episode reward | 1.3           |
| n_updates               | 637748        |
| policy_loss             | -0.22615515   |
| qf1_loss                | 0.0002299395  |
| qf2_loss                | 0.00016756926 |
| time_elapsed            | 3232          |
| total timesteps         | 637848        |
| value_loss              | 0.00012068979 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016840394  |
| ent_coef_loss           | -1.0754337    |
| entropy                 | 1.4097435     |
| episodes                | 1710          |
| fps                     | 197           |
| mean 100 episode reward | 1.3           |
| n_updates               | 639709        |
| policy_loss             | -0.23715341   |
| qf1_loss                | 0.0002651767  |
| qf2_loss                | 0.00021346827 |
| time_elapsed            | 3242          |
| total timesteps         | 639809        |
| value_loss              | 0.00015031407 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016351342  |
| ent_coef_loss           | -3.2523608    |
| entropy                 | 1.288132      |
| episodes                | 1720          |
| fps                     | 197           |
| mean 100 episode reward | 1.3           |
| n_updates               | 641319        |
| policy_loss             | -0.27188492   |
| qf1_loss                | 0.00022497652 |
| qf2_loss                | 0.00015556681 |
| time_elapsed            | 3251          |
| total timesteps         | 641419        |
| value_loss              | 0.0002149849  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016447345  |
| ent_coef_loss           | -3.4128308    |
| entropy                 | 1.2747467     |
| episodes                | 1730          |
| fps                     | 197           |
| mean 100 episode reward | 1.3           |
| n_updates               | 642940        |
| policy_loss             | -0.2012502    |
| qf1_loss                | 0.00020410164 |
| qf2_loss                | 0.000204272   |
| time_elapsed            | 3259          |
| total timesteps         | 643040        |
| value_loss              | 0.0001510279  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016700651  |
| ent_coef_loss           | -2.1266556    |
| entropy                 | 1.2229888     |
| episodes                | 1740          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 644671        |
| policy_loss             | -0.25571844   |
| qf1_loss                | 0.0002158294  |
| qf2_loss                | 0.0002410924  |
| time_elapsed            | 3267          |
| total timesteps         | 644771        |
| value_loss              | 0.00013665287 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.001681402    |
| ent_coef_loss           | 0.04222238     |
| entropy                 | 1.2258153      |
| episodes                | 1750           |
| fps                     | 197            |
| mean 100 episode reward | 1.5            |
| n_updates               | 646589         |
| policy_loss             | -0.26259273    |
| qf1_loss                | 0.00024936243  |
| qf2_loss                | 0.00029678858  |
| time_elapsed            | 3277           |
| total timesteps         | 646689         |
| value_loss              | 0.000106573876 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001697071   |
| ent_coef_loss           | 4.7531624     |
| entropy                 | 1.4259171     |
| episodes                | 1760          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 648536        |
| policy_loss             | -0.22638917   |
| qf1_loss                | 0.0002004501  |
| qf2_loss                | 0.00016293746 |
| time_elapsed            | 3287          |
| total timesteps         | 648636        |
| value_loss              | 0.0002397501  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016979056  |
| ent_coef_loss           | 1.1201873     |
| entropy                 | 1.2819841     |
| episodes                | 1770          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 650508        |
| policy_loss             | -0.22076243   |
| qf1_loss                | 0.00043658007 |
| qf2_loss                | 0.00030078035 |
| time_elapsed            | 3297          |
| total timesteps         | 650608        |
| value_loss              | 0.00018106462 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016793003  |
| ent_coef_loss           | -0.4809373    |
| entropy                 | 1.3166323     |
| episodes                | 1780          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 652431        |
| policy_loss             | -0.25920698   |
| qf1_loss                | 0.00033240506 |
| qf2_loss                | 0.00023068367 |
| time_elapsed            | 3307          |
| total timesteps         | 652531        |
| value_loss              | 0.00012187167 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017034232  |
| ent_coef_loss           | -0.73463345   |
| entropy                 | 1.3647051     |
| episodes                | 1790          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 654086        |
| policy_loss             | -0.24368814   |
| qf1_loss                | 0.00023988214 |
| qf2_loss                | 0.00022842246 |
| time_elapsed            | 3315          |
| total timesteps         | 654186        |
| value_loss              | 0.00014973743 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017109491  |
| ent_coef_loss           | 0.31848124    |
| entropy                 | 1.2948337     |
| episodes                | 1800          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 656213        |
| policy_loss             | -0.33115572   |
| qf1_loss                | 0.00023251826 |
| qf2_loss                | 0.00025963623 |
| time_elapsed            | 3326          |
| total timesteps         | 656313        |
| value_loss              | 0.00010618295 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017286376  |
| ent_coef_loss           | -1.3275793    |
| entropy                 | 1.2551305     |
| episodes                | 1810          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 657862        |
| policy_loss             | -0.2872486    |
| qf1_loss                | 0.000195244   |
| qf2_loss                | 0.00016841131 |
| time_elapsed            | 3335          |
| total timesteps         | 657962        |
| value_loss              | 0.00011215864 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.001727704    |
| ent_coef_loss           | 1.3342892      |
| entropy                 | 1.3242046      |
| episodes                | 1820           |
| fps                     | 197            |
| mean 100 episode reward | 1.6            |
| n_updates               | 660044         |
| policy_loss             | -0.16956978    |
| qf1_loss                | 0.00039123342  |
| qf2_loss                | 0.00039929023  |
| time_elapsed            | 3346           |
| total timesteps         | 660144         |
| value_loss              | 0.000121370285 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017848241  |
| ent_coef_loss           | -0.801781     |
| entropy                 | 1.3399147     |
| episodes                | 1830          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 661902        |
| policy_loss             | -0.32483685   |
| qf1_loss                | 0.00018977407 |
| qf2_loss                | 0.0002193939  |
| time_elapsed            | 3355          |
| total timesteps         | 662002        |
| value_loss              | 0.00015663328 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018246972  |
| ent_coef_loss           | 2.5175405     |
| entropy                 | 1.4047002     |
| episodes                | 1840          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 663950        |
| policy_loss             | -0.23007502   |
| qf1_loss                | 0.00031238564 |
| qf2_loss                | 0.00025244794 |
| time_elapsed            | 3366          |
| total timesteps         | 664050        |
| value_loss              | 0.00011795671 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018680062  |
| ent_coef_loss           | -0.9659512    |
| entropy                 | 1.4271777     |
| episodes                | 1850          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 665600        |
| policy_loss             | -0.24565044   |
| qf1_loss                | 0.00016697196 |
| qf2_loss                | 0.00025357638 |
| time_elapsed            | 3374          |
| total timesteps         | 665700        |
| value_loss              | 0.00012585716 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019077826  |
| ent_coef_loss           | 0.7154125     |
| entropy                 | 1.4413462     |
| episodes                | 1860          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 667504        |
| policy_loss             | -0.29354244   |
| qf1_loss                | 0.0002474559  |
| qf2_loss                | 0.0002917382  |
| time_elapsed            | 3383          |
| total timesteps         | 667604        |
| value_loss              | 0.00011741863 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019561513  |
| ent_coef_loss           | 2.0895815     |
| entropy                 | 1.4183209     |
| episodes                | 1870          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 669148        |
| policy_loss             | -0.18675356   |
| qf1_loss                | 0.00024248539 |
| qf2_loss                | 0.00035696465 |
| time_elapsed            | 3392          |
| total timesteps         | 669248        |
| value_loss              | 0.00013965499 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001940376   |
| ent_coef_loss           | -0.25497937   |
| entropy                 | 1.3966529     |
| episodes                | 1880          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 670679        |
| policy_loss             | -0.2575342    |
| qf1_loss                | 0.00023395297 |
| qf2_loss                | 0.00022762993 |
| time_elapsed            | 3399          |
| total timesteps         | 670779        |
| value_loss              | 0.00010792011 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019276412  |
| ent_coef_loss           | -0.45920628   |
| entropy                 | 1.4599445     |
| episodes                | 1890          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 672595        |
| policy_loss             | -0.24734354   |
| qf1_loss                | 0.00018928261 |
| qf2_loss                | 0.0001614771  |
| time_elapsed            | 3409          |
| total timesteps         | 672695        |
| value_loss              | 0.00014630155 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019087517  |
| ent_coef_loss           | -0.34213895   |
| entropy                 | 1.4045212     |
| episodes                | 1900          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 674494        |
| policy_loss             | -0.16619802   |
| qf1_loss                | 0.00016292212 |
| qf2_loss                | 0.00023560511 |
| time_elapsed            | 3419          |
| total timesteps         | 674594        |
| value_loss              | 0.00011148804 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019092569  |
| ent_coef_loss           | 0.22609341    |
| entropy                 | 1.3935869     |
| episodes                | 1910          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 676279        |
| policy_loss             | -0.20921586   |
| qf1_loss                | 0.00042201398 |
| qf2_loss                | 0.00047470513 |
| time_elapsed            | 3428          |
| total timesteps         | 676379        |
| value_loss              | 0.00015114053 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019537117  |
| ent_coef_loss           | 0.21123043    |
| entropy                 | 1.3502941     |
| episodes                | 1920          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 677861        |
| policy_loss             | -0.31208402   |
| qf1_loss                | 0.0001785555  |
| qf2_loss                | 0.0001608903  |
| time_elapsed            | 3436          |
| total timesteps         | 677961        |
| value_loss              | 0.00024279942 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019670173  |
| ent_coef_loss           | -1.7454801    |
| entropy                 | 1.436467      |
| episodes                | 1930          |
| fps                     | 197           |
| mean 100 episode reward | 1.3           |
| n_updates               | 680279        |
| policy_loss             | -0.1624971    |
| qf1_loss                | 0.00016765295 |
| qf2_loss                | 0.00023026792 |
| time_elapsed            | 3448          |
| total timesteps         | 680379        |
| value_loss              | 0.00012400621 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.001936877    |
| ent_coef_loss           | -1.4584401     |
| entropy                 | 1.3506472      |
| episodes                | 1940           |
| fps                     | 197            |
| mean 100 episode reward | 1.3            |
| n_updates               | 682274         |
| policy_loss             | -0.22076869    |
| qf1_loss                | 0.00025144866  |
| qf2_loss                | 0.00024167245  |
| time_elapsed            | 3459           |
| total timesteps         | 682374         |
| value_loss              | 0.000115496034 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019261371  |
| ent_coef_loss           | 1.340729      |
| entropy                 | 1.4156563     |
| episodes                | 1950          |
| fps                     | 197           |
| mean 100 episode reward | 1.3           |
| n_updates               | 683789        |
| policy_loss             | -0.26940554   |
| qf1_loss                | 0.0005131249  |
| qf2_loss                | 0.00038719666 |
| time_elapsed            | 3466          |
| total timesteps         | 683889        |
| value_loss              | 0.00020288318 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019146632  |
| ent_coef_loss           | -1.2525065    |
| entropy                 | 1.3796117     |
| episodes                | 1960          |
| fps                     | 197           |
| mean 100 episode reward | 1.2           |
| n_updates               | 685381        |
| policy_loss             | -0.26878104   |
| qf1_loss                | 0.0001669625  |
| qf2_loss                | 0.00013387593 |
| time_elapsed            | 3474          |
| total timesteps         | 685481        |
| value_loss              | 0.00011102198 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001901983   |
| ent_coef_loss           | -1.3552394    |
| entropy                 | 1.4536961     |
| episodes                | 1970          |
| fps                     | 197           |
| mean 100 episode reward | 1.3           |
| n_updates               | 687396        |
| policy_loss             | -0.21960533   |
| qf1_loss                | 0.00023875301 |
| qf2_loss                | 0.00022606748 |
| time_elapsed            | 3485          |
| total timesteps         | 687496        |
| value_loss              | 8.580513e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018810482  |
| ent_coef_loss           | 0.34554243    |
| entropy                 | 1.4166543     |
| episodes                | 1980          |
| fps                     | 197           |
| mean 100 episode reward | 1.3           |
| n_updates               | 688886        |
| policy_loss             | -0.24925959   |
| qf1_loss                | 0.00054390554 |
| qf2_loss                | 0.00037126694 |
| time_elapsed            | 3492          |
| total timesteps         | 688986        |
| value_loss              | 0.00028089865 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018984266  |
| ent_coef_loss           | -3.5178847    |
| entropy                 | 1.4525216     |
| episodes                | 1990          |
| fps                     | 197           |
| mean 100 episode reward | 1.3           |
| n_updates               | 690570        |
| policy_loss             | -0.1998735    |
| qf1_loss                | 0.00029366097 |
| qf2_loss                | 0.00024278194 |
| time_elapsed            | 3500          |
| total timesteps         | 690670        |
| value_loss              | 0.00016298103 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.001925879  |
| ent_coef_loss           | -0.86919314  |
| entropy                 | 1.3976156    |
| episodes                | 2000         |
| fps                     | 197          |
| mean 100 episode reward | 1.3          |
| n_updates               | 692529       |
| policy_loss             | -0.19713691  |
| qf1_loss                | 0.015896576  |
| qf2_loss                | 0.01641684   |
| time_elapsed            | 3511         |
| total timesteps         | 692629       |
| value_loss              | 0.0001583257 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019363923  |
| ent_coef_loss           | -3.1301246    |
| entropy                 | 1.3873249     |
| episodes                | 2010          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 694353        |
| policy_loss             | -0.12629086   |
| qf1_loss                | 0.0002359754  |
| qf2_loss                | 0.0001427395  |
| time_elapsed            | 3520          |
| total timesteps         | 694453        |
| value_loss              | 0.00010596914 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0019070114   |
| ent_coef_loss           | -0.46249908    |
| entropy                 | 1.2644627      |
| episodes                | 2020           |
| fps                     | 197            |
| mean 100 episode reward | 1.4            |
| n_updates               | 696493         |
| policy_loss             | -0.23897919    |
| qf1_loss                | 0.00030617072  |
| qf2_loss                | 0.00016687633  |
| time_elapsed            | 3531           |
| total timesteps         | 696593         |
| value_loss              | 0.000115892835 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019518178  |
| ent_coef_loss           | -0.5404214    |
| entropy                 | 1.3687723     |
| episodes                | 2030          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 698217        |
| policy_loss             | -0.2284938    |
| qf1_loss                | 0.00053080154 |
| qf2_loss                | 0.00033830307 |
| time_elapsed            | 3540          |
| total timesteps         | 698317        |
| value_loss              | 0.00015026882 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019946035  |
| ent_coef_loss           | 1.6099298     |
| entropy                 | 1.3532598     |
| episodes                | 2040          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 699895        |
| policy_loss             | -0.15403965   |
| qf1_loss                | 0.00034282263 |
| qf2_loss                | 0.0003297471  |
| time_elapsed            | 3548          |
| total timesteps         | 699995        |
| value_loss              | 0.00039520214 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.002040449   |
| ent_coef_loss           | 0.4218184     |
| entropy                 | 1.4168718     |
| episodes                | 2050          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 701720        |
| policy_loss             | -0.25541556   |
| qf1_loss                | 0.00026324333 |
| qf2_loss                | 0.00017638868 |
| time_elapsed            | 3558          |
| total timesteps         | 701820        |
| value_loss              | 0.00015213309 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020527795  |
| ent_coef_loss           | -2.1527889    |
| entropy                 | 1.4073668     |
| episodes                | 2060          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 703661        |
| policy_loss             | -0.24992396   |
| qf1_loss                | 0.00020505562 |
| qf2_loss                | 0.00030446588 |
| time_elapsed            | 3567          |
| total timesteps         | 703761        |
| value_loss              | 0.0001698366  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020814238  |
| ent_coef_loss           | 3.1705377     |
| entropy                 | 1.3997388     |
| episodes                | 2070          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 705483        |
| policy_loss             | -0.18868092   |
| qf1_loss                | 0.00057963625 |
| qf2_loss                | 0.00062676286 |
| time_elapsed            | 3577          |
| total timesteps         | 705583        |
| value_loss              | 0.00020354647 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.002104174   |
| ent_coef_loss           | -0.97358567   |
| entropy                 | 1.3270516     |
| episodes                | 2080          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 707451        |
| policy_loss             | -0.2941599    |
| qf1_loss                | 0.00033428092 |
| qf2_loss                | 0.00027985062 |
| time_elapsed            | 3587          |
| total timesteps         | 707551        |
| value_loss              | 0.00015185724 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00208747    |
| ent_coef_loss           | -1.8449368    |
| entropy                 | 1.3276701     |
| episodes                | 2090          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 709244        |
| policy_loss             | -0.18459047   |
| qf1_loss                | 0.000292151   |
| qf2_loss                | 0.00026958424 |
| time_elapsed            | 3595          |
| total timesteps         | 709344        |
| value_loss              | 0.00029751327 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0021318188   |
| ent_coef_loss           | 3.2688096      |
| entropy                 | 1.4768269      |
| episodes                | 2100           |
| fps                     | 197            |
| mean 100 episode reward | 1.7            |
| n_updates               | 711067         |
| policy_loss             | -0.21340996    |
| qf1_loss                | 0.00037701597  |
| qf2_loss                | 0.0007454847   |
| time_elapsed            | 3605           |
| total timesteps         | 711167         |
| value_loss              | 0.000121656776 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0021577298  |
| ent_coef_loss           | 1.2164991     |
| entropy                 | 1.329424      |
| episodes                | 2110          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 712493        |
| policy_loss             | -0.27549648   |
| qf1_loss                | 0.00013262156 |
| qf2_loss                | 0.00021786672 |
| time_elapsed            | 3612          |
| total timesteps         | 712593        |
| value_loss              | 0.00011605883 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0021648833  |
| ent_coef_loss           | -0.14569503   |
| entropy                 | 1.3691359     |
| episodes                | 2120          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 713892        |
| policy_loss             | -0.1844881    |
| qf1_loss                | 0.00035278843 |
| qf2_loss                | 0.0003281623  |
| time_elapsed            | 3619          |
| total timesteps         | 713992        |
| value_loss              | 0.00021449773 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0021426296  |
| ent_coef_loss           | 1.9283884     |
| entropy                 | 1.3561285     |
| episodes                | 2130          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 715422        |
| policy_loss             | -0.1627379    |
| qf1_loss                | 0.00017895152 |
| qf2_loss                | 0.0003298266  |
| time_elapsed            | 3627          |
| total timesteps         | 715522        |
| value_loss              | 0.00010007554 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0021553452  |
| ent_coef_loss           | -3.2091432    |
| entropy                 | 1.380888      |
| episodes                | 2140          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 717183        |
| policy_loss             | -0.17307147   |
| qf1_loss                | 0.00024020742 |
| qf2_loss                | 0.00030680528 |
| time_elapsed            | 3637          |
| total timesteps         | 717283        |
| value_loss              | 0.00012492613 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00214184    |
| ent_coef_loss           | -1.1326996    |
| entropy                 | 1.4116013     |
| episodes                | 2150          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 718579        |
| policy_loss             | -0.17211108   |
| qf1_loss                | 0.0003366468  |
| qf2_loss                | 0.00030045072 |
| time_elapsed            | 3644          |
| total timesteps         | 718679        |
| value_loss              | 0.00022420038 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0021026367  |
| ent_coef_loss           | 1.3210557     |
| entropy                 | 1.4850528     |
| episodes                | 2160          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 720426        |
| policy_loss             | -0.16383563   |
| qf1_loss                | 0.00024237037 |
| qf2_loss                | 0.00029062413 |
| time_elapsed            | 3653          |
| total timesteps         | 720526        |
| value_loss              | 0.00017590469 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020406079  |
| ent_coef_loss           | -1.7281588    |
| entropy                 | 1.3896164     |
| episodes                | 2170          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 722168        |
| policy_loss             | -0.16440697   |
| qf1_loss                | 0.00016725447 |
| qf2_loss                | 0.00015079026 |
| time_elapsed            | 3662          |
| total timesteps         | 722268        |
| value_loss              | 0.00017349629 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0020356823 |
| ent_coef_loss           | -2.48686     |
| entropy                 | 1.4016652    |
| episodes                | 2180         |
| fps                     | 197          |
| mean 100 episode reward | 1.4          |
| n_updates               | 723841       |
| policy_loss             | -0.16639027  |
| qf1_loss                | 0.0002820692 |
| qf2_loss                | 0.0005534166 |
| time_elapsed            | 3670         |
| total timesteps         | 723941       |
| value_loss              | 0.0001776348 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020353058  |
| ent_coef_loss           | -2.5495996    |
| entropy                 | 1.3301346     |
| episodes                | 2190          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 725353        |
| policy_loss             | -0.1724068    |
| qf1_loss                | 0.00025915622 |
| qf2_loss                | 0.00023582943 |
| time_elapsed            | 3678          |
| total timesteps         | 725453        |
| value_loss              | 0.00011389084 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.002076106   |
| ent_coef_loss           | 0.6528872     |
| entropy                 | 1.4029711     |
| episodes                | 2200          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 727548        |
| policy_loss             | -0.22722447   |
| qf1_loss                | 0.00016896828 |
| qf2_loss                | 0.00014351266 |
| time_elapsed            | 3689          |
| total timesteps         | 727648        |
| value_loss              | 0.00013155767 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020952034  |
| ent_coef_loss           | -0.15802386   |
| entropy                 | 1.3499596     |
| episodes                | 2210          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 729301        |
| policy_loss             | -0.28791317   |
| qf1_loss                | 0.00030492677 |
| qf2_loss                | 0.00035218574 |
| time_elapsed            | 3698          |
| total timesteps         | 729401        |
| value_loss              | 0.00020124072 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0021222252  |
| ent_coef_loss           | 3.152608      |
| entropy                 | 1.3874304     |
| episodes                | 2220          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 731040        |
| policy_loss             | -0.23767799   |
| qf1_loss                | 0.0003796974  |
| qf2_loss                | 0.00033154147 |
| time_elapsed            | 3707          |
| total timesteps         | 731140        |
| value_loss              | 0.00022210706 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0021071765  |
| ent_coef_loss           | -0.88528544   |
| entropy                 | 1.4002745     |
| episodes                | 2230          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 732802        |
| policy_loss             | -0.32651532   |
| qf1_loss                | 0.0005173203  |
| qf2_loss                | 0.0006056608  |
| time_elapsed            | 3715          |
| total timesteps         | 732902        |
| value_loss              | 0.00022160838 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.002122038   |
| ent_coef_loss           | 0.32838327    |
| entropy                 | 1.3890438     |
| episodes                | 2240          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 734553        |
| policy_loss             | -0.28164008   |
| qf1_loss                | 0.00022062649 |
| qf2_loss                | 0.00024348048 |
| time_elapsed            | 3725          |
| total timesteps         | 734653        |
| value_loss              | 0.00017973593 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.002127083   |
| ent_coef_loss           | -1.5749495    |
| entropy                 | 1.3478272     |
| episodes                | 2250          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 736534        |
| policy_loss             | -0.12813306   |
| qf1_loss                | 0.00026314284 |
| qf2_loss                | 0.00027346425 |
| time_elapsed            | 3735          |
| total timesteps         | 736634        |
| value_loss              | 0.00016105722 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0021204741  |
| ent_coef_loss           | 0.19616777    |
| entropy                 | 1.3807764     |
| episodes                | 2260          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 738315        |
| policy_loss             | -0.22882996   |
| qf1_loss                | 0.00024091662 |
| qf2_loss                | 0.00016962238 |
| time_elapsed            | 3743          |
| total timesteps         | 738415        |
| value_loss              | 0.00015022697 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0021302418  |
| ent_coef_loss           | 1.4698577     |
| entropy                 | 1.4002395     |
| episodes                | 2270          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 740141        |
| policy_loss             | -0.106821686  |
| qf1_loss                | 0.00030633179 |
| qf2_loss                | 0.0002354371  |
| time_elapsed            | 3753          |
| total timesteps         | 740241        |
| value_loss              | 8.470073e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0021721483  |
| ent_coef_loss           | 1.4253438     |
| entropy                 | 1.3345037     |
| episodes                | 2280          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 741737        |
| policy_loss             | -0.2637508    |
| qf1_loss                | 0.00020042835 |
| qf2_loss                | 0.00013353258 |
| time_elapsed            | 3761          |
| total timesteps         | 741837        |
| value_loss              | 0.00019043466 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.002231359   |
| ent_coef_loss           | 1.8902014     |
| entropy                 | 1.4088457     |
| episodes                | 2290          |
| fps                     | 197           |
| mean 100 episode reward | 1.8           |
| n_updates               | 743390        |
| policy_loss             | -0.17532322   |
| qf1_loss                | 0.00049137545 |
| qf2_loss                | 0.00030372947 |
| time_elapsed            | 3769          |
| total timesteps         | 743490        |
| value_loss              | 0.00010928206 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0022679842  |
| ent_coef_loss           | -0.053474724  |
| entropy                 | 1.4178634     |
| episodes                | 2300          |
| fps                     | 197           |
| mean 100 episode reward | 1.8           |
| n_updates               | 745116        |
| policy_loss             | -0.19144632   |
| qf1_loss                | 0.00023827562 |
| qf2_loss                | 0.00030730647 |
| time_elapsed            | 3778          |
| total timesteps         | 745216        |
| value_loss              | 9.368223e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.002245357   |
| ent_coef_loss           | 1.4790108     |
| entropy                 | 1.3942585     |
| episodes                | 2310          |
| fps                     | 197           |
| mean 100 episode reward | 1.8           |
| n_updates               | 746960        |
| policy_loss             | -0.22793508   |
| qf1_loss                | 0.00020269952 |
| qf2_loss                | 0.00031949035 |
| time_elapsed            | 3787          |
| total timesteps         | 747060        |
| value_loss              | 0.0001611505  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0021843037  |
| ent_coef_loss           | 1.8266199     |
| entropy                 | 1.4136481     |
| episodes                | 2320          |
| fps                     | 197           |
| mean 100 episode reward | 1.8           |
| n_updates               | 748796        |
| policy_loss             | -0.25746232   |
| qf1_loss                | 0.00020727841 |
| qf2_loss                | 0.00017157673 |
| time_elapsed            | 3796          |
| total timesteps         | 748896        |
| value_loss              | 0.00015431987 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0021217214  |
| ent_coef_loss           | 0.93193555    |
| entropy                 | 1.3966386     |
| episodes                | 2330          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 750783        |
| policy_loss             | -0.11850782   |
| qf1_loss                | 0.00020449786 |
| qf2_loss                | 0.00019408899 |
| time_elapsed            | 3806          |
| total timesteps         | 750883        |
| value_loss              | 0.00010207741 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0021151826  |
| ent_coef_loss           | -1.0083747    |
| entropy                 | 1.3492516     |
| episodes                | 2340          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 752559        |
| policy_loss             | -0.11379947   |
| qf1_loss                | 0.00039139038 |
| qf2_loss                | 0.00014171127 |
| time_elapsed            | 3816          |
| total timesteps         | 752659        |
| value_loss              | 0.00011385383 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0021364696  |
| ent_coef_loss           | 0.33075637    |
| entropy                 | 1.297096      |
| episodes                | 2350          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 754423        |
| policy_loss             | -0.23632194   |
| qf1_loss                | 0.00023013647 |
| qf2_loss                | 0.0002839421  |
| time_elapsed            | 3825          |
| total timesteps         | 754523        |
| value_loss              | 0.00015004049 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.002161368   |
| ent_coef_loss           | 0.50763863    |
| entropy                 | 1.3531309     |
| episodes                | 2360          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 756051        |
| policy_loss             | -0.3069696    |
| qf1_loss                | 0.00014278808 |
| qf2_loss                | 0.00014357587 |
| time_elapsed            | 3833          |
| total timesteps         | 756151        |
| value_loss              | 0.00012053769 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0021133316  |
| ent_coef_loss           | 1.3594968     |
| entropy                 | 1.2800264     |
| episodes                | 2370          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 758012        |
| policy_loss             | -0.14300779   |
| qf1_loss                | 0.00018731141 |
| qf2_loss                | 0.0001336721  |
| time_elapsed            | 3843          |
| total timesteps         | 758112        |
| value_loss              | 0.00010635295 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.002080126   |
| ent_coef_loss           | 0.38407576    |
| entropy                 | 1.3546154     |
| episodes                | 2380          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 759763        |
| policy_loss             | -0.17402613   |
| qf1_loss                | 0.0001549809  |
| qf2_loss                | 0.0002353788  |
| time_elapsed            | 3851          |
| total timesteps         | 759863        |
| value_loss              | 0.00017137299 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.002054556   |
| ent_coef_loss           | -0.22999766   |
| entropy                 | 1.319986      |
| episodes                | 2390          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 761494        |
| policy_loss             | -0.1845082    |
| qf1_loss                | 0.00023851683 |
| qf2_loss                | 0.00029182795 |
| time_elapsed            | 3860          |
| total timesteps         | 761594        |
| value_loss              | 0.00017126743 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020354379  |
| ent_coef_loss           | -2.181734     |
| entropy                 | 1.3313661     |
| episodes                | 2400          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 763279        |
| policy_loss             | -0.22673722   |
| qf1_loss                | 0.00029667607 |
| qf2_loss                | 0.0002513909  |
| time_elapsed            | 3869          |
| total timesteps         | 763379        |
| value_loss              | 9.246876e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020074446  |
| ent_coef_loss           | -2.8327177    |
| entropy                 | 1.2994889     |
| episodes                | 2410          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 765145        |
| policy_loss             | -0.08746667   |
| qf1_loss                | 0.00037989038 |
| qf2_loss                | 0.00019201853 |
| time_elapsed            | 3879          |
| total timesteps         | 765245        |
| value_loss              | 0.0001290293  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.002044105   |
| ent_coef_loss           | -0.6686491    |
| entropy                 | 1.3453393     |
| episodes                | 2420          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 766842        |
| policy_loss             | -0.263247     |
| qf1_loss                | 0.00016817656 |
| qf2_loss                | 0.00025738458 |
| time_elapsed            | 3888          |
| total timesteps         | 766942        |
| value_loss              | 0.00014055519 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020364814  |
| ent_coef_loss           | -1.5469034    |
| entropy                 | 1.3063768     |
| episodes                | 2430          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 768471        |
| policy_loss             | -0.20896852   |
| qf1_loss                | 0.00021593938 |
| qf2_loss                | 0.00021622804 |
| time_elapsed            | 3896          |
| total timesteps         | 768571        |
| value_loss              | 0.00022890116 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020577728  |
| ent_coef_loss           | 0.15043819    |
| entropy                 | 1.3755066     |
| episodes                | 2440          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 770182        |
| policy_loss             | -0.2306042    |
| qf1_loss                | 0.000248513   |
| qf2_loss                | 0.00022987716 |
| time_elapsed            | 3905          |
| total timesteps         | 770282        |
| value_loss              | 0.00032816708 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020165897  |
| ent_coef_loss           | 1.2381142     |
| entropy                 | 1.2250057     |
| episodes                | 2450          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 771795        |
| policy_loss             | -0.2506147    |
| qf1_loss                | 0.00017015281 |
| qf2_loss                | 0.00014944439 |
| time_elapsed            | 3913          |
| total timesteps         | 771895        |
| value_loss              | 0.00015814458 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020378686  |
| ent_coef_loss           | -2.0869641    |
| entropy                 | 1.3185792     |
| episodes                | 2460          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 773650        |
| policy_loss             | -0.19521242   |
| qf1_loss                | 0.0002315142  |
| qf2_loss                | 0.00039487414 |
| time_elapsed            | 3922          |
| total timesteps         | 773750        |
| value_loss              | 0.00016156724 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020215902  |
| ent_coef_loss           | 3.4682446     |
| entropy                 | 1.3358893     |
| episodes                | 2470          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 775580        |
| policy_loss             | -0.3064283    |
| qf1_loss                | 0.0001697623  |
| qf2_loss                | 0.00017403955 |
| time_elapsed            | 3932          |
| total timesteps         | 775680        |
| value_loss              | 0.00010463571 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020025964  |
| ent_coef_loss           | 2.4312723     |
| entropy                 | 1.3863485     |
| episodes                | 2480          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 777413        |
| policy_loss             | -0.29374894   |
| qf1_loss                | 0.00011927466 |
| qf2_loss                | 0.00017412554 |
| time_elapsed            | 3941          |
| total timesteps         | 777513        |
| value_loss              | 0.00010721808 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020143974  |
| ent_coef_loss           | 1.3681195     |
| entropy                 | 1.3581709     |
| episodes                | 2490          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 779177        |
| policy_loss             | -0.24621598   |
| qf1_loss                | 0.00010718908 |
| qf2_loss                | 0.00014340173 |
| time_elapsed            | 3950          |
| total timesteps         | 779277        |
| value_loss              | 9.507252e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.002004767   |
| ent_coef_loss           | -0.67500263   |
| entropy                 | 1.3001665     |
| episodes                | 2500          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 781234        |
| policy_loss             | -0.28254065   |
| qf1_loss                | 0.00021611582 |
| qf2_loss                | 0.00022637825 |
| time_elapsed            | 3960          |
| total timesteps         | 781334        |
| value_loss              | 0.00010113036 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020107096  |
| ent_coef_loss           | -0.6431316    |
| entropy                 | 1.3593478     |
| episodes                | 2510          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 783076        |
| policy_loss             | -0.35373765   |
| qf1_loss                | 0.00012732233 |
| qf2_loss                | 0.00011516336 |
| time_elapsed            | 3970          |
| total timesteps         | 783176        |
| value_loss              | 0.00025826367 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020107296  |
| ent_coef_loss           | -0.012306154  |
| entropy                 | 1.2634736     |
| episodes                | 2520          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 784742        |
| policy_loss             | -0.3089994    |
| qf1_loss                | 0.00030644255 |
| qf2_loss                | 0.00054621766 |
| time_elapsed            | 3978          |
| total timesteps         | 784842        |
| value_loss              | 0.00014157062 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001981188   |
| ent_coef_loss           | 0.12165499    |
| entropy                 | 1.3277698     |
| episodes                | 2530          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 786552        |
| policy_loss             | -0.30613202   |
| qf1_loss                | 0.00022078087 |
| qf2_loss                | 0.00017949105 |
| time_elapsed            | 3987          |
| total timesteps         | 786652        |
| value_loss              | 8.36742e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001988447   |
| ent_coef_loss           | -1.2942616    |
| entropy                 | 1.33308       |
| episodes                | 2540          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 788061        |
| policy_loss             | -0.16596813   |
| qf1_loss                | 0.00026219335 |
| qf2_loss                | 0.0002617928  |
| time_elapsed            | 3995          |
| total timesteps         | 788161        |
| value_loss              | 0.00019485269 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020146098  |
| ent_coef_loss           | 0.051996768   |
| entropy                 | 1.3289334     |
| episodes                | 2550          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 789698        |
| policy_loss             | -0.22990048   |
| qf1_loss                | 0.0002653275  |
| qf2_loss                | 0.000206084   |
| time_elapsed            | 4003          |
| total timesteps         | 789798        |
| value_loss              | 8.1437785e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020478629  |
| ent_coef_loss           | -0.33330834   |
| entropy                 | 1.2862978     |
| episodes                | 2560          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 791474        |
| policy_loss             | -0.29048935   |
| qf1_loss                | 0.00050659734 |
| qf2_loss                | 0.0003088431  |
| time_elapsed            | 4012          |
| total timesteps         | 791574        |
| value_loss              | 0.00016772497 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.002043075   |
| ent_coef_loss           | -1.2354126    |
| entropy                 | 1.344447      |
| episodes                | 2570          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 793278        |
| policy_loss             | -0.23544657   |
| qf1_loss                | 0.00015030499 |
| qf2_loss                | 0.00012462217 |
| time_elapsed            | 4021          |
| total timesteps         | 793378        |
| value_loss              | 8.9667934e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020670446  |
| ent_coef_loss           | -2.3934298    |
| entropy                 | 1.3309042     |
| episodes                | 2580          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 795029        |
| policy_loss             | -0.33541209   |
| qf1_loss                | 0.00012045131 |
| qf2_loss                | 0.00012947609 |
| time_elapsed            | 4030          |
| total timesteps         | 795129        |
| value_loss              | 0.00016047293 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020568497  |
| ent_coef_loss           | -0.8242712    |
| entropy                 | 1.3420005     |
| episodes                | 2590          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 796754        |
| policy_loss             | -0.22886309   |
| qf1_loss                | 0.00020418421 |
| qf2_loss                | 0.00020018086 |
| time_elapsed            | 4039          |
| total timesteps         | 796854        |
| value_loss              | 0.00013810201 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020528804  |
| ent_coef_loss           | 1.3333963     |
| entropy                 | 1.3417801     |
| episodes                | 2600          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 798300        |
| policy_loss             | -0.2733306    |
| qf1_loss                | 0.00041717148 |
| qf2_loss                | 0.00024967542 |
| time_elapsed            | 4047          |
| total timesteps         | 798400        |
| value_loss              | 0.00020727655 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020019931  |
| ent_coef_loss           | -1.989432     |
| entropy                 | 1.4213266     |
| episodes                | 2610          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 799809        |
| policy_loss             | -0.2916142    |
| qf1_loss                | 0.00023926987 |
| qf2_loss                | 0.0003333439  |
| time_elapsed            | 4055          |
| total timesteps         | 799909        |
| value_loss              | 7.9647965e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019546612  |
| ent_coef_loss           | -1.9244514    |
| entropy                 | 1.3085942     |
| episodes                | 2620          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 801568        |
| policy_loss             | -0.22372787   |
| qf1_loss                | 0.00035103096 |
| qf2_loss                | 0.00038728694 |
| time_elapsed            | 4064          |
| total timesteps         | 801668        |
| value_loss              | 0.00017046349 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019221387  |
| ent_coef_loss           | 1.3474088     |
| entropy                 | 1.3605442     |
| episodes                | 2630          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 803527        |
| policy_loss             | -0.2847475    |
| qf1_loss                | 0.0002697399  |
| qf2_loss                | 0.0002489124  |
| time_elapsed            | 4073          |
| total timesteps         | 803627        |
| value_loss              | 0.00012519612 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0019149801   |
| ent_coef_loss           | 1.3035562      |
| entropy                 | 1.3672867      |
| episodes                | 2640           |
| fps                     | 197            |
| mean 100 episode reward | 1.5            |
| n_updates               | 805327         |
| policy_loss             | -0.2460424     |
| qf1_loss                | 0.00059839315  |
| qf2_loss                | 0.00088164356  |
| time_elapsed            | 4083           |
| total timesteps         | 805427         |
| value_loss              | 0.000117830656 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019286278  |
| ent_coef_loss           | 2.6562748     |
| entropy                 | 1.3295951     |
| episodes                | 2650          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 806801        |
| policy_loss             | -0.36992377   |
| qf1_loss                | 0.00015577748 |
| qf2_loss                | 0.000156706   |
| time_elapsed            | 4090          |
| total timesteps         | 806901        |
| value_loss              | 0.00015061359 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019147692  |
| ent_coef_loss           | 1.4184575     |
| entropy                 | 1.3436617     |
| episodes                | 2660          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 808599        |
| policy_loss             | -0.34498656   |
| qf1_loss                | 0.00018122885 |
| qf2_loss                | 0.0002245268  |
| time_elapsed            | 4099          |
| total timesteps         | 808699        |
| value_loss              | 0.00014637971 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018968142  |
| ent_coef_loss           | -0.26049656   |
| entropy                 | 1.3068001     |
| episodes                | 2670          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 810196        |
| policy_loss             | -0.2992803    |
| qf1_loss                | 0.00015919615 |
| qf2_loss                | 0.00016215857 |
| time_elapsed            | 4107          |
| total timesteps         | 810296        |
| value_loss              | 7.282589e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0018772893 |
| ent_coef_loss           | -0.025433004 |
| entropy                 | 1.3299054    |
| episodes                | 2680         |
| fps                     | 197          |
| mean 100 episode reward | 1.5          |
| n_updates               | 811805       |
| policy_loss             | -0.32640678  |
| qf1_loss                | 0.0001928976 |
| qf2_loss                | 0.0001726594 |
| time_elapsed            | 4116         |
| total timesteps         | 811905       |
| value_loss              | 9.74448e-05  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019049982  |
| ent_coef_loss           | -0.9413958    |
| entropy                 | 1.3238235     |
| episodes                | 2690          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 813601        |
| policy_loss             | -0.21586224   |
| qf1_loss                | 0.0003264336  |
| qf2_loss                | 0.00025771337 |
| time_elapsed            | 4125          |
| total timesteps         | 813701        |
| value_loss              | 9.672515e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019164727  |
| ent_coef_loss           | 1.0776341     |
| entropy                 | 1.3706522     |
| episodes                | 2700          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 815361        |
| policy_loss             | -0.32509348   |
| qf1_loss                | 0.00017730343 |
| qf2_loss                | 8.757139e-05  |
| time_elapsed            | 4134          |
| total timesteps         | 815461        |
| value_loss              | 9.33138e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019091313  |
| ent_coef_loss           | -0.7622067    |
| entropy                 | 1.2774173     |
| episodes                | 2710          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 817209        |
| policy_loss             | -0.384037     |
| qf1_loss                | 0.00015415423 |
| qf2_loss                | 0.00011669664 |
| time_elapsed            | 4143          |
| total timesteps         | 817309        |
| value_loss              | 8.727338e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019181814  |
| ent_coef_loss           | 1.1674207     |
| entropy                 | 1.3068877     |
| episodes                | 2720          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 819049        |
| policy_loss             | -0.25718388   |
| qf1_loss                | 0.00029257507 |
| qf2_loss                | 0.00025538195 |
| time_elapsed            | 4152          |
| total timesteps         | 819149        |
| value_loss              | 0.00015609572 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019261123  |
| ent_coef_loss           | 1.5637852     |
| entropy                 | 1.3537023     |
| episodes                | 2730          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 820809        |
| policy_loss             | -0.29035118   |
| qf1_loss                | 0.00017695551 |
| qf2_loss                | 0.00022706532 |
| time_elapsed            | 4161          |
| total timesteps         | 820909        |
| value_loss              | 8.049232e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019324858  |
| ent_coef_loss           | -0.1991131    |
| entropy                 | 1.2962475     |
| episodes                | 2740          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 822624        |
| policy_loss             | -0.33764368   |
| qf1_loss                | 0.00049382995 |
| qf2_loss                | 0.00082013954 |
| time_elapsed            | 4170          |
| total timesteps         | 822724        |
| value_loss              | 0.00011646932 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019120894  |
| ent_coef_loss           | -2.691833     |
| entropy                 | 1.2475202     |
| episodes                | 2750          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 824451        |
| policy_loss             | -0.34820262   |
| qf1_loss                | 0.00018464599 |
| qf2_loss                | 0.00018525502 |
| time_elapsed            | 4179          |
| total timesteps         | 824551        |
| value_loss              | 0.00012755157 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018874642  |
| ent_coef_loss           | 0.47970116    |
| entropy                 | 1.2281622     |
| episodes                | 2760          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 826202        |
| policy_loss             | -0.29556054   |
| qf1_loss                | 0.00013752845 |
| qf2_loss                | 0.00013613334 |
| time_elapsed            | 4188          |
| total timesteps         | 826302        |
| value_loss              | 8.0655605e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019079691  |
| ent_coef_loss           | -3.0046482    |
| entropy                 | 1.2830594     |
| episodes                | 2770          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 828093        |
| policy_loss             | -0.2599492    |
| qf1_loss                | 0.00017167025 |
| qf2_loss                | 0.00011627797 |
| time_elapsed            | 4198          |
| total timesteps         | 828193        |
| value_loss              | 7.374531e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0019058132 |
| ent_coef_loss           | 1.4534255    |
| entropy                 | 1.3007236    |
| episodes                | 2780         |
| fps                     | 197          |
| mean 100 episode reward | 1.6          |
| n_updates               | 829232       |
| policy_loss             | -0.3384917   |
| qf1_loss                | 0.0002766397 |
| qf2_loss                | 0.0003474002 |
| time_elapsed            | 4204         |
| total timesteps         | 829332       |
| value_loss              | 9.662371e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018704671  |
| ent_coef_loss           | 1.3051493     |
| entropy                 | 1.3188623     |
| episodes                | 2790          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 830774        |
| policy_loss             | -0.3578571    |
| qf1_loss                | 9.2140384e-05 |
| qf2_loss                | 0.00012460299 |
| time_elapsed            | 4212          |
| total timesteps         | 830874        |
| value_loss              | 6.4860425e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0018308234   |
| ent_coef_loss           | 1.3687456      |
| entropy                 | 1.3243785      |
| episodes                | 2800           |
| fps                     | 197            |
| mean 100 episode reward | 1.5            |
| n_updates               | 832249         |
| policy_loss             | -0.33019048    |
| qf1_loss                | 7.515945e-05   |
| qf2_loss                | 0.000113998336 |
| time_elapsed            | 4219           |
| total timesteps         | 832349         |
| value_loss              | 0.00011948953  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018176849  |
| ent_coef_loss           | -0.15246665   |
| entropy                 | 1.1572274     |
| episodes                | 2810          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 834001        |
| policy_loss             | -0.351494     |
| qf1_loss                | 0.00021254056 |
| qf2_loss                | 0.00023108665 |
| time_elapsed            | 4228          |
| total timesteps         | 834101        |
| value_loss              | 0.00014475934 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0017882948   |
| ent_coef_loss           | -2.2251272     |
| entropy                 | 1.2118866      |
| episodes                | 2820           |
| fps                     | 197            |
| mean 100 episode reward | 1.5            |
| n_updates               | 835716         |
| policy_loss             | -0.32650942    |
| qf1_loss                | 0.00015737949  |
| qf2_loss                | 0.00017409648  |
| time_elapsed            | 4237           |
| total timesteps         | 835816         |
| value_loss              | 0.000116743875 |
--------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0018064831   |
| ent_coef_loss           | 1.2472489      |
| entropy                 | 1.2516248      |
| episodes                | 2830           |
| fps                     | 197            |
| mean 100 episode reward | 1.5            |
| n_updates               | 837489         |
| policy_loss             | -0.30325484    |
| qf1_loss                | 0.00026433825  |
| qf2_loss                | 0.000122038095 |
| time_elapsed            | 4246           |
| total timesteps         | 837589         |
| value_loss              | 7.064157e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018308618  |
| ent_coef_loss           | -1.2186065    |
| entropy                 | 1.2771764     |
| episodes                | 2840          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 839155        |
| policy_loss             | -0.32288843   |
| qf1_loss                | 0.00012487949 |
| qf2_loss                | 0.00013682836 |
| time_elapsed            | 4254          |
| total timesteps         | 839255        |
| value_loss              | 7.85238e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018541181  |
| ent_coef_loss           | -0.99120206   |
| entropy                 | 1.3002818     |
| episodes                | 2850          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 840687        |
| policy_loss             | -0.29713485   |
| qf1_loss                | 0.00013430111 |
| qf2_loss                | 0.00015835994 |
| time_elapsed            | 4262          |
| total timesteps         | 840787        |
| value_loss              | 8.8659464e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018229858  |
| ent_coef_loss           | 2.138564      |
| entropy                 | 1.2445198     |
| episodes                | 2860          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 842385        |
| policy_loss             | -0.31402016   |
| qf1_loss                | 0.00019620264 |
| qf2_loss                | 0.0002919202  |
| time_elapsed            | 4271          |
| total timesteps         | 842485        |
| value_loss              | 0.0001299716  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0018736477 |
| ent_coef_loss           | -2.1900637   |
| entropy                 | 1.2486517    |
| episodes                | 2870         |
| fps                     | 197          |
| mean 100 episode reward | 1.4          |
| n_updates               | 844216       |
| policy_loss             | -0.3084428   |
| qf1_loss                | 9.311654e-05 |
| qf2_loss                | 9.22623e-05  |
| time_elapsed            | 4280         |
| total timesteps         | 844316       |
| value_loss              | 7.532927e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018786996  |
| ent_coef_loss           | 1.3393689     |
| entropy                 | 1.2629154     |
| episodes                | 2880          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 845836        |
| policy_loss             | -0.3896392    |
| qf1_loss                | 0.00015016983 |
| qf2_loss                | 9.203491e-05  |
| time_elapsed            | 4288          |
| total timesteps         | 845936        |
| value_loss              | 8.116475e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0019044016   |
| ent_coef_loss           | 0.29615948     |
| entropy                 | 1.2549403      |
| episodes                | 2890           |
| fps                     | 197            |
| mean 100 episode reward | 1.5            |
| n_updates               | 847266         |
| policy_loss             | -0.32430947    |
| qf1_loss                | 0.000115204806 |
| qf2_loss                | 0.00013722209  |
| time_elapsed            | 4296           |
| total timesteps         | 847366         |
| value_loss              | 9.6752236e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001932648   |
| ent_coef_loss           | -0.5761284    |
| entropy                 | 1.3311362     |
| episodes                | 2900          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 848916        |
| policy_loss             | -0.25638425   |
| qf1_loss                | 0.00019142337 |
| qf2_loss                | 0.000276957   |
| time_elapsed            | 4304          |
| total timesteps         | 849016        |
| value_loss              | 0.0001295335  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019527664  |
| ent_coef_loss           | 0.4297722     |
| entropy                 | 1.2934778     |
| episodes                | 2910          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 850741        |
| policy_loss             | -0.25078595   |
| qf1_loss                | 0.00029157885 |
| qf2_loss                | 0.00020781555 |
| time_elapsed            | 4313          |
| total timesteps         | 850841        |
| value_loss              | 0.00016201509 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019065249  |
| ent_coef_loss           | -0.9855069    |
| entropy                 | 1.3182843     |
| episodes                | 2920          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 852439        |
| policy_loss             | -0.2609241    |
| qf1_loss                | 0.00016953768 |
| qf2_loss                | 0.00010726815 |
| time_elapsed            | 4322          |
| total timesteps         | 852539        |
| value_loss              | 0.00014539258 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018972004  |
| ent_coef_loss           | 3.7369497     |
| entropy                 | 1.2506425     |
| episodes                | 2930          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 854237        |
| policy_loss             | -0.33338004   |
| qf1_loss                | 0.0001227813  |
| qf2_loss                | 0.00010406648 |
| time_elapsed            | 4331          |
| total timesteps         | 854337        |
| value_loss              | 0.00021578406 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001935891   |
| ent_coef_loss           | 0.31925458    |
| entropy                 | 1.3117847     |
| episodes                | 2940          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 856211        |
| policy_loss             | -0.23891744   |
| qf1_loss                | 0.00027102313 |
| qf2_loss                | 0.00020084353 |
| time_elapsed            | 4341          |
| total timesteps         | 856311        |
| value_loss              | 0.00010195517 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0019316106   |
| ent_coef_loss           | 3.2075787      |
| entropy                 | 1.3050079      |
| episodes                | 2950           |
| fps                     | 197            |
| mean 100 episode reward | 1.6            |
| n_updates               | 857936         |
| policy_loss             | -0.26747006    |
| qf1_loss                | 0.00028343263  |
| qf2_loss                | 0.00076690834  |
| time_elapsed            | 4350           |
| total timesteps         | 858036         |
| value_loss              | 0.000104001156 |
--------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0019366997   |
| ent_coef_loss           | -2.7697597     |
| entropy                 | 1.304153       |
| episodes                | 2960           |
| fps                     | 197            |
| mean 100 episode reward | 1.6            |
| n_updates               | 859664         |
| policy_loss             | -0.31360358    |
| qf1_loss                | 0.0002081251   |
| qf2_loss                | 0.00022304532  |
| time_elapsed            | 4359           |
| total timesteps         | 859764         |
| value_loss              | 0.000101857746 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019276192  |
| ent_coef_loss           | 2.0083299     |
| entropy                 | 1.3330181     |
| episodes                | 2970          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 860749        |
| policy_loss             | -0.34327513   |
| qf1_loss                | 0.00042430044 |
| qf2_loss                | 0.00049639924 |
| time_elapsed            | 4364          |
| total timesteps         | 860849        |
| value_loss              | 0.00014095781 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019269695  |
| ent_coef_loss           | -0.34596384   |
| entropy                 | 1.3581421     |
| episodes                | 2980          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 862655        |
| policy_loss             | -0.24696717   |
| qf1_loss                | 0.00031709875 |
| qf2_loss                | 0.00018595895 |
| time_elapsed            | 4374          |
| total timesteps         | 862755        |
| value_loss              | 0.00013607662 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018844444  |
| ent_coef_loss           | -0.26522252   |
| entropy                 | 1.322198      |
| episodes                | 2990          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 864397        |
| policy_loss             | -0.226866     |
| qf1_loss                | 0.00015736095 |
| qf2_loss                | 0.00021822542 |
| time_elapsed            | 4383          |
| total timesteps         | 864497        |
| value_loss              | 0.0001186567  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018675876  |
| ent_coef_loss           | -2.4532754    |
| entropy                 | 1.3296835     |
| episodes                | 3000          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 866223        |
| policy_loss             | -0.23151949   |
| qf1_loss                | 0.00013127679 |
| qf2_loss                | 0.00011304473 |
| time_elapsed            | 4392          |
| total timesteps         | 866323        |
| value_loss              | 0.00012783191 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018853531  |
| ent_coef_loss           | 1.3171175     |
| entropy                 | 1.3033078     |
| episodes                | 3010          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 867653        |
| policy_loss             | -0.30472457   |
| qf1_loss                | 0.00013401525 |
| qf2_loss                | 0.00020918205 |
| time_elapsed            | 4399          |
| total timesteps         | 867753        |
| value_loss              | 9.737736e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018579325  |
| ent_coef_loss           | -1.5197102    |
| entropy                 | 1.2801456     |
| episodes                | 3020          |
| fps                     | 197           |
| mean 100 episode reward | 1.3           |
| n_updates               | 870347        |
| policy_loss             | -0.27619308   |
| qf1_loss                | 0.00097230927 |
| qf2_loss                | 0.00064406346 |
| time_elapsed            | 4413          |
| total timesteps         | 870447        |
| value_loss              | 0.00010364662 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001845019   |
| ent_coef_loss           | 0.69886476    |
| entropy                 | 1.2781887     |
| episodes                | 3030          |
| fps                     | 197           |
| mean 100 episode reward | 1.2           |
| n_updates               | 872071        |
| policy_loss             | -0.18713781   |
| qf1_loss                | 0.00021669906 |
| qf2_loss                | 0.00014029176 |
| time_elapsed            | 4422          |
| total timesteps         | 872171        |
| value_loss              | 0.00013001452 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018687875  |
| ent_coef_loss           | -1.4514134    |
| entropy                 | 1.3453326     |
| episodes                | 3040          |
| fps                     | 197           |
| mean 100 episode reward | 1.3           |
| n_updates               | 873626        |
| policy_loss             | -0.23864529   |
| qf1_loss                | 0.0004508358  |
| qf2_loss                | 0.00028877557 |
| time_elapsed            | 4430          |
| total timesteps         | 873726        |
| value_loss              | 0.00012289186 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018868532  |
| ent_coef_loss           | -0.41840565   |
| entropy                 | 1.2778461     |
| episodes                | 3050          |
| fps                     | 197           |
| mean 100 episode reward | 1.3           |
| n_updates               | 875541        |
| policy_loss             | -0.22678597   |
| qf1_loss                | 0.00084642734 |
| qf2_loss                | 0.00081108685 |
| time_elapsed            | 4440          |
| total timesteps         | 875641        |
| value_loss              | 0.00028945555 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019146806  |
| ent_coef_loss           | -0.540089     |
| entropy                 | 1.3575927     |
| episodes                | 3060          |
| fps                     | 197           |
| mean 100 episode reward | 1.3           |
| n_updates               | 877305        |
| policy_loss             | -0.26617783   |
| qf1_loss                | 0.00015380068 |
| qf2_loss                | 0.00011087486 |
| time_elapsed            | 4449          |
| total timesteps         | 877405        |
| value_loss              | 6.830465e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001946507   |
| ent_coef_loss           | -0.8038353    |
| entropy                 | 1.3499973     |
| episodes                | 3070          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 879029        |
| policy_loss             | -0.37092036   |
| qf1_loss                | 0.00027863547 |
| qf2_loss                | 0.00016578201 |
| time_elapsed            | 4457          |
| total timesteps         | 879129        |
| value_loss              | 0.0001249935  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019485139  |
| ent_coef_loss           | -0.98723924   |
| entropy                 | 1.3328761     |
| episodes                | 3080          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 880677        |
| policy_loss             | -0.30682874   |
| qf1_loss                | 0.00023455186 |
| qf2_loss                | 0.00028310434 |
| time_elapsed            | 4466          |
| total timesteps         | 880777        |
| value_loss              | 7.963499e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019789068  |
| ent_coef_loss           | -2.0070052    |
| entropy                 | 1.3428723     |
| episodes                | 3090          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 882256        |
| policy_loss             | -0.32403323   |
| qf1_loss                | 0.00026277517 |
| qf2_loss                | 0.0001578006  |
| time_elapsed            | 4474          |
| total timesteps         | 882356        |
| value_loss              | 0.00016803571 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.002011002   |
| ent_coef_loss           | -0.14665991   |
| entropy                 | 1.3995204     |
| episodes                | 3100          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 884172        |
| policy_loss             | -0.39835447   |
| qf1_loss                | 0.00029745826 |
| qf2_loss                | 0.0001964473  |
| time_elapsed            | 4484          |
| total timesteps         | 884272        |
| value_loss              | 0.00015252357 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020723473  |
| ent_coef_loss           | -1.5136613    |
| entropy                 | 1.3827229     |
| episodes                | 3110          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 885812        |
| policy_loss             | -0.25081727   |
| qf1_loss                | 0.00015555877 |
| qf2_loss                | 0.00025474012 |
| time_elapsed            | 4492          |
| total timesteps         | 885912        |
| value_loss              | 8.3410225e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020514557  |
| ent_coef_loss           | -0.6105028    |
| entropy                 | 1.4195949     |
| episodes                | 3120          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 887174        |
| policy_loss             | -0.25157      |
| qf1_loss                | 0.00022715172 |
| qf2_loss                | 0.0002653896  |
| time_elapsed            | 4499          |
| total timesteps         | 887274        |
| value_loss              | 8.574115e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0020133355  |
| ent_coef_loss           | 1.0714799     |
| entropy                 | 1.3124897     |
| episodes                | 3130          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 888694        |
| policy_loss             | -0.2793625    |
| qf1_loss                | 0.0005286507  |
| qf2_loss                | 0.0005669209  |
| time_elapsed            | 4507          |
| total timesteps         | 888794        |
| value_loss              | 0.00024827223 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019879239  |
| ent_coef_loss           | -1.010087     |
| entropy                 | 1.3314147     |
| episodes                | 3140          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 890219        |
| policy_loss             | -0.2914834    |
| qf1_loss                | 0.00027853448 |
| qf2_loss                | 0.0001557084  |
| time_elapsed            | 4515          |
| total timesteps         | 890319        |
| value_loss              | 0.00019916476 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0019659642  |
| ent_coef_loss           | 2.857911      |
| entropy                 | 1.3654115     |
| episodes                | 3150          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 891991        |
| policy_loss             | -0.27833402   |
| qf1_loss                | 0.00031414878 |
| qf2_loss                | 0.0002261782  |
| time_elapsed            | 4524          |
| total timesteps         | 892091        |
| value_loss              | 0.00021093151 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001966252   |
| ent_coef_loss           | -2.7879686    |
| entropy                 | 1.370882      |
| episodes                | 3160          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 893137        |
| policy_loss             | -0.27645743   |
| qf1_loss                | 0.00018183001 |
| qf2_loss                | 0.00025440924 |
| time_elapsed            | 4530          |
| total timesteps         | 893237        |
| value_loss              | 0.00012958815 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001945837   |
| ent_coef_loss           | -1.2973468    |
| entropy                 | 1.2436391     |
| episodes                | 3170          |
| fps                     | 197           |
| mean 100 episode reward | 1.3           |
| n_updates               | 894729        |
| policy_loss             | -0.23055798   |
| qf1_loss                | 0.00018435447 |
| qf2_loss                | 0.00024024647 |
| time_elapsed            | 4538          |
| total timesteps         | 894829        |
| value_loss              | 0.00012134935 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018954119  |
| ent_coef_loss           | -0.368102     |
| entropy                 | 1.2963593     |
| episodes                | 3180          |
| fps                     | 197           |
| mean 100 episode reward | 1.2           |
| n_updates               | 896282        |
| policy_loss             | -0.26488644   |
| qf1_loss                | 0.00043602104 |
| qf2_loss                | 0.00039084707 |
| time_elapsed            | 4546          |
| total timesteps         | 896382        |
| value_loss              | 0.00020491678 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018399392  |
| ent_coef_loss           | 3.1054602     |
| entropy                 | 1.2402438     |
| episodes                | 3190          |
| fps                     | 197           |
| mean 100 episode reward | 1.2           |
| n_updates               | 897744        |
| policy_loss             | -0.21920118   |
| qf1_loss                | 0.00012958345 |
| qf2_loss                | 0.00018238253 |
| time_elapsed            | 4553          |
| total timesteps         | 897844        |
| value_loss              | 0.00011945046 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018132508  |
| ent_coef_loss           | 1.4346272     |
| entropy                 | 1.2799801     |
| episodes                | 3200          |
| fps                     | 197           |
| mean 100 episode reward | 1.2           |
| n_updates               | 899385        |
| policy_loss             | -0.20135666   |
| qf1_loss                | 0.0002496688  |
| qf2_loss                | 0.00028360603 |
| time_elapsed            | 4561          |
| total timesteps         | 899485        |
| value_loss              | 0.00010957557 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018128463  |
| ent_coef_loss           | -1.1113231    |
| entropy                 | 1.2515877     |
| episodes                | 3210          |
| fps                     | 197           |
| mean 100 episode reward | 1.2           |
| n_updates               | 901117        |
| policy_loss             | -0.34356165   |
| qf1_loss                | 0.00010226593 |
| qf2_loss                | 8.1115424e-05 |
| time_elapsed            | 4570          |
| total timesteps         | 901217        |
| value_loss              | 9.898309e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018151688  |
| ent_coef_loss           | -0.05498898   |
| entropy                 | 1.3037871     |
| episodes                | 3220          |
| fps                     | 197           |
| mean 100 episode reward | 1.3           |
| n_updates               | 902716        |
| policy_loss             | -0.28422612   |
| qf1_loss                | 0.0001264464  |
| qf2_loss                | 0.00012161915 |
| time_elapsed            | 4578          |
| total timesteps         | 902816        |
| value_loss              | 0.00011398597 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018078472  |
| ent_coef_loss           | 0.97861046    |
| entropy                 | 1.2365649     |
| episodes                | 3230          |
| fps                     | 197           |
| mean 100 episode reward | 1.3           |
| n_updates               | 904672        |
| policy_loss             | -0.2884633    |
| qf1_loss                | 0.00033319305 |
| qf2_loss                | 0.00016168028 |
| time_elapsed            | 4588          |
| total timesteps         | 904772        |
| value_loss              | 0.00018852764 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018084913  |
| ent_coef_loss           | 0.67396146    |
| entropy                 | 1.2486819     |
| episodes                | 3240          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 906473        |
| policy_loss             | -0.31919873   |
| qf1_loss                | 0.00043134135 |
| qf2_loss                | 0.0003455493  |
| time_elapsed            | 4597          |
| total timesteps         | 906573        |
| value_loss              | 0.00016049814 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018236552  |
| ent_coef_loss           | 1.0332029     |
| entropy                 | 1.2921019     |
| episodes                | 3250          |
| fps                     | 197           |
| mean 100 episode reward | 1.4           |
| n_updates               | 908287        |
| policy_loss             | -0.2718702    |
| qf1_loss                | 0.0012284754  |
| qf2_loss                | 0.0010787601  |
| time_elapsed            | 4606          |
| total timesteps         | 908387        |
| value_loss              | 0.00018955312 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0018366941   |
| ent_coef_loss           | 2.8569126      |
| entropy                 | 1.3020761      |
| episodes                | 3260           |
| fps                     | 197            |
| mean 100 episode reward | 1.5            |
| n_updates               | 910047         |
| policy_loss             | -0.29492062    |
| qf1_loss                | 0.00052284094  |
| qf2_loss                | 0.0006024498   |
| time_elapsed            | 4615           |
| total timesteps         | 910147         |
| value_loss              | 0.000103360566 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018381117  |
| ent_coef_loss           | -0.15020981   |
| entropy                 | 1.2585086     |
| episodes                | 3270          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 911803        |
| policy_loss             | -0.27587086   |
| qf1_loss                | 0.00044993826 |
| qf2_loss                | 0.0003012287  |
| time_elapsed            | 4624          |
| total timesteps         | 911903        |
| value_loss              | 0.00016220259 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017821894  |
| ent_coef_loss           | 0.32594573    |
| entropy                 | 1.2582132     |
| episodes                | 3280          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 913404        |
| policy_loss             | -0.21743326   |
| qf1_loss                | 0.0002679467  |
| qf2_loss                | 0.00020429533 |
| time_elapsed            | 4633          |
| total timesteps         | 913504        |
| value_loss              | 0.00025072222 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017986605  |
| ent_coef_loss           | -0.64098024   |
| entropy                 | 1.2472823     |
| episodes                | 3290          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 915011        |
| policy_loss             | -0.31284505   |
| qf1_loss                | 0.00027760328 |
| qf2_loss                | 0.00010275538 |
| time_elapsed            | 4641          |
| total timesteps         | 915111        |
| value_loss              | 6.359999e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018199632  |
| ent_coef_loss           | 1.5112195     |
| entropy                 | 1.2563227     |
| episodes                | 3300          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 916729        |
| policy_loss             | -0.2831392    |
| qf1_loss                | 0.00012939518 |
| qf2_loss                | 0.00016848613 |
| time_elapsed            | 4649          |
| total timesteps         | 916829        |
| value_loss              | 8.568731e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018180498  |
| ent_coef_loss           | 3.5370371     |
| entropy                 | 1.2249844     |
| episodes                | 3310          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 918272        |
| policy_loss             | -0.16202429   |
| qf1_loss                | 0.00047678917 |
| qf2_loss                | 0.00043428998 |
| time_elapsed            | 4657          |
| total timesteps         | 918372        |
| value_loss              | 0.00011260679 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018287669  |
| ent_coef_loss           | 0.6500077     |
| entropy                 | 1.3365171     |
| episodes                | 3320          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 919991        |
| policy_loss             | -0.23994222   |
| qf1_loss                | 0.00030748354 |
| qf2_loss                | 0.00019140588 |
| time_elapsed            | 4666          |
| total timesteps         | 920091        |
| value_loss              | 0.00011647324 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017803063  |
| ent_coef_loss           | 1.4112804     |
| entropy                 | 1.2910614     |
| episodes                | 3330          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 921754        |
| policy_loss             | -0.2789152    |
| qf1_loss                | 0.00010936391 |
| qf2_loss                | 0.00014580316 |
| time_elapsed            | 4675          |
| total timesteps         | 921854        |
| value_loss              | 7.214722e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017749248  |
| ent_coef_loss           | -2.3397741    |
| entropy                 | 1.3125354     |
| episodes                | 3340          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 923519        |
| policy_loss             | -0.29125145   |
| qf1_loss                | 0.00048672335 |
| qf2_loss                | 0.0004343239  |
| time_elapsed            | 4684          |
| total timesteps         | 923619        |
| value_loss              | 0.00013976874 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018007107  |
| ent_coef_loss           | 2.0980244     |
| entropy                 | 1.133522      |
| episodes                | 3350          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 925263        |
| policy_loss             | -0.17338443   |
| qf1_loss                | 0.00023832633 |
| qf2_loss                | 0.00013369892 |
| time_elapsed            | 4693          |
| total timesteps         | 925363        |
| value_loss              | 0.00013548305 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018113877  |
| ent_coef_loss           | -0.9240345    |
| entropy                 | 1.2428784     |
| episodes                | 3360          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 927033        |
| policy_loss             | -0.34274697   |
| qf1_loss                | 0.00019578091 |
| qf2_loss                | 0.00018855816 |
| time_elapsed            | 4701          |
| total timesteps         | 927133        |
| value_loss              | 0.00018314246 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001769821   |
| ent_coef_loss           | -3.4554422    |
| entropy                 | 1.2349758     |
| episodes                | 3370          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 928924        |
| policy_loss             | -0.33128726   |
| qf1_loss                | 0.00021993913 |
| qf2_loss                | 0.0001950631  |
| time_elapsed            | 4711          |
| total timesteps         | 929024        |
| value_loss              | 8.611068e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017730223  |
| ent_coef_loss           | 3.585007      |
| entropy                 | 1.2720904     |
| episodes                | 3380          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 930667        |
| policy_loss             | -0.30115694   |
| qf1_loss                | 0.00021610127 |
| qf2_loss                | 0.00026277115 |
| time_elapsed            | 4720          |
| total timesteps         | 930767        |
| value_loss              | 7.8104764e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017875786  |
| ent_coef_loss           | -1.8630846    |
| entropy                 | 1.2324176     |
| episodes                | 3390          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 932506        |
| policy_loss             | -0.29856795   |
| qf1_loss                | 0.00019333487 |
| qf2_loss                | 0.00028402652 |
| time_elapsed            | 4729          |
| total timesteps         | 932606        |
| value_loss              | 0.00033863477 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017752303  |
| ent_coef_loss           | -0.33330095   |
| entropy                 | 1.3031547     |
| episodes                | 3400          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 934339        |
| policy_loss             | -0.19016814   |
| qf1_loss                | 0.00022603854 |
| qf2_loss                | 0.00021704254 |
| time_elapsed            | 4738          |
| total timesteps         | 934439        |
| value_loss              | 0.00010813211 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017597842  |
| ent_coef_loss           | -0.2548455    |
| entropy                 | 1.2823973     |
| episodes                | 3410          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 935983        |
| policy_loss             | -0.41138667   |
| qf1_loss                | 0.0012233286  |
| qf2_loss                | 0.0037952675  |
| time_elapsed            | 4747          |
| total timesteps         | 936083        |
| value_loss              | 0.00012900145 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017758458  |
| ent_coef_loss           | 1.0734141     |
| entropy                 | 1.331623      |
| episodes                | 3420          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 937801        |
| policy_loss             | -0.30171466   |
| qf1_loss                | 0.00020359473 |
| qf2_loss                | 0.00025159356 |
| time_elapsed            | 4756          |
| total timesteps         | 937901        |
| value_loss              | 7.440377e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017369324  |
| ent_coef_loss           | 0.25073856    |
| entropy                 | 1.3022727     |
| episodes                | 3430          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 939502        |
| policy_loss             | -0.30313665   |
| qf1_loss                | 0.00023370644 |
| qf2_loss                | 0.00047682045 |
| time_elapsed            | 4764          |
| total timesteps         | 939602        |
| value_loss              | 8.787145e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016966148  |
| ent_coef_loss           | -1.8339393    |
| entropy                 | 1.1442707     |
| episodes                | 3440          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 941307        |
| policy_loss             | -0.31722823   |
| qf1_loss                | 0.00016498234 |
| qf2_loss                | 0.00019703747 |
| time_elapsed            | 4773          |
| total timesteps         | 941407        |
| value_loss              | 9.9309924e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001721863   |
| ent_coef_loss           | 0.89624774    |
| entropy                 | 1.1935617     |
| episodes                | 3450          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 943295        |
| policy_loss             | -0.2784145    |
| qf1_loss                | 0.00013916306 |
| qf2_loss                | 0.00018051342 |
| time_elapsed            | 4783          |
| total timesteps         | 943395        |
| value_loss              | 0.00024460175 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017509377  |
| ent_coef_loss           | 3.3973064     |
| entropy                 | 1.294481      |
| episodes                | 3460          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 944534        |
| policy_loss             | -0.22127709   |
| qf1_loss                | 0.0003114973  |
| qf2_loss                | 0.00020818635 |
| time_elapsed            | 4790          |
| total timesteps         | 944634        |
| value_loss              | 0.00013741438 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017932858  |
| ent_coef_loss           | -0.30459547   |
| entropy                 | 1.2027082     |
| episodes                | 3470          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 946300        |
| policy_loss             | -0.24310908   |
| qf1_loss                | 0.00039680736 |
| qf2_loss                | 0.0005229309  |
| time_elapsed            | 4799          |
| total timesteps         | 946400        |
| value_loss              | 0.0001151929  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017834714  |
| ent_coef_loss           | -2.0674198    |
| entropy                 | 1.2315989     |
| episodes                | 3480          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 947944        |
| policy_loss             | -0.24150869   |
| qf1_loss                | 0.00020886175 |
| qf2_loss                | 0.00016106243 |
| time_elapsed            | 4807          |
| total timesteps         | 948044        |
| value_loss              | 0.00013997495 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001771818   |
| ent_coef_loss           | -2.3386016    |
| entropy                 | 1.2613801     |
| episodes                | 3490          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 950242        |
| policy_loss             | -0.37936625   |
| qf1_loss                | 0.0003523075  |
| qf2_loss                | 0.0002952506  |
| time_elapsed            | 4819          |
| total timesteps         | 950342        |
| value_loss              | 0.00018180328 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001786855   |
| ent_coef_loss           | 2.8497872     |
| entropy                 | 1.2195404     |
| episodes                | 3500          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 952019        |
| policy_loss             | -0.29041716   |
| qf1_loss                | 0.00018505847 |
| qf2_loss                | 0.00015756137 |
| time_elapsed            | 4828          |
| total timesteps         | 952119        |
| value_loss              | 8.761724e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017915354  |
| ent_coef_loss           | -1.0423067    |
| entropy                 | 1.3013017     |
| episodes                | 3510          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 953550        |
| policy_loss             | -0.31935662   |
| qf1_loss                | 0.00022353367 |
| qf2_loss                | 0.00019099293 |
| time_elapsed            | 4836          |
| total timesteps         | 953650        |
| value_loss              | 0.00010926949 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017748782  |
| ent_coef_loss           | 1.4452062     |
| entropy                 | 1.3075032     |
| episodes                | 3520          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 955265        |
| policy_loss             | -0.27232334   |
| qf1_loss                | 0.00026368105 |
| qf2_loss                | 0.0005215773  |
| time_elapsed            | 4844          |
| total timesteps         | 955365        |
| value_loss              | 9.162273e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017455975  |
| ent_coef_loss           | 1.6612498     |
| entropy                 | 1.2746053     |
| episodes                | 3530          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 957295        |
| policy_loss             | -0.31696174   |
| qf1_loss                | 0.0005521825  |
| qf2_loss                | 0.0002810193  |
| time_elapsed            | 4855          |
| total timesteps         | 957395        |
| value_loss              | 0.00019510434 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017459437  |
| ent_coef_loss           | -0.3166585    |
| entropy                 | 1.3278874     |
| episodes                | 3540          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 958912        |
| policy_loss             | -0.31670424   |
| qf1_loss                | 0.00018558188 |
| qf2_loss                | 0.00019707411 |
| time_elapsed            | 4863          |
| total timesteps         | 959012        |
| value_loss              | 7.345847e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017585577  |
| ent_coef_loss           | 1.957958      |
| entropy                 | 1.301573      |
| episodes                | 3550          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 960670        |
| policy_loss             | -0.2816172    |
| qf1_loss                | 0.00064074073 |
| qf2_loss                | 0.00067218795 |
| time_elapsed            | 4872          |
| total timesteps         | 960770        |
| value_loss              | 0.00011411554 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017437439  |
| ent_coef_loss           | -0.3953318    |
| entropy                 | 1.2621409     |
| episodes                | 3560          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 962326        |
| policy_loss             | -0.3193658    |
| qf1_loss                | 0.0001248609  |
| qf2_loss                | 0.00017635553 |
| time_elapsed            | 4880          |
| total timesteps         | 962426        |
| value_loss              | 7.592956e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016960445  |
| ent_coef_loss           | 1.1659019     |
| entropy                 | 1.3002995     |
| episodes                | 3570          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 964087        |
| policy_loss             | -0.28660256   |
| qf1_loss                | 0.00037438303 |
| qf2_loss                | 0.0003273653  |
| time_elapsed            | 4889          |
| total timesteps         | 964187        |
| value_loss              | 0.00011212162 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016800131  |
| ent_coef_loss           | 1.2777762     |
| entropy                 | 1.323057      |
| episodes                | 3580          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 965495        |
| policy_loss             | -0.33585656   |
| qf1_loss                | 0.00054441334 |
| qf2_loss                | 0.0004595724  |
| time_elapsed            | 4896          |
| total timesteps         | 965595        |
| value_loss              | 0.00010718862 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017160099  |
| ent_coef_loss           | 0.18096024    |
| entropy                 | 1.2620698     |
| episodes                | 3590          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 967265        |
| policy_loss             | -0.39061695   |
| qf1_loss                | 0.000367361   |
| qf2_loss                | 0.00036544824 |
| time_elapsed            | 4905          |
| total timesteps         | 967365        |
| value_loss              | 0.00010406423 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017567726  |
| ent_coef_loss           | 1.3814826     |
| entropy                 | 1.2886698     |
| episodes                | 3600          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 969028        |
| policy_loss             | -0.3348546    |
| qf1_loss                | 0.00014139104 |
| qf2_loss                | 0.00014467354 |
| time_elapsed            | 4914          |
| total timesteps         | 969128        |
| value_loss              | 0.00016026528 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017641034  |
| ent_coef_loss           | -1.4837677    |
| entropy                 | 1.3297257     |
| episodes                | 3610          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 970652        |
| policy_loss             | -0.33398354   |
| qf1_loss                | 0.00021261886 |
| qf2_loss                | 0.00015459507 |
| time_elapsed            | 4922          |
| total timesteps         | 970752        |
| value_loss              | 0.00012466958 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0017553515   |
| ent_coef_loss           | -0.6865195     |
| entropy                 | 1.3193538      |
| episodes                | 3620           |
| fps                     | 197            |
| mean 100 episode reward | 1.7            |
| n_updates               | 972480         |
| policy_loss             | -0.29631573    |
| qf1_loss                | 0.00023174475  |
| qf2_loss                | 0.00028883718  |
| time_elapsed            | 4931           |
| total timesteps         | 972580         |
| value_loss              | 0.000104862964 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017608678  |
| ent_coef_loss           | 0.78423494    |
| entropy                 | 1.3321753     |
| episodes                | 3630          |
| fps                     | 197           |
| mean 100 episode reward | 1.6           |
| n_updates               | 973824        |
| policy_loss             | -0.3100239    |
| qf1_loss                | 0.00045630027 |
| qf2_loss                | 0.00063409307 |
| time_elapsed            | 4938          |
| total timesteps         | 973924        |
| value_loss              | 0.00014797701 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.001762901    |
| ent_coef_loss           | -0.35225296    |
| entropy                 | 1.3411441      |
| episodes                | 3640           |
| fps                     | 197            |
| mean 100 episode reward | 1.5            |
| n_updates               | 975402         |
| policy_loss             | -0.30625358    |
| qf1_loss                | 0.00014736508  |
| qf2_loss                | 0.000105690735 |
| time_elapsed            | 4946           |
| total timesteps         | 975502         |
| value_loss              | 7.08069e-05    |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016923356  |
| ent_coef_loss           | 3.2731776     |
| entropy                 | 1.3905762     |
| episodes                | 3650          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 977246        |
| policy_loss             | -0.26694578   |
| qf1_loss                | 0.00014197541 |
| qf2_loss                | 0.00023861018 |
| time_elapsed            | 4955          |
| total timesteps         | 977346        |
| value_loss              | 0.00012485673 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016473238  |
| ent_coef_loss           | -1.7040614    |
| entropy                 | 1.219506      |
| episodes                | 3660          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 978997        |
| policy_loss             | -0.30483514   |
| qf1_loss                | 0.00029292775 |
| qf2_loss                | 0.00043959756 |
| time_elapsed            | 4964          |
| total timesteps         | 979097        |
| value_loss              | 7.288898e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016495303  |
| ent_coef_loss           | 1.1700681     |
| entropy                 | 1.2592797     |
| episodes                | 3670          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 980705        |
| policy_loss             | -0.3607893    |
| qf1_loss                | 0.00019639384 |
| qf2_loss                | 0.00042209594 |
| time_elapsed            | 4973          |
| total timesteps         | 980805        |
| value_loss              | 7.5461736e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001661718   |
| ent_coef_loss           | 0.15582836    |
| entropy                 | 1.2993271     |
| episodes                | 3680          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 982380        |
| policy_loss             | -0.28841543   |
| qf1_loss                | 0.0001114682  |
| qf2_loss                | 0.00012337725 |
| time_elapsed            | 4982          |
| total timesteps         | 982480        |
| value_loss              | 0.00010905528 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016099066  |
| ent_coef_loss           | 1.5939409     |
| entropy                 | 1.2984228     |
| episodes                | 3690          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 984104        |
| policy_loss             | -0.39419055   |
| qf1_loss                | 0.00012633481 |
| qf2_loss                | 9.623151e-05  |
| time_elapsed            | 4990          |
| total timesteps         | 984204        |
| value_loss              | 7.395302e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016448686  |
| ent_coef_loss           | 0.26175845    |
| entropy                 | 1.2743512     |
| episodes                | 3700          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 985806        |
| policy_loss             | -0.244834     |
| qf1_loss                | 0.00018546238 |
| qf2_loss                | 0.00021832528 |
| time_elapsed            | 4999          |
| total timesteps         | 985906        |
| value_loss              | 0.00015925796 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001647536   |
| ent_coef_loss           | 1.0153977     |
| entropy                 | 1.3645201     |
| episodes                | 3710          |
| fps                     | 197           |
| mean 100 episode reward | 1.5           |
| n_updates               | 987524        |
| policy_loss             | -0.3402795    |
| qf1_loss                | 0.0002784284  |
| qf2_loss                | 0.0001522901  |
| time_elapsed            | 5009          |
| total timesteps         | 987624        |
| value_loss              | 0.00010154121 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0016905644   |
| ent_coef_loss           | -0.20113105    |
| entropy                 | 1.2794671      |
| episodes                | 3720           |
| fps                     | 197            |
| mean 100 episode reward | 1.6            |
| n_updates               | 989178         |
| policy_loss             | -0.3576562     |
| qf1_loss                | 0.00030172878  |
| qf2_loss                | 0.00011886374  |
| time_elapsed            | 5017           |
| total timesteps         | 989278         |
| value_loss              | 0.000121906116 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017223911  |
| ent_coef_loss           | 1.3481898     |
| entropy                 | 1.2709558     |
| episodes                | 3730          |
| fps                     | 197           |
| mean 100 episode reward | 1.7           |
| n_updates               | 990946        |
| policy_loss             | -0.39050287   |
| qf1_loss                | 0.0006424028  |
| qf2_loss                | 0.00018806229 |
| time_elapsed            | 5026          |
| total timesteps         | 991046        |
| value_loss              | 0.00016763242 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017135226  |
| ent_coef_loss           | -3.5511308    |
| entropy                 | 1.2260528     |
| episodes                | 3740          |
| fps                     | 197           |
| mean 100 episode reward | 1.8           |
| n_updates               | 992609        |
| policy_loss             | -0.34790835   |
| qf1_loss                | 0.00018400635 |
| qf2_loss                | 8.3660176e-05 |
| time_elapsed            | 5035          |
| total timesteps         | 992709        |
| value_loss              | 8.8541885e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016833297  |
| ent_coef_loss           | -0.9201029    |
| entropy                 | 1.2625259     |
| episodes                | 3750          |
| fps                     | 197           |
| mean 100 episode reward | 1.8           |
| n_updates               | 994377        |
| policy_loss             | -0.27541703   |
| qf1_loss                | 0.00031687814 |
| qf2_loss                | 0.0005200495  |
| time_elapsed            | 5044          |
| total timesteps         | 994477        |
| value_loss              | 0.0008278488  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017005827  |
| ent_coef_loss           | 0.3888378     |
| entropy                 | 1.3664613     |
| episodes                | 3760          |
| fps                     | 197           |
| mean 100 episode reward | 1.8           |
| n_updates               | 996024        |
| policy_loss             | -0.40372425   |
| qf1_loss                | 0.00022291788 |
| qf2_loss                | 0.00021921612 |
| time_elapsed            | 5053          |
| total timesteps         | 996124        |
| value_loss              | 0.00019686356 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001649708   |
| ent_coef_loss           | -1.0623246    |
| entropy                 | 1.2172724     |
| episodes                | 3770          |
| fps                     | 197           |
| mean 100 episode reward | 1.8           |
| n_updates               | 997870        |
| policy_loss             | -0.3558287    |
| qf1_loss                | 0.00020005592 |
| qf2_loss                | 0.0001916527  |
| time_elapsed            | 5063          |
| total timesteps         | 997970        |
| value_loss              | 0.00015205127 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016480498  |
| ent_coef_loss           | 2.8710465     |
| entropy                 | 1.3496053     |
| episodes                | 3780          |
| fps                     | 197           |
| mean 100 episode reward | 1.8           |
| n_updates               | 999584        |
| policy_loss             | -0.36537006   |
| qf1_loss                | 0.00025941    |
| qf2_loss                | 0.00016184714 |
| time_elapsed            | 5072          |
| total timesteps         | 999684        |
| value_loss              | 0.00017970477 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016594122  |
| ent_coef_loss           | -0.90586984   |
| entropy                 | 1.2467091     |
| episodes                | 3790          |
| fps                     | 197           |
| mean 100 episode reward | 1.8           |
| n_updates               | 1001251       |
| policy_loss             | -0.36452246   |
| qf1_loss                | 0.0003522283  |
| qf2_loss                | 0.00029340922 |
| time_elapsed            | 5081          |
| total timesteps         | 1001351       |
| value_loss              | 6.360977e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016388356  |
| ent_coef_loss           | 0.022638112   |
| entropy                 | 1.4162062     |
| episodes                | 3800          |
| fps                     | 197           |
| mean 100 episode reward | 1.8           |
| n_updates               | 1003028       |
| policy_loss             | -0.33607554   |
| qf1_loss                | 0.00013336379 |
| qf2_loss                | 0.00012535512 |
| time_elapsed            | 5090          |
| total timesteps         | 1003128       |
| value_loss              | 6.6630535e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001626632   |
| ent_coef_loss           | -1.1828498    |
| entropy                 | 1.2719576     |
| episodes                | 3810          |
| fps                     | 197           |
| mean 100 episode reward | 1.8           |
| n_updates               | 1004877       |
| policy_loss             | -0.34925082   |
| qf1_loss                | 0.00013617377 |
| qf2_loss                | 7.632536e-05  |
| time_elapsed            | 5100          |
| total timesteps         | 1004977       |
| value_loss              | 8.1161e-05    |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.001639504  |
| ent_coef_loss           | -1.493517    |
| entropy                 | 1.3075862    |
| episodes                | 3820         |
| fps                     | 197          |
| mean 100 episode reward | 1.8          |
| n_updates               | 1006606      |
| policy_loss             | -0.48348126  |
| qf1_loss                | 7.667755e-05 |
| qf2_loss                | 7.04135e-05  |
| time_elapsed            | 5109         |
| total timesteps         | 1006706      |
| value_loss              | 6.426066e-05 |
------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0016139834   |
| ent_coef_loss           | 0.039250016    |
| entropy                 | 1.336198       |
| episodes                | 3830           |
| fps                     | 196            |
| mean 100 episode reward | 1.7            |
| n_updates               | 1008265        |
| policy_loss             | -0.3836344     |
| qf1_loss                | 5.5570195e-05  |
| qf2_loss                | 0.000118747426 |
| time_elapsed            | 5119           |
| total timesteps         | 1008365        |
| value_loss              | 0.00018554376  |
--------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0016286701   |
| ent_coef_loss           | 0.7986053      |
| entropy                 | 1.2788377      |
| episodes                | 3840           |
| fps                     | 196            |
| mean 100 episode reward | 1.7            |
| n_updates               | 1010016        |
| policy_loss             | -0.379795      |
| qf1_loss                | 0.00013935559  |
| qf2_loss                | 0.00015488447  |
| time_elapsed            | 5128           |
| total timesteps         | 1010116        |
| value_loss              | 0.000100590056 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016142328  |
| ent_coef_loss           | -1.2262719    |
| entropy                 | 1.2851428     |
| episodes                | 3850          |
| fps                     | 196           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1011660       |
| policy_loss             | -0.39929026   |
| qf1_loss                | 8.415123e-05  |
| qf2_loss                | 0.00014777613 |
| time_elapsed            | 5136          |
| total timesteps         | 1011760       |
| value_loss              | 6.48242e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016760284  |
| ent_coef_loss           | 0.90443647    |
| entropy                 | 1.3424338     |
| episodes                | 3860          |
| fps                     | 196           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1013471       |
| policy_loss             | -0.35929757   |
| qf1_loss                | 0.00012401587 |
| qf2_loss                | 8.766549e-05  |
| time_elapsed            | 5146          |
| total timesteps         | 1013571       |
| value_loss              | 5.7997182e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017039838  |
| ent_coef_loss           | 0.689378      |
| entropy                 | 1.2818916     |
| episodes                | 3870          |
| fps                     | 196           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1014975       |
| policy_loss             | -0.33783144   |
| qf1_loss                | 0.00011561222 |
| qf2_loss                | 0.00020260402 |
| time_elapsed            | 5154          |
| total timesteps         | 1015075       |
| value_loss              | 0.00012449213 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017453869  |
| ent_coef_loss           | 1.3905833     |
| entropy                 | 1.3469902     |
| episodes                | 3880          |
| fps                     | 196           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1016783       |
| policy_loss             | -0.34915012   |
| qf1_loss                | 0.00030997442 |
| qf2_loss                | 0.00027988    |
| time_elapsed            | 5163          |
| total timesteps         | 1016883       |
| value_loss              | 0.00013919493 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017946648  |
| ent_coef_loss           | 3.1240869     |
| entropy                 | 1.3569456     |
| episodes                | 3890          |
| fps                     | 196           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1018520       |
| policy_loss             | -0.29154432   |
| qf1_loss                | 0.0005331096  |
| qf2_loss                | 0.00010943896 |
| time_elapsed            | 5172          |
| total timesteps         | 1018620       |
| value_loss              | 0.00017286924 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018093789  |
| ent_coef_loss           | 1.6674205     |
| entropy                 | 1.3184981     |
| episodes                | 3900          |
| fps                     | 196           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1020304       |
| policy_loss             | -0.41024548   |
| qf1_loss                | 0.00021281709 |
| qf2_loss                | 0.00013572793 |
| time_elapsed            | 5182          |
| total timesteps         | 1020404       |
| value_loss              | 0.0001309622  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001811088   |
| ent_coef_loss           | 1.2241764     |
| entropy                 | 1.2864707     |
| episodes                | 3910          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1021805       |
| policy_loss             | -0.3081272    |
| qf1_loss                | 0.00016247643 |
| qf2_loss                | 0.000171203   |
| time_elapsed            | 5190          |
| total timesteps         | 1021905       |
| value_loss              | 0.00013645353 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017522357  |
| ent_coef_loss           | 0.23346716    |
| entropy                 | 1.2094665     |
| episodes                | 3920          |
| fps                     | 196           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1023498       |
| policy_loss             | -0.36896646   |
| qf1_loss                | 0.00025177575 |
| qf2_loss                | 0.00022372484 |
| time_elapsed            | 5198          |
| total timesteps         | 1023598       |
| value_loss              | 0.00017964374 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017669776  |
| ent_coef_loss           | 0.14779747    |
| entropy                 | 1.333292      |
| episodes                | 3930          |
| fps                     | 196           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1024937       |
| policy_loss             | -0.32403243   |
| qf1_loss                | 0.00016782022 |
| qf2_loss                | 0.00020955934 |
| time_elapsed            | 5207          |
| total timesteps         | 1025037       |
| value_loss              | 0.0001585507  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017737893  |
| ent_coef_loss           | 0.7018225     |
| entropy                 | 1.2932664     |
| episodes                | 3940          |
| fps                     | 196           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1026325       |
| policy_loss             | -0.3989659    |
| qf1_loss                | 0.00028137272 |
| qf2_loss                | 0.00022681194 |
| time_elapsed            | 5214          |
| total timesteps         | 1026425       |
| value_loss              | 0.00022324144 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017717597  |
| ent_coef_loss           | 4.2672486     |
| entropy                 | 1.2297896     |
| episodes                | 3950          |
| fps                     | 196           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1028359       |
| policy_loss             | -0.29267183   |
| qf1_loss                | 0.0002544088  |
| qf2_loss                | 0.00031838956 |
| time_elapsed            | 5225          |
| total timesteps         | 1028459       |
| value_loss              | 0.0002690248  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017696936  |
| ent_coef_loss           | 0.1184417     |
| entropy                 | 1.2181256     |
| episodes                | 3960          |
| fps                     | 196           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1029963       |
| policy_loss             | -0.35272253   |
| qf1_loss                | 0.00035406445 |
| qf2_loss                | 0.00033964834 |
| time_elapsed            | 5233          |
| total timesteps         | 1030063       |
| value_loss              | 0.00017910509 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017448551  |
| ent_coef_loss           | -0.6529187    |
| entropy                 | 1.2940521     |
| episodes                | 3970          |
| fps                     | 196           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1031760       |
| policy_loss             | -0.29686505   |
| qf1_loss                | 0.00020018051 |
| qf2_loss                | 0.00022054867 |
| time_elapsed            | 5243          |
| total timesteps         | 1031860       |
| value_loss              | 0.0001010594  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017228863  |
| ent_coef_loss           | 0.74181336    |
| entropy                 | 1.26618       |
| episodes                | 3980          |
| fps                     | 196           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1033091       |
| policy_loss             | -0.28254467   |
| qf1_loss                | 0.00028429565 |
| qf2_loss                | 0.00034793263 |
| time_elapsed            | 5250          |
| total timesteps         | 1033191       |
| value_loss              | 0.00014627878 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017170461  |
| ent_coef_loss           | -0.3122691    |
| entropy                 | 1.2325444     |
| episodes                | 3990          |
| fps                     | 196           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1034555       |
| policy_loss             | -0.37735042   |
| qf1_loss                | 0.00012403888 |
| qf2_loss                | 9.67603e-05   |
| time_elapsed            | 5257          |
| total timesteps         | 1034655       |
| value_loss              | 0.00022182759 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.00166615     |
| ent_coef_loss           | -0.05953008    |
| entropy                 | 1.1437742      |
| episodes                | 4000           |
| fps                     | 196            |
| mean 100 episode reward | 1.2            |
| n_updates               | 1036187        |
| policy_loss             | -0.36326692    |
| qf1_loss                | 0.000120698816 |
| qf2_loss                | 0.0001403139   |
| time_elapsed            | 5266           |
| total timesteps         | 1036287        |
| value_loss              | 8.932542e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001659235   |
| ent_coef_loss           | 2.1583362     |
| entropy                 | 1.258887      |
| episodes                | 4010          |
| fps                     | 196           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1037543       |
| policy_loss             | -0.33349168   |
| qf1_loss                | 0.0001693813  |
| qf2_loss                | 0.0001648862  |
| time_elapsed            | 5274          |
| total timesteps         | 1037643       |
| value_loss              | 0.00014358968 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0016201799   |
| ent_coef_loss           | 0.9587765      |
| entropy                 | 1.1136961      |
| episodes                | 4020           |
| fps                     | 196            |
| mean 100 episode reward | 1.1            |
| n_updates               | 1039112        |
| policy_loss             | -0.2790389     |
| qf1_loss                | 0.00027544698  |
| qf2_loss                | 0.0002198136   |
| time_elapsed            | 5282           |
| total timesteps         | 1039212        |
| value_loss              | 0.000104871026 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016375413  |
| ent_coef_loss           | 0.07117331    |
| entropy                 | 1.0977501     |
| episodes                | 4030          |
| fps                     | 196           |
| mean 100 episode reward | 1.1           |
| n_updates               | 1040665       |
| policy_loss             | -0.32434726   |
| qf1_loss                | 0.00017308272 |
| qf2_loss                | 0.00013497047 |
| time_elapsed            | 5289          |
| total timesteps         | 1040765       |
| value_loss              | 8.95844e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016632654  |
| ent_coef_loss           | 2.7577908     |
| entropy                 | 1.1901236     |
| episodes                | 4040          |
| fps                     | 196           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1042300       |
| policy_loss             | -0.32533067   |
| qf1_loss                | 0.00011795081 |
| qf2_loss                | 0.00021905982 |
| time_elapsed            | 5298          |
| total timesteps         | 1042400       |
| value_loss              | 0.00013025705 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016330242  |
| ent_coef_loss           | 0.039171875   |
| entropy                 | 1.152324      |
| episodes                | 4050          |
| fps                     | 196           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1043947       |
| policy_loss             | -0.33548686   |
| qf1_loss                | 0.00033707928 |
| qf2_loss                | 0.00044510418 |
| time_elapsed            | 5307          |
| total timesteps         | 1044047       |
| value_loss              | 0.00021257004 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0016192484 |
| ent_coef_loss           | 1.7222624    |
| entropy                 | 1.1199807    |
| episodes                | 4060         |
| fps                     | 196          |
| mean 100 episode reward | 1.2          |
| n_updates               | 1045680      |
| policy_loss             | -0.35884053  |
| qf1_loss                | 0.0001805693 |
| qf2_loss                | 0.0001861306 |
| time_elapsed            | 5316         |
| total timesteps         | 1045780      |
| value_loss              | 7.784316e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015723425  |
| ent_coef_loss           | -0.6491901    |
| entropy                 | 1.073199      |
| episodes                | 4070          |
| fps                     | 196           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1047148       |
| policy_loss             | -0.3300289    |
| qf1_loss                | 0.00015571828 |
| qf2_loss                | 0.00014464262 |
| time_elapsed            | 5324          |
| total timesteps         | 1047248       |
| value_loss              | 0.00022538227 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015568188  |
| ent_coef_loss           | 0.25859725    |
| entropy                 | 1.1549649     |
| episodes                | 4080          |
| fps                     | 196           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1048717       |
| policy_loss             | -0.3412173    |
| qf1_loss                | 0.0005589055  |
| qf2_loss                | 0.000225624   |
| time_elapsed            | 5332          |
| total timesteps         | 1048817       |
| value_loss              | 0.00017125462 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0015406129   |
| ent_coef_loss           | -2.960952      |
| entropy                 | 1.125884       |
| episodes                | 4090           |
| fps                     | 196            |
| mean 100 episode reward | 1.3            |
| n_updates               | 1050336        |
| policy_loss             | -0.326547      |
| qf1_loss                | 0.000104105304 |
| qf2_loss                | 0.00012710337  |
| time_elapsed            | 5341           |
| total timesteps         | 1050436        |
| value_loss              | 5.0783383e-05  |
--------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0015338318   |
| ent_coef_loss           | -1.0890255     |
| entropy                 | 1.1555445      |
| episodes                | 4100           |
| fps                     | 196            |
| mean 100 episode reward | 1.3            |
| n_updates               | 1051657        |
| policy_loss             | -0.3268556     |
| qf1_loss                | 0.000106135165 |
| qf2_loss                | 0.00014281628  |
| time_elapsed            | 5347           |
| total timesteps         | 1051757        |
| value_loss              | 8.772306e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015633727  |
| ent_coef_loss           | -0.37036252   |
| entropy                 | 1.1107314     |
| episodes                | 4110          |
| fps                     | 196           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1053229       |
| policy_loss             | -0.27022278   |
| qf1_loss                | 0.0002229198  |
| qf2_loss                | 0.00010803586 |
| time_elapsed            | 5356          |
| total timesteps         | 1053329       |
| value_loss              | 0.0001269216  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015668011  |
| ent_coef_loss           | -1.7053612    |
| entropy                 | 1.0674634     |
| episodes                | 4120          |
| fps                     | 196           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1054834       |
| policy_loss             | -0.37356934   |
| qf1_loss                | 0.00012305507 |
| qf2_loss                | 0.00012911772 |
| time_elapsed            | 5365          |
| total timesteps         | 1054934       |
| value_loss              | 8.926276e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015734427  |
| ent_coef_loss           | 1.7180233     |
| entropy                 | 1.1487727     |
| episodes                | 4130          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1056486       |
| policy_loss             | -0.29713538   |
| qf1_loss                | 0.00010005378 |
| qf2_loss                | 9.8940225e-05 |
| time_elapsed            | 5374          |
| total timesteps         | 1056586       |
| value_loss              | 0.00010161715 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015923423  |
| ent_coef_loss           | -5.315868     |
| entropy                 | 1.1695657     |
| episodes                | 4140          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1058205       |
| policy_loss             | -0.2870381    |
| qf1_loss                | 0.00017865081 |
| qf2_loss                | 0.00029333032 |
| time_elapsed            | 5383          |
| total timesteps         | 1058305       |
| value_loss              | 9.462085e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015663753  |
| ent_coef_loss           | -0.80504316   |
| entropy                 | 1.119133      |
| episodes                | 4150          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1059899       |
| policy_loss             | -0.32321766   |
| qf1_loss                | 0.00021807394 |
| qf2_loss                | 0.00042967495 |
| time_elapsed            | 5392          |
| total timesteps         | 1059999       |
| value_loss              | 9.887063e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015646995  |
| ent_coef_loss           | 1.6406819     |
| entropy                 | 1.1770933     |
| episodes                | 4160          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1061623       |
| policy_loss             | -0.26925066   |
| qf1_loss                | 0.00017734032 |
| qf2_loss                | 0.0002531453  |
| time_elapsed            | 5401          |
| total timesteps         | 1061723       |
| value_loss              | 0.00016524873 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015911127  |
| ent_coef_loss           | -2.1534967    |
| entropy                 | 1.2225041     |
| episodes                | 4170          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1063240       |
| policy_loss             | -0.31750655   |
| qf1_loss                | 0.00012011121 |
| qf2_loss                | 9.035954e-05  |
| time_elapsed            | 5410          |
| total timesteps         | 1063340       |
| value_loss              | 0.00014759405 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016225681  |
| ent_coef_loss           | 0.8561902     |
| entropy                 | 1.1732407     |
| episodes                | 4180          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1065347       |
| policy_loss             | -0.2759496    |
| qf1_loss                | 0.00017001551 |
| qf2_loss                | 0.00026843505 |
| time_elapsed            | 5422          |
| total timesteps         | 1065447       |
| value_loss              | 0.00012068958 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016205964  |
| ent_coef_loss           | -1.7744725    |
| entropy                 | 1.2114365     |
| episodes                | 4190          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1067053       |
| policy_loss             | -0.28045613   |
| qf1_loss                | 0.00025004614 |
| qf2_loss                | 0.00016360186 |
| time_elapsed            | 5431          |
| total timesteps         | 1067153       |
| value_loss              | 9.3862465e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015865132  |
| ent_coef_loss           | 1.7805033     |
| entropy                 | 1.2337396     |
| episodes                | 4200          |
| fps                     | 196           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1068592       |
| policy_loss             | -0.34344235   |
| qf1_loss                | 0.00012940088 |
| qf2_loss                | 0.00017173456 |
| time_elapsed            | 5438          |
| total timesteps         | 1068692       |
| value_loss              | 0.00015693603 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015434165  |
| ent_coef_loss           | -1.246448     |
| entropy                 | 1.1500785     |
| episodes                | 4210          |
| fps                     | 196           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1070325       |
| policy_loss             | -0.3301543    |
| qf1_loss                | 0.0001630444  |
| qf2_loss                | 0.00021873532 |
| time_elapsed            | 5448          |
| total timesteps         | 1070425       |
| value_loss              | 9.916008e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015703988  |
| ent_coef_loss           | -1.5519682    |
| entropy                 | 1.2266345     |
| episodes                | 4220          |
| fps                     | 196           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1071984       |
| policy_loss             | -0.35003555   |
| qf1_loss                | 0.00029246166 |
| qf2_loss                | 0.00025952136 |
| time_elapsed            | 5457          |
| total timesteps         | 1072084       |
| value_loss              | 0.00017762213 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015726327  |
| ent_coef_loss           | -1.7389057    |
| entropy                 | 1.2239451     |
| episodes                | 4230          |
| fps                     | 196           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1073732       |
| policy_loss             | -0.38367066   |
| qf1_loss                | 0.00017377647 |
| qf2_loss                | 0.00016651792 |
| time_elapsed            | 5465          |
| total timesteps         | 1073832       |
| value_loss              | 9.661316e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016256022  |
| ent_coef_loss           | -1.5460565    |
| entropy                 | 1.1883056     |
| episodes                | 4240          |
| fps                     | 196           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1075566       |
| policy_loss             | -0.31192136   |
| qf1_loss                | 0.0001724046  |
| qf2_loss                | 0.00024929267 |
| time_elapsed            | 5475          |
| total timesteps         | 1075666       |
| value_loss              | 0.0001169044  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016542493  |
| ent_coef_loss           | -0.048005432  |
| entropy                 | 1.19667       |
| episodes                | 4250          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1076787       |
| policy_loss             | -0.34875333   |
| qf1_loss                | 0.00016535216 |
| qf2_loss                | 8.207277e-05  |
| time_elapsed            | 5481          |
| total timesteps         | 1076887       |
| value_loss              | 8.010589e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016774044  |
| ent_coef_loss           | -0.9538799    |
| entropy                 | 1.1151265     |
| episodes                | 4260          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1078518       |
| policy_loss             | -0.29381117   |
| qf1_loss                | 0.0004849641  |
| qf2_loss                | 0.00023883554 |
| time_elapsed            | 5491          |
| total timesteps         | 1078618       |
| value_loss              | 0.00025318481 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016320129  |
| ent_coef_loss           | -1.9349488    |
| entropy                 | 1.1860224     |
| episodes                | 4270          |
| fps                     | 196           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1080542       |
| policy_loss             | -0.30255073   |
| qf1_loss                | 0.00018435401 |
| qf2_loss                | 0.0002551066  |
| time_elapsed            | 5502          |
| total timesteps         | 1080642       |
| value_loss              | 0.0002524529  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016038588  |
| ent_coef_loss           | -5.6592836    |
| entropy                 | 1.2253103     |
| episodes                | 4280          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1081947       |
| policy_loss             | -0.34399176   |
| qf1_loss                | 0.00024308857 |
| qf2_loss                | 0.00010430467 |
| time_elapsed            | 5510          |
| total timesteps         | 1082047       |
| value_loss              | 9.4265255e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015729829  |
| ent_coef_loss           | -0.8440387    |
| entropy                 | 1.1742908     |
| episodes                | 4290          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1083797       |
| policy_loss             | -0.296812     |
| qf1_loss                | 0.00012021453 |
| qf2_loss                | 0.00021157136 |
| time_elapsed            | 5520          |
| total timesteps         | 1083897       |
| value_loss              | 0.00010828486 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015710085  |
| ent_coef_loss           | -1.129755     |
| entropy                 | 1.2397599     |
| episodes                | 4300          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1085461       |
| policy_loss             | -0.41011295   |
| qf1_loss                | 0.00015321077 |
| qf2_loss                | 0.00010826711 |
| time_elapsed            | 5528          |
| total timesteps         | 1085561       |
| value_loss              | 8.611402e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015733062  |
| ent_coef_loss           | -1.5407113    |
| entropy                 | 1.0894922     |
| episodes                | 4310          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1087362       |
| policy_loss             | -0.30075896   |
| qf1_loss                | 0.00022790147 |
| qf2_loss                | 0.0002263459  |
| time_elapsed            | 5538          |
| total timesteps         | 1087462       |
| value_loss              | 0.00017443075 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001556801   |
| ent_coef_loss           | 0.18060839    |
| entropy                 | 1.1440823     |
| episodes                | 4320          |
| fps                     | 196           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1088922       |
| policy_loss             | -0.30896014   |
| qf1_loss                | 0.00026974286 |
| qf2_loss                | 0.00018764916 |
| time_elapsed            | 5547          |
| total timesteps         | 1089022       |
| value_loss              | 0.00023865112 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015865519  |
| ent_coef_loss           | -1.5762181    |
| entropy                 | 1.0853239     |
| episodes                | 4330          |
| fps                     | 196           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1090656       |
| policy_loss             | -0.2931331    |
| qf1_loss                | 9.513882e-05  |
| qf2_loss                | 0.00018909227 |
| time_elapsed            | 5556          |
| total timesteps         | 1090756       |
| value_loss              | 0.00010579195 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0016091338 |
| ent_coef_loss           | 0.92536134   |
| entropy                 | 1.2112089    |
| episodes                | 4340         |
| fps                     | 196          |
| mean 100 episode reward | 1.4          |
| n_updates               | 1092272      |
| policy_loss             | -0.39286375  |
| qf1_loss                | 0.014448844  |
| qf2_loss                | 0.010525454  |
| time_elapsed            | 5564         |
| total timesteps         | 1092372      |
| value_loss              | 9.406265e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016224706  |
| ent_coef_loss           | -2.814593     |
| entropy                 | 1.177995      |
| episodes                | 4350          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1093839       |
| policy_loss             | -0.3271215    |
| qf1_loss                | 8.6391185e-05 |
| qf2_loss                | 0.00013001732 |
| time_elapsed            | 5572          |
| total timesteps         | 1093939       |
| value_loss              | 9.2363414e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016341708  |
| ent_coef_loss           | 0.8774648     |
| entropy                 | 1.1698952     |
| episodes                | 4360          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1095440       |
| policy_loss             | -0.3220595    |
| qf1_loss                | 0.00071285444 |
| qf2_loss                | 0.0012012239  |
| time_elapsed            | 5582          |
| total timesteps         | 1095540       |
| value_loss              | 0.00016505373 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016401451  |
| ent_coef_loss           | 0.6346069     |
| entropy                 | 1.2910483     |
| episodes                | 4370          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1097315       |
| policy_loss             | -0.41053456   |
| qf1_loss                | 0.00022281542 |
| qf2_loss                | 0.00015532246 |
| time_elapsed            | 5591          |
| total timesteps         | 1097415       |
| value_loss              | 7.342645e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016688773  |
| ent_coef_loss           | -0.85212934   |
| entropy                 | 1.2703316     |
| episodes                | 4380          |
| fps                     | 196           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1099407       |
| policy_loss             | -0.46137425   |
| qf1_loss                | 0.00018956902 |
| qf2_loss                | 0.00014362411 |
| time_elapsed            | 5603          |
| total timesteps         | 1099507       |
| value_loss              | 6.521755e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001671991   |
| ent_coef_loss           | -3.867688     |
| entropy                 | 1.1538088     |
| episodes                | 4390          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1100958       |
| policy_loss             | -0.27946958   |
| qf1_loss                | 0.00013555332 |
| qf2_loss                | 0.00017235104 |
| time_elapsed            | 5611          |
| total timesteps         | 1101058       |
| value_loss              | 0.000174321   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016726082  |
| ent_coef_loss           | 3.7234395     |
| entropy                 | 1.149696      |
| episodes                | 4400          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1102412       |
| policy_loss             | -0.16586652   |
| qf1_loss                | 0.00033103934 |
| qf2_loss                | 0.00023097123 |
| time_elapsed            | 5618          |
| total timesteps         | 1102512       |
| value_loss              | 0.00018855593 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016883193  |
| ent_coef_loss           | -0.39463472   |
| entropy                 | 1.2128775     |
| episodes                | 4410          |
| fps                     | 196           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1103924       |
| policy_loss             | -0.37205127   |
| qf1_loss                | 0.00012077306 |
| qf2_loss                | 0.00011617952 |
| time_elapsed            | 5627          |
| total timesteps         | 1104024       |
| value_loss              | 8.212062e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017249768  |
| ent_coef_loss           | 0.5923148     |
| entropy                 | 1.1909673     |
| episodes                | 4420          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1105652       |
| policy_loss             | -0.28245845   |
| qf1_loss                | 0.00053134793 |
| qf2_loss                | 0.0002606808  |
| time_elapsed            | 5636          |
| total timesteps         | 1105752       |
| value_loss              | 0.000313706   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00174495    |
| ent_coef_loss           | -1.0624379    |
| entropy                 | 1.2302686     |
| episodes                | 4430          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1107333       |
| policy_loss             | -0.3782608    |
| qf1_loss                | 0.00024365706 |
| qf2_loss                | 0.00029269228 |
| time_elapsed            | 5645          |
| total timesteps         | 1107433       |
| value_loss              | 0.00010072926 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017022856  |
| ent_coef_loss           | 0.5407487     |
| entropy                 | 1.1599585     |
| episodes                | 4440          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1109132       |
| policy_loss             | -0.2626401    |
| qf1_loss                | 0.00014353683 |
| qf2_loss                | 0.00019401504 |
| time_elapsed            | 5654          |
| total timesteps         | 1109232       |
| value_loss              | 9.525417e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00173577    |
| ent_coef_loss           | -2.0082576    |
| entropy                 | 1.2010875     |
| episodes                | 4450          |
| fps                     | 196           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1110782       |
| policy_loss             | -0.33757532   |
| qf1_loss                | 0.0001620783  |
| qf2_loss                | 0.00015956494 |
| time_elapsed            | 5663          |
| total timesteps         | 1110882       |
| value_loss              | 8.190167e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017729057  |
| ent_coef_loss           | 1.0427022     |
| entropy                 | 1.231005      |
| episodes                | 4460          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1112206       |
| policy_loss             | -0.31058615   |
| qf1_loss                | 0.00017461667 |
| qf2_loss                | 0.00019246007 |
| time_elapsed            | 5671          |
| total timesteps         | 1112306       |
| value_loss              | 0.00010678999 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017505203  |
| ent_coef_loss           | -0.78284794   |
| entropy                 | 1.2028053     |
| episodes                | 4470          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1113667       |
| policy_loss             | -0.36066255   |
| qf1_loss                | 0.00028538628 |
| qf2_loss                | 0.0003538629  |
| time_elapsed            | 5678          |
| total timesteps         | 1113767       |
| value_loss              | 0.00014742676 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017103993  |
| ent_coef_loss           | 0.91808456    |
| entropy                 | 1.2926599     |
| episodes                | 4480          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1115346       |
| policy_loss             | -0.26140308   |
| qf1_loss                | 0.00011700277 |
| qf2_loss                | 0.00014696148 |
| time_elapsed            | 5687          |
| total timesteps         | 1115446       |
| value_loss              | 5.7557136e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016883764  |
| ent_coef_loss           | -1.2346631    |
| entropy                 | 1.2504752     |
| episodes                | 4490          |
| fps                     | 196           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1117270       |
| policy_loss             | -0.3139009    |
| qf1_loss                | 0.00017311759 |
| qf2_loss                | 0.00019131505 |
| time_elapsed            | 5697          |
| total timesteps         | 1117370       |
| value_loss              | 0.00018669388 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017069846  |
| ent_coef_loss           | -2.024337     |
| entropy                 | 1.1341884     |
| episodes                | 4500          |
| fps                     | 196           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1119176       |
| policy_loss             | -0.3243904    |
| qf1_loss                | 0.00015809471 |
| qf2_loss                | 0.00018900528 |
| time_elapsed            | 5707          |
| total timesteps         | 1119276       |
| value_loss              | 6.8509224e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017718264  |
| ent_coef_loss           | -0.9599899    |
| entropy                 | 1.2269948     |
| episodes                | 4510          |
| fps                     | 196           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1121942       |
| policy_loss             | -0.30761307   |
| qf1_loss                | 0.0003351786  |
| qf2_loss                | 0.0002567331  |
| time_elapsed            | 5722          |
| total timesteps         | 1122042       |
| value_loss              | 0.00015301412 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017452653  |
| ent_coef_loss           | 1.0044422     |
| entropy                 | 1.2165188     |
| episodes                | 4520          |
| fps                     | 196           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1123697       |
| policy_loss             | -0.31151235   |
| qf1_loss                | 0.0002663182  |
| qf2_loss                | 0.00023888142 |
| time_elapsed            | 5731          |
| total timesteps         | 1123797       |
| value_loss              | 0.00014577314 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017568613  |
| ent_coef_loss           | -0.48202467   |
| entropy                 | 1.3115923     |
| episodes                | 4530          |
| fps                     | 196           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1125474       |
| policy_loss             | -0.37239277   |
| qf1_loss                | 0.00014127283 |
| qf2_loss                | 0.00015268725 |
| time_elapsed            | 5740          |
| total timesteps         | 1125574       |
| value_loss              | 9.733515e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018234414  |
| ent_coef_loss           | 1.1330545     |
| entropy                 | 1.2948747     |
| episodes                | 4540          |
| fps                     | 196           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1127260       |
| policy_loss             | -0.31364834   |
| qf1_loss                | 0.00068451493 |
| qf2_loss                | 0.00083369436 |
| time_elapsed            | 5750          |
| total timesteps         | 1127360       |
| value_loss              | 7.141211e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018157288  |
| ent_coef_loss           | -0.7081162    |
| entropy                 | 1.2663192     |
| episodes                | 4550          |
| fps                     | 196           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1128873       |
| policy_loss             | -0.34499675   |
| qf1_loss                | 0.00027774685 |
| qf2_loss                | 0.0002911034  |
| time_elapsed            | 5759          |
| total timesteps         | 1128973       |
| value_loss              | 0.0001785727  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.001814614    |
| ent_coef_loss           | 2.965371       |
| entropy                 | 1.2673267      |
| episodes                | 4560           |
| fps                     | 196            |
| mean 100 episode reward | 1.7            |
| n_updates               | 1130188        |
| policy_loss             | -0.34298128    |
| qf1_loss                | 0.00012717972  |
| qf2_loss                | 0.000100488236 |
| time_elapsed            | 5765           |
| total timesteps         | 1130288        |
| value_loss              | 0.00010688158  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018105605  |
| ent_coef_loss           | -2.416655     |
| entropy                 | 1.1815425     |
| episodes                | 4570          |
| fps                     | 196           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1131907       |
| policy_loss             | -0.2889042    |
| qf1_loss                | 0.00024125191 |
| qf2_loss                | 0.00037667283 |
| time_elapsed            | 5774          |
| total timesteps         | 1132007       |
| value_loss              | 7.6599725e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0018105794  |
| ent_coef_loss           | -1.7079074    |
| entropy                 | 1.2458272     |
| episodes                | 4580          |
| fps                     | 196           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1133512       |
| policy_loss             | -0.3038605    |
| qf1_loss                | 0.00017425884 |
| qf2_loss                | 0.00021413928 |
| time_elapsed            | 5783          |
| total timesteps         | 1133612       |
| value_loss              | 0.00015985248 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017922515  |
| ent_coef_loss           | 0.49846196    |
| entropy                 | 1.152905      |
| episodes                | 4590          |
| fps                     | 196           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1135251       |
| policy_loss             | -0.26921237   |
| qf1_loss                | 0.00013693864 |
| qf2_loss                | 0.00012283411 |
| time_elapsed            | 5792          |
| total timesteps         | 1135351       |
| value_loss              | 0.0001607344  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017967079  |
| ent_coef_loss           | -0.47068182   |
| entropy                 | 1.1421232     |
| episodes                | 4600          |
| fps                     | 195           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1137074       |
| policy_loss             | -0.34955555   |
| qf1_loss                | 0.00020896776 |
| qf2_loss                | 0.0002836349  |
| time_elapsed            | 5802          |
| total timesteps         | 1137174       |
| value_loss              | 0.00010298118 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017317439  |
| ent_coef_loss           | -2.1959488    |
| entropy                 | 1.1590834     |
| episodes                | 4610          |
| fps                     | 195           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1138688       |
| policy_loss             | -0.35627484   |
| qf1_loss                | 0.0001339982  |
| qf2_loss                | 0.00010879695 |
| time_elapsed            | 5810          |
| total timesteps         | 1138788       |
| value_loss              | 7.768823e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017279858  |
| ent_coef_loss           | -1.3880887    |
| entropy                 | 1.1587005     |
| episodes                | 4620          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1139953       |
| policy_loss             | -0.287328     |
| qf1_loss                | 0.00085744436 |
| qf2_loss                | 0.00084289396 |
| time_elapsed            | 5817          |
| total timesteps         | 1140053       |
| value_loss              | 9.993056e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016879796  |
| ent_coef_loss           | 0.64671385    |
| entropy                 | 1.1249349     |
| episodes                | 4630          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1141733       |
| policy_loss             | -0.25982052   |
| qf1_loss                | 0.00022851564 |
| qf2_loss                | 0.0003344875  |
| time_elapsed            | 5826          |
| total timesteps         | 1141833       |
| value_loss              | 0.00024562597 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017056437  |
| ent_coef_loss           | 1.970968      |
| entropy                 | 1.2515624     |
| episodes                | 4640          |
| fps                     | 195           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1143357       |
| policy_loss             | -0.33573842   |
| qf1_loss                | 0.00051323464 |
| qf2_loss                | 0.0006719802  |
| time_elapsed            | 5835          |
| total timesteps         | 1143457       |
| value_loss              | 8.205978e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017371279  |
| ent_coef_loss           | 1.3220726     |
| entropy                 | 1.2333167     |
| episodes                | 4650          |
| fps                     | 195           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1144716       |
| policy_loss             | -0.27798498   |
| qf1_loss                | 0.0008939239  |
| qf2_loss                | 0.0006938699  |
| time_elapsed            | 5843          |
| total timesteps         | 1144816       |
| value_loss              | 0.00097517244 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017529083  |
| ent_coef_loss           | -0.34455848   |
| entropy                 | 1.2887363     |
| episodes                | 4660          |
| fps                     | 195           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1147023       |
| policy_loss             | -0.36082673   |
| qf1_loss                | 0.0002304888  |
| qf2_loss                | 0.00017628926 |
| time_elapsed            | 5855          |
| total timesteps         | 1147123       |
| value_loss              | 0.00010949593 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0017356392   |
| ent_coef_loss           | 1.7929235      |
| entropy                 | 1.1572781      |
| episodes                | 4670           |
| fps                     | 195            |
| mean 100 episode reward | 1.4            |
| n_updates               | 1148724        |
| policy_loss             | -0.33318138    |
| qf1_loss                | 0.00021827781  |
| qf2_loss                | 0.00012856946  |
| time_elapsed            | 5864           |
| total timesteps         | 1148824        |
| value_loss              | 0.000109196444 |
--------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0017667762   |
| ent_coef_loss           | 0.55020964     |
| entropy                 | 1.256727       |
| episodes                | 4680           |
| fps                     | 195            |
| mean 100 episode reward | 1.3            |
| n_updates               | 1150064        |
| policy_loss             | -0.34382683    |
| qf1_loss                | 0.00024577993  |
| qf2_loss                | 0.0002450407   |
| time_elapsed            | 5871           |
| total timesteps         | 1150164        |
| value_loss              | 0.000106686246 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001781141   |
| ent_coef_loss           | -1.3069446    |
| entropy                 | 1.2459702     |
| episodes                | 4690          |
| fps                     | 195           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1151403       |
| policy_loss             | -0.2696861    |
| qf1_loss                | 0.0006512293  |
| qf2_loss                | 0.00043589337 |
| time_elapsed            | 5879          |
| total timesteps         | 1151503       |
| value_loss              | 0.00012973114 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017635097  |
| ent_coef_loss           | -0.55881596   |
| entropy                 | 1.2018694     |
| episodes                | 4700          |
| fps                     | 195           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1153047       |
| policy_loss             | -0.32909623   |
| qf1_loss                | 0.00025830197 |
| qf2_loss                | 0.0002584496  |
| time_elapsed            | 5887          |
| total timesteps         | 1153147       |
| value_loss              | 0.00018894517 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017817798  |
| ent_coef_loss           | 0.12323964    |
| entropy                 | 1.2298579     |
| episodes                | 4710          |
| fps                     | 195           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1154423       |
| policy_loss             | -0.25486374   |
| qf1_loss                | 0.00013307472 |
| qf2_loss                | 0.00016965883 |
| time_elapsed            | 5894          |
| total timesteps         | 1154523       |
| value_loss              | 0.00011255985 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017484456  |
| ent_coef_loss           | 1.6278543     |
| entropy                 | 1.2558608     |
| episodes                | 4720          |
| fps                     | 195           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1156138       |
| policy_loss             | -0.29927954   |
| qf1_loss                | 0.00012353603 |
| qf2_loss                | 0.0001380195  |
| time_elapsed            | 5903          |
| total timesteps         | 1156238       |
| value_loss              | 8.4160056e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.001773654    |
| ent_coef_loss           | 0.15393016     |
| entropy                 | 1.219634       |
| episodes                | 4730           |
| fps                     | 195            |
| mean 100 episode reward | 1.2            |
| n_updates               | 1157552        |
| policy_loss             | -0.27852172    |
| qf1_loss                | 0.00035519124  |
| qf2_loss                | 0.0002757724   |
| time_elapsed            | 5911           |
| total timesteps         | 1157652        |
| value_loss              | 0.000107645246 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001771801   |
| ent_coef_loss           | -0.16268337   |
| entropy                 | 1.2448678     |
| episodes                | 4740          |
| fps                     | 195           |
| mean 100 episode reward | 1.2           |
| n_updates               | 1158815       |
| policy_loss             | -0.35300934   |
| qf1_loss                | 0.00015214243 |
| qf2_loss                | 0.00014973237 |
| time_elapsed            | 5917          |
| total timesteps         | 1158915       |
| value_loss              | 8.884168e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017715747  |
| ent_coef_loss           | -1.6091208    |
| entropy                 | 1.2677871     |
| episodes                | 4750          |
| fps                     | 195           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1160550       |
| policy_loss             | -0.3597797    |
| qf1_loss                | 0.00014923977 |
| qf2_loss                | 0.00010785165 |
| time_elapsed            | 5926          |
| total timesteps         | 1160650       |
| value_loss              | 9.7429656e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017406286  |
| ent_coef_loss           | 5.103176      |
| entropy                 | 1.2837174     |
| episodes                | 4760          |
| fps                     | 195           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1162313       |
| policy_loss             | -0.29957503   |
| qf1_loss                | 0.0004926996  |
| qf2_loss                | 0.00065258064 |
| time_elapsed            | 5935          |
| total timesteps         | 1162413       |
| value_loss              | 0.00017554284 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017917943  |
| ent_coef_loss           | 0.72411966    |
| entropy                 | 1.361017      |
| episodes                | 4770          |
| fps                     | 195           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1163962       |
| policy_loss             | -0.31778613   |
| qf1_loss                | 0.00024132433 |
| qf2_loss                | 0.00020157453 |
| time_elapsed            | 5944          |
| total timesteps         | 1164062       |
| value_loss              | 0.00015772835 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017944893  |
| ent_coef_loss           | 1.4553031     |
| entropy                 | 1.3109574     |
| episodes                | 4780          |
| fps                     | 195           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1165358       |
| policy_loss             | -0.39291495   |
| qf1_loss                | 0.00017980661 |
| qf2_loss                | 0.00012142053 |
| time_elapsed            | 5951          |
| total timesteps         | 1165458       |
| value_loss              | 0.00022745231 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017879255  |
| ent_coef_loss           | -1.344245     |
| entropy                 | 1.3024852     |
| episodes                | 4790          |
| fps                     | 195           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1166989       |
| policy_loss             | -0.27485818   |
| qf1_loss                | 0.00013347343 |
| qf2_loss                | 0.00012883061 |
| time_elapsed            | 5960          |
| total timesteps         | 1167089       |
| value_loss              | 0.00011227917 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017720959  |
| ent_coef_loss           | -1.1066582    |
| entropy                 | 1.2434938     |
| episodes                | 4800          |
| fps                     | 195           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1168647       |
| policy_loss             | -0.30791008   |
| qf1_loss                | 0.00031457952 |
| qf2_loss                | 0.00033969563 |
| time_elapsed            | 5969          |
| total timesteps         | 1168747       |
| value_loss              | 0.0001033587  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017311263  |
| ent_coef_loss           | -2.2985768    |
| entropy                 | 1.2620745     |
| episodes                | 4810          |
| fps                     | 195           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1170979       |
| policy_loss             | -0.3557456    |
| qf1_loss                | 0.0001840774  |
| qf2_loss                | 0.00015924167 |
| time_elapsed            | 5982          |
| total timesteps         | 1171079       |
| value_loss              | 0.00012676518 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017146219  |
| ent_coef_loss           | 1.5202998     |
| entropy                 | 1.3371001     |
| episodes                | 4820          |
| fps                     | 195           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1172594       |
| policy_loss             | -0.32281196   |
| qf1_loss                | 0.00046984843 |
| qf2_loss                | 0.00012792298 |
| time_elapsed            | 5990          |
| total timesteps         | 1172694       |
| value_loss              | 0.0001242821  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016863457  |
| ent_coef_loss           | 0.67736965    |
| entropy                 | 1.2779664     |
| episodes                | 4830          |
| fps                     | 195           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1174344       |
| policy_loss             | -0.30177605   |
| qf1_loss                | 0.00016102628 |
| qf2_loss                | 0.00015980261 |
| time_elapsed            | 6000          |
| total timesteps         | 1174444       |
| value_loss              | 9.960335e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016586954  |
| ent_coef_loss           | -0.5898056    |
| entropy                 | 1.2405378     |
| episodes                | 4840          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1176057       |
| policy_loss             | -0.3363411    |
| qf1_loss                | 0.00018970207 |
| qf2_loss                | 0.00022754345 |
| time_elapsed            | 6009          |
| total timesteps         | 1176157       |
| value_loss              | 0.00010692341 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016619676  |
| ent_coef_loss           | -0.63457894   |
| entropy                 | 1.262673      |
| episodes                | 4850          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1177839       |
| policy_loss             | -0.31875718   |
| qf1_loss                | 0.00018694662 |
| qf2_loss                | 0.00014201322 |
| time_elapsed            | 6019          |
| total timesteps         | 1177939       |
| value_loss              | 0.00010251748 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0016396423   |
| ent_coef_loss           | 0.6669744      |
| entropy                 | 1.2659205      |
| episodes                | 4860           |
| fps                     | 195            |
| mean 100 episode reward | 1.5            |
| n_updates               | 1179309        |
| policy_loss             | -0.27516124    |
| qf1_loss                | 0.00012937363  |
| qf2_loss                | 0.00015209304  |
| time_elapsed            | 6027           |
| total timesteps         | 1179409        |
| value_loss              | 0.000105887375 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001635659   |
| ent_coef_loss           | 1.3552456     |
| entropy                 | 1.2285957     |
| episodes                | 4870          |
| fps                     | 195           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1181088       |
| policy_loss             | -0.29078323   |
| qf1_loss                | 0.00085150043 |
| qf2_loss                | 0.0006736902  |
| time_elapsed            | 6035          |
| total timesteps         | 1181188       |
| value_loss              | 0.00019053201 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016517657  |
| ent_coef_loss           | -0.38197032   |
| entropy                 | 1.27246       |
| episodes                | 4880          |
| fps                     | 195           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1182643       |
| policy_loss             | -0.26922938   |
| qf1_loss                | 0.00021907277 |
| qf2_loss                | 0.00022811738 |
| time_elapsed            | 6044          |
| total timesteps         | 1182743       |
| value_loss              | 9.5550124e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016207254  |
| ent_coef_loss           | 1.3415285     |
| entropy                 | 1.2100865     |
| episodes                | 4890          |
| fps                     | 195           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1184577       |
| policy_loss             | -0.34833288   |
| qf1_loss                | 0.00016763355 |
| qf2_loss                | 0.0001474545  |
| time_elapsed            | 6054          |
| total timesteps         | 1184677       |
| value_loss              | 8.281899e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016036967  |
| ent_coef_loss           | -1.0961208    |
| entropy                 | 1.1688395     |
| episodes                | 4900          |
| fps                     | 195           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1186351       |
| policy_loss             | -0.3521434    |
| qf1_loss                | 0.00025785356 |
| qf2_loss                | 0.00018817725 |
| time_elapsed            | 6064          |
| total timesteps         | 1186451       |
| value_loss              | 0.00011284143 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016214002  |
| ent_coef_loss           | -2.2975235    |
| entropy                 | 1.2596298     |
| episodes                | 4910          |
| fps                     | 195           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1187895       |
| policy_loss             | -0.32676342   |
| qf1_loss                | 0.00017769584 |
| qf2_loss                | 0.00019433053 |
| time_elapsed            | 6072          |
| total timesteps         | 1187995       |
| value_loss              | 0.00025575102 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016947575  |
| ent_coef_loss           | -1.0592746    |
| entropy                 | 1.2909963     |
| episodes                | 4920          |
| fps                     | 195           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1189543       |
| policy_loss             | -0.360226     |
| qf1_loss                | 0.00022445308 |
| qf2_loss                | 0.00023138267 |
| time_elapsed            | 6081          |
| total timesteps         | 1189643       |
| value_loss              | 0.0001121956  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001680905   |
| ent_coef_loss           | 1.3174733     |
| entropy                 | 1.2528565     |
| episodes                | 4930          |
| fps                     | 195           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1191351       |
| policy_loss             | -0.22201999   |
| qf1_loss                | 0.00015617488 |
| qf2_loss                | 0.00019739196 |
| time_elapsed            | 6091          |
| total timesteps         | 1191451       |
| value_loss              | 0.00012952981 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016549223  |
| ent_coef_loss           | -0.06831831   |
| entropy                 | 1.3061955     |
| episodes                | 4940          |
| fps                     | 195           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1192987       |
| policy_loss             | -0.34801656   |
| qf1_loss                | 0.0002334328  |
| qf2_loss                | 0.00023637366 |
| time_elapsed            | 6099          |
| total timesteps         | 1193087       |
| value_loss              | 0.00014819592 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016460055  |
| ent_coef_loss           | -1.1986492    |
| entropy                 | 1.3528259     |
| episodes                | 4950          |
| fps                     | 195           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1194704       |
| policy_loss             | -0.3767193    |
| qf1_loss                | 0.00035936144 |
| qf2_loss                | 0.00027685324 |
| time_elapsed            | 6109          |
| total timesteps         | 1194804       |
| value_loss              | 0.0001313849  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016269322  |
| ent_coef_loss           | -0.026271343  |
| entropy                 | 1.1803434     |
| episodes                | 4960          |
| fps                     | 195           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1195873       |
| policy_loss             | -0.3496725    |
| qf1_loss                | 0.0006127057  |
| qf2_loss                | 0.00049576495 |
| time_elapsed            | 6114          |
| total timesteps         | 1195973       |
| value_loss              | 0.00016467928 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0015826817   |
| ent_coef_loss           | 3.559423       |
| entropy                 | 1.2100426      |
| episodes                | 4970           |
| fps                     | 195            |
| mean 100 episode reward | 1.4            |
| n_updates               | 1197633        |
| policy_loss             | -0.27957392    |
| qf1_loss                | 0.000112013164 |
| qf2_loss                | 9.3282746e-05  |
| time_elapsed            | 6123           |
| total timesteps         | 1197733        |
| value_loss              | 9.451184e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016095006  |
| ent_coef_loss           | 1.9241495     |
| entropy                 | 1.2171934     |
| episodes                | 4980          |
| fps                     | 195           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1199383       |
| policy_loss             | -0.3425401    |
| qf1_loss                | 0.00030460142 |
| qf2_loss                | 0.0003738571  |
| time_elapsed            | 6133          |
| total timesteps         | 1199483       |
| value_loss              | 0.00019852875 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015697797  |
| ent_coef_loss           | 0.006109029   |
| entropy                 | 1.2261075     |
| episodes                | 4990          |
| fps                     | 195           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1201134       |
| policy_loss             | -0.3429456    |
| qf1_loss                | 0.00023821693 |
| qf2_loss                | 0.00017443662 |
| time_elapsed            | 6142          |
| total timesteps         | 1201234       |
| value_loss              | 0.00019126173 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015483103  |
| ent_coef_loss           | -1.8142184    |
| entropy                 | 1.2365113     |
| episodes                | 5000          |
| fps                     | 195           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1202836       |
| policy_loss             | -0.334504     |
| qf1_loss                | 0.00024354996 |
| qf2_loss                | 0.0001904213  |
| time_elapsed            | 6152          |
| total timesteps         | 1202936       |
| value_loss              | 0.00020522956 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015566488  |
| ent_coef_loss           | -2.9002948    |
| entropy                 | 1.1968246     |
| episodes                | 5010          |
| fps                     | 195           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1204341       |
| policy_loss             | -0.31756592   |
| qf1_loss                | 0.00033030254 |
| qf2_loss                | 0.00030558597 |
| time_elapsed            | 6159          |
| total timesteps         | 1204441       |
| value_loss              | 0.00012270085 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015341544  |
| ent_coef_loss           | -1.3731263    |
| entropy                 | 1.1984329     |
| episodes                | 5020          |
| fps                     | 195           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1206041       |
| policy_loss             | -0.36813462   |
| qf1_loss                | 0.00015751823 |
| qf2_loss                | 0.00013871037 |
| time_elapsed            | 6169          |
| total timesteps         | 1206141       |
| value_loss              | 0.00013472782 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0015356907   |
| ent_coef_loss           | 0.44404185     |
| entropy                 | 1.1267836      |
| episodes                | 5030           |
| fps                     | 195            |
| mean 100 episode reward | 1.4            |
| n_updates               | 1208261        |
| policy_loss             | -0.25776666    |
| qf1_loss                | 0.00020491667  |
| qf2_loss                | 0.00030478308  |
| time_elapsed            | 6181           |
| total timesteps         | 1208361        |
| value_loss              | 0.000110609326 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015681031  |
| ent_coef_loss           | 0.38529736    |
| entropy                 | 1.1746331     |
| episodes                | 5040          |
| fps                     | 195           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1209854       |
| policy_loss             | -0.3753274    |
| qf1_loss                | 0.00047904748 |
| qf2_loss                | 0.0003103505  |
| time_elapsed            | 6189          |
| total timesteps         | 1209954       |
| value_loss              | 0.00013641562 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015597717  |
| ent_coef_loss           | 0.42064667    |
| entropy                 | 1.305898      |
| episodes                | 5050          |
| fps                     | 195           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1211553       |
| policy_loss             | -0.30403918   |
| qf1_loss                | 0.00019228051 |
| qf2_loss                | 0.00024378338 |
| time_elapsed            | 6198          |
| total timesteps         | 1211653       |
| value_loss              | 0.00013960793 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015707598  |
| ent_coef_loss           | -1.6195536    |
| entropy                 | 1.2279298     |
| episodes                | 5060          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1213169       |
| policy_loss             | -0.30302238   |
| qf1_loss                | 0.00024446356 |
| qf2_loss                | 0.00018832952 |
| time_elapsed            | 6207          |
| total timesteps         | 1213269       |
| value_loss              | 0.00022250201 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016104133  |
| ent_coef_loss           | -1.0694345    |
| entropy                 | 1.2151401     |
| episodes                | 5070          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1214853       |
| policy_loss             | -0.26385826   |
| qf1_loss                | 0.0001956274  |
| qf2_loss                | 0.0002600284  |
| time_elapsed            | 6216          |
| total timesteps         | 1214953       |
| value_loss              | 0.00014368769 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0016192484   |
| ent_coef_loss           | -0.18131775    |
| entropy                 | 1.20682        |
| episodes                | 5080           |
| fps                     | 195            |
| mean 100 episode reward | 1.6            |
| n_updates               | 1216655        |
| policy_loss             | -0.19760251    |
| qf1_loss                | 0.00089512375  |
| qf2_loss                | 0.00046743354  |
| time_elapsed            | 6225           |
| total timesteps         | 1216755        |
| value_loss              | 0.000115557836 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016185606  |
| ent_coef_loss           | 1.6165283     |
| entropy                 | 1.1894336     |
| episodes                | 5090          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1218477       |
| policy_loss             | -0.28141516   |
| qf1_loss                | 8.5117266e-05 |
| qf2_loss                | 0.00011677017 |
| time_elapsed            | 6235          |
| total timesteps         | 1218577       |
| value_loss              | 0.0001405965  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016211737  |
| ent_coef_loss           | -2.549964     |
| entropy                 | 1.180131      |
| episodes                | 5100          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1220256       |
| policy_loss             | -0.3265632    |
| qf1_loss                | 0.00026286958 |
| qf2_loss                | 0.000235632   |
| time_elapsed            | 6244          |
| total timesteps         | 1220356       |
| value_loss              | 9.4861185e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016591637  |
| ent_coef_loss           | -2.4859715    |
| entropy                 | 1.2936687     |
| episodes                | 5110          |
| fps                     | 195           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1221968       |
| policy_loss             | -0.35118124   |
| qf1_loss                | 0.00012881756 |
| qf2_loss                | 9.8061224e-05 |
| time_elapsed            | 6253          |
| total timesteps         | 1222068       |
| value_loss              | 0.00010185214 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016304456  |
| ent_coef_loss           | 0.18683136    |
| entropy                 | 1.2562279     |
| episodes                | 5120          |
| fps                     | 195           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1223685       |
| policy_loss             | -0.3130902    |
| qf1_loss                | 0.00037192102 |
| qf2_loss                | 0.00043761783 |
| time_elapsed            | 6262          |
| total timesteps         | 1223785       |
| value_loss              | 0.00012322281 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0015874077   |
| ent_coef_loss           | 1.9003693      |
| entropy                 | 1.2253792      |
| episodes                | 5130           |
| fps                     | 195            |
| mean 100 episode reward | 1.7            |
| n_updates               | 1225482        |
| policy_loss             | -0.32303846    |
| qf1_loss                | 0.0002293243   |
| qf2_loss                | 0.00030187285  |
| time_elapsed            | 6272           |
| total timesteps         | 1225582        |
| value_loss              | 0.000116655385 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015760394  |
| ent_coef_loss           | 1.0030713     |
| entropy                 | 1.2055919     |
| episodes                | 5140          |
| fps                     | 195           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1227113       |
| policy_loss             | -0.28846118   |
| qf1_loss                | 9.8816134e-05 |
| qf2_loss                | 0.00012167967 |
| time_elapsed            | 6280          |
| total timesteps         | 1227213       |
| value_loss              | 0.00011756658 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015880663  |
| ent_coef_loss           | 1.9278067     |
| entropy                 | 1.354058      |
| episodes                | 5150          |
| fps                     | 195           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1228815       |
| policy_loss             | -0.34147823   |
| qf1_loss                | 0.00011837586 |
| qf2_loss                | 0.00012692038 |
| time_elapsed            | 6289          |
| total timesteps         | 1228915       |
| value_loss              | 0.00010427272 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015839658  |
| ent_coef_loss           | 3.2199726     |
| entropy                 | 1.268311      |
| episodes                | 5160          |
| fps                     | 195           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1230513       |
| policy_loss             | -0.32017264   |
| qf1_loss                | 0.00013271722 |
| qf2_loss                | 0.00014705543 |
| time_elapsed            | 6298          |
| total timesteps         | 1230613       |
| value_loss              | 7.2054085e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016151675  |
| ent_coef_loss           | -0.6560709    |
| entropy                 | 1.2944517     |
| episodes                | 5170          |
| fps                     | 195           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1232424       |
| policy_loss             | -0.38112867   |
| qf1_loss                | 0.00010947371 |
| qf2_loss                | 0.00012451675 |
| time_elapsed            | 6308          |
| total timesteps         | 1232524       |
| value_loss              | 8.978174e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016112559  |
| ent_coef_loss           | 0.39370358    |
| entropy                 | 1.2571723     |
| episodes                | 5180          |
| fps                     | 195           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1234189       |
| policy_loss             | -0.29090524   |
| qf1_loss                | 9.21136e-05   |
| qf2_loss                | 8.661037e-05  |
| time_elapsed            | 6317          |
| total timesteps         | 1234289       |
| value_loss              | 0.00011430227 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015727406  |
| ent_coef_loss           | -1.3926482    |
| entropy                 | 1.2295674     |
| episodes                | 5190          |
| fps                     | 195           |
| mean 100 episode reward | 1.8           |
| n_updates               | 1236114       |
| policy_loss             | -0.3409428    |
| qf1_loss                | 0.00020688227 |
| qf2_loss                | 0.00019066475 |
| time_elapsed            | 6327          |
| total timesteps         | 1236214       |
| value_loss              | 0.00020843255 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015754285  |
| ent_coef_loss           | -1.0719067    |
| entropy                 | 1.2919362     |
| episodes                | 5200          |
| fps                     | 195           |
| mean 100 episode reward | 1.8           |
| n_updates               | 1238095       |
| policy_loss             | -0.3690861    |
| qf1_loss                | 0.00022257233 |
| qf2_loss                | 0.00012728578 |
| time_elapsed            | 6337          |
| total timesteps         | 1238195       |
| value_loss              | 9.522836e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015876015  |
| ent_coef_loss           | 1.4710246     |
| entropy                 | 1.2483308     |
| episodes                | 5210          |
| fps                     | 195           |
| mean 100 episode reward | 1.8           |
| n_updates               | 1239891       |
| policy_loss             | -0.36111057   |
| qf1_loss                | 9.869947e-05  |
| qf2_loss                | 0.00018537723 |
| time_elapsed            | 6347          |
| total timesteps         | 1239991       |
| value_loss              | 4.4867924e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015764467  |
| ent_coef_loss           | 0.02317983    |
| entropy                 | 1.244657      |
| episodes                | 5220          |
| fps                     | 195           |
| mean 100 episode reward | 1.8           |
| n_updates               | 1241517       |
| policy_loss             | -0.30387223   |
| qf1_loss                | 0.00019543059 |
| qf2_loss                | 0.00020956052 |
| time_elapsed            | 6356          |
| total timesteps         | 1241617       |
| value_loss              | 0.0002485008  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015533011  |
| ent_coef_loss           | -0.7079793    |
| entropy                 | 1.2596132     |
| episodes                | 5230          |
| fps                     | 195           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1243373       |
| policy_loss             | -0.41889995   |
| qf1_loss                | 0.00019831891 |
| qf2_loss                | 0.0001476914  |
| time_elapsed            | 6365          |
| total timesteps         | 1243473       |
| value_loss              | 0.00016896479 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015509313  |
| ent_coef_loss           | -1.6684089    |
| entropy                 | 1.3022008     |
| episodes                | 5240          |
| fps                     | 195           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1244930       |
| policy_loss             | -0.3172507    |
| qf1_loss                | 0.00011786361 |
| qf2_loss                | 0.0002143243  |
| time_elapsed            | 6374          |
| total timesteps         | 1245030       |
| value_loss              | 7.4554744e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015260266  |
| ent_coef_loss           | -0.17414004   |
| entropy                 | 1.2147211     |
| episodes                | 5250          |
| fps                     | 195           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1246764       |
| policy_loss             | -0.29152107   |
| qf1_loss                | 0.00026372835 |
| qf2_loss                | 0.00030331974 |
| time_elapsed            | 6383          |
| total timesteps         | 1246864       |
| value_loss              | 0.00010605467 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014929498  |
| ent_coef_loss           | 0.8302833     |
| entropy                 | 1.1756816     |
| episodes                | 5260          |
| fps                     | 195           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1248490       |
| policy_loss             | -0.26744068   |
| qf1_loss                | 0.00022217393 |
| qf2_loss                | 0.00016724819 |
| time_elapsed            | 6393          |
| total timesteps         | 1248590       |
| value_loss              | 9.8922676e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0014934867   |
| ent_coef_loss           | -0.27150345    |
| entropy                 | 1.2287772      |
| episodes                | 5270           |
| fps                     | 195            |
| mean 100 episode reward | 1.7            |
| n_updates               | 1250026        |
| policy_loss             | -0.39483467    |
| qf1_loss                | 0.000119817996 |
| qf2_loss                | 0.00015597102  |
| time_elapsed            | 6400           |
| total timesteps         | 1250126        |
| value_loss              | 0.00011344721  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015097043  |
| ent_coef_loss           | 0.78722227    |
| entropy                 | 1.2451215     |
| episodes                | 5280          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1251451       |
| policy_loss             | -0.3404525    |
| qf1_loss                | 0.00012404981 |
| qf2_loss                | 9.313607e-05  |
| time_elapsed            | 6409          |
| total timesteps         | 1251551       |
| value_loss              | 6.223809e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014855786  |
| ent_coef_loss           | 1.0463796     |
| entropy                 | 1.2360344     |
| episodes                | 5290          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1253109       |
| policy_loss             | -0.4115591    |
| qf1_loss                | 0.00013364665 |
| qf2_loss                | 9.055351e-05  |
| time_elapsed            | 6417          |
| total timesteps         | 1253209       |
| value_loss              | 5.506853e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014697483  |
| ent_coef_loss           | 0.81312114    |
| entropy                 | 1.142997      |
| episodes                | 5300          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1254753       |
| policy_loss             | -0.3604375    |
| qf1_loss                | 0.00027397342 |
| qf2_loss                | 0.00034377212 |
| time_elapsed            | 6425          |
| total timesteps         | 1254853       |
| value_loss              | 7.621964e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014701297  |
| ent_coef_loss           | -1.0662949    |
| entropy                 | 1.1948981     |
| episodes                | 5310          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1256491       |
| policy_loss             | -0.31983632   |
| qf1_loss                | 0.00014445958 |
| qf2_loss                | 0.00019190955 |
| time_elapsed            | 6435          |
| total timesteps         | 1256591       |
| value_loss              | 8.822822e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001429859   |
| ent_coef_loss           | 0.19447267    |
| entropy                 | 1.2173762     |
| episodes                | 5320          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1258264       |
| policy_loss             | -0.31744432   |
| qf1_loss                | 0.0002067191  |
| qf2_loss                | 9.6970645e-05 |
| time_elapsed            | 6445          |
| total timesteps         | 1258364       |
| value_loss              | 0.00012092331 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0013995537  |
| ent_coef_loss           | 0.4642882     |
| entropy                 | 1.199808      |
| episodes                | 5330          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1260064       |
| policy_loss             | -0.32650015   |
| qf1_loss                | 0.00012473798 |
| qf2_loss                | 0.0001336478  |
| time_elapsed            | 6454          |
| total timesteps         | 1260164       |
| value_loss              | 0.00012973972 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001448371   |
| ent_coef_loss           | -0.90470684   |
| entropy                 | 1.2063711     |
| episodes                | 5340          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1261866       |
| policy_loss             | -0.34483907   |
| qf1_loss                | 0.00016585243 |
| qf2_loss                | 0.0002207386  |
| time_elapsed            | 6463          |
| total timesteps         | 1261966       |
| value_loss              | 8.1961785e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014506871  |
| ent_coef_loss           | 0.6104549     |
| entropy                 | 1.2727782     |
| episodes                | 5350          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1263718       |
| policy_loss             | -0.33000982   |
| qf1_loss                | 0.00016557288 |
| qf2_loss                | 0.00016644842 |
| time_elapsed            | 6474          |
| total timesteps         | 1263818       |
| value_loss              | 8.8457e-05    |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014565587  |
| ent_coef_loss           | -0.9518432    |
| entropy                 | 1.1844237     |
| episodes                | 5360          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1265310       |
| policy_loss             | -0.3853214    |
| qf1_loss                | 0.00016559038 |
| qf2_loss                | 0.00013069538 |
| time_elapsed            | 6482          |
| total timesteps         | 1265410       |
| value_loss              | 6.411575e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014615018  |
| ent_coef_loss           | 0.9461706     |
| entropy                 | 1.2921791     |
| episodes                | 5370          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1267094       |
| policy_loss             | -0.42836165   |
| qf1_loss                | 0.00011166206 |
| qf2_loss                | 9.124828e-05  |
| time_elapsed            | 6491          |
| total timesteps         | 1267194       |
| value_loss              | 4.2974858e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014673527  |
| ent_coef_loss           | -1.7769264    |
| entropy                 | 1.2556617     |
| episodes                | 5380          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1268762       |
| policy_loss             | -0.34211946   |
| qf1_loss                | 0.00024296502 |
| qf2_loss                | 0.00035937675 |
| time_elapsed            | 6500          |
| total timesteps         | 1268862       |
| value_loss              | 0.00016900199 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014791082  |
| ent_coef_loss           | -0.52731293   |
| entropy                 | 1.2257162     |
| episodes                | 5390          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1270572       |
| policy_loss             | -0.30089238   |
| qf1_loss                | 0.0001617733  |
| qf2_loss                | 0.00012019556 |
| time_elapsed            | 6510          |
| total timesteps         | 1270672       |
| value_loss              | 0.00014589823 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014854482  |
| ent_coef_loss           | -0.01835221   |
| entropy                 | 1.2844748     |
| episodes                | 5400          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1272304       |
| policy_loss             | -0.3568766    |
| qf1_loss                | 0.00016894042 |
| qf2_loss                | 0.00015461973 |
| time_elapsed            | 6518          |
| total timesteps         | 1272404       |
| value_loss              | 0.00012490031 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00146517    |
| ent_coef_loss           | -2.9358408    |
| entropy                 | 1.2236658     |
| episodes                | 5410          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1273864       |
| policy_loss             | -0.348392     |
| qf1_loss                | 0.00010568772 |
| qf2_loss                | 0.00015339922 |
| time_elapsed            | 6527          |
| total timesteps         | 1273964       |
| value_loss              | 0.00010746265 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015013918  |
| ent_coef_loss           | 0.046303034   |
| entropy                 | 1.2351935     |
| episodes                | 5420          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1275619       |
| policy_loss             | -0.32004464   |
| qf1_loss                | 0.00027214407 |
| qf2_loss                | 0.00026373536 |
| time_elapsed            | 6536          |
| total timesteps         | 1275719       |
| value_loss              | 0.00019769873 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001505949   |
| ent_coef_loss           | 3.4232972     |
| entropy                 | 1.295568      |
| episodes                | 5430          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1277272       |
| policy_loss             | -0.37029076   |
| qf1_loss                | 0.00024833743 |
| qf2_loss                | 0.00015281804 |
| time_elapsed            | 6545          |
| total timesteps         | 1277372       |
| value_loss              | 9.7765165e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015649442  |
| ent_coef_loss           | -1.3279521    |
| entropy                 | 1.2944515     |
| episodes                | 5440          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1279149       |
| policy_loss             | -0.35750073   |
| qf1_loss                | 0.00030571347 |
| qf2_loss                | 0.00027562826 |
| time_elapsed            | 6555          |
| total timesteps         | 1279249       |
| value_loss              | 0.00030456838 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015858734  |
| ent_coef_loss           | -1.9000993    |
| entropy                 | 1.3120005     |
| episodes                | 5450          |
| fps                     | 195           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1280929       |
| policy_loss             | -0.3595882    |
| qf1_loss                | 0.00017408215 |
| qf2_loss                | 0.00019785755 |
| time_elapsed            | 6565          |
| total timesteps         | 1281029       |
| value_loss              | 8.3621926e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016041326  |
| ent_coef_loss           | -2.2356718    |
| entropy                 | 1.2860941     |
| episodes                | 5460          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1282672       |
| policy_loss             | -0.3993947    |
| qf1_loss                | 0.0001526326  |
| qf2_loss                | 0.00011377543 |
| time_elapsed            | 6574          |
| total timesteps         | 1282772       |
| value_loss              | 7.623261e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016223197  |
| ent_coef_loss           | 3.9681947     |
| entropy                 | 1.3711352     |
| episodes                | 5470          |
| fps                     | 195           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1283914       |
| policy_loss             | -0.34782293   |
| qf1_loss                | 0.00018950683 |
| qf2_loss                | 0.0001910723  |
| time_elapsed            | 6580          |
| total timesteps         | 1284014       |
| value_loss              | 0.00017232791 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016597501  |
| ent_coef_loss           | -1.5842476    |
| entropy                 | 1.2535039     |
| episodes                | 5480          |
| fps                     | 195           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1285779       |
| policy_loss             | -0.3249915    |
| qf1_loss                | 0.00021798913 |
| qf2_loss                | 0.00013839916 |
| time_elapsed            | 6590          |
| total timesteps         | 1285879       |
| value_loss              | 0.00016793821 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016667055  |
| ent_coef_loss           | 0.2945354     |
| entropy                 | 1.2846237     |
| episodes                | 5490          |
| fps                     | 195           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1287585       |
| policy_loss             | -0.2753929    |
| qf1_loss                | 0.00035089548 |
| qf2_loss                | 0.0001624096  |
| time_elapsed            | 6600          |
| total timesteps         | 1287685       |
| value_loss              | 8.545267e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016695595  |
| ent_coef_loss           | -0.286035     |
| entropy                 | 1.2994606     |
| episodes                | 5500          |
| fps                     | 195           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1289147       |
| policy_loss             | -0.2535086    |
| qf1_loss                | 0.0003208368  |
| qf2_loss                | 0.00021619823 |
| time_elapsed            | 6607          |
| total timesteps         | 1289247       |
| value_loss              | 7.872758e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016989803  |
| ent_coef_loss           | 3.9954276     |
| entropy                 | 1.3572786     |
| episodes                | 5510          |
| fps                     | 195           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1290843       |
| policy_loss             | -0.30871046   |
| qf1_loss                | 9.8895034e-05 |
| qf2_loss                | 0.00014338485 |
| time_elapsed            | 6616          |
| total timesteps         | 1290943       |
| value_loss              | 0.00012488563 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016801485  |
| ent_coef_loss           | -2.586293     |
| entropy                 | 1.2526476     |
| episodes                | 5520          |
| fps                     | 195           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1292664       |
| policy_loss             | -0.26387498   |
| qf1_loss                | 0.00016636525 |
| qf2_loss                | 0.00015073184 |
| time_elapsed            | 6626          |
| total timesteps         | 1292764       |
| value_loss              | 8.121265e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0016572938   |
| ent_coef_loss           | -1.4005013     |
| entropy                 | 1.2991573      |
| episodes                | 5530           |
| fps                     | 195            |
| mean 100 episode reward | 1.5            |
| n_updates               | 1294443        |
| policy_loss             | -0.37374154    |
| qf1_loss                | 0.00025598303  |
| qf2_loss                | 0.00038849667  |
| time_elapsed            | 6635           |
| total timesteps         | 1294543        |
| value_loss              | 0.000106575535 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016882798  |
| ent_coef_loss           | 0.06879473    |
| entropy                 | 1.3432531     |
| episodes                | 5540          |
| fps                     | 195           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1296038       |
| policy_loss             | -0.3063107    |
| qf1_loss                | 0.00014791093 |
| qf2_loss                | 0.00015449831 |
| time_elapsed            | 6644          |
| total timesteps         | 1296138       |
| value_loss              | 0.00016787223 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0017410454 |
| ent_coef_loss           | -0.73569345  |
| entropy                 | 1.2553225    |
| episodes                | 5550         |
| fps                     | 195          |
| mean 100 episode reward | 1.6          |
| n_updates               | 1297657      |
| policy_loss             | -0.28379005  |
| qf1_loss                | 0.0004192187 |
| qf2_loss                | 0.0003827762 |
| time_elapsed            | 6652         |
| total timesteps         | 1297757      |
| value_loss              | 7.575634e-05 |
------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0017511548   |
| ent_coef_loss           | 2.8931997      |
| entropy                 | 1.2900575      |
| episodes                | 5560           |
| fps                     | 195            |
| mean 100 episode reward | 1.6            |
| n_updates               | 1299343        |
| policy_loss             | -0.32327393    |
| qf1_loss                | 0.0003657734   |
| qf2_loss                | 0.00036027835  |
| time_elapsed            | 6662           |
| total timesteps         | 1299443        |
| value_loss              | 0.000101635684 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017075081  |
| ent_coef_loss           | -4.1308327    |
| entropy                 | 1.3576168     |
| episodes                | 5570          |
| fps                     | 195           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1301116       |
| policy_loss             | -0.37936875   |
| qf1_loss                | 9.95057e-05   |
| qf2_loss                | 5.5833534e-05 |
| time_elapsed            | 6671          |
| total timesteps         | 1301216       |
| value_loss              | 7.364558e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017393285  |
| ent_coef_loss           | -0.7452558    |
| entropy                 | 1.3268876     |
| episodes                | 5580          |
| fps                     | 195           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1302929       |
| policy_loss             | -0.34766048   |
| qf1_loss                | 0.00014574779 |
| qf2_loss                | 0.00013976874 |
| time_elapsed            | 6681          |
| total timesteps         | 1303029       |
| value_loss              | 0.00021948383 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0017367619   |
| ent_coef_loss           | -0.47769397    |
| entropy                 | 1.3252519      |
| episodes                | 5590           |
| fps                     | 194            |
| mean 100 episode reward | 1.7            |
| n_updates               | 1304606        |
| policy_loss             | -0.3207373     |
| qf1_loss                | 0.00012177561  |
| qf2_loss                | 0.00017440214  |
| time_elapsed            | 6690           |
| total timesteps         | 1304706        |
| value_loss              | 0.000103870625 |
--------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0017743756   |
| ent_coef_loss           | 0.9669072      |
| entropy                 | 1.3244102      |
| episodes                | 5600           |
| fps                     | 195            |
| mean 100 episode reward | 1.8            |
| n_updates               | 1306347        |
| policy_loss             | -0.34253865    |
| qf1_loss                | 0.000113475704 |
| qf2_loss                | 0.00012607737  |
| time_elapsed            | 6699           |
| total timesteps         | 1306447        |
| value_loss              | 0.00011042738  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017744983  |
| ent_coef_loss           | -2.466829     |
| entropy                 | 1.3382918     |
| episodes                | 5610          |
| fps                     | 194           |
| mean 100 episode reward | 1.8           |
| n_updates               | 1307998       |
| policy_loss             | -0.28638005   |
| qf1_loss                | 0.0021230958  |
| qf2_loss                | 0.0017306731  |
| time_elapsed            | 6709          |
| total timesteps         | 1308098       |
| value_loss              | 0.00021376625 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017260374  |
| ent_coef_loss           | 2.2034755     |
| entropy                 | 1.3250084     |
| episodes                | 5620          |
| fps                     | 194           |
| mean 100 episode reward | 1.8           |
| n_updates               | 1309705       |
| policy_loss             | -0.419226     |
| qf1_loss                | 0.00011925216 |
| qf2_loss                | 0.00010306471 |
| time_elapsed            | 6718          |
| total timesteps         | 1309805       |
| value_loss              | 0.00011465319 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016988085  |
| ent_coef_loss           | -0.76316506   |
| entropy                 | 1.3425311     |
| episodes                | 5630          |
| fps                     | 194           |
| mean 100 episode reward | 1.8           |
| n_updates               | 1311505       |
| policy_loss             | -0.35384583   |
| qf1_loss                | 8.317842e-05  |
| qf2_loss                | 0.00011550622 |
| time_elapsed            | 6727          |
| total timesteps         | 1311605       |
| value_loss              | 0.00020574543 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017178544  |
| ent_coef_loss           | 0.17428827    |
| entropy                 | 1.2997397     |
| episodes                | 5640          |
| fps                     | 194           |
| mean 100 episode reward | 1.8           |
| n_updates               | 1313237       |
| policy_loss             | -0.3828847    |
| qf1_loss                | 0.000124925   |
| qf2_loss                | 0.00026822946 |
| time_elapsed            | 6736          |
| total timesteps         | 1313337       |
| value_loss              | 4.9614413e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016797632  |
| ent_coef_loss           | 2.4554136     |
| entropy                 | 1.3029447     |
| episodes                | 5650          |
| fps                     | 194           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1314890       |
| policy_loss             | -0.3421317    |
| qf1_loss                | 0.00023017258 |
| qf2_loss                | 0.00015582133 |
| time_elapsed            | 6745          |
| total timesteps         | 1314990       |
| value_loss              | 8.1377904e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016998951  |
| ent_coef_loss           | 1.6323547     |
| entropy                 | 1.2995833     |
| episodes                | 5660          |
| fps                     | 194           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1316335       |
| policy_loss             | -0.3629188    |
| qf1_loss                | 0.00014269298 |
| qf2_loss                | 0.00011567962 |
| time_elapsed            | 6752          |
| total timesteps         | 1316435       |
| value_loss              | 0.00010359404 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016741481  |
| ent_coef_loss           | -0.31287542   |
| entropy                 | 1.3472692     |
| episodes                | 5670          |
| fps                     | 194           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1318080       |
| policy_loss             | -0.33657497   |
| qf1_loss                | 0.00040543667 |
| qf2_loss                | 0.00016220656 |
| time_elapsed            | 6761          |
| total timesteps         | 1318180       |
| value_loss              | 9.817437e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0016641603 |
| ent_coef_loss           | 2.5161457    |
| entropy                 | 1.3358425    |
| episodes                | 5680         |
| fps                     | 194          |
| mean 100 episode reward | 1.5          |
| n_updates               | 1319305      |
| policy_loss             | -0.35341698  |
| qf1_loss                | 8.156108e-05 |
| qf2_loss                | 7.047456e-05 |
| time_elapsed            | 6768         |
| total timesteps         | 1319405      |
| value_loss              | 6.475813e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016136302  |
| ent_coef_loss           | 0.45122784    |
| entropy                 | 1.287127      |
| episodes                | 5690          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1321061       |
| policy_loss             | -0.30601045   |
| qf1_loss                | 0.00019667375 |
| qf2_loss                | 0.00013267499 |
| time_elapsed            | 6777          |
| total timesteps         | 1321161       |
| value_loss              | 8.558897e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015657458  |
| ent_coef_loss           | -1.4587282    |
| entropy                 | 1.2977388     |
| episodes                | 5700          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1322633       |
| policy_loss             | -0.35515738   |
| qf1_loss                | 0.00016974859 |
| qf2_loss                | 0.00018640222 |
| time_elapsed            | 6785          |
| total timesteps         | 1322733       |
| value_loss              | 7.417152e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015609569  |
| ent_coef_loss           | 0.3119278     |
| entropy                 | 1.3069525     |
| episodes                | 5710          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1324350       |
| policy_loss             | -0.38465858   |
| qf1_loss                | 0.00016893786 |
| qf2_loss                | 0.00014924843 |
| time_elapsed            | 6794          |
| total timesteps         | 1324450       |
| value_loss              | 0.00020248382 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016036087  |
| ent_coef_loss           | -4.468944     |
| entropy                 | 1.271487      |
| episodes                | 5720          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1326134       |
| policy_loss             | -0.34242862   |
| qf1_loss                | 0.0002771237  |
| qf2_loss                | 0.0004198996  |
| time_elapsed            | 6804          |
| total timesteps         | 1326234       |
| value_loss              | 0.00011995877 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015901107  |
| ent_coef_loss           | -3.3414915    |
| entropy                 | 1.3132463     |
| episodes                | 5730          |
| fps                     | 194           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1327638       |
| policy_loss             | -0.36531368   |
| qf1_loss                | 0.00012423945 |
| qf2_loss                | 0.00017898368 |
| time_elapsed            | 6812          |
| total timesteps         | 1327738       |
| value_loss              | 0.00012487211 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016613052  |
| ent_coef_loss           | -2.183041     |
| entropy                 | 1.3179266     |
| episodes                | 5740          |
| fps                     | 194           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1329304       |
| policy_loss             | -0.3112049    |
| qf1_loss                | 0.00013393746 |
| qf2_loss                | 9.4615316e-05 |
| time_elapsed            | 6820          |
| total timesteps         | 1329404       |
| value_loss              | 0.00011195319 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001637229   |
| ent_coef_loss           | -0.21697491   |
| entropy                 | 1.2284446     |
| episodes                | 5750          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1331075       |
| policy_loss             | -0.26208055   |
| qf1_loss                | 0.00021706178 |
| qf2_loss                | 0.00028410406 |
| time_elapsed            | 6830          |
| total timesteps         | 1331175       |
| value_loss              | 8.652118e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001636404   |
| ent_coef_loss           | 0.7506014     |
| entropy                 | 1.3155723     |
| episodes                | 5760          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1332810       |
| policy_loss             | -0.40274283   |
| qf1_loss                | 0.00012403642 |
| qf2_loss                | 0.00015692145 |
| time_elapsed            | 6839          |
| total timesteps         | 1332910       |
| value_loss              | 8.6993845e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016389779  |
| ent_coef_loss           | 0.3157394     |
| entropy                 | 1.2213242     |
| episodes                | 5770          |
| fps                     | 194           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1334304       |
| policy_loss             | -0.35335207   |
| qf1_loss                | 0.00037991325 |
| qf2_loss                | 0.00026612225 |
| time_elapsed            | 6846          |
| total timesteps         | 1334404       |
| value_loss              | 0.00019107044 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016052146  |
| ent_coef_loss           | -1.6062186    |
| entropy                 | 1.2629542     |
| episodes                | 5780          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1335883       |
| policy_loss             | -0.24658202   |
| qf1_loss                | 0.00022033406 |
| qf2_loss                | 0.00018844585 |
| time_elapsed            | 6855          |
| total timesteps         | 1335983       |
| value_loss              | 0.00017265661 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016225913  |
| ent_coef_loss           | 2.4880908     |
| entropy                 | 1.3730403     |
| episodes                | 5790          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1337404       |
| policy_loss             | -0.39582625   |
| qf1_loss                | 0.00014244068 |
| qf2_loss                | 9.469844e-05  |
| time_elapsed            | 6863          |
| total timesteps         | 1337504       |
| value_loss              | 6.5337146e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016269601  |
| ent_coef_loss           | 0.8823689     |
| entropy                 | 1.3531607     |
| episodes                | 5800          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1338863       |
| policy_loss             | -0.3380555    |
| qf1_loss                | 0.00023245317 |
| qf2_loss                | 0.0002204041  |
| time_elapsed            | 6871          |
| total timesteps         | 1338963       |
| value_loss              | 0.00014715755 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0016170648   |
| ent_coef_loss           | 2.256735       |
| entropy                 | 1.3172266      |
| episodes                | 5810           |
| fps                     | 194            |
| mean 100 episode reward | 1.4            |
| n_updates               | 1340382        |
| policy_loss             | -0.3557725     |
| qf1_loss                | 0.00017661019  |
| qf2_loss                | 0.00014986192  |
| time_elapsed            | 6878           |
| total timesteps         | 1340482        |
| value_loss              | 0.000105540676 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016204881  |
| ent_coef_loss           | -0.83222127   |
| entropy                 | 1.325311      |
| episodes                | 5820          |
| fps                     | 194           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1342031       |
| policy_loss             | -0.37305975   |
| qf1_loss                | 0.00021928386 |
| qf2_loss                | 0.00027714958 |
| time_elapsed            | 6887          |
| total timesteps         | 1342131       |
| value_loss              | 0.00016442002 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016287594  |
| ent_coef_loss           | -0.33912385   |
| entropy                 | 1.341634      |
| episodes                | 5830          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1343792       |
| policy_loss             | -0.35739046   |
| qf1_loss                | 0.00022463132 |
| qf2_loss                | 0.00021679    |
| time_elapsed            | 6897          |
| total timesteps         | 1343892       |
| value_loss              | 0.00022470267 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0016596837   |
| ent_coef_loss           | -0.26954964    |
| entropy                 | 1.2899184      |
| episodes                | 5840           |
| fps                     | 194            |
| mean 100 episode reward | 1.4            |
| n_updates               | 1345304        |
| policy_loss             | -0.33004385    |
| qf1_loss                | 0.0002588124   |
| qf2_loss                | 0.00015818614  |
| time_elapsed            | 6904           |
| total timesteps         | 1345404        |
| value_loss              | 0.000122008256 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016460825  |
| ent_coef_loss           | -0.23602879   |
| entropy                 | 1.2747892     |
| episodes                | 5850          |
| fps                     | 194           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1347061       |
| policy_loss             | -0.29601476   |
| qf1_loss                | 0.00027831405 |
| qf2_loss                | 0.00022913325 |
| time_elapsed            | 6913          |
| total timesteps         | 1347161       |
| value_loss              | 0.00012133653 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016746344  |
| ent_coef_loss           | 0.7586992     |
| entropy                 | 1.383743      |
| episodes                | 5860          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1349146       |
| policy_loss             | -0.3414023    |
| qf1_loss                | 0.00015680952 |
| qf2_loss                | 0.00012698087 |
| time_elapsed            | 6925          |
| total timesteps         | 1349246       |
| value_loss              | 9.84723e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016712544  |
| ent_coef_loss           | 0.9927072     |
| entropy                 | 1.3322196     |
| episodes                | 5870          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1350624       |
| policy_loss             | -0.2259525    |
| qf1_loss                | 0.0006149771  |
| qf2_loss                | 0.00037975638 |
| time_elapsed            | 6933          |
| total timesteps         | 1350724       |
| value_loss              | 0.00013669755 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016784661  |
| ent_coef_loss           | -1.0484921    |
| entropy                 | 1.2798649     |
| episodes                | 5880          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1352121       |
| policy_loss             | -0.30822948   |
| qf1_loss                | 0.00025786913 |
| qf2_loss                | 0.0001867915  |
| time_elapsed            | 6941          |
| total timesteps         | 1352221       |
| value_loss              | 0.00013301302 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016765688  |
| ent_coef_loss           | -0.30947685   |
| entropy                 | 1.3280482     |
| episodes                | 5890          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1354017       |
| policy_loss             | -0.4102547    |
| qf1_loss                | 0.00030714346 |
| qf2_loss                | 0.0003424338  |
| time_elapsed            | 6951          |
| total timesteps         | 1354117       |
| value_loss              | 0.00012362278 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016769757  |
| ent_coef_loss           | 1.0331016     |
| entropy                 | 1.4388928     |
| episodes                | 5900          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1355659       |
| policy_loss             | -0.3528141    |
| qf1_loss                | 0.00018781854 |
| qf2_loss                | 0.00013657607 |
| time_elapsed            | 6960          |
| total timesteps         | 1355759       |
| value_loss              | 6.7911256e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017067608  |
| ent_coef_loss           | -0.39352742   |
| entropy                 | 1.3433007     |
| episodes                | 5910          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1357523       |
| policy_loss             | -0.36221737   |
| qf1_loss                | 0.00016684143 |
| qf2_loss                | 0.000270492   |
| time_elapsed            | 6969          |
| total timesteps         | 1357623       |
| value_loss              | 9.5864e-05    |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017044161  |
| ent_coef_loss           | -1.9053059    |
| entropy                 | 1.3039627     |
| episodes                | 5920          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1358925       |
| policy_loss             | -0.39279777   |
| qf1_loss                | 0.00020641096 |
| qf2_loss                | 0.00015124182 |
| time_elapsed            | 6977          |
| total timesteps         | 1359025       |
| value_loss              | 9.146228e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016791906  |
| ent_coef_loss           | 0.39427608    |
| entropy                 | 1.3454622     |
| episodes                | 5930          |
| fps                     | 194           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1360368       |
| policy_loss             | -0.35007608   |
| qf1_loss                | 0.00012551234 |
| qf2_loss                | 0.00016659447 |
| time_elapsed            | 6985          |
| total timesteps         | 1360468       |
| value_loss              | 6.681241e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016516916  |
| ent_coef_loss           | -0.43286815   |
| entropy                 | 1.3490032     |
| episodes                | 5940          |
| fps                     | 194           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1361656       |
| policy_loss             | -0.35618788   |
| qf1_loss                | 0.0001874471  |
| qf2_loss                | 0.00014329191 |
| time_elapsed            | 6992          |
| total timesteps         | 1361756       |
| value_loss              | 0.00010405191 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016350851  |
| ent_coef_loss           | 1.1690471     |
| entropy                 | 1.3043749     |
| episodes                | 5950          |
| fps                     | 194           |
| mean 100 episode reward | 1.3           |
| n_updates               | 1363044       |
| policy_loss             | -0.3381964    |
| qf1_loss                | 8.302526e-05  |
| qf2_loss                | 9.418395e-05  |
| time_elapsed            | 6999          |
| total timesteps         | 1363144       |
| value_loss              | 0.00012025779 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016112183  |
| ent_coef_loss           | -3.2275572    |
| entropy                 | 1.2588882     |
| episodes                | 5960          |
| fps                     | 194           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1364831       |
| policy_loss             | -0.3431753    |
| qf1_loss                | 0.012898305   |
| qf2_loss                | 0.012184072   |
| time_elapsed            | 7009          |
| total timesteps         | 1364931       |
| value_loss              | 0.00010461883 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001593322   |
| ent_coef_loss           | 0.95302165    |
| entropy                 | 1.2127934     |
| episodes                | 5970          |
| fps                     | 194           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1366634       |
| policy_loss             | -0.27603585   |
| qf1_loss                | 0.00011606475 |
| qf2_loss                | 0.00021038206 |
| time_elapsed            | 7019          |
| total timesteps         | 1366734       |
| value_loss              | 0.00011592161 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001599507   |
| ent_coef_loss           | -1.2075235    |
| entropy                 | 1.2549925     |
| episodes                | 5980          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1368451       |
| policy_loss             | -0.33957753   |
| qf1_loss                | 0.00010550169 |
| qf2_loss                | 0.00010494142 |
| time_elapsed            | 7027          |
| total timesteps         | 1368551       |
| value_loss              | 9.349426e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015500048  |
| ent_coef_loss           | 1.1039559     |
| entropy                 | 1.2559755     |
| episodes                | 5990          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1370252       |
| policy_loss             | -0.33428586   |
| qf1_loss                | 0.00013397615 |
| qf2_loss                | 0.00016568825 |
| time_elapsed            | 7037          |
| total timesteps         | 1370352       |
| value_loss              | 0.00012203976 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015370732  |
| ent_coef_loss           | -2.670938     |
| entropy                 | 1.2765038     |
| episodes                | 6000          |
| fps                     | 194           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1371867       |
| policy_loss             | -0.26529667   |
| qf1_loss                | 0.00023186658 |
| qf2_loss                | 0.000194344   |
| time_elapsed            | 7045          |
| total timesteps         | 1371967       |
| value_loss              | 9.967015e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015178095  |
| ent_coef_loss           | 1.6617162     |
| entropy                 | 1.2524512     |
| episodes                | 6010          |
| fps                     | 194           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1373572       |
| policy_loss             | -0.2880214    |
| qf1_loss                | 0.0002383753  |
| qf2_loss                | 0.00021633919 |
| time_elapsed            | 7054          |
| total timesteps         | 1373672       |
| value_loss              | 6.719189e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015260092  |
| ent_coef_loss           | 0.6346295     |
| entropy                 | 1.2878833     |
| episodes                | 6020          |
| fps                     | 194           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1375060       |
| policy_loss             | -0.33686337   |
| qf1_loss                | 8.4870626e-05 |
| qf2_loss                | 5.5222925e-05 |
| time_elapsed            | 7062          |
| total timesteps         | 1375160       |
| value_loss              | 4.911081e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015061536  |
| ent_coef_loss           | 2.631555      |
| entropy                 | 1.3188331     |
| episodes                | 6030          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1376828       |
| policy_loss             | -0.36328155   |
| qf1_loss                | 0.00013938645 |
| qf2_loss                | 0.00023924818 |
| time_elapsed            | 7072          |
| total timesteps         | 1376928       |
| value_loss              | 0.00013695752 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015073384  |
| ent_coef_loss           | 0.58864427    |
| entropy                 | 1.2718506     |
| episodes                | 6040          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1378445       |
| policy_loss             | -0.32210436   |
| qf1_loss                | 0.00020731328 |
| qf2_loss                | 0.00023754811 |
| time_elapsed            | 7081          |
| total timesteps         | 1378545       |
| value_loss              | 0.00011791781 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014935699  |
| ent_coef_loss           | 2.2349455     |
| entropy                 | 1.2932911     |
| episodes                | 6050          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1380059       |
| policy_loss             | -0.39330575   |
| qf1_loss                | 0.00021497028 |
| qf2_loss                | 0.0001993789  |
| time_elapsed            | 7089          |
| total timesteps         | 1380159       |
| value_loss              | 8.549083e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015066378  |
| ent_coef_loss           | -0.9162084    |
| entropy                 | 1.2347631     |
| episodes                | 6060          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1381938       |
| policy_loss             | -0.34862274   |
| qf1_loss                | 0.00010188626 |
| qf2_loss                | 0.00025464446 |
| time_elapsed            | 7099          |
| total timesteps         | 1382038       |
| value_loss              | 0.00020069802 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014775933  |
| ent_coef_loss           | 0.30201405    |
| entropy                 | 1.234397      |
| episodes                | 6070          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1383251       |
| policy_loss             | -0.30980712   |
| qf1_loss                | 0.00012376906 |
| qf2_loss                | 8.1888575e-05 |
| time_elapsed            | 7107          |
| total timesteps         | 1383351       |
| value_loss              | 5.457957e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014671667  |
| ent_coef_loss           | -1.5658141    |
| entropy                 | 1.2159061     |
| episodes                | 6080          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1384895       |
| policy_loss             | -0.4112814    |
| qf1_loss                | 0.00020864303 |
| qf2_loss                | 0.00026005006 |
| time_elapsed            | 7115          |
| total timesteps         | 1384995       |
| value_loss              | 0.00013014651 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014926173  |
| ent_coef_loss           | -1.4530498    |
| entropy                 | 1.2253013     |
| episodes                | 6090          |
| fps                     | 194           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1386487       |
| policy_loss             | -0.3991896    |
| qf1_loss                | 0.00010285143 |
| qf2_loss                | 7.0638445e-05 |
| time_elapsed            | 7123          |
| total timesteps         | 1386587       |
| value_loss              | 7.264389e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015158205  |
| ent_coef_loss           | -1.0032285    |
| entropy                 | 1.2443572     |
| episodes                | 6100          |
| fps                     | 194           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1388406       |
| policy_loss             | -0.2303964    |
| qf1_loss                | 0.00020909289 |
| qf2_loss                | 0.00015904543 |
| time_elapsed            | 7133          |
| total timesteps         | 1388506       |
| value_loss              | 9.582679e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015384583  |
| ent_coef_loss           | -1.4791708    |
| entropy                 | 1.3083761     |
| episodes                | 6110          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1390198       |
| policy_loss             | -0.3201375    |
| qf1_loss                | 0.0004050786  |
| qf2_loss                | 0.00040855954 |
| time_elapsed            | 7143          |
| total timesteps         | 1390298       |
| value_loss              | 0.0003383269  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015297146  |
| ent_coef_loss           | 0.8570212     |
| entropy                 | 1.3144587     |
| episodes                | 6120          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1391886       |
| policy_loss             | -0.36020625   |
| qf1_loss                | 0.00012892293 |
| qf2_loss                | 0.00010044684 |
| time_elapsed            | 7152          |
| total timesteps         | 1391986       |
| value_loss              | 9.3356546e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015655695  |
| ent_coef_loss           | -1.1608979    |
| entropy                 | 1.2956333     |
| episodes                | 6130          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1393334       |
| policy_loss             | -0.4268887    |
| qf1_loss                | 0.00019285796 |
| qf2_loss                | 0.00039417084 |
| time_elapsed            | 7160          |
| total timesteps         | 1393434       |
| value_loss              | 0.00020407434 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015805097  |
| ent_coef_loss           | 0.97687304    |
| entropy                 | 1.3214482     |
| episodes                | 6140          |
| fps                     | 194           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1394889       |
| policy_loss             | -0.3696465    |
| qf1_loss                | 0.00012147952 |
| qf2_loss                | 0.00016338858 |
| time_elapsed            | 7168          |
| total timesteps         | 1394989       |
| value_loss              | 8.766653e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00152723    |
| ent_coef_loss           | 0.44023293    |
| entropy                 | 1.2846755     |
| episodes                | 6150          |
| fps                     | 194           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1396477       |
| policy_loss             | -0.41056576   |
| qf1_loss                | 0.0002414934  |
| qf2_loss                | 0.00017831838 |
| time_elapsed            | 7176          |
| total timesteps         | 1396577       |
| value_loss              | 0.00019612757 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015275942  |
| ent_coef_loss           | -1.8885164    |
| entropy                 | 1.2410038     |
| episodes                | 6160          |
| fps                     | 194           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1397989       |
| policy_loss             | -0.34599125   |
| qf1_loss                | 0.00026440923 |
| qf2_loss                | 0.00043413293 |
| time_elapsed            | 7184          |
| total timesteps         | 1398089       |
| value_loss              | 0.00021924484 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001573586   |
| ent_coef_loss           | 0.4774468     |
| entropy                 | 1.370109      |
| episodes                | 6170          |
| fps                     | 194           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1399367       |
| policy_loss             | -0.3487899    |
| qf1_loss                | 0.00020564832 |
| qf2_loss                | 0.00019963695 |
| time_elapsed            | 7192          |
| total timesteps         | 1399467       |
| value_loss              | 0.0001958904  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0016204828 |
| ent_coef_loss           | 0.34177876   |
| entropy                 | 1.285187     |
| episodes                | 6180         |
| fps                     | 194          |
| mean 100 episode reward | 1.3          |
| n_updates               | 1400614      |
| policy_loss             | -0.31905437  |
| qf1_loss                | 0.0002380618 |
| qf2_loss                | 0.0002784807 |
| time_elapsed            | 7199         |
| total timesteps         | 1400714      |
| value_loss              | 0.0001541161 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016559176  |
| ent_coef_loss           | 1.0261083     |
| entropy                 | 1.3266528     |
| episodes                | 6190          |
| fps                     | 194           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1402345       |
| policy_loss             | -0.31017286   |
| qf1_loss                | 0.00024964756 |
| qf2_loss                | 0.00017118812 |
| time_elapsed            | 7208          |
| total timesteps         | 1402445       |
| value_loss              | 0.00010215906 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015857047  |
| ent_coef_loss           | -1.5361573    |
| entropy                 | 1.2697834     |
| episodes                | 6200          |
| fps                     | 194           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1403964       |
| policy_loss             | -0.3735869    |
| qf1_loss                | 0.00021286248 |
| qf2_loss                | 0.00020596824 |
| time_elapsed            | 7217          |
| total timesteps         | 1404064       |
| value_loss              | 0.00013494754 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015420188  |
| ent_coef_loss           | -2.7742772    |
| entropy                 | 1.2965851     |
| episodes                | 6210          |
| fps                     | 194           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1405684       |
| policy_loss             | -0.3993098    |
| qf1_loss                | 0.00010581002 |
| qf2_loss                | 0.00011295974 |
| time_elapsed            | 7226          |
| total timesteps         | 1405784       |
| value_loss              | 7.109827e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0015313574 |
| ent_coef_loss           | 0.529251     |
| entropy                 | 1.2678113    |
| episodes                | 6220         |
| fps                     | 194          |
| mean 100 episode reward | 1.4          |
| n_updates               | 1407249      |
| policy_loss             | -0.40612558  |
| qf1_loss                | 8.987528e-05 |
| qf2_loss                | 0.0001161986 |
| time_elapsed            | 7234         |
| total timesteps         | 1407349      |
| value_loss              | 7.682243e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015150964  |
| ent_coef_loss           | -2.1864386    |
| entropy                 | 1.2386518     |
| episodes                | 6230          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1409091       |
| policy_loss             | -0.42840686   |
| qf1_loss                | 0.00011001338 |
| qf2_loss                | 0.00012959377 |
| time_elapsed            | 7243          |
| total timesteps         | 1409191       |
| value_loss              | 0.00011153314 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0015097957 |
| ent_coef_loss           | -0.16268843  |
| entropy                 | 1.2325459    |
| episodes                | 6240         |
| fps                     | 194          |
| mean 100 episode reward | 1.5          |
| n_updates               | 1410785      |
| policy_loss             | -0.30014652  |
| qf1_loss                | 0.0002450281 |
| qf2_loss                | 0.0001192015 |
| time_elapsed            | 7253         |
| total timesteps         | 1410885      |
| value_loss              | 9.509295e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001492665   |
| ent_coef_loss           | 2.206354      |
| entropy                 | 1.2288206     |
| episodes                | 6250          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1412525       |
| policy_loss             | -0.39019138   |
| qf1_loss                | 0.00016021548 |
| qf2_loss                | 0.0002597282  |
| time_elapsed            | 7262          |
| total timesteps         | 1412625       |
| value_loss              | 0.0002558573  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014525886  |
| ent_coef_loss           | -0.0676578    |
| entropy                 | 1.1811688     |
| episodes                | 6260          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1414174       |
| policy_loss             | -0.339263     |
| qf1_loss                | 8.7364395e-05 |
| qf2_loss                | 7.358457e-05  |
| time_elapsed            | 7270          |
| total timesteps         | 1414274       |
| value_loss              | 7.7427314e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014513859  |
| ent_coef_loss           | 0.25694287    |
| entropy                 | 1.1148843     |
| episodes                | 6270          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1415791       |
| policy_loss             | -0.30174375   |
| qf1_loss                | 0.00021784037 |
| qf2_loss                | 0.00014342788 |
| time_elapsed            | 7280          |
| total timesteps         | 1415891       |
| value_loss              | 7.703857e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0001       |
| ent_coef                | 0.0014597746 |
| ent_coef_loss           | 1.9332756    |
| entropy                 | 1.273355     |
| episodes                | 6280         |
| fps                     | 194          |
| mean 100 episode reward | 1.7          |
| n_updates               | 1417510      |
| policy_loss             | -0.38514125  |
| qf1_loss                | 8.204355e-05 |
| qf2_loss                | 9.264621e-05 |
| time_elapsed            | 7289         |
| total timesteps         | 1417610      |
| value_loss              | 6.611916e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014764847  |
| ent_coef_loss           | -0.48515344   |
| entropy                 | 1.2865332     |
| episodes                | 6290          |
| fps                     | 194           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1419404       |
| policy_loss             | -0.3415264    |
| qf1_loss                | 0.00029449415 |
| qf2_loss                | 0.00012550724 |
| time_elapsed            | 7299          |
| total timesteps         | 1419504       |
| value_loss              | 0.00017626947 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0014923285  |
| ent_coef_loss           | -0.3338635    |
| entropy                 | 1.3321747     |
| episodes                | 6300          |
| fps                     | 194           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1421662       |
| policy_loss             | -0.4867241    |
| qf1_loss                | 0.00048584    |
| qf2_loss                | 0.00045361748 |
| time_elapsed            | 7311          |
| total timesteps         | 1421762       |
| value_loss              | 0.00014702935 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0015187977   |
| ent_coef_loss           | 1.2184998      |
| entropy                 | 1.2940363      |
| episodes                | 6310           |
| fps                     | 194            |
| mean 100 episode reward | 1.7            |
| n_updates               | 1424102        |
| policy_loss             | -0.37733373    |
| qf1_loss                | 0.00015806084  |
| qf2_loss                | 0.0003588176   |
| time_elapsed            | 7324           |
| total timesteps         | 1424202        |
| value_loss              | 0.000100541336 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015169666  |
| ent_coef_loss           | 0.7522279     |
| entropy                 | 1.26844       |
| episodes                | 6320          |
| fps                     | 194           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1425826       |
| policy_loss             | -0.28479546   |
| qf1_loss                | 0.00034016877 |
| qf2_loss                | 0.00030539045 |
| time_elapsed            | 7332          |
| total timesteps         | 1425926       |
| value_loss              | 0.00010973474 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001527514   |
| ent_coef_loss           | -1.3896413    |
| entropy                 | 1.2821785     |
| episodes                | 6330          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1427287       |
| policy_loss             | -0.37134248   |
| qf1_loss                | 0.00015227516 |
| qf2_loss                | 0.0001757592  |
| time_elapsed            | 7340          |
| total timesteps         | 1427387       |
| value_loss              | 0.00016981378 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015274944  |
| ent_coef_loss           | 0.67579323    |
| entropy                 | 1.2324737     |
| episodes                | 6340          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1428888       |
| policy_loss             | -0.3944747    |
| qf1_loss                | 0.00011563125 |
| qf2_loss                | 0.0001025514  |
| time_elapsed            | 7349          |
| total timesteps         | 1428988       |
| value_loss              | 0.00013265904 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015415953  |
| ent_coef_loss           | -0.95806277   |
| entropy                 | 1.3044324     |
| episodes                | 6350          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1430449       |
| policy_loss             | -0.3268997    |
| qf1_loss                | 0.00013968215 |
| qf2_loss                | 0.00016597795 |
| time_elapsed            | 7357          |
| total timesteps         | 1430549       |
| value_loss              | 0.00012862327 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015655793  |
| ent_coef_loss           | -1.3025662    |
| entropy                 | 1.254592      |
| episodes                | 6360          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1432079       |
| policy_loss             | -0.3240971    |
| qf1_loss                | 0.00023364283 |
| qf2_loss                | 0.00022563449 |
| time_elapsed            | 7366          |
| total timesteps         | 1432179       |
| value_loss              | 7.123081e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015584149  |
| ent_coef_loss           | 1.779417      |
| entropy                 | 1.2171977     |
| episodes                | 6370          |
| fps                     | 194           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1433967       |
| policy_loss             | -0.34443778   |
| qf1_loss                | 0.00033241184 |
| qf2_loss                | 0.00020188428 |
| time_elapsed            | 7376          |
| total timesteps         | 1434067       |
| value_loss              | 0.0001462226  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015438626  |
| ent_coef_loss           | -2.485157     |
| entropy                 | 1.2338507     |
| episodes                | 6380          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1435720       |
| policy_loss             | -0.29307485   |
| qf1_loss                | 0.00033767876 |
| qf2_loss                | 0.00028955477 |
| time_elapsed            | 7385          |
| total timesteps         | 1435820       |
| value_loss              | 0.00010484795 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.00154719    |
| ent_coef_loss           | 1.8931019     |
| entropy                 | 1.2883513     |
| episodes                | 6390          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1437429       |
| policy_loss             | -0.38973543   |
| qf1_loss                | 0.00018256501 |
| qf2_loss                | 0.00023978914 |
| time_elapsed            | 7394          |
| total timesteps         | 1437529       |
| value_loss              | 6.770977e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0015461841   |
| ent_coef_loss           | -3.6916847     |
| entropy                 | 1.220855       |
| episodes                | 6400           |
| fps                     | 194            |
| mean 100 episode reward | 1.6            |
| n_updates               | 1439219        |
| policy_loss             | -0.32293284    |
| qf1_loss                | 0.00012776844  |
| qf2_loss                | 0.00014540402  |
| time_elapsed            | 7404           |
| total timesteps         | 1439319        |
| value_loss              | 0.000107539425 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015766106  |
| ent_coef_loss           | 1.2243813     |
| entropy                 | 1.2896287     |
| episodes                | 6410          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1440984       |
| policy_loss             | -0.3880691    |
| qf1_loss                | 0.00020951995 |
| qf2_loss                | 0.00017612224 |
| time_elapsed            | 7413          |
| total timesteps         | 1441084       |
| value_loss              | 6.7316374e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0015885541   |
| ent_coef_loss           | 0.18026169     |
| entropy                 | 1.3189223      |
| episodes                | 6420           |
| fps                     | 194            |
| mean 100 episode reward | 1.5            |
| n_updates               | 1442441        |
| policy_loss             | -0.39762673    |
| qf1_loss                | 7.4338066e-05  |
| qf2_loss                | 0.000119404634 |
| time_elapsed            | 7420           |
| total timesteps         | 1442541        |
| value_loss              | 3.5515048e-05  |
--------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.001580931    |
| ent_coef_loss           | -0.3138928     |
| entropy                 | 1.3303814      |
| episodes                | 6430           |
| fps                     | 194            |
| mean 100 episode reward | 1.5            |
| n_updates               | 1444181        |
| policy_loss             | -0.3496799     |
| qf1_loss                | 0.00017526367  |
| qf2_loss                | 0.00021038597  |
| time_elapsed            | 7430           |
| total timesteps         | 1444281        |
| value_loss              | 0.000120421995 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016042007  |
| ent_coef_loss           | 0.6466074     |
| entropy                 | 1.3060349     |
| episodes                | 6440          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1446057       |
| policy_loss             | -0.39320344   |
| qf1_loss                | 0.000487668   |
| qf2_loss                | 0.0006377162  |
| time_elapsed            | 7440          |
| total timesteps         | 1446157       |
| value_loss              | 0.00022339396 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016520232  |
| ent_coef_loss           | 0.3597808     |
| entropy                 | 1.316856      |
| episodes                | 6450          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1447446       |
| policy_loss             | -0.41373664   |
| qf1_loss                | 0.00016288128 |
| qf2_loss                | 0.00015907986 |
| time_elapsed            | 7447          |
| total timesteps         | 1447546       |
| value_loss              | 0.00010511629 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016865121  |
| ent_coef_loss           | 0.7716435     |
| entropy                 | 1.3460107     |
| episodes                | 6460          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1449087       |
| policy_loss             | -0.35323545   |
| qf1_loss                | 0.00014587035 |
| qf2_loss                | 0.00013482594 |
| time_elapsed            | 7455          |
| total timesteps         | 1449187       |
| value_loss              | 0.00010601382 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0016791313   |
| ent_coef_loss           | -1.8610942     |
| entropy                 | 1.2728987      |
| episodes                | 6470           |
| fps                     | 194            |
| mean 100 episode reward | 1.5            |
| n_updates               | 1450860        |
| policy_loss             | -0.30439007    |
| qf1_loss                | 0.0002455375   |
| qf2_loss                | 0.00019994497  |
| time_elapsed            | 7465           |
| total timesteps         | 1450960        |
| value_loss              | 0.000108923996 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016631623  |
| ent_coef_loss           | 0.7416056     |
| entropy                 | 1.2996128     |
| episodes                | 6480          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1452434       |
| policy_loss             | -0.32539323   |
| qf1_loss                | 0.00023894588 |
| qf2_loss                | 0.00016151591 |
| time_elapsed            | 7473          |
| total timesteps         | 1452534       |
| value_loss              | 0.00011429671 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0016368629   |
| ent_coef_loss           | -1.2597759     |
| entropy                 | 1.2297462      |
| episodes                | 6490           |
| fps                     | 194            |
| mean 100 episode reward | 1.6            |
| n_updates               | 1454133        |
| policy_loss             | -0.3730979     |
| qf1_loss                | 0.00011222753  |
| qf2_loss                | 0.00012323487  |
| time_elapsed            | 7482           |
| total timesteps         | 1454233        |
| value_loss              | 0.000105704225 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016695507  |
| ent_coef_loss           | -0.7822398    |
| entropy                 | 1.3460534     |
| episodes                | 6500          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1455656       |
| policy_loss             | -0.46894214   |
| qf1_loss                | 7.5708114e-05 |
| qf2_loss                | 9.344147e-05  |
| time_elapsed            | 7490          |
| total timesteps         | 1455756       |
| value_loss              | 8.243647e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016535474  |
| ent_coef_loss           | 0.3925755     |
| entropy                 | 1.2525535     |
| episodes                | 6510          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1457245       |
| policy_loss             | -0.32309172   |
| qf1_loss                | 0.00020017962 |
| qf2_loss                | 0.00019544439 |
| time_elapsed            | 7499          |
| total timesteps         | 1457345       |
| value_loss              | 0.00019562386 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016188377  |
| ent_coef_loss           | -0.4567145    |
| entropy                 | 1.3355992     |
| episodes                | 6520          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1458932       |
| policy_loss             | -0.22793597   |
| qf1_loss                | 0.00020289519 |
| qf2_loss                | 0.00021498554 |
| time_elapsed            | 7507          |
| total timesteps         | 1459032       |
| value_loss              | 0.00016628811 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016365249  |
| ent_coef_loss           | 0.01600194    |
| entropy                 | 1.250896      |
| episodes                | 6530          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1460695       |
| policy_loss             | -0.33527613   |
| qf1_loss                | 0.00011678092 |
| qf2_loss                | 0.00020611152 |
| time_elapsed            | 7517          |
| total timesteps         | 1460795       |
| value_loss              | 8.92047e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016350258  |
| ent_coef_loss           | -0.66403544   |
| entropy                 | 1.3076484     |
| episodes                | 6540          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1462286       |
| policy_loss             | -0.30813873   |
| qf1_loss                | 0.00027994442 |
| qf2_loss                | 0.00023270785 |
| time_elapsed            | 7526          |
| total timesteps         | 1462386       |
| value_loss              | 0.00011608403 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016348504  |
| ent_coef_loss           | 1.7643325     |
| entropy                 | 1.3323786     |
| episodes                | 6550          |
| fps                     | 194           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1463979       |
| policy_loss             | -0.3585357    |
| qf1_loss                | 0.0002515962  |
| qf2_loss                | 0.00026931404 |
| time_elapsed            | 7535          |
| total timesteps         | 1464079       |
| value_loss              | 0.00012092388 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016634327  |
| ent_coef_loss           | -0.35788      |
| entropy                 | 1.2999398     |
| episodes                | 6560          |
| fps                     | 194           |
| mean 100 episode reward | 1.7           |
| n_updates               | 1465747       |
| policy_loss             | -0.30753773   |
| qf1_loss                | 0.00028325975 |
| qf2_loss                | 0.00023629786 |
| time_elapsed            | 7544          |
| total timesteps         | 1465847       |
| value_loss              | 0.00018218745 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0001         |
| ent_coef                | 0.0016754898   |
| ent_coef_loss           | 1.0997932      |
| entropy                 | 1.3277323      |
| episodes                | 6570           |
| fps                     | 194            |
| mean 100 episode reward | 1.6            |
| n_updates               | 1467352        |
| policy_loss             | -0.41086492    |
| qf1_loss                | 0.00027363695  |
| qf2_loss                | 0.00027463396  |
| time_elapsed            | 7553           |
| total timesteps         | 1467452        |
| value_loss              | 0.000111587695 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001651972   |
| ent_coef_loss           | -1.8003576    |
| entropy                 | 1.3629576     |
| episodes                | 6580          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1469201       |
| policy_loss             | -0.32446775   |
| qf1_loss                | 0.00036359817 |
| qf2_loss                | 0.0003783993  |
| time_elapsed            | 7563          |
| total timesteps         | 1469301       |
| value_loss              | 0.00012368767 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016433658  |
| ent_coef_loss           | -1.6393077    |
| entropy                 | 1.3148444     |
| episodes                | 6590          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1470702       |
| policy_loss             | -0.40462974   |
| qf1_loss                | 9.285679e-05  |
| qf2_loss                | 8.591216e-05  |
| time_elapsed            | 7570          |
| total timesteps         | 1470802       |
| value_loss              | 8.0011756e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017284893  |
| ent_coef_loss           | 0.36457312    |
| entropy                 | 1.3522749     |
| episodes                | 6600          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1472369       |
| policy_loss             | -0.31224728   |
| qf1_loss                | 0.00022667118 |
| qf2_loss                | 0.00049934216 |
| time_elapsed            | 7579          |
| total timesteps         | 1472469       |
| value_loss              | 8.0311234e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001759316   |
| ent_coef_loss           | 0.66787094    |
| entropy                 | 1.4218214     |
| episodes                | 6610          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1474006       |
| policy_loss             | -0.35267097   |
| qf1_loss                | 0.00017395982 |
| qf2_loss                | 9.839791e-05  |
| time_elapsed            | 7588          |
| total timesteps         | 1474106       |
| value_loss              | 8.138933e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017461111  |
| ent_coef_loss           | -1.9019065    |
| entropy                 | 1.2974007     |
| episodes                | 6620          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1475430       |
| policy_loss             | -0.2744543    |
| qf1_loss                | 0.000498112   |
| qf2_loss                | 0.00053453405 |
| time_elapsed            | 7595          |
| total timesteps         | 1475530       |
| value_loss              | 0.00016879106 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.001724254   |
| ent_coef_loss           | 0.9134667     |
| entropy                 | 1.29498       |
| episodes                | 6630          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1477201       |
| policy_loss             | -0.34600782   |
| qf1_loss                | 0.00029190062 |
| qf2_loss                | 0.00018313766 |
| time_elapsed            | 7604          |
| total timesteps         | 1477301       |
| value_loss              | 0.00013342127 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0017138699  |
| ent_coef_loss           | -0.27889392   |
| entropy                 | 1.3325721     |
| episodes                | 6640          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1478883       |
| policy_loss             | -0.31932777   |
| qf1_loss                | 0.00015205715 |
| qf2_loss                | 0.00012648852 |
| time_elapsed            | 7613          |
| total timesteps         | 1478983       |
| value_loss              | 9.8469565e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016848161  |
| ent_coef_loss           | -0.38641107   |
| entropy                 | 1.2744544     |
| episodes                | 6650          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1480397       |
| policy_loss             | -0.3710389    |
| qf1_loss                | 0.00010864981 |
| qf2_loss                | 0.00010697993 |
| time_elapsed            | 7622          |
| total timesteps         | 1480497       |
| value_loss              | 7.711631e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016547242  |
| ent_coef_loss           | 1.2959558     |
| entropy                 | 1.29752       |
| episodes                | 6660          |
| fps                     | 194           |
| mean 100 episode reward | 1.4           |
| n_updates               | 1481875       |
| policy_loss             | -0.3109001    |
| qf1_loss                | 0.00020321128 |
| qf2_loss                | 0.00016190903 |
| time_elapsed            | 7629          |
| total timesteps         | 1481975       |
| value_loss              | 0.00011945363 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016569634  |
| ent_coef_loss           | -0.24039507   |
| entropy                 | 1.311269      |
| episodes                | 6670          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1483488       |
| policy_loss             | -0.3275581    |
| qf1_loss                | 0.000277486   |
| qf2_loss                | 0.00015805672 |
| time_elapsed            | 7638          |
| total timesteps         | 1483588       |
| value_loss              | 0.00012524908 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016466234  |
| ent_coef_loss           | 3.682878      |
| entropy                 | 1.2793849     |
| episodes                | 6680          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1485298       |
| policy_loss             | -0.30381346   |
| qf1_loss                | 0.00014034612 |
| qf2_loss                | 0.00014401595 |
| time_elapsed            | 7647          |
| total timesteps         | 1485398       |
| value_loss              | 0.00010912716 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016257829  |
| ent_coef_loss           | -0.47207862   |
| entropy                 | 1.2736714     |
| episodes                | 6690          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1486880       |
| policy_loss             | -0.2979191    |
| qf1_loss                | 0.0002368096  |
| qf2_loss                | 0.00018911579 |
| time_elapsed            | 7655          |
| total timesteps         | 1486980       |
| value_loss              | 0.0001257491  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016052154  |
| ent_coef_loss           | -0.33923006   |
| entropy                 | 1.266636      |
| episodes                | 6700          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1488565       |
| policy_loss             | -0.30175826   |
| qf1_loss                | 0.00038755534 |
| qf2_loss                | 0.0005487438  |
| time_elapsed            | 7664          |
| total timesteps         | 1488665       |
| value_loss              | 0.00014825758 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016077509  |
| ent_coef_loss           | 2.7902508     |
| entropy                 | 1.3060756     |
| episodes                | 6710          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1490184       |
| policy_loss             | -0.34330577   |
| qf1_loss                | 0.0005425719  |
| qf2_loss                | 0.00050320645 |
| time_elapsed            | 7673          |
| total timesteps         | 1490284       |
| value_loss              | 0.00012335827 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015536232  |
| ent_coef_loss           | -2.4154181    |
| entropy                 | 1.3508875     |
| episodes                | 6720          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1491812       |
| policy_loss             | -0.42404985   |
| qf1_loss                | 0.0001519142  |
| qf2_loss                | 0.00010631814 |
| time_elapsed            | 7682          |
| total timesteps         | 1491912       |
| value_loss              | 8.818385e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0015669827  |
| ent_coef_loss           | 2.932617      |
| entropy                 | 1.3132281     |
| episodes                | 6730          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1493663       |
| policy_loss             | -0.33811635   |
| qf1_loss                | 0.00026837212 |
| qf2_loss                | 0.0002222551  |
| time_elapsed            | 7692          |
| total timesteps         | 1493763       |
| value_loss              | 0.00012560084 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016271727  |
| ent_coef_loss           | -0.46650934   |
| entropy                 | 1.3071604     |
| episodes                | 6740          |
| fps                     | 194           |
| mean 100 episode reward | 1.5           |
| n_updates               | 1495324       |
| policy_loss             | -0.43282872   |
| qf1_loss                | 0.0001050828  |
| qf2_loss                | 0.00014267418 |
| time_elapsed            | 7701          |
| total timesteps         | 1495424       |
| value_loss              | 8.882291e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016450617  |
| ent_coef_loss           | 0.4237535     |
| entropy                 | 1.3516244     |
| episodes                | 6750          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1497089       |
| policy_loss             | -0.39680457   |
| qf1_loss                | 0.00011207636 |
| qf2_loss                | 0.00013104398 |
| time_elapsed            | 7710          |
| total timesteps         | 1497189       |
| value_loss              | 8.3114865e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0001        |
| ent_coef                | 0.0016406778  |
| ent_coef_loss           | 0.039009094   |
| entropy                 | 1.2813509     |
| episodes                | 6760          |
| fps                     | 194           |
| mean 100 episode reward | 1.6           |
| n_updates               | 1498810       |
| policy_loss             | -0.3316762    |
| qf1_loss                | 9.073959e-05  |
| qf2_loss                | 0.00011070136 |
| time_elapsed            | 7719          |
| total timesteps         | 1498910       |
| value_loss              | 9.086751e-05  |
-------------------------------------------
>>>>> End testing <<<<< collision_penalty:_-1.0__learning_trials:_1500000__n_obstacles:_1__nn_layers:_[256__128__64]__n_sensors:_8
Final weights saved at:  /home/admin/tensorboard_logs/sac_1_collision_penalty:_-1.0__learning_trials:_1500000__n_obstacles:_1__nn_layers:_[256__128__64]__n_sensors:_8/stable_baselines.pkl
TEST COMMAND:

python3 py3_learning.py --test --weights  /home/admin/tensorboard_logs/sac_1_collision_penalty:_-1.0__learning_trials:_1500000__n_obstacles:_1__nn_layers:_[256__128__64]__n_sensors:_8/stable_baselines.pkl --visualize
