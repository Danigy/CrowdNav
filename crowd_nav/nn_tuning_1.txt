pygame 1.9.6
Hello from the pygame community. https://www.pygame.org/contribute.html
Loading chipmunk for Linux (64bit) [/usr/local/lib/python3.5/dist-packages/pymunk/libchipmunk.so]
Starting test with params: {'nn_layers': [64, 64]}
Namespace(draw_screen=False, env_config='configs/env.config', policy='multi_human_rl', policy_config='configs/policy.config', test=False, train_config='configs/train.config', weights=None)
Gym environment created.
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.54357624   |
| ent_coef_loss           | -2.0354004   |
| entropy                 | 2.5830958    |
| episodes                | 4            |
| fps                     | 227          |
| mean 100 episode reward | -0.1         |
| n_updates               | 1220         |
| policy_loss             | -5.364778    |
| qf1_loss                | 0.0025964105 |
| qf2_loss                | 0.0027838354 |
| time_elapsed            | 5            |
| total timesteps         | 1320         |
| value_loss              | 0.009430096  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.22573365   |
| ent_coef_loss           | -4.9029474   |
| entropy                 | 2.6155753    |
| episodes                | 8            |
| fps                     | 230          |
| mean 100 episode reward | -0.1         |
| n_updates               | 2980         |
| policy_loss             | -8.321677    |
| qf1_loss                | 0.001115584  |
| qf2_loss                | 0.001175999  |
| time_elapsed            | 13           |
| total timesteps         | 3080         |
| value_loss              | 0.0033797987 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.09393969   |
| ent_coef_loss           | -7.8534083   |
| entropy                 | 2.6739373    |
| episodes                | 12           |
| fps                     | 222          |
| mean 100 episode reward | -0.1         |
| n_updates               | 4740         |
| policy_loss             | -8.842837    |
| qf1_loss                | 0.008617761  |
| qf2_loss                | 0.010041839  |
| time_elapsed            | 21           |
| total timesteps         | 4840         |
| value_loss              | 0.0049969517 |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0005      |
| ent_coef                | 0.0397102   |
| ent_coef_loss           | -9.842552   |
| entropy                 | 2.5540156   |
| episodes                | 16          |
| fps                     | 215         |
| mean 100 episode reward | -0.1        |
| n_updates               | 6500        |
| policy_loss             | -8.60391    |
| qf1_loss                | 0.004502758 |
| qf2_loss                | 0.004718414 |
| time_elapsed            | 30          |
| total timesteps         | 6600        |
| value_loss              | 0.024321975 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.017211251  |
| ent_coef_loss           | -9.131942    |
| entropy                 | 2.815669     |
| episodes                | 20           |
| fps                     | 211          |
| mean 100 episode reward | -0.1         |
| n_updates               | 8260         |
| policy_loss             | -7.891783    |
| qf1_loss                | 0.0034046918 |
| qf2_loss                | 0.0041849464 |
| time_elapsed            | 39           |
| total timesteps         | 8360         |
| value_loss              | 0.0058638565 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.009384235  |
| ent_coef_loss           | -5.1046596   |
| entropy                 | 2.203351     |
| episodes                | 24           |
| fps                     | 207          |
| mean 100 episode reward | -0.2         |
| n_updates               | 10020        |
| policy_loss             | -7.251786    |
| qf1_loss                | 0.006385692  |
| qf2_loss                | 0.005837418  |
| time_elapsed            | 48           |
| total timesteps         | 10120        |
| value_loss              | 0.0078167375 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0054907575 |
| ent_coef_loss           | -6.770486    |
| entropy                 | 0.7385682    |
| episodes                | 28           |
| fps                     | 205          |
| mean 100 episode reward | -0.3         |
| n_updates               | 11780        |
| policy_loss             | -6.7129436   |
| qf1_loss                | 0.0020158333 |
| qf2_loss                | 0.00168798   |
| time_elapsed            | 57           |
| total timesteps         | 11880        |
| value_loss              | 0.0014894593 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0039088028 |
| ent_coef_loss           | -1.4670067   |
| entropy                 | 0.18572627   |
| episodes                | 32           |
| fps                     | 204          |
| mean 100 episode reward | -0.4         |
| n_updates               | 13540        |
| policy_loss             | -6.0909667   |
| qf1_loss                | 0.23608138   |
| qf2_loss                | 0.23181728   |
| time_elapsed            | 66           |
| total timesteps         | 13640        |
| value_loss              | 0.009821884  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.003796855  |
| ent_coef_loss           | -1.4064155   |
| entropy                 | 1.0657015    |
| episodes                | 36           |
| fps                     | 202          |
| mean 100 episode reward | -0.3         |
| n_updates               | 14909        |
| policy_loss             | -5.496798    |
| qf1_loss                | 0.0040042344 |
| qf2_loss                | 0.004857751  |
| time_elapsed            | 73           |
| total timesteps         | 15009        |
| value_loss              | 0.008418563  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0069734827 |
| ent_coef_loss           | 5.0110044    |
| entropy                 | 0.9134824    |
| episodes                | 40           |
| fps                     | 202          |
| mean 100 episode reward | -0.4         |
| n_updates               | 16283        |
| policy_loss             | -5.4685516   |
| qf1_loss                | 0.022168571  |
| qf2_loss                | 0.14445725   |
| time_elapsed            | 81           |
| total timesteps         | 16383        |
| value_loss              | 0.0071419757 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.008733571  |
| ent_coef_loss           | -0.33732438  |
| entropy                 | 1.1660954    |
| episodes                | 44           |
| fps                     | 201          |
| mean 100 episode reward | -0.4         |
| n_updates               | 18043        |
| policy_loss             | -5.1925707   |
| qf1_loss                | 0.0046983524 |
| qf2_loss                | 0.0028433958 |
| time_elapsed            | 90           |
| total timesteps         | 18143        |
| value_loss              | 0.0130661605 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0043016043  |
| ent_coef_loss           | -2.742142     |
| entropy                 | -0.3894751    |
| episodes                | 48            |
| fps                     | 201           |
| mean 100 episode reward | -0.3          |
| n_updates               | 19803         |
| policy_loss             | -4.6608796    |
| qf1_loss                | 0.00091610383 |
| qf2_loss                | 0.0011249831  |
| time_elapsed            | 98            |
| total timesteps         | 19903         |
| value_loss              | 0.0008789926  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.003426573  |
| ent_coef_loss           | -1.6034251   |
| entropy                 | -0.22795004  |
| episodes                | 52           |
| fps                     | 200          |
| mean 100 episode reward | -0.3         |
| n_updates               | 21563        |
| policy_loss             | -4.126232    |
| qf1_loss                | 0.005560007  |
| qf2_loss                | 0.0024326146 |
| time_elapsed            | 108          |
| total timesteps         | 21663        |
| value_loss              | 0.0058046556 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0032445884 |
| ent_coef_loss           | 2.6613336    |
| entropy                 | 0.056712113  |
| episodes                | 56           |
| fps                     | 200          |
| mean 100 episode reward | -0.3         |
| n_updates               | 23323        |
| policy_loss             | -3.7420986   |
| qf1_loss                | 0.0014307147 |
| qf2_loss                | 0.0013876278 |
| time_elapsed            | 117          |
| total timesteps         | 23423        |
| value_loss              | 0.0020873118 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.002615833   |
| ent_coef_loss           | -3.8835802    |
| entropy                 | 0.10236348    |
| episodes                | 60            |
| fps                     | 199           |
| mean 100 episode reward | -0.3          |
| n_updates               | 25083         |
| policy_loss             | -3.2188485    |
| qf1_loss                | 0.00052401074 |
| qf2_loss                | 0.00057854987 |
| time_elapsed            | 126           |
| total timesteps         | 25183         |
| value_loss              | 0.0009440215  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0020119823 |
| ent_coef_loss           | -1.3841988   |
| entropy                 | -0.5701926   |
| episodes                | 64           |
| fps                     | 199          |
| mean 100 episode reward | -0.3         |
| n_updates               | 26843        |
| policy_loss             | -3.1716673   |
| qf1_loss                | 0.0036589552 |
| qf2_loss                | 0.0038178416 |
| time_elapsed            | 135          |
| total timesteps         | 26943        |
| value_loss              | 0.0191123    |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0023898361 |
| ent_coef_loss           | 0.4736523    |
| entropy                 | -0.3492028   |
| episodes                | 68           |
| fps                     | 199          |
| mean 100 episode reward | -0.3         |
| n_updates               | 28603        |
| policy_loss             | -2.8098521   |
| qf1_loss                | 0.0012826682 |
| qf2_loss                | 0.0013131176 |
| time_elapsed            | 144          |
| total timesteps         | 28703        |
| value_loss              | 0.0005907363 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0018143302  |
| ent_coef_loss           | -2.191184     |
| entropy                 | -0.19557971   |
| episodes                | 72            |
| fps                     | 199           |
| mean 100 episode reward | -0.2          |
| n_updates               | 30363         |
| policy_loss             | -2.5273473    |
| qf1_loss                | 0.0052839904  |
| qf2_loss                | 0.028592031   |
| time_elapsed            | 153           |
| total timesteps         | 30463         |
| value_loss              | 0.00069660327 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0017703274  |
| ent_coef_loss           | -0.41699564   |
| entropy                 | -0.10105899   |
| episodes                | 76            |
| fps                     | 198           |
| mean 100 episode reward | -0.2          |
| n_updates               | 32123         |
| policy_loss             | -2.3742647    |
| qf1_loss                | 0.00062646426 |
| qf2_loss                | 0.0006737101  |
| time_elapsed            | 161           |
| total timesteps         | 32223         |
| value_loss              | 0.00032969867 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0015918701  |
| ent_coef_loss           | -4.1930437    |
| entropy                 | 0.13415574    |
| episodes                | 80            |
| fps                     | 198           |
| mean 100 episode reward | -0.3          |
| n_updates               | 33883         |
| policy_loss             | -2.0859113    |
| qf1_loss                | 0.00047251198 |
| qf2_loss                | 0.00059804466 |
| time_elapsed            | 171           |
| total timesteps         | 33983         |
| value_loss              | 0.0003488626  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0015260886  |
| ent_coef_loss           | 0.7520865     |
| entropy                 | -0.61297494   |
| episodes                | 84            |
| fps                     | 198           |
| mean 100 episode reward | -0.3          |
| n_updates               | 35643         |
| policy_loss             | -1.9648738    |
| qf1_loss                | 0.00079173234 |
| qf2_loss                | 0.0008495245  |
| time_elapsed            | 180           |
| total timesteps         | 35743         |
| value_loss              | 0.0002983737  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001286197   |
| ent_coef_loss           | -4.736038     |
| entropy                 | -0.1387593    |
| episodes                | 88            |
| fps                     | 198           |
| mean 100 episode reward | -0.2          |
| n_updates               | 37403         |
| policy_loss             | -1.7603106    |
| qf1_loss                | 0.000250324   |
| qf2_loss                | 0.00023874007 |
| time_elapsed            | 189           |
| total timesteps         | 37503         |
| value_loss              | 0.000231062   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008872643  |
| ent_coef_loss           | 1.7300634     |
| entropy                 | -0.73210126   |
| episodes                | 92            |
| fps                     | 198           |
| mean 100 episode reward | -0.2          |
| n_updates               | 39163         |
| policy_loss             | -1.6017668    |
| qf1_loss                | 0.00016515884 |
| qf2_loss                | 0.00017757506 |
| time_elapsed            | 198           |
| total timesteps         | 39263         |
| value_loss              | 0.0002557352  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094114855 |
| ent_coef_loss           | -0.8717301    |
| entropy                 | 0.23097035    |
| episodes                | 96            |
| fps                     | 197           |
| mean 100 episode reward | -0.3          |
| n_updates               | 40923         |
| policy_loss             | -1.4740022    |
| qf1_loss                | 5.3774012e-05 |
| qf2_loss                | 0.00010170813 |
| time_elapsed            | 207           |
| total timesteps         | 41023         |
| value_loss              | 0.00012291939 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00084810593 |
| ent_coef_loss           | 4.6945424     |
| entropy                 | 0.41132313    |
| episodes                | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.3          |
| n_updates               | 42683         |
| policy_loss             | -1.3190842    |
| qf1_loss                | 0.012717386   |
| qf2_loss                | 0.012601366   |
| time_elapsed            | 216           |
| total timesteps         | 42783         |
| value_loss              | 0.00014316809 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00074275315 |
| ent_coef_loss           | -0.88555086   |
| entropy                 | -0.32657975   |
| episodes                | 104           |
| fps                     | 197           |
| mean 100 episode reward | -0.3          |
| n_updates               | 44443         |
| policy_loss             | -1.1845832    |
| qf1_loss                | 0.010988005   |
| qf2_loss                | 0.010932126   |
| time_elapsed            | 225           |
| total timesteps         | 44543         |
| value_loss              | 5.146628e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006720706  |
| ent_coef_loss           | -3.5640213    |
| entropy                 | 0.011256911   |
| episodes                | 108           |
| fps                     | 197           |
| mean 100 episode reward | -0.3          |
| n_updates               | 46203         |
| policy_loss             | -1.0659282    |
| qf1_loss                | 4.260135e-05  |
| qf2_loss                | 4.5984198e-05 |
| time_elapsed            | 234           |
| total timesteps         | 46303         |
| value_loss              | 5.4250107e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0005988663 |
| ent_coef_loss           | -0.6584227   |
| entropy                 | 0.1546387    |
| episodes                | 112          |
| fps                     | 197          |
| mean 100 episode reward | -0.2         |
| n_updates               | 47963        |
| policy_loss             | -0.9560525   |
| qf1_loss                | 0.0001271297 |
| qf2_loss                | 9.211294e-05 |
| time_elapsed            | 243          |
| total timesteps         | 48063        |
| value_loss              | 3.21674e-05  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00061326247 |
| ent_coef_loss           | -1.0972189    |
| entropy                 | 0.09822762    |
| episodes                | 116           |
| fps                     | 197           |
| mean 100 episode reward | -0.3          |
| n_updates               | 49288         |
| policy_loss             | -0.9084034    |
| qf1_loss                | 3.8391598e-05 |
| qf2_loss                | 3.5299847e-05 |
| time_elapsed            | 250           |
| total timesteps         | 49388         |
| value_loss              | 3.9743973e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0004524228  |
| ent_coef_loss           | 0.12823698    |
| entropy                 | -0.28184462   |
| episodes                | 120           |
| fps                     | 197           |
| mean 100 episode reward | -0.4          |
| n_updates               | 50787         |
| policy_loss             | -0.8341712    |
| qf1_loss                | 3.2032265e-05 |
| qf2_loss                | 2.8157885e-05 |
| time_elapsed            | 258           |
| total timesteps         | 50887         |
| value_loss              | 1.2947205e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00039921983 |
| ent_coef_loss           | -0.97722805   |
| entropy                 | -0.57094955   |
| episodes                | 124           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 52380         |
| policy_loss             | -0.75146365   |
| qf1_loss                | 5.6858706e-05 |
| qf2_loss                | 5.0202383e-05 |
| time_elapsed            | 266           |
| total timesteps         | 52480         |
| value_loss              | 0.0001419876  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00045886994 |
| ent_coef_loss           | 5.106173      |
| entropy                 | -1.0729568    |
| episodes                | 128           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 54140         |
| policy_loss             | -0.66640806   |
| qf1_loss                | 8.838093e-05  |
| qf2_loss                | 9.91617e-05   |
| time_elapsed            | 275           |
| total timesteps         | 54240         |
| value_loss              | 7.5241674e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00032560728 |
| ent_coef_loss           | -3.0292115    |
| entropy                 | -0.8647077    |
| episodes                | 132           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 55900         |
| policy_loss             | -0.6060467    |
| qf1_loss                | 0.003272675   |
| qf2_loss                | 0.0030194838  |
| time_elapsed            | 284           |
| total timesteps         | 56000         |
| value_loss              | 3.5198384e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00034692726 |
| ent_coef_loss           | -0.3735243    |
| entropy                 | -0.7186712    |
| episodes                | 136           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 57660         |
| policy_loss             | -0.5409044    |
| qf1_loss                | 0.0020602003  |
| qf2_loss                | 0.0020851912  |
| time_elapsed            | 293           |
| total timesteps         | 57760         |
| value_loss              | 0.00010343865 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.00041331   |
| ent_coef_loss           | 7.7060432    |
| entropy                 | 0.1997023    |
| episodes                | 140          |
| fps                     | 196          |
| mean 100 episode reward | -0.4         |
| n_updates               | 59420        |
| policy_loss             | -0.49407953  |
| qf1_loss                | 3.034131e-05 |
| qf2_loss                | 7.083264e-05 |
| time_elapsed            | 302          |
| total timesteps         | 59520        |
| value_loss              | 3.022695e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0004283686  |
| ent_coef_loss           | 0.6117183     |
| entropy                 | 0.40323895    |
| episodes                | 144           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 61180         |
| policy_loss             | -0.4289106    |
| qf1_loss                | 6.4079235e-05 |
| qf2_loss                | 5.1787727e-05 |
| time_elapsed            | 311           |
| total timesteps         | 61280         |
| value_loss              | 5.451306e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006732397  |
| ent_coef_loss           | -1.8262949    |
| entropy                 | 0.7894193     |
| episodes                | 148           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 62940         |
| policy_loss             | -0.3728946    |
| qf1_loss                | 2.0456026e-05 |
| qf2_loss                | 2.4978843e-05 |
| time_elapsed            | 320           |
| total timesteps         | 63040         |
| value_loss              | 2.5856874e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0003291016  |
| ent_coef_loss           | 0.16471416    |
| entropy                 | 0.16274309    |
| episodes                | 152           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 64700         |
| policy_loss             | -0.3164314    |
| qf1_loss                | 7.379013e-05  |
| qf2_loss                | 0.00012880453 |
| time_elapsed            | 329           |
| total timesteps         | 64800         |
| value_loss              | 3.5824505e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00047525184 |
| ent_coef_loss           | 3.6594868     |
| entropy                 | 0.09941793    |
| episodes                | 156           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 66238         |
| policy_loss             | -0.2924687    |
| qf1_loss                | 1.5837644e-05 |
| qf2_loss                | 1.5853579e-05 |
| time_elapsed            | 337           |
| total timesteps         | 66338         |
| value_loss              | 2.4670982e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00043702865 |
| ent_coef_loss           | -0.8665238    |
| entropy                 | -0.2070376    |
| episodes                | 160           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 67319         |
| policy_loss             | -0.286793     |
| qf1_loss                | 1.0416864e-05 |
| qf2_loss                | 1.5616475e-05 |
| time_elapsed            | 342           |
| total timesteps         | 67419         |
| value_loss              | 1.4031255e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00034223174 |
| ent_coef_loss           | -0.35738036   |
| entropy                 | -0.49796557   |
| episodes                | 164           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 68927         |
| policy_loss             | -0.25999713   |
| qf1_loss                | 0.0004225675  |
| qf2_loss                | 0.00034971462 |
| time_elapsed            | 351           |
| total timesteps         | 69027         |
| value_loss              | 9.459554e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00039986492 |
| ent_coef_loss           | 2.5329943     |
| entropy                 | -0.0925043    |
| episodes                | 168           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 70553         |
| policy_loss             | -0.2167795    |
| qf1_loss                | 0.00048669302 |
| qf2_loss                | 0.00047459884 |
| time_elapsed            | 359           |
| total timesteps         | 70653         |
| value_loss              | 1.1443924e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00037446283 |
| ent_coef_loss           | -1.3894029    |
| entropy                 | -0.05290281   |
| episodes                | 172           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 72258         |
| policy_loss             | -0.18643337   |
| qf1_loss                | 2.3174369e-05 |
| qf2_loss                | 2.3090737e-05 |
| time_elapsed            | 368           |
| total timesteps         | 72358         |
| value_loss              | 3.9147337e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0003985203  |
| ent_coef_loss           | -2.410016     |
| entropy                 | -0.10194955   |
| episodes                | 176           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 73625         |
| policy_loss             | -0.17318472   |
| qf1_loss                | 2.5003415e-05 |
| qf2_loss                | 2.6847098e-05 |
| time_elapsed            | 375           |
| total timesteps         | 73725         |
| value_loss              | 2.8363953e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00040584497 |
| ent_coef_loss           | -0.7329314    |
| entropy                 | 0.0752857     |
| episodes                | 180           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 75328         |
| policy_loss             | -0.124763355  |
| qf1_loss                | 0.00026390827 |
| qf2_loss                | 0.00027913027 |
| time_elapsed            | 384           |
| total timesteps         | 75428         |
| value_loss              | 2.3210745e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00045138568 |
| ent_coef_loss           | -0.2748263    |
| entropy                 | 0.11334487    |
| episodes                | 184           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 76917         |
| policy_loss             | -0.118158914  |
| qf1_loss                | 2.703038e-05  |
| qf2_loss                | 2.8619166e-05 |
| time_elapsed            | 392           |
| total timesteps         | 77017         |
| value_loss              | 2.8122318e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0005543927  |
| ent_coef_loss           | 3.7334998     |
| entropy                 | 0.60352063    |
| episodes                | 188           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 78557         |
| policy_loss             | -0.06207723   |
| qf1_loss                | 2.3386494e-05 |
| qf2_loss                | 2.0743852e-05 |
| time_elapsed            | 400           |
| total timesteps         | 78657         |
| value_loss              | 1.9323845e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00062325154 |
| ent_coef_loss           | 2.47465       |
| entropy                 | 0.8410597     |
| episodes                | 192           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 80317         |
| policy_loss             | -0.048971854  |
| qf1_loss                | 4.789907e-05  |
| qf2_loss                | 3.6366426e-05 |
| time_elapsed            | 410           |
| total timesteps         | 80417         |
| value_loss              | 7.757178e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0005325239  |
| ent_coef_loss           | 1.5667263     |
| entropy                 | 0.8655321     |
| episodes                | 196           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 82077         |
| policy_loss             | -0.05873861   |
| qf1_loss                | 2.488412e-05  |
| qf2_loss                | 2.5768117e-05 |
| time_elapsed            | 418           |
| total timesteps         | 82177         |
| value_loss              | 3.028129e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00041293845  |
| ent_coef_loss           | 1.8429153      |
| entropy                 | 0.37201965     |
| episodes                | 200            |
| fps                     | 196            |
| mean 100 episode reward | -0.6           |
| n_updates               | 83837          |
| policy_loss             | -0.060719028   |
| qf1_loss                | 0.00010710639  |
| qf2_loss                | 0.000106043495 |
| time_elapsed            | 427            |
| total timesteps         | 83937          |
| value_loss              | 3.4737946e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0004122074  |
| ent_coef_loss           | 2.4436872     |
| entropy                 | 0.46287745    |
| episodes                | 204           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 85597         |
| policy_loss             | -0.058066018  |
| qf1_loss                | 5.6010533e-05 |
| qf2_loss                | 3.444899e-05  |
| time_elapsed            | 437           |
| total timesteps         | 85697         |
| value_loss              | 4.063185e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00034407288 |
| ent_coef_loss           | 0.9569461     |
| entropy                 | 0.27448648    |
| episodes                | 208           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 87314         |
| policy_loss             | -0.03192346   |
| qf1_loss                | 6.310608e-05  |
| qf2_loss                | 8.202501e-05  |
| time_elapsed            | 445           |
| total timesteps         | 87414         |
| value_loss              | 0.00010074125 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00044631987 |
| ent_coef_loss           | 0.97504514    |
| entropy                 | 0.5572758     |
| episodes                | 212           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 88684         |
| policy_loss             | -0.013767218  |
| qf1_loss                | 6.036291e-05  |
| qf2_loss                | 5.494105e-05  |
| time_elapsed            | 452           |
| total timesteps         | 88784         |
| value_loss              | 3.3589808e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00041069003 |
| ent_coef_loss           | -4.46258      |
| entropy                 | 0.54927766    |
| episodes                | 216           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 89842         |
| policy_loss             | -0.009588943  |
| qf1_loss                | 0.00057092623 |
| qf2_loss                | 0.00032119508 |
| time_elapsed            | 458           |
| total timesteps         | 89942         |
| value_loss              | 6.0536884e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0004747746  |
| ent_coef_loss           | 1.2493072     |
| entropy                 | 0.44175932    |
| episodes                | 220           |
| fps                     | 195           |
| mean 100 episode reward | -0.5          |
| n_updates               | 91358         |
| policy_loss             | -0.0065806597 |
| qf1_loss                | 1.8201534e-05 |
| qf2_loss                | 3.1005737e-05 |
| time_elapsed            | 466           |
| total timesteps         | 91458         |
| value_loss              | 6.7973e-05    |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0004535659  |
| ent_coef_loss           | -0.038574815  |
| entropy                 | 0.3212162     |
| episodes                | 224           |
| fps                     | 195           |
| mean 100 episode reward | -0.4          |
| n_updates               | 92645         |
| policy_loss             | -0.00791159   |
| qf1_loss                | 4.4164684e-05 |
| qf2_loss                | 3.2335327e-05 |
| time_elapsed            | 473           |
| total timesteps         | 92745         |
| value_loss              | 5.625154e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0004633419  |
| ent_coef_loss           | -1.4184952    |
| entropy                 | 0.41050205    |
| episodes                | 228           |
| fps                     | 195           |
| mean 100 episode reward | -0.4          |
| n_updates               | 93823         |
| policy_loss             | -0.015827592  |
| qf1_loss                | 5.1665207e-05 |
| qf2_loss                | 4.296023e-05  |
| time_elapsed            | 479           |
| total timesteps         | 93923         |
| value_loss              | 5.609452e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00053513737  |
| ent_coef_loss           | -1.2788476     |
| entropy                 | 0.73081934     |
| episodes                | 232            |
| fps                     | 195            |
| mean 100 episode reward | -0.4           |
| n_updates               | 95129          |
| policy_loss             | 0.019770317    |
| qf1_loss                | 6.08658e-05    |
| qf2_loss                | 3.955866e-05   |
| time_elapsed            | 486            |
| total timesteps         | 95229          |
| value_loss              | 0.000106659354 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00050381845 |
| ent_coef_loss           | 0.6716134     |
| entropy                 | 0.5613084     |
| episodes                | 236           |
| fps                     | 195           |
| mean 100 episode reward | -0.3          |
| n_updates               | 96284         |
| policy_loss             | 0.0064563444  |
| qf1_loss                | 8.782458e-05  |
| qf2_loss                | 0.00012933469 |
| time_elapsed            | 491           |
| total timesteps         | 96384         |
| value_loss              | 9.626185e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0005683557  |
| ent_coef_loss           | -0.5208262    |
| entropy                 | 0.62534726    |
| episodes                | 240           |
| fps                     | 195           |
| mean 100 episode reward | -0.3          |
| n_updates               | 97821         |
| policy_loss             | -0.014247738  |
| qf1_loss                | 0.00020921425 |
| qf2_loss                | 0.00020170175 |
| time_elapsed            | 499           |
| total timesteps         | 97921         |
| value_loss              | 8.1380895e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000498595   |
| ent_coef_loss           | -0.58960867   |
| entropy                 | 0.12695713    |
| episodes                | 244           |
| fps                     | 195           |
| mean 100 episode reward | -0.2          |
| n_updates               | 99581         |
| policy_loss             | -0.053375985  |
| qf1_loss                | 6.028518e-05  |
| qf2_loss                | 8.723617e-05  |
| time_elapsed            | 508           |
| total timesteps         | 99681         |
| value_loss              | 0.00013730381 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00052562484 |
| ent_coef_loss           | 2.4339366     |
| entropy                 | 0.20054273    |
| episodes                | 248           |
| fps                     | 195           |
| mean 100 episode reward | -0.2          |
| n_updates               | 101075        |
| policy_loss             | -0.03581362   |
| qf1_loss                | 0.000147511   |
| qf2_loss                | 0.003785947   |
| time_elapsed            | 516           |
| total timesteps         | 101175        |
| value_loss              | 0.00020069443 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00044205878 |
| ent_coef_loss           | -1.3757309    |
| entropy                 | 0.045580566   |
| episodes                | 252           |
| fps                     | 195           |
| mean 100 episode reward | -0.2          |
| n_updates               | 102730        |
| policy_loss             | -0.020126054  |
| qf1_loss                | 5.046441e-05  |
| qf2_loss                | 6.1217914e-05 |
| time_elapsed            | 525           |
| total timesteps         | 102830        |
| value_loss              | 4.3983222e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00039864404 |
| ent_coef_loss           | 0.5865865     |
| entropy                 | -0.06625621   |
| episodes                | 256           |
| fps                     | 195           |
| mean 100 episode reward | -0.1          |
| n_updates               | 103949        |
| policy_loss             | -0.025414985  |
| qf1_loss                | 0.00019697637 |
| qf2_loss                | 0.00023331595 |
| time_elapsed            | 531           |
| total timesteps         | 104049        |
| value_loss              | 0.00010753295 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0004299691  |
| ent_coef_loss           | -0.37489703   |
| entropy                 | 0.017589368   |
| episodes                | 260           |
| fps                     | 195           |
| mean 100 episode reward | -0.1          |
| n_updates               | 105247        |
| policy_loss             | -0.03260889   |
| qf1_loss                | 7.525248e-05  |
| qf2_loss                | 0.00014637521 |
| time_elapsed            | 538           |
| total timesteps         | 105347        |
| value_loss              | 5.4657714e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0003719531   |
| ent_coef_loss           | 2.1130888      |
| entropy                 | -0.19409566    |
| episodes                | 264            |
| fps                     | 195            |
| mean 100 episode reward | -0             |
| n_updates               | 106771         |
| policy_loss             | 0.012595007    |
| qf1_loss                | 0.0004575322   |
| qf2_loss                | 0.0005305369   |
| time_elapsed            | 545            |
| total timesteps         | 106871         |
| value_loss              | 0.000118676384 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0004694201  |
| ent_coef_loss           | -0.49920785   |
| entropy                 | 0.0508632     |
| episodes                | 268           |
| fps                     | 195           |
| mean 100 episode reward | -0            |
| n_updates               | 108120        |
| policy_loss             | -0.01713609   |
| qf1_loss                | 6.973843e-05  |
| qf2_loss                | 5.8049576e-05 |
| time_elapsed            | 552           |
| total timesteps         | 108220        |
| value_loss              | 0.00010156952 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00063366763 |
| ent_coef_loss           | 2.2976317     |
| entropy                 | 0.33132043    |
| episodes                | 272           |
| fps                     | 195           |
| mean 100 episode reward | -0            |
| n_updates               | 109526        |
| policy_loss             | -0.02786122   |
| qf1_loss                | 0.00023018544 |
| qf2_loss                | 0.00014138034 |
| time_elapsed            | 560           |
| total timesteps         | 109626        |
| value_loss              | 0.00011554098 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0004977857  |
| ent_coef_loss           | -0.070599556  |
| entropy                 | 0.11179493    |
| episodes                | 276           |
| fps                     | 195           |
| mean 100 episode reward | -0            |
| n_updates               | 110905        |
| policy_loss             | -0.043813266  |
| qf1_loss                | 0.0001557657  |
| qf2_loss                | 0.00013178335 |
| time_elapsed            | 567           |
| total timesteps         | 111005        |
| value_loss              | 0.00012788436 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0005163562  |
| ent_coef_loss           | -3.2549074    |
| entropy                 | 0.17397451    |
| episodes                | 280           |
| fps                     | 195           |
| mean 100 episode reward | -0            |
| n_updates               | 112219        |
| policy_loss             | -0.053279083  |
| qf1_loss                | 4.36785e-05   |
| qf2_loss                | 4.9641058e-05 |
| time_elapsed            | 574           |
| total timesteps         | 112319        |
| value_loss              | 4.8348847e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0006059975 |
| ent_coef_loss           | 0.15453073   |
| entropy                 | 0.246634     |
| episodes                | 284          |
| fps                     | 195          |
| mean 100 episode reward | -0           |
| n_updates               | 113786       |
| policy_loss             | -0.08033593  |
| qf1_loss                | 7.017106e-05 |
| qf2_loss                | 6.599685e-05 |
| time_elapsed            | 582          |
| total timesteps         | 113886       |
| value_loss              | 7.453447e-05 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0007092475 |
| ent_coef_loss           | 1.4946495    |
| entropy                 | 0.49035594   |
| episodes                | 288          |
| fps                     | 195          |
| mean 100 episode reward | 0            |
| n_updates               | 115053       |
| policy_loss             | -0.06862236  |
| qf1_loss                | 0.004585945  |
| qf2_loss                | 0.0027562226 |
| time_elapsed            | 588          |
| total timesteps         | 115153       |
| value_loss              | 0.0005434304 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000702298   |
| ent_coef_loss           | 0.25691658    |
| entropy                 | 0.36580408    |
| episodes                | 292           |
| fps                     | 195           |
| mean 100 episode reward | 0.1           |
| n_updates               | 116430        |
| policy_loss             | -0.08380951   |
| qf1_loss                | 8.049181e-05  |
| qf2_loss                | 9.423177e-05  |
| time_elapsed            | 595           |
| total timesteps         | 116530        |
| value_loss              | 4.5858993e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006712427  |
| ent_coef_loss           | -0.23968339   |
| entropy                 | 0.5916314     |
| episodes                | 296           |
| fps                     | 195           |
| mean 100 episode reward | 0.1           |
| n_updates               | 117441        |
| policy_loss             | -0.06280628   |
| qf1_loss                | 5.3374857e-05 |
| qf2_loss                | 4.363344e-05  |
| time_elapsed            | 600           |
| total timesteps         | 117541        |
| value_loss              | 6.111256e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006832335  |
| ent_coef_loss           | -1.919467     |
| entropy                 | 0.88276696    |
| episodes                | 300           |
| fps                     | 195           |
| mean 100 episode reward | 0.1           |
| n_updates               | 118706        |
| policy_loss             | -0.06920895   |
| qf1_loss                | 8.563447e-05  |
| qf2_loss                | 8.1385166e-05 |
| time_elapsed            | 607           |
| total timesteps         | 118806        |
| value_loss              | 0.00010891809 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006422879  |
| ent_coef_loss           | -0.32753286   |
| entropy                 | 0.63753545    |
| episodes                | 304           |
| fps                     | 195           |
| mean 100 episode reward | 0.1           |
| n_updates               | 119589        |
| policy_loss             | -0.067939825  |
| qf1_loss                | 5.2510535e-05 |
| qf2_loss                | 7.780386e-05  |
| time_elapsed            | 611           |
| total timesteps         | 119689        |
| value_loss              | 0.00019459614 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00065101834 |
| ent_coef_loss           | -1.4130883    |
| entropy                 | 0.46588728    |
| episodes                | 308           |
| fps                     | 195           |
| mean 100 episode reward | 0.2           |
| n_updates               | 121090        |
| policy_loss             | -0.09758439   |
| qf1_loss                | 5.747578e-05  |
| qf2_loss                | 5.1566556e-05 |
| time_elapsed            | 619           |
| total timesteps         | 121190        |
| value_loss              | 7.7548444e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007259931  |
| ent_coef_loss           | -1.1151059    |
| entropy                 | 0.64275205    |
| episodes                | 312           |
| fps                     | 195           |
| mean 100 episode reward | 0.2           |
| n_updates               | 122098        |
| policy_loss             | -0.08723277   |
| qf1_loss                | 4.5826848e-05 |
| qf2_loss                | 5.8079717e-05 |
| time_elapsed            | 624           |
| total timesteps         | 122198        |
| value_loss              | 6.378307e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008108083  |
| ent_coef_loss           | 0.65998757    |
| entropy                 | 0.7635278     |
| episodes                | 316           |
| fps                     | 195           |
| mean 100 episode reward | 0.2           |
| n_updates               | 123593        |
| policy_loss             | -0.12037813   |
| qf1_loss                | 4.882145e-05  |
| qf2_loss                | 4.2046802e-05 |
| time_elapsed            | 632           |
| total timesteps         | 123693        |
| value_loss              | 5.7905985e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0007970227   |
| ent_coef_loss           | 2.8057868      |
| entropy                 | 0.958284       |
| episodes                | 320            |
| fps                     | 195            |
| mean 100 episode reward | 0.2            |
| n_updates               | 124450         |
| policy_loss             | -0.10715549    |
| qf1_loss                | 6.9029076e-05  |
| qf2_loss                | 5.546261e-05   |
| time_elapsed            | 637            |
| total timesteps         | 124550         |
| value_loss              | 0.000100155434 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00081840064 |
| ent_coef_loss           | 3.0831902     |
| entropy                 | 1.0191605     |
| episodes                | 324           |
| fps                     | 195           |
| mean 100 episode reward | 0.3           |
| n_updates               | 125447        |
| policy_loss             | -0.12313883   |
| qf1_loss                | 8.735482e-05  |
| qf2_loss                | 7.840521e-05  |
| time_elapsed            | 642           |
| total timesteps         | 125547        |
| value_loss              | 0.00011549717 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0008232705   |
| ent_coef_loss           | -0.021457344   |
| entropy                 | 1.0506933      |
| episodes                | 328            |
| fps                     | 195            |
| mean 100 episode reward | 0.3            |
| n_updates               | 126710         |
| policy_loss             | -0.14460854    |
| qf1_loss                | 5.5736607e-05  |
| qf2_loss                | 6.192557e-05   |
| time_elapsed            | 648            |
| total timesteps         | 126810         |
| value_loss              | 0.000112537215 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008788744  |
| ent_coef_loss           | 4.4455996     |
| entropy                 | 0.9506343     |
| episodes                | 332           |
| fps                     | 195           |
| mean 100 episode reward | 0.3           |
| n_updates               | 127661        |
| policy_loss             | -0.165036     |
| qf1_loss                | 0.00035715138 |
| qf2_loss                | 0.0004122774  |
| time_elapsed            | 653           |
| total timesteps         | 127761        |
| value_loss              | 6.8365975e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009224418   |
| ent_coef_loss           | 0.27339435     |
| entropy                 | 0.6793883      |
| episodes                | 336            |
| fps                     | 195            |
| mean 100 episode reward | 0.3            |
| n_updates               | 128391         |
| policy_loss             | -0.21337569    |
| qf1_loss                | 0.000109520515 |
| qf2_loss                | 5.6180303e-05  |
| time_elapsed            | 657            |
| total timesteps         | 128491         |
| value_loss              | 6.655966e-05   |
--------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0009351216 |
| ent_coef_loss           | -1.4529393   |
| entropy                 | 0.77976096   |
| episodes                | 340          |
| fps                     | 195          |
| mean 100 episode reward | 0.3          |
| n_updates               | 129148       |
| policy_loss             | -0.14978534  |
| qf1_loss                | 4.401109e-05 |
| qf2_loss                | 3.940826e-05 |
| time_elapsed            | 661          |
| total timesteps         | 129248       |
| value_loss              | 6.579065e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010646249  |
| ent_coef_loss           | -5.2619524    |
| entropy                 | 1.060653      |
| episodes                | 344           |
| fps                     | 195           |
| mean 100 episode reward | 0.4           |
| n_updates               | 129987        |
| policy_loss             | -0.110130176  |
| qf1_loss                | 8.468864e-05  |
| qf2_loss                | 0.00010018968 |
| time_elapsed            | 665           |
| total timesteps         | 130087        |
| value_loss              | 9.0109155e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010167032  |
| ent_coef_loss           | 0.20325452    |
| entropy                 | 1.0337434     |
| episodes                | 348           |
| fps                     | 195           |
| mean 100 episode reward | 0.4           |
| n_updates               | 130991        |
| policy_loss             | -0.18373656   |
| qf1_loss                | 0.00011242232 |
| qf2_loss                | 0.00013224699 |
| time_elapsed            | 670           |
| total timesteps         | 131091        |
| value_loss              | 6.570782e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0008907697   |
| ent_coef_loss           | -3.1091561     |
| entropy                 | 1.0548127      |
| episodes                | 352            |
| fps                     | 195            |
| mean 100 episode reward | 0.4            |
| n_updates               | 132058         |
| policy_loss             | -0.22799842    |
| qf1_loss                | 0.000105622574 |
| qf2_loss                | 0.00013602007  |
| time_elapsed            | 676            |
| total timesteps         | 132158         |
| value_loss              | 0.00014371291  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008804541  |
| ent_coef_loss           | 4.490783      |
| entropy                 | 0.94016725    |
| episodes                | 356           |
| fps                     | 195           |
| mean 100 episode reward | 0.5           |
| n_updates               | 132846        |
| policy_loss             | -0.2380653    |
| qf1_loss                | 0.00030231773 |
| qf2_loss                | 0.0008606652  |
| time_elapsed            | 680           |
| total timesteps         | 132946        |
| value_loss              | 0.00022744504 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008383863  |
| ent_coef_loss           | -2.8025374    |
| entropy                 | 0.708526      |
| episodes                | 360           |
| fps                     | 195           |
| mean 100 episode reward | 0.5           |
| n_updates               | 133600        |
| policy_loss             | -0.166199     |
| qf1_loss                | 0.00010293194 |
| qf2_loss                | 4.9575145e-05 |
| time_elapsed            | 684           |
| total timesteps         | 133700        |
| value_loss              | 5.8198355e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009844044   |
| ent_coef_loss           | 1.6879494      |
| entropy                 | 1.0419198      |
| episodes                | 364            |
| fps                     | 195            |
| mean 100 episode reward | 0.5            |
| n_updates               | 134392         |
| policy_loss             | -0.174613      |
| qf1_loss                | 0.0001369255   |
| qf2_loss                | 0.000102278515 |
| time_elapsed            | 688            |
| total timesteps         | 134492         |
| value_loss              | 0.0001416661   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010778998  |
| ent_coef_loss           | -0.40574414   |
| entropy                 | 0.9661453     |
| episodes                | 368           |
| fps                     | 195           |
| mean 100 episode reward | 0.6           |
| n_updates               | 135239        |
| policy_loss             | -0.23457286   |
| qf1_loss                | 0.00030953548 |
| qf2_loss                | 0.0003260702  |
| time_elapsed            | 692           |
| total timesteps         | 135339        |
| value_loss              | 0.00010154824 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009935591  |
| ent_coef_loss           | 0.5611042     |
| entropy                 | 0.8967777     |
| episodes                | 372           |
| fps                     | 195           |
| mean 100 episode reward | 0.6           |
| n_updates               | 136208        |
| policy_loss             | -0.23394969   |
| qf1_loss                | 4.8409413e-05 |
| qf2_loss                | 6.7456844e-05 |
| time_elapsed            | 697           |
| total timesteps         | 136308        |
| value_loss              | 0.00011064506 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.001024477    |
| ent_coef_loss           | 2.554037       |
| entropy                 | 0.60243344     |
| episodes                | 376            |
| fps                     | 195            |
| mean 100 episode reward | 0.6            |
| n_updates               | 137499         |
| policy_loss             | -0.33004418    |
| qf1_loss                | 8.841384e-05   |
| qf2_loss                | 5.6387857e-05  |
| time_elapsed            | 704            |
| total timesteps         | 137599         |
| value_loss              | 0.000120926634 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010689883  |
| ent_coef_loss           | 2.8032265     |
| entropy                 | 0.84684515    |
| episodes                | 380           |
| fps                     | 195           |
| mean 100 episode reward | 0.6           |
| n_updates               | 138238        |
| policy_loss             | -0.26316005   |
| qf1_loss                | 9.7605036e-05 |
| qf2_loss                | 0.00011081251 |
| time_elapsed            | 708           |
| total timesteps         | 138338        |
| value_loss              | 0.00013827678 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011243741  |
| ent_coef_loss           | 1.0082067     |
| entropy                 | 0.98159224    |
| episodes                | 384           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 139082        |
| policy_loss             | -0.24494179   |
| qf1_loss                | 9.8466524e-05 |
| qf2_loss                | 6.872263e-05  |
| time_elapsed            | 712           |
| total timesteps         | 139182        |
| value_loss              | 0.00011811657 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012382484  |
| ent_coef_loss           | -2.0291855    |
| entropy                 | 1.1721922     |
| episodes                | 388           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 139979        |
| policy_loss             | -0.2746238    |
| qf1_loss                | 0.0005103003  |
| qf2_loss                | 0.0012336763  |
| time_elapsed            | 717           |
| total timesteps         | 140079        |
| value_loss              | 0.00034078606 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013469546  |
| ent_coef_loss           | -0.4969977    |
| entropy                 | 1.3128092     |
| episodes                | 392           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 140789        |
| policy_loss             | -0.26065844   |
| qf1_loss                | 0.00012971152 |
| qf2_loss                | 0.00011392463 |
| time_elapsed            | 721           |
| total timesteps         | 140889        |
| value_loss              | 9.586022e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013446374  |
| ent_coef_loss           | -1.2150424    |
| entropy                 | 1.070562      |
| episodes                | 396           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 141619        |
| policy_loss             | -0.29386073   |
| qf1_loss                | 6.7322144e-05 |
| qf2_loss                | 8.339726e-05  |
| time_elapsed            | 725           |
| total timesteps         | 141719        |
| value_loss              | 8.49068e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0014000837  |
| ent_coef_loss           | -2.936861     |
| entropy                 | 1.1165024     |
| episodes                | 400           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 142352        |
| policy_loss             | -0.2650925    |
| qf1_loss                | 0.00042448178 |
| qf2_loss                | 0.000445      |
| time_elapsed            | 729           |
| total timesteps         | 142452        |
| value_loss              | 6.7955036e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012828001  |
| ent_coef_loss           | 2.7742982     |
| entropy                 | 1.2193139     |
| episodes                | 404           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 143096        |
| policy_loss             | -0.2292943    |
| qf1_loss                | 0.004416687   |
| qf2_loss                | 0.0035462694  |
| time_elapsed            | 733           |
| total timesteps         | 143196        |
| value_loss              | 0.00013931324 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012275155  |
| ent_coef_loss           | 5.248906      |
| entropy                 | 1.3671829     |
| episodes                | 408           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 143897        |
| policy_loss             | -0.33402532   |
| qf1_loss                | 0.00033007114 |
| qf2_loss                | 0.00038526268 |
| time_elapsed            | 737           |
| total timesteps         | 143997        |
| value_loss              | 8.8976914e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011601065  |
| ent_coef_loss           | 1.1595464     |
| entropy                 | 1.0579613     |
| episodes                | 412           |
| fps                     | 195           |
| mean 100 episode reward | 0.8           |
| n_updates               | 144618        |
| policy_loss             | -0.39011803   |
| qf1_loss                | 8.171075e-05  |
| qf2_loss                | 9.8093195e-05 |
| time_elapsed            | 740           |
| total timesteps         | 144718        |
| value_loss              | 7.125609e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012292428  |
| ent_coef_loss           | 1.5818448     |
| entropy                 | 1.1567204     |
| episodes                | 416           |
| fps                     | 195           |
| mean 100 episode reward | 0.8           |
| n_updates               | 145376        |
| policy_loss             | -0.33393297   |
| qf1_loss                | 0.00012222627 |
| qf2_loss                | 0.00011054972 |
| time_elapsed            | 744           |
| total timesteps         | 145476        |
| value_loss              | 0.00020055103 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011966423  |
| ent_coef_loss           | 0.19594443    |
| entropy                 | 1.113889      |
| episodes                | 420           |
| fps                     | 195           |
| mean 100 episode reward | 0.8           |
| n_updates               | 146167        |
| policy_loss             | -0.33106017   |
| qf1_loss                | 0.00042792474 |
| qf2_loss                | 0.00085981964 |
| time_elapsed            | 748           |
| total timesteps         | 146267        |
| value_loss              | 0.00013318381 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011890081  |
| ent_coef_loss           | -0.6238308    |
| entropy                 | 1.2330023     |
| episodes                | 424           |
| fps                     | 195           |
| mean 100 episode reward | 0.8           |
| n_updates               | 146896        |
| policy_loss             | -0.4041791    |
| qf1_loss                | 6.70405e-05   |
| qf2_loss                | 0.00015028591 |
| time_elapsed            | 752           |
| total timesteps         | 146996        |
| value_loss              | 7.4102274e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011542427  |
| ent_coef_loss           | -3.546177     |
| entropy                 | 0.9935533     |
| episodes                | 428           |
| fps                     | 195           |
| mean 100 episode reward | 0.8           |
| n_updates               | 147622        |
| policy_loss             | -0.42057022   |
| qf1_loss                | 0.00010517327 |
| qf2_loss                | 5.051402e-05  |
| time_elapsed            | 756           |
| total timesteps         | 147722        |
| value_loss              | 0.00016269949 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012791639  |
| ent_coef_loss           | -2.6694236    |
| entropy                 | 1.0621188     |
| episodes                | 432           |
| fps                     | 195           |
| mean 100 episode reward | 0.9           |
| n_updates               | 148389        |
| policy_loss             | -0.3733241    |
| qf1_loss                | 0.0035978584  |
| qf2_loss                | 0.0034485536  |
| time_elapsed            | 760           |
| total timesteps         | 148489        |
| value_loss              | 0.00020239483 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012827793  |
| ent_coef_loss           | 6.0720677     |
| entropy                 | 1.3531768     |
| episodes                | 436           |
| fps                     | 195           |
| mean 100 episode reward | 0.9           |
| n_updates               | 149199        |
| policy_loss             | -0.34764928   |
| qf1_loss                | 7.364242e-05  |
| qf2_loss                | 0.00010071652 |
| time_elapsed            | 764           |
| total timesteps         | 149299        |
| value_loss              | 0.0001132392  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013158214  |
| ent_coef_loss           | 0.15887782    |
| entropy                 | 1.4235353     |
| episodes                | 440           |
| fps                     | 195           |
| mean 100 episode reward | 0.9           |
| n_updates               | 149901        |
| policy_loss             | -0.39518607   |
| qf1_loss                | 0.00029573395 |
| qf2_loss                | 0.00025971545 |
| time_elapsed            | 768           |
| total timesteps         | 150001        |
| value_loss              | 0.0001105604  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0013099274   |
| ent_coef_loss           | -1.5992585     |
| entropy                 | 1.2249593      |
| episodes                | 444            |
| fps                     | 195            |
| mean 100 episode reward | 0.9            |
| n_updates               | 150630         |
| policy_loss             | -0.42936593    |
| qf1_loss                | 0.000121963065 |
| qf2_loss                | 9.506008e-05   |
| time_elapsed            | 771            |
| total timesteps         | 150730         |
| value_loss              | 6.309604e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012961543  |
| ent_coef_loss           | -0.60914063   |
| entropy                 | 1.259069      |
| episodes                | 448           |
| fps                     | 195           |
| mean 100 episode reward | 0.9           |
| n_updates               | 151306        |
| policy_loss             | -0.42945814   |
| qf1_loss                | 9.93827e-05   |
| qf2_loss                | 8.793906e-05  |
| time_elapsed            | 775           |
| total timesteps         | 151406        |
| value_loss              | 0.00017505362 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0013109135 |
| ent_coef_loss           | 2.531364     |
| entropy                 | 1.1684448    |
| episodes                | 452          |
| fps                     | 195          |
| mean 100 episode reward | 0.9          |
| n_updates               | 152036       |
| policy_loss             | -0.34199417  |
| qf1_loss                | 0.0002714717 |
| qf2_loss                | 0.0003107036 |
| time_elapsed            | 779          |
| total timesteps         | 152136       |
| value_loss              | 9.931246e-05 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.001278217  |
| ent_coef_loss           | 1.3468893    |
| entropy                 | 1.0091609    |
| episodes                | 456          |
| fps                     | 195          |
| mean 100 episode reward | 0.9          |
| n_updates               | 152980       |
| policy_loss             | -0.38024095  |
| qf1_loss                | 9.780192e-05 |
| qf2_loss                | 7.523217e-05 |
| time_elapsed            | 784          |
| total timesteps         | 153080       |
| value_loss              | 6.841863e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011388187  |
| ent_coef_loss           | 0.17349818    |
| entropy                 | 1.1254251     |
| episodes                | 460           |
| fps                     | 195           |
| mean 100 episode reward | 0.9           |
| n_updates               | 153698        |
| policy_loss             | -0.39585304   |
| qf1_loss                | 8.566134e-05  |
| qf2_loss                | 0.00015029567 |
| time_elapsed            | 787           |
| total timesteps         | 153798        |
| value_loss              | 4.8502392e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010357236  |
| ent_coef_loss           | 1.6936276     |
| entropy                 | 1.0611057     |
| episodes                | 464           |
| fps                     | 195           |
| mean 100 episode reward | 0.9           |
| n_updates               | 154468        |
| policy_loss             | -0.4601246    |
| qf1_loss                | 6.0737366e-05 |
| qf2_loss                | 5.267475e-05  |
| time_elapsed            | 791           |
| total timesteps         | 154568        |
| value_loss              | 8.77427e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011412507  |
| ent_coef_loss           | 0.6196851     |
| entropy                 | 1.2582538     |
| episodes                | 468           |
| fps                     | 195           |
| mean 100 episode reward | 0.9           |
| n_updates               | 155167        |
| policy_loss             | -0.44475543   |
| qf1_loss                | 7.1140574e-05 |
| qf2_loss                | 7.7834484e-05 |
| time_elapsed            | 795           |
| total timesteps         | 155267        |
| value_loss              | 6.864284e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0012025529   |
| ent_coef_loss           | 1.562809       |
| entropy                 | 1.2983395      |
| episodes                | 472            |
| fps                     | 195            |
| mean 100 episode reward | 0.9            |
| n_updates               | 155830         |
| policy_loss             | -0.36533248    |
| qf1_loss                | 6.609193e-05   |
| qf2_loss                | 7.587856e-05   |
| time_elapsed            | 798            |
| total timesteps         | 155930         |
| value_loss              | 0.000114973285 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011522427  |
| ent_coef_loss           | 2.6183805     |
| entropy                 | 1.1088481     |
| episodes                | 476           |
| fps                     | 195           |
| mean 100 episode reward | 0.9           |
| n_updates               | 156574        |
| policy_loss             | -0.42806235   |
| qf1_loss                | 7.4784446e-05 |
| qf2_loss                | 5.7621684e-05 |
| time_elapsed            | 802           |
| total timesteps         | 156674        |
| value_loss              | 6.334549e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011613114  |
| ent_coef_loss           | -1.9764303    |
| entropy                 | 1.132923      |
| episodes                | 480           |
| fps                     | 195           |
| mean 100 episode reward | 0.9           |
| n_updates               | 157206        |
| policy_loss             | -0.39751506   |
| qf1_loss                | 0.0009732733  |
| qf2_loss                | 0.0009968979  |
| time_elapsed            | 805           |
| total timesteps         | 157306        |
| value_loss              | 9.7799755e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0011972542   |
| ent_coef_loss           | -0.56938505    |
| entropy                 | 1.1149645      |
| episodes                | 484            |
| fps                     | 195            |
| mean 100 episode reward | 0.9            |
| n_updates               | 157992         |
| policy_loss             | -0.4084357     |
| qf1_loss                | 0.000111147696 |
| qf2_loss                | 0.00011737707  |
| time_elapsed            | 809            |
| total timesteps         | 158092         |
| value_loss              | 0.00017503623  |
--------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0012002569   |
| ent_coef_loss           | -0.41332576    |
| entropy                 | 1.0769042      |
| episodes                | 488            |
| fps                     | 195            |
| mean 100 episode reward | 0.9            |
| n_updates               | 159008         |
| policy_loss             | -0.40266478    |
| qf1_loss                | 0.00023502126  |
| qf2_loss                | 0.00021864189  |
| time_elapsed            | 815            |
| total timesteps         | 159108         |
| value_loss              | 0.000120507204 |
--------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0012926479   |
| ent_coef_loss           | 0.3608836      |
| entropy                 | 1.2310638      |
| episodes                | 492            |
| fps                     | 195            |
| mean 100 episode reward | 0.9            |
| n_updates               | 159759         |
| policy_loss             | -0.47939512    |
| qf1_loss                | 7.998133e-05   |
| qf2_loss                | 0.0001148707   |
| time_elapsed            | 818            |
| total timesteps         | 159859         |
| value_loss              | 0.000120920115 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011731122  |
| ent_coef_loss           | -1.3596649    |
| entropy                 | 1.0483793     |
| episodes                | 496           |
| fps                     | 195           |
| mean 100 episode reward | 0.8           |
| n_updates               | 160428        |
| policy_loss             | -0.44244605   |
| qf1_loss                | 0.00014771204 |
| qf2_loss                | 0.00013242652 |
| time_elapsed            | 822           |
| total timesteps         | 160528        |
| value_loss              | 8.040851e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010947572  |
| ent_coef_loss           | 0.7352572     |
| entropy                 | 1.0538324     |
| episodes                | 500           |
| fps                     | 195           |
| mean 100 episode reward | 0.8           |
| n_updates               | 161175        |
| policy_loss             | -0.43184426   |
| qf1_loss                | 0.00016420276 |
| qf2_loss                | 0.0001194599  |
| time_elapsed            | 826           |
| total timesteps         | 161275        |
| value_loss              | 6.784645e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0012053458   |
| ent_coef_loss           | -1.8076248     |
| entropy                 | 1.0947723      |
| episodes                | 504            |
| fps                     | 195            |
| mean 100 episode reward | 0.8            |
| n_updates               | 161880         |
| policy_loss             | -0.39435482    |
| qf1_loss                | 7.09008e-05    |
| qf2_loss                | 0.000100015575 |
| time_elapsed            | 829            |
| total timesteps         | 161980         |
| value_loss              | 7.4097e-05     |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013038534  |
| ent_coef_loss           | -1.989083     |
| entropy                 | 1.3487985     |
| episodes                | 508           |
| fps                     | 195           |
| mean 100 episode reward | 0.8           |
| n_updates               | 162582        |
| policy_loss             | -0.38842234   |
| qf1_loss                | 8.346975e-05  |
| qf2_loss                | 4.0166597e-05 |
| time_elapsed            | 833           |
| total timesteps         | 162682        |
| value_loss              | 0.00010166024 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012812547  |
| ent_coef_loss           | 1.2144251     |
| entropy                 | 1.2293994     |
| episodes                | 512           |
| fps                     | 195           |
| mean 100 episode reward | 0.8           |
| n_updates               | 163294        |
| policy_loss             | -0.49898252   |
| qf1_loss                | 5.0461684e-05 |
| qf2_loss                | 4.8832193e-05 |
| time_elapsed            | 837           |
| total timesteps         | 163394        |
| value_loss              | 4.5056466e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0012031432   |
| ent_coef_loss           | -0.37528062    |
| entropy                 | 1.1046857      |
| episodes                | 516            |
| fps                     | 195            |
| mean 100 episode reward | 0.8            |
| n_updates               | 164329         |
| policy_loss             | -0.4847414     |
| qf1_loss                | 6.737102e-05   |
| qf2_loss                | 0.000119056334 |
| time_elapsed            | 842            |
| total timesteps         | 164429         |
| value_loss              | 8.257957e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012767599  |
| ent_coef_loss           | -0.18295187   |
| entropy                 | 0.99762833    |
| episodes                | 520           |
| fps                     | 195           |
| mean 100 episode reward | 0.8           |
| n_updates               | 165069        |
| policy_loss             | -0.43251494   |
| qf1_loss                | 8.220417e-05  |
| qf2_loss                | 7.861947e-05  |
| time_elapsed            | 846           |
| total timesteps         | 165169        |
| value_loss              | 0.00012063452 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0012292217 |
| ent_coef_loss           | -0.3356477   |
| entropy                 | 0.887667     |
| episodes                | 524          |
| fps                     | 195          |
| mean 100 episode reward | 0.8          |
| n_updates               | 165984       |
| policy_loss             | -0.423537    |
| qf1_loss                | 6.98978e-05  |
| qf2_loss                | 8.294194e-05 |
| time_elapsed            | 850          |
| total timesteps         | 166084       |
| value_loss              | 5.233286e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011889123  |
| ent_coef_loss           | -0.9271338    |
| entropy                 | 1.1001128     |
| episodes                | 528           |
| fps                     | 195           |
| mean 100 episode reward | 0.8           |
| n_updates               | 166801        |
| policy_loss             | -0.45070225   |
| qf1_loss                | 0.00018104857 |
| qf2_loss                | 0.00022164588 |
| time_elapsed            | 855           |
| total timesteps         | 166901        |
| value_loss              | 8.164994e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001108157   |
| ent_coef_loss           | -1.8794937    |
| entropy                 | 0.9235127     |
| episodes                | 532           |
| fps                     | 195           |
| mean 100 episode reward | 0.8           |
| n_updates               | 167577        |
| policy_loss             | -0.4238392    |
| qf1_loss                | 0.00014170069 |
| qf2_loss                | 0.000371715   |
| time_elapsed            | 859           |
| total timesteps         | 167677        |
| value_loss              | 8.872742e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010958457  |
| ent_coef_loss           | 0.099063665   |
| entropy                 | 0.8687416     |
| episodes                | 536           |
| fps                     | 195           |
| mean 100 episode reward | 0.8           |
| n_updates               | 168408        |
| policy_loss             | -0.42132568   |
| qf1_loss                | 4.072455e-05  |
| qf2_loss                | 7.115159e-05  |
| time_elapsed            | 863           |
| total timesteps         | 168508        |
| value_loss              | 4.3445798e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010685689  |
| ent_coef_loss           | 1.3687437     |
| entropy                 | 0.9247734     |
| episodes                | 540           |
| fps                     | 195           |
| mean 100 episode reward | 0.8           |
| n_updates               | 169388        |
| policy_loss             | -0.46584886   |
| qf1_loss                | 0.00044429675 |
| qf2_loss                | 0.0004887684  |
| time_elapsed            | 868           |
| total timesteps         | 169488        |
| value_loss              | 8.668016e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0011338753   |
| ent_coef_loss           | -0.6344374     |
| entropy                 | 1.2031124      |
| episodes                | 544            |
| fps                     | 195            |
| mean 100 episode reward | 0.8            |
| n_updates               | 170347         |
| policy_loss             | -0.48534054    |
| qf1_loss                | 0.00012372211  |
| qf2_loss                | 0.000118979835 |
| time_elapsed            | 873            |
| total timesteps         | 170447         |
| value_loss              | 3.924629e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010528951  |
| ent_coef_loss           | -2.584903     |
| entropy                 | 0.81000453    |
| episodes                | 548           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 171364        |
| policy_loss             | -0.46621704   |
| qf1_loss                | 6.3173284e-05 |
| qf2_loss                | 6.1333114e-05 |
| time_elapsed            | 878           |
| total timesteps         | 171464        |
| value_loss              | 8.5140055e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011271666  |
| ent_coef_loss           | -1.0772619    |
| entropy                 | 1.1271033     |
| episodes                | 552           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 172081        |
| policy_loss             | -0.48222202   |
| qf1_loss                | 4.4869106e-05 |
| qf2_loss                | 4.3855754e-05 |
| time_elapsed            | 882           |
| total timesteps         | 172181        |
| value_loss              | 7.179454e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011006647  |
| ent_coef_loss           | -0.1716587    |
| entropy                 | 1.0202341     |
| episodes                | 556           |
| fps                     | 195           |
| mean 100 episode reward | 0.8           |
| n_updates               | 172746        |
| policy_loss             | -0.5157491    |
| qf1_loss                | 9.673285e-05  |
| qf2_loss                | 8.017912e-05  |
| time_elapsed            | 885           |
| total timesteps         | 172846        |
| value_loss              | 2.9210136e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010568452  |
| ent_coef_loss           | 3.250199      |
| entropy                 | 1.1837435     |
| episodes                | 560           |
| fps                     | 195           |
| mean 100 episode reward | 0.8           |
| n_updates               | 173855        |
| policy_loss             | -0.47904745   |
| qf1_loss                | 3.9523547e-05 |
| qf2_loss                | 5.4682372e-05 |
| time_elapsed            | 891           |
| total timesteps         | 173955        |
| value_loss              | 7.4929405e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011027397  |
| ent_coef_loss           | -0.29398173   |
| entropy                 | 1.1293745     |
| episodes                | 564           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 174569        |
| policy_loss             | -0.5031574    |
| qf1_loss                | 4.1975716e-05 |
| qf2_loss                | 4.5910012e-05 |
| time_elapsed            | 895           |
| total timesteps         | 174669        |
| value_loss              | 3.2357686e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010871359  |
| ent_coef_loss           | 0.76972294    |
| entropy                 | 1.1754587     |
| episodes                | 568           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 175354        |
| policy_loss             | -0.47488016   |
| qf1_loss                | 3.657193e-05  |
| qf2_loss                | 4.4824534e-05 |
| time_elapsed            | 899           |
| total timesteps         | 175454        |
| value_loss              | 3.7738646e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010250101  |
| ent_coef_loss           | -1.4325094    |
| entropy                 | 1.1560783     |
| episodes                | 572           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 176193        |
| policy_loss             | -0.44392067   |
| qf1_loss                | 4.956177e-05  |
| qf2_loss                | 1.9311512e-05 |
| time_elapsed            | 903           |
| total timesteps         | 176293        |
| value_loss              | 2.9820218e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010611439  |
| ent_coef_loss           | -0.73101795   |
| entropy                 | 1.29053       |
| episodes                | 576           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 176976        |
| policy_loss             | -0.49234763   |
| qf1_loss                | 5.1474075e-05 |
| qf2_loss                | 8.621512e-05  |
| time_elapsed            | 907           |
| total timesteps         | 177076        |
| value_loss              | 5.812524e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010861845  |
| ent_coef_loss           | 4.356031      |
| entropy                 | 1.1767867     |
| episodes                | 580           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 177618        |
| policy_loss             | -0.50785244   |
| qf1_loss                | 3.3846896e-05 |
| qf2_loss                | 3.1199248e-05 |
| time_elapsed            | 911           |
| total timesteps         | 177718        |
| value_loss              | 4.8728623e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001094596   |
| ent_coef_loss           | -2.2471251    |
| entropy                 | 1.2665162     |
| episodes                | 584           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 178383        |
| policy_loss             | -0.4929123    |
| qf1_loss                | 8.396454e-05  |
| qf2_loss                | 0.0001607939  |
| time_elapsed            | 915           |
| total timesteps         | 178483        |
| value_loss              | 5.1925643e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009958686  |
| ent_coef_loss           | 0.13781169    |
| entropy                 | 1.0709524     |
| episodes                | 588           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 179209        |
| policy_loss             | -0.48217782   |
| qf1_loss                | 0.00012206531 |
| qf2_loss                | 8.280331e-05  |
| time_elapsed            | 919           |
| total timesteps         | 179309        |
| value_loss              | 0.00014719606 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010384385  |
| ent_coef_loss           | -1.662574     |
| entropy                 | 1.1700168     |
| episodes                | 592           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 179948        |
| policy_loss             | -0.5235811    |
| qf1_loss                | 0.00025209348 |
| qf2_loss                | 0.00029888592 |
| time_elapsed            | 923           |
| total timesteps         | 180048        |
| value_loss              | 0.00039645348 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001033583   |
| ent_coef_loss           | -2.2916217    |
| entropy                 | 1.0218384     |
| episodes                | 596           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 180753        |
| policy_loss             | -0.48897114   |
| qf1_loss                | 0.00010737326 |
| qf2_loss                | 6.799194e-05  |
| time_elapsed            | 927           |
| total timesteps         | 180853        |
| value_loss              | 4.8498667e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010497689  |
| ent_coef_loss           | -1.1334176    |
| entropy                 | 1.1844761     |
| episodes                | 600           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 181475        |
| policy_loss             | -0.49895495   |
| qf1_loss                | 0.00011523301 |
| qf2_loss                | 0.00012237628 |
| time_elapsed            | 930           |
| total timesteps         | 181575        |
| value_loss              | 5.1048024e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010537324  |
| ent_coef_loss           | 2.0426538     |
| entropy                 | 1.1074553     |
| episodes                | 604           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 182210        |
| policy_loss             | -0.5235126    |
| qf1_loss                | 5.6219083e-05 |
| qf2_loss                | 5.0396116e-05 |
| time_elapsed            | 934           |
| total timesteps         | 182310        |
| value_loss              | 4.0647414e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010176189  |
| ent_coef_loss           | 1.2859616     |
| entropy                 | 1.0697923     |
| episodes                | 608           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 182951        |
| policy_loss             | -0.63596195   |
| qf1_loss                | 3.377828e-05  |
| qf2_loss                | 4.621324e-05  |
| time_elapsed            | 938           |
| total timesteps         | 183051        |
| value_loss              | 3.8458114e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009896351  |
| ent_coef_loss           | 2.056078      |
| entropy                 | 1.2920222     |
| episodes                | 612           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 183639        |
| policy_loss             | -0.48011932   |
| qf1_loss                | 8.083829e-05  |
| qf2_loss                | 4.216185e-05  |
| time_elapsed            | 941           |
| total timesteps         | 183739        |
| value_loss              | 8.7126886e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010484548  |
| ent_coef_loss           | 0.25624132    |
| entropy                 | 1.1957203     |
| episodes                | 616           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 184431        |
| policy_loss             | -0.4941071    |
| qf1_loss                | 5.7739213e-05 |
| qf2_loss                | 4.2338317e-05 |
| time_elapsed            | 946           |
| total timesteps         | 184531        |
| value_loss              | 8.231802e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010091871  |
| ent_coef_loss           | 1.1968989     |
| entropy                 | 1.0626833     |
| episodes                | 620           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 185217        |
| policy_loss             | -0.4994528    |
| qf1_loss                | 9.531895e-05  |
| qf2_loss                | 7.437995e-05  |
| time_elapsed            | 950           |
| total timesteps         | 185317        |
| value_loss              | 0.00017048398 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010132351  |
| ent_coef_loss           | 2.5516043     |
| entropy                 | 1.1943256     |
| episodes                | 624           |
| fps                     | 195           |
| mean 100 episode reward | 0.7           |
| n_updates               | 185943        |
| policy_loss             | -0.4745226    |
| qf1_loss                | 9.122293e-05  |
| qf2_loss                | 5.4872286e-05 |
| time_elapsed            | 953           |
| total timesteps         | 186043        |
| value_loss              | 0.00010238739 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000992041   |
| ent_coef_loss           | 0.19256282    |
| entropy                 | 0.99874854    |
| episodes                | 628           |
| fps                     | 195           |
| mean 100 episode reward | 0.8           |
| n_updates               | 186717        |
| policy_loss             | -0.50194395   |
| qf1_loss                | 5.0807703e-05 |
| qf2_loss                | 5.205912e-05  |
| time_elapsed            | 957           |
| total timesteps         | 186817        |
| value_loss              | 9.544601e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0009904377 |
| ent_coef_loss           | 1.6407105    |
| entropy                 | 1.2640535    |
| episodes                | 632          |
| fps                     | 195          |
| mean 100 episode reward | 0.8          |
| n_updates               | 187439       |
| policy_loss             | -0.5298178   |
| qf1_loss                | 7.317442e-05 |
| qf2_loss                | 5.774912e-05 |
| time_elapsed            | 961          |
| total timesteps         | 187539       |
| value_loss              | 0.0001436988 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009785212  |
| ent_coef_loss           | 2.1062226     |
| entropy                 | 1.1122565     |
| episodes                | 636           |
| fps                     | 195           |
| mean 100 episode reward | 0.8           |
| n_updates               | 188111        |
| policy_loss             | -0.4457816    |
| qf1_loss                | 4.7977657e-05 |
| qf2_loss                | 3.9076825e-05 |
| time_elapsed            | 965           |
| total timesteps         | 188211        |
| value_loss              | 6.548596e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010475942  |
| ent_coef_loss           | -1.1861507    |
| entropy                 | 1.3057711     |
| episodes                | 640           |
| fps                     | 195           |
| mean 100 episode reward | 0.8           |
| n_updates               | 188824        |
| policy_loss             | -0.48683053   |
| qf1_loss                | 8.373181e-05  |
| qf2_loss                | 8.4741936e-05 |
| time_elapsed            | 968           |
| total timesteps         | 188924        |
| value_loss              | 5.4864537e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010329153  |
| ent_coef_loss           | -1.7469113    |
| entropy                 | 1.3749983     |
| episodes                | 644           |
| fps                     | 195           |
| mean 100 episode reward | 0.8           |
| n_updates               | 189609        |
| policy_loss             | -0.45982492   |
| qf1_loss                | 0.00011262953 |
| qf2_loss                | 3.618354e-05  |
| time_elapsed            | 972           |
| total timesteps         | 189709        |
| value_loss              | 0.00031403385 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010277935  |
| ent_coef_loss           | -1.7048358    |
| entropy                 | 1.1711798     |
| episodes                | 648           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 190434        |
| policy_loss             | -0.5280828    |
| qf1_loss                | 3.903073e-05  |
| qf2_loss                | 2.789863e-05  |
| time_elapsed            | 977           |
| total timesteps         | 190534        |
| value_loss              | 4.2619373e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010145481  |
| ent_coef_loss           | 0.6689382     |
| entropy                 | 1.2520754     |
| episodes                | 652           |
| fps                     | 195           |
| mean 100 episode reward | 0.8           |
| n_updates               | 191281        |
| policy_loss             | -0.52485615   |
| qf1_loss                | 3.2863725e-05 |
| qf2_loss                | 3.851367e-05  |
| time_elapsed            | 981           |
| total timesteps         | 191381        |
| value_loss              | 7.46312e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010480904  |
| ent_coef_loss           | 1.719068      |
| entropy                 | 1.2601374     |
| episodes                | 656           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 191935        |
| policy_loss             | -0.4941737    |
| qf1_loss                | 8.555577e-05  |
| qf2_loss                | 0.00010584435 |
| time_elapsed            | 984           |
| total timesteps         | 192035        |
| value_loss              | 4.2814285e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010781285  |
| ent_coef_loss           | -1.3997357    |
| entropy                 | 1.1191058     |
| episodes                | 660           |
| fps                     | 195           |
| mean 100 episode reward | 0.8           |
| n_updates               | 192652        |
| policy_loss             | -0.5182978    |
| qf1_loss                | 0.00012522568 |
| qf2_loss                | 7.595601e-05  |
| time_elapsed            | 988           |
| total timesteps         | 192752        |
| value_loss              | 0.00011605127 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00103598    |
| ent_coef_loss           | 2.5224566     |
| entropy                 | 1.2422416     |
| episodes                | 664           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 193373        |
| policy_loss             | -0.48404047   |
| qf1_loss                | 0.00024832744 |
| qf2_loss                | 0.0001670895  |
| time_elapsed            | 992           |
| total timesteps         | 193473        |
| value_loss              | 4.3161297e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010433657 |
| ent_coef_loss           | 2.1323502    |
| entropy                 | 1.312712     |
| episodes                | 668          |
| fps                     | 194          |
| mean 100 episode reward | 0.8          |
| n_updates               | 194067       |
| policy_loss             | -0.5214094   |
| qf1_loss                | 4.675507e-05 |
| qf2_loss                | 3.644346e-05 |
| time_elapsed            | 995          |
| total timesteps         | 194167       |
| value_loss              | 9.151816e-05 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010440779 |
| ent_coef_loss           | -1.6423697   |
| entropy                 | 1.2733078    |
| episodes                | 672          |
| fps                     | 194          |
| mean 100 episode reward | 0.8          |
| n_updates               | 194809       |
| policy_loss             | -0.48103178  |
| qf1_loss                | 6.466643e-05 |
| qf2_loss                | 6.406202e-05 |
| time_elapsed            | 999          |
| total timesteps         | 194909       |
| value_loss              | 6.757956e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009954418  |
| ent_coef_loss           | -3.5783076    |
| entropy                 | 1.1285682     |
| episodes                | 676           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 195495        |
| policy_loss             | -0.5399041    |
| qf1_loss                | 0.00029063268 |
| qf2_loss                | 0.0005133854  |
| time_elapsed            | 1003          |
| total timesteps         | 195595        |
| value_loss              | 0.00037219064 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010018938  |
| ent_coef_loss           | -1.9954442    |
| entropy                 | 1.228926      |
| episodes                | 680           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 196219        |
| policy_loss             | -0.47466838   |
| qf1_loss                | 6.5520486e-05 |
| qf2_loss                | 6.336408e-05  |
| time_elapsed            | 1006          |
| total timesteps         | 196319        |
| value_loss              | 7.34089e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009791695  |
| ent_coef_loss           | 0.038028687   |
| entropy                 | 1.1350915     |
| episodes                | 684           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 196921        |
| policy_loss             | -0.4647243    |
| qf1_loss                | 4.6190926e-05 |
| qf2_loss                | 4.4031054e-05 |
| time_elapsed            | 1010          |
| total timesteps         | 197021        |
| value_loss              | 3.9192877e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009928122  |
| ent_coef_loss           | 3.0646133     |
| entropy                 | 1.0777342     |
| episodes                | 688           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 197579        |
| policy_loss             | -0.4928342    |
| qf1_loss                | 0.00017224168 |
| qf2_loss                | 0.00017278508 |
| time_elapsed            | 1013          |
| total timesteps         | 197679        |
| value_loss              | 0.00018630897 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009853821  |
| ent_coef_loss           | 0.17540616    |
| entropy                 | 1.1938882     |
| episodes                | 692           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 198349        |
| policy_loss             | -0.47266808   |
| qf1_loss                | 3.4311503e-05 |
| qf2_loss                | 8.78475e-05   |
| time_elapsed            | 1017          |
| total timesteps         | 198449        |
| value_loss              | 7.7872304e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010330345  |
| ent_coef_loss           | 1.2816346     |
| entropy                 | 1.2035279     |
| episodes                | 696           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 199130        |
| policy_loss             | -0.5279521    |
| qf1_loss                | 2.7432548e-05 |
| qf2_loss                | 4.404904e-05  |
| time_elapsed            | 1021          |
| total timesteps         | 199230        |
| value_loss              | 4.6417823e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009865137  |
| ent_coef_loss           | 0.65283215    |
| entropy                 | 1.0548923     |
| episodes                | 700           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 199787        |
| policy_loss             | -0.5094299    |
| qf1_loss                | 6.5556465e-05 |
| qf2_loss                | 6.615355e-05  |
| time_elapsed            | 1025          |
| total timesteps         | 199887        |
| value_loss              | 5.690223e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010070979  |
| ent_coef_loss           | -1.2269806    |
| entropy                 | 1.1456072     |
| episodes                | 704           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 200607        |
| policy_loss             | -0.5518735    |
| qf1_loss                | 2.295339e-05  |
| qf2_loss                | 2.6777594e-05 |
| time_elapsed            | 1029          |
| total timesteps         | 200707        |
| value_loss              | 4.5746507e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009954859  |
| ent_coef_loss           | -1.4018929    |
| entropy                 | 1.1416526     |
| episodes                | 708           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 201330        |
| policy_loss             | -0.51175296   |
| qf1_loss                | 0.00010711377 |
| qf2_loss                | 9.189601e-05  |
| time_elapsed            | 1033          |
| total timesteps         | 201430        |
| value_loss              | 2.6829577e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010045957  |
| ent_coef_loss           | 0.2432633     |
| entropy                 | 1.3587725     |
| episodes                | 712           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 202038        |
| policy_loss             | -0.46851456   |
| qf1_loss                | 3.3463286e-05 |
| qf2_loss                | 2.9813771e-05 |
| time_elapsed            | 1036          |
| total timesteps         | 202138        |
| value_loss              | 3.6878126e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010880298  |
| ent_coef_loss           | -2.0433068    |
| entropy                 | 1.1531221     |
| episodes                | 716           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 202818        |
| policy_loss             | -0.5575767    |
| qf1_loss                | 3.1851938e-05 |
| qf2_loss                | 4.2474545e-05 |
| time_elapsed            | 1041          |
| total timesteps         | 202918        |
| value_loss              | 9.795926e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.001087422  |
| ent_coef_loss           | 2.3886497    |
| entropy                 | 1.2241908    |
| episodes                | 720          |
| fps                     | 194          |
| mean 100 episode reward | 0.9          |
| n_updates               | 203474       |
| policy_loss             | -0.5392889   |
| qf1_loss                | 4.340446e-05 |
| qf2_loss                | 6.56081e-05  |
| time_elapsed            | 1044         |
| total timesteps         | 203574       |
| value_loss              | 6.36788e-05  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010753806  |
| ent_coef_loss           | -2.9722824    |
| entropy                 | 1.1666577     |
| episodes                | 724           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 204174        |
| policy_loss             | -0.5468331    |
| qf1_loss                | 3.9068524e-05 |
| qf2_loss                | 3.907171e-05  |
| time_elapsed            | 1047          |
| total timesteps         | 204274        |
| value_loss              | 9.3866234e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010831098  |
| ent_coef_loss           | 0.5904925     |
| entropy                 | 1.0763394     |
| episodes                | 728           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 204852        |
| policy_loss             | -0.54534507   |
| qf1_loss                | 0.00019580181 |
| qf2_loss                | 0.00015913807 |
| time_elapsed            | 1051          |
| total timesteps         | 204952        |
| value_loss              | 0.00012533757 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011024517  |
| ent_coef_loss           | -2.0996685    |
| entropy                 | 1.1857635     |
| episodes                | 732           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 205525        |
| policy_loss             | -0.5642338    |
| qf1_loss                | 3.207116e-05  |
| qf2_loss                | 3.7028167e-05 |
| time_elapsed            | 1054          |
| total timesteps         | 205625        |
| value_loss              | 8.799519e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0011312858 |
| ent_coef_loss           | -0.93086696  |
| entropy                 | 1.2397416    |
| episodes                | 736          |
| fps                     | 194          |
| mean 100 episode reward | 0.9          |
| n_updates               | 206192       |
| policy_loss             | -0.49963388  |
| qf1_loss                | 0.0001709711 |
| qf2_loss                | 0.0002583214 |
| time_elapsed            | 1058         |
| total timesteps         | 206292       |
| value_loss              | 9.843395e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011421969  |
| ent_coef_loss           | -2.2138937    |
| entropy                 | 1.2208592     |
| episodes                | 740           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 206900        |
| policy_loss             | -0.512444     |
| qf1_loss                | 2.1589232e-05 |
| qf2_loss                | 3.8604547e-05 |
| time_elapsed            | 1061          |
| total timesteps         | 207000        |
| value_loss              | 2.3574714e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010694376  |
| ent_coef_loss           | 1.4281826     |
| entropy                 | 1.2901845     |
| episodes                | 744           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 207600        |
| policy_loss             | -0.5226108    |
| qf1_loss                | 2.9769773e-05 |
| qf2_loss                | 4.13904e-05   |
| time_elapsed            | 1065          |
| total timesteps         | 207700        |
| value_loss              | 5.878842e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001034104   |
| ent_coef_loss           | -3.137548     |
| entropy                 | 1.1463857     |
| episodes                | 748           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 208320        |
| policy_loss             | -0.47479445   |
| qf1_loss                | 4.4079883e-05 |
| qf2_loss                | 4.7001515e-05 |
| time_elapsed            | 1069          |
| total timesteps         | 208420        |
| value_loss              | 0.00011304804 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010374185  |
| ent_coef_loss           | 1.2719638     |
| entropy                 | 1.2777474     |
| episodes                | 752           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 209079        |
| policy_loss             | -0.49830684   |
| qf1_loss                | 2.3631736e-05 |
| qf2_loss                | 3.712644e-05  |
| time_elapsed            | 1073          |
| total timesteps         | 209179        |
| value_loss              | 3.7035243e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010930386  |
| ent_coef_loss           | -1.0815774    |
| entropy                 | 1.2110739     |
| episodes                | 756           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 209863        |
| policy_loss             | -0.5289001    |
| qf1_loss                | 3.5420097e-05 |
| qf2_loss                | 2.9540926e-05 |
| time_elapsed            | 1077          |
| total timesteps         | 209963        |
| value_loss              | 4.698481e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011230098  |
| ent_coef_loss           | -1.732497     |
| entropy                 | 1.1644468     |
| episodes                | 760           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 210586        |
| policy_loss             | -0.46864617   |
| qf1_loss                | 3.5035984e-05 |
| qf2_loss                | 6.443016e-05  |
| time_elapsed            | 1080          |
| total timesteps         | 210686        |
| value_loss              | 0.00011042824 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001081136   |
| ent_coef_loss           | -1.9209914    |
| entropy                 | 1.2683159     |
| episodes                | 764           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 211355        |
| policy_loss             | -0.52263254   |
| qf1_loss                | 5.950935e-05  |
| qf2_loss                | 7.862059e-05  |
| time_elapsed            | 1084          |
| total timesteps         | 211455        |
| value_loss              | 3.6865473e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009847025  |
| ent_coef_loss           | -1.1048409    |
| entropy                 | 1.1479993     |
| episodes                | 768           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 212246        |
| policy_loss             | -0.5170224    |
| qf1_loss                | 0.0002866556  |
| qf2_loss                | 0.00030360103 |
| time_elapsed            | 1089          |
| total timesteps         | 212346        |
| value_loss              | 3.879505e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009741259  |
| ent_coef_loss           | 2.9550972     |
| entropy                 | 1.3211453     |
| episodes                | 772           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 212918        |
| policy_loss             | -0.49270278   |
| qf1_loss                | 6.481762e-05  |
| qf2_loss                | 6.466459e-05  |
| time_elapsed            | 1092          |
| total timesteps         | 213018        |
| value_loss              | 7.6852986e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001005561   |
| ent_coef_loss           | 0.10636783    |
| entropy                 | 1.3441705     |
| episodes                | 776           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 213679        |
| policy_loss             | -0.51390576   |
| qf1_loss                | 2.9468596e-05 |
| qf2_loss                | 5.106291e-05  |
| time_elapsed            | 1096          |
| total timesteps         | 213779        |
| value_loss              | 6.484102e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010145457  |
| ent_coef_loss           | 0.02398014    |
| entropy                 | 1.2591131     |
| episodes                | 780           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 214376        |
| policy_loss             | -0.49204433   |
| qf1_loss                | 4.44979e-05   |
| qf2_loss                | 3.3894823e-05 |
| time_elapsed            | 1100          |
| total timesteps         | 214476        |
| value_loss              | 7.173633e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010107099  |
| ent_coef_loss           | 0.4515193     |
| entropy                 | 1.2580478     |
| episodes                | 784           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 215053        |
| policy_loss             | -0.49256134   |
| qf1_loss                | 5.21143e-05   |
| qf2_loss                | 4.5235294e-05 |
| time_elapsed            | 1103          |
| total timesteps         | 215153        |
| value_loss              | 5.512104e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010276479  |
| ent_coef_loss           | -2.0108905    |
| entropy                 | 1.3415235     |
| episodes                | 788           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 215785        |
| policy_loss             | -0.49332765   |
| qf1_loss                | 3.7788734e-05 |
| qf2_loss                | 5.0224895e-05 |
| time_elapsed            | 1107          |
| total timesteps         | 215885        |
| value_loss              | 3.8293685e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009442156  |
| ent_coef_loss           | -2.7063606    |
| entropy                 | 1.2399896     |
| episodes                | 792           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 216456        |
| policy_loss             | -0.55168796   |
| qf1_loss                | 3.7102247e-05 |
| qf2_loss                | 3.2731023e-05 |
| time_elapsed            | 1111          |
| total timesteps         | 216556        |
| value_loss              | 9.4759576e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009958672  |
| ent_coef_loss           | 0.9436573     |
| entropy                 | 1.4469024     |
| episodes                | 796           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 217139        |
| policy_loss             | -0.53013045   |
| qf1_loss                | 8.226647e-05  |
| qf2_loss                | 5.9895923e-05 |
| time_elapsed            | 1114          |
| total timesteps         | 217239        |
| value_loss              | 6.0527862e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009182849  |
| ent_coef_loss           | -1.5107484    |
| entropy                 | 1.409944      |
| episodes                | 800           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 217839        |
| policy_loss             | -0.5834439    |
| qf1_loss                | 3.6419777e-05 |
| qf2_loss                | 4.3176777e-05 |
| time_elapsed            | 1118          |
| total timesteps         | 217939        |
| value_loss              | 6.318929e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009820807  |
| ent_coef_loss           | 0.5061436     |
| entropy                 | 1.4112144     |
| episodes                | 804           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 218643        |
| policy_loss             | -0.54202163   |
| qf1_loss                | 2.8971643e-05 |
| qf2_loss                | 6.0372135e-05 |
| time_elapsed            | 1122          |
| total timesteps         | 218743        |
| value_loss              | 6.986323e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010174471  |
| ent_coef_loss           | -1.3344436    |
| entropy                 | 1.4669793     |
| episodes                | 808           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 219308        |
| policy_loss             | -0.4755147    |
| qf1_loss                | 4.8356145e-05 |
| qf2_loss                | 6.9400645e-05 |
| time_elapsed            | 1125          |
| total timesteps         | 219408        |
| value_loss              | 5.712602e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009761644  |
| ent_coef_loss           | -3.5746593    |
| entropy                 | 1.37021       |
| episodes                | 812           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 220043        |
| policy_loss             | -0.50072515   |
| qf1_loss                | 3.513344e-05  |
| qf2_loss                | 2.9475897e-05 |
| time_elapsed            | 1129          |
| total timesteps         | 220143        |
| value_loss              | 3.536576e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000951711   |
| ent_coef_loss           | 0.49525404    |
| entropy                 | 1.35799       |
| episodes                | 816           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 220754        |
| policy_loss             | -0.591414     |
| qf1_loss                | 4.1127954e-05 |
| qf2_loss                | 4.4115804e-05 |
| time_elapsed            | 1133          |
| total timesteps         | 220854        |
| value_loss              | 5.8447094e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009286035  |
| ent_coef_loss           | -1.4575922    |
| entropy                 | 1.2285447     |
| episodes                | 820           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 221731        |
| policy_loss             | -0.5091113    |
| qf1_loss                | 4.4982546e-05 |
| qf2_loss                | 3.2566488e-05 |
| time_elapsed            | 1138          |
| total timesteps         | 221831        |
| value_loss              | 4.7347676e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0010454075   |
| ent_coef_loss           | 2.3101232      |
| entropy                 | 1.3647305      |
| episodes                | 824            |
| fps                     | 194            |
| mean 100 episode reward | 0.9            |
| n_updates               | 222848         |
| policy_loss             | -0.51385725    |
| qf1_loss                | 0.000107257976 |
| qf2_loss                | 0.00012254094  |
| time_elapsed            | 1144           |
| total timesteps         | 222948         |
| value_loss              | 8.500789e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010961327  |
| ent_coef_loss           | 2.845306      |
| entropy                 | 1.3599539     |
| episodes                | 828           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 223545        |
| policy_loss             | -0.49809316   |
| qf1_loss                | 9.241211e-05  |
| qf2_loss                | 6.7217676e-05 |
| time_elapsed            | 1147          |
| total timesteps         | 223645        |
| value_loss              | 5.821794e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0011082605 |
| ent_coef_loss           | 3.5351293    |
| entropy                 | 1.4612093    |
| episodes                | 832          |
| fps                     | 194          |
| mean 100 episode reward | 0.9          |
| n_updates               | 224242       |
| policy_loss             | -0.5489445   |
| qf1_loss                | 6.706108e-05 |
| qf2_loss                | 8.226436e-05 |
| time_elapsed            | 1151         |
| total timesteps         | 224342       |
| value_loss              | 7.146783e-05 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010664066 |
| ent_coef_loss           | 1.0853386    |
| entropy                 | 1.390435     |
| episodes                | 836          |
| fps                     | 194          |
| mean 100 episode reward | 0.9          |
| n_updates               | 224916       |
| policy_loss             | -0.5051191   |
| qf1_loss                | 7.672411e-05 |
| qf2_loss                | 3.876874e-05 |
| time_elapsed            | 1154         |
| total timesteps         | 225016       |
| value_loss              | 0.0003658794 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010642787  |
| ent_coef_loss           | -0.006034434  |
| entropy                 | 1.3885307     |
| episodes                | 840           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 225641        |
| policy_loss             | -0.52279264   |
| qf1_loss                | 5.7062825e-05 |
| qf2_loss                | 7.385667e-05  |
| time_elapsed            | 1158          |
| total timesteps         | 225741        |
| value_loss              | 5.669398e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010996313  |
| ent_coef_loss           | 0.9675697     |
| entropy                 | 1.6246446     |
| episodes                | 844           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 226384        |
| policy_loss             | -0.52452004   |
| qf1_loss                | 3.7531612e-05 |
| qf2_loss                | 7.178727e-05  |
| time_elapsed            | 1162          |
| total timesteps         | 226484        |
| value_loss              | 3.650921e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010694804  |
| ent_coef_loss           | 0.5601523     |
| entropy                 | 1.347116      |
| episodes                | 848           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 227107        |
| policy_loss             | -0.5139122    |
| qf1_loss                | 5.3788637e-05 |
| qf2_loss                | 4.149127e-05  |
| time_elapsed            | 1165          |
| total timesteps         | 227207        |
| value_loss              | 0.00013058376 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009917159  |
| ent_coef_loss           | -1.7072922    |
| entropy                 | 1.2619877     |
| episodes                | 852           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 227822        |
| policy_loss             | -0.5182383    |
| qf1_loss                | 3.2978387e-05 |
| qf2_loss                | 4.1024716e-05 |
| time_elapsed            | 1169          |
| total timesteps         | 227922        |
| value_loss              | 6.054264e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010378347  |
| ent_coef_loss           | -0.4116763    |
| entropy                 | 1.1519878     |
| episodes                | 856           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 228589        |
| policy_loss             | -0.5105548    |
| qf1_loss                | 4.2525957e-05 |
| qf2_loss                | 2.2341786e-05 |
| time_elapsed            | 1173          |
| total timesteps         | 228689        |
| value_loss              | 4.998553e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010161492  |
| ent_coef_loss           | 4.3624063     |
| entropy                 | 1.3098806     |
| episodes                | 860           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 229275        |
| policy_loss             | -0.50850767   |
| qf1_loss                | 8.694989e-05  |
| qf2_loss                | 6.295674e-05  |
| time_elapsed            | 1177          |
| total timesteps         | 229375        |
| value_loss              | 6.2547755e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010217986  |
| ent_coef_loss           | 1.8140179     |
| entropy                 | 1.6247704     |
| episodes                | 864           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 230007        |
| policy_loss             | -0.589512     |
| qf1_loss                | 3.4577024e-05 |
| qf2_loss                | 4.5212488e-05 |
| time_elapsed            | 1180          |
| total timesteps         | 230107        |
| value_loss              | 3.9219572e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010826868  |
| ent_coef_loss           | -1.1771679    |
| entropy                 | 1.4969046     |
| episodes                | 868           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 231225        |
| policy_loss             | -0.5244988    |
| qf1_loss                | 3.7556212e-05 |
| qf2_loss                | 2.4403158e-05 |
| time_elapsed            | 1187          |
| total timesteps         | 231325        |
| value_loss              | 9.612148e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010380772  |
| ent_coef_loss           | -0.70961416   |
| entropy                 | 1.3480247     |
| episodes                | 872           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 231919        |
| policy_loss             | -0.51356643   |
| qf1_loss                | 5.233354e-05  |
| qf2_loss                | 4.442649e-05  |
| time_elapsed            | 1190          |
| total timesteps         | 232019        |
| value_loss              | 6.4573425e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010236859  |
| ent_coef_loss           | -0.41769862   |
| entropy                 | 1.2258112     |
| episodes                | 876           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 232713        |
| policy_loss             | -0.5253271    |
| qf1_loss                | 4.5722787e-05 |
| qf2_loss                | 5.1600728e-05 |
| time_elapsed            | 1194          |
| total timesteps         | 232813        |
| value_loss              | 2.6755406e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010215526  |
| ent_coef_loss           | -0.3966434    |
| entropy                 | 1.3080324     |
| episodes                | 880           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 233758        |
| policy_loss             | -0.545997     |
| qf1_loss                | 4.4447606e-05 |
| qf2_loss                | 3.5661014e-05 |
| time_elapsed            | 1200          |
| total timesteps         | 233858        |
| value_loss              | 3.1171003e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009366152  |
| ent_coef_loss           | 0.54924464    |
| entropy                 | 1.5467999     |
| episodes                | 884           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 234490        |
| policy_loss             | -0.59339267   |
| qf1_loss                | 2.2317443e-05 |
| qf2_loss                | 1.6107098e-05 |
| time_elapsed            | 1203          |
| total timesteps         | 234590        |
| value_loss              | 2.398327e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00097009545  |
| ent_coef_loss           | -0.870365      |
| entropy                 | 1.2232974      |
| episodes                | 888            |
| fps                     | 194            |
| mean 100 episode reward | 0.8            |
| n_updates               | 235322         |
| policy_loss             | -0.50078714    |
| qf1_loss                | 7.081909e-05   |
| qf2_loss                | 0.000105208004 |
| time_elapsed            | 1208           |
| total timesteps         | 235422         |
| value_loss              | 7.613046e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010137372  |
| ent_coef_loss           | -0.33785582   |
| entropy                 | 1.3397479     |
| episodes                | 892           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 236011        |
| policy_loss             | -0.51020384   |
| qf1_loss                | 2.6250149e-05 |
| qf2_loss                | 2.4480109e-05 |
| time_elapsed            | 1211          |
| total timesteps         | 236111        |
| value_loss              | 3.720836e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009359326  |
| ent_coef_loss           | -3.0453832    |
| entropy                 | 1.2993126     |
| episodes                | 896           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 236785        |
| policy_loss             | -0.5453816    |
| qf1_loss                | 4.7037098e-05 |
| qf2_loss                | 5.051788e-05  |
| time_elapsed            | 1215          |
| total timesteps         | 236885        |
| value_loss              | 7.479641e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008936589  |
| ent_coef_loss           | 1.5162458     |
| entropy                 | 1.2919172     |
| episodes                | 900           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 237631        |
| policy_loss             | -0.537491     |
| qf1_loss                | 1.8802857e-05 |
| qf2_loss                | 1.739657e-05  |
| time_elapsed            | 1220          |
| total timesteps         | 237731        |
| value_loss              | 3.580024e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008751533  |
| ent_coef_loss           | -0.4994272    |
| entropy                 | 1.3379625     |
| episodes                | 904           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 238270        |
| policy_loss             | -0.54888177   |
| qf1_loss                | 3.661704e-05  |
| qf2_loss                | 3.1623462e-05 |
| time_elapsed            | 1223          |
| total timesteps         | 238370        |
| value_loss              | 4.4796732e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093509397 |
| ent_coef_loss           | -1.3518231    |
| entropy                 | 1.5408497     |
| episodes                | 908           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 238921        |
| policy_loss             | -0.57470155   |
| qf1_loss                | 2.1704538e-05 |
| qf2_loss                | 2.3384468e-05 |
| time_elapsed            | 1226          |
| total timesteps         | 239021        |
| value_loss              | 3.542512e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090300426 |
| ent_coef_loss           | -2.1422076    |
| entropy                 | 1.2995975     |
| episodes                | 912           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 239658        |
| policy_loss             | -0.5421263    |
| qf1_loss                | 6.997505e-05  |
| qf2_loss                | 4.931091e-05  |
| time_elapsed            | 1230          |
| total timesteps         | 239758        |
| value_loss              | 4.6501274e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009157775  |
| ent_coef_loss           | 3.4678023     |
| entropy                 | 1.3104589     |
| episodes                | 916           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 240471        |
| policy_loss             | -0.53091663   |
| qf1_loss                | 5.139194e-05  |
| qf2_loss                | 3.916334e-05  |
| time_elapsed            | 1234          |
| total timesteps         | 240571        |
| value_loss              | 0.00013006572 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009925505  |
| ent_coef_loss           | -2.84443      |
| entropy                 | 1.4005604     |
| episodes                | 920           |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 241181        |
| policy_loss             | -0.58470005   |
| qf1_loss                | 2.2474622e-05 |
| qf2_loss                | 1.5716048e-05 |
| time_elapsed            | 1238          |
| total timesteps         | 241281        |
| value_loss              | 7.552732e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009768517  |
| ent_coef_loss           | -0.76387733   |
| entropy                 | 1.3143623     |
| episodes                | 924           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 241869        |
| policy_loss             | -0.5369878    |
| qf1_loss                | 4.3745993e-05 |
| qf2_loss                | 4.9715163e-05 |
| time_elapsed            | 1242          |
| total timesteps         | 241969        |
| value_loss              | 4.6813504e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009640026  |
| ent_coef_loss           | 0.08670986    |
| entropy                 | 1.2795384     |
| episodes                | 928           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 242648        |
| policy_loss             | -0.57817405   |
| qf1_loss                | 3.970549e-05  |
| qf2_loss                | 3.6239777e-05 |
| time_elapsed            | 1246          |
| total timesteps         | 242748        |
| value_loss              | 8.8034154e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094079186 |
| ent_coef_loss           | -2.3963783    |
| entropy                 | 1.3138732     |
| episodes                | 932           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 243365        |
| policy_loss             | -0.5383687    |
| qf1_loss                | 3.4030258e-05 |
| qf2_loss                | 2.6128302e-05 |
| time_elapsed            | 1249          |
| total timesteps         | 243465        |
| value_loss              | 3.9654136e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010121466  |
| ent_coef_loss           | 0.071552604   |
| entropy                 | 1.5016725     |
| episodes                | 936           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 244054        |
| policy_loss             | -0.5567614    |
| qf1_loss                | 4.182605e-05  |
| qf2_loss                | 1.7486847e-05 |
| time_elapsed            | 1253          |
| total timesteps         | 244154        |
| value_loss              | 2.9742227e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008941401  |
| ent_coef_loss           | -0.75223446   |
| entropy                 | 1.1637182     |
| episodes                | 940           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 244811        |
| policy_loss             | -0.5394156    |
| qf1_loss                | 2.4869634e-05 |
| qf2_loss                | 1.9694253e-05 |
| time_elapsed            | 1257          |
| total timesteps         | 244911        |
| value_loss              | 6.996103e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001002539   |
| ent_coef_loss           | 0.5728313     |
| entropy                 | 1.2337375     |
| episodes                | 944           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 245554        |
| policy_loss             | -0.51011467   |
| qf1_loss                | 4.119278e-05  |
| qf2_loss                | 4.1231495e-05 |
| time_elapsed            | 1261          |
| total timesteps         | 245654        |
| value_loss              | 7.2622715e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010035037 |
| ent_coef_loss           | -0.5216614   |
| entropy                 | 1.167613     |
| episodes                | 948          |
| fps                     | 194          |
| mean 100 episode reward | 0.9          |
| n_updates               | 246233       |
| policy_loss             | -0.58342844  |
| qf1_loss                | 3.578841e-05 |
| qf2_loss                | 2.012001e-05 |
| time_elapsed            | 1264         |
| total timesteps         | 246333       |
| value_loss              | 6.605475e-05 |
------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009456416   |
| ent_coef_loss           | -1.2776413     |
| entropy                 | 1.1999319      |
| episodes                | 952            |
| fps                     | 194            |
| mean 100 episode reward | 0.9            |
| n_updates               | 247197         |
| policy_loss             | -0.5050438     |
| qf1_loss                | 8.175032e-05   |
| qf2_loss                | 0.000109716384 |
| time_elapsed            | 1269           |
| total timesteps         | 247297         |
| value_loss              | 9.1002024e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093837385 |
| ent_coef_loss           | -1.3417122    |
| entropy                 | 1.1795026     |
| episodes                | 956           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 247907        |
| policy_loss             | -0.52772534   |
| qf1_loss                | 4.8139715e-05 |
| qf2_loss                | 2.4946981e-05 |
| time_elapsed            | 1273          |
| total timesteps         | 248007        |
| value_loss              | 5.4354638e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010633757  |
| ent_coef_loss           | 1.2052219     |
| entropy                 | 1.2686467     |
| episodes                | 960           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 248593        |
| policy_loss             | -0.542061     |
| qf1_loss                | 3.6334313e-05 |
| qf2_loss                | 4.0460087e-05 |
| time_elapsed            | 1276          |
| total timesteps         | 248693        |
| value_loss              | 5.9499405e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010631699  |
| ent_coef_loss           | 2.1535413     |
| entropy                 | 1.3319778     |
| episodes                | 964           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 249278        |
| policy_loss             | -0.5290997    |
| qf1_loss                | 3.1847754e-05 |
| qf2_loss                | 3.458176e-05  |
| time_elapsed            | 1280          |
| total timesteps         | 249378        |
| value_loss              | 4.827557e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009987052  |
| ent_coef_loss           | 0.08739042    |
| entropy                 | 1.2174962     |
| episodes                | 968           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 250109        |
| policy_loss             | -0.48806185   |
| qf1_loss                | 7.8567886e-05 |
| qf2_loss                | 6.986837e-05  |
| time_elapsed            | 1284          |
| total timesteps         | 250209        |
| value_loss              | 0.00014620116 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010254828  |
| ent_coef_loss           | 5.806849      |
| entropy                 | 1.404443      |
| episodes                | 972           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 250768        |
| policy_loss             | -0.546464     |
| qf1_loss                | 4.9393948e-05 |
| qf2_loss                | 5.603568e-05  |
| time_elapsed            | 1288          |
| total timesteps         | 250868        |
| value_loss              | 4.5531895e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010305962  |
| ent_coef_loss           | -0.39754623   |
| entropy                 | 1.2743857     |
| episodes                | 976           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 251482        |
| policy_loss             | -0.50979626   |
| qf1_loss                | 5.912276e-05  |
| qf2_loss                | 6.7849505e-05 |
| time_elapsed            | 1291          |
| total timesteps         | 251582        |
| value_loss              | 4.1025865e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010380143  |
| ent_coef_loss           | -0.5477474    |
| entropy                 | 1.313504      |
| episodes                | 980           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 252182        |
| policy_loss             | -0.53141046   |
| qf1_loss                | 7.597702e-05  |
| qf2_loss                | 6.0313563e-05 |
| time_elapsed            | 1295          |
| total timesteps         | 252282        |
| value_loss              | 3.615406e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0010579983   |
| ent_coef_loss           | -0.1071434     |
| entropy                 | 1.1176693      |
| episodes                | 984            |
| fps                     | 194            |
| mean 100 episode reward | 0.9            |
| n_updates               | 252893         |
| policy_loss             | -0.532673      |
| qf1_loss                | 0.000101844635 |
| qf2_loss                | 0.00013114657  |
| time_elapsed            | 1299           |
| total timesteps         | 252993         |
| value_loss              | 0.00015048808  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011152853  |
| ent_coef_loss           | -2.5901492    |
| entropy                 | 1.2986987     |
| episodes                | 988           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 253627        |
| policy_loss             | -0.5481786    |
| qf1_loss                | 7.308283e-05  |
| qf2_loss                | 6.0708295e-05 |
| time_elapsed            | 1302          |
| total timesteps         | 253727        |
| value_loss              | 3.5672743e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010622212  |
| ent_coef_loss           | 0.1389615     |
| entropy                 | 1.2411662     |
| episodes                | 992           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 254400        |
| policy_loss             | -0.51950336   |
| qf1_loss                | 3.5391404e-05 |
| qf2_loss                | 5.4609496e-05 |
| time_elapsed            | 1306          |
| total timesteps         | 254500        |
| value_loss              | 0.00012721488 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001134031   |
| ent_coef_loss           | -0.61323595   |
| entropy                 | 1.1648018     |
| episodes                | 996           |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 255160        |
| policy_loss             | -0.5542159    |
| qf1_loss                | 3.9386825e-05 |
| qf2_loss                | 2.4890134e-05 |
| time_elapsed            | 1310          |
| total timesteps         | 255260        |
| value_loss              | 6.616975e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011137022  |
| ent_coef_loss           | -3.2228441    |
| entropy                 | 1.2476145     |
| episodes                | 1000          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 255873        |
| policy_loss             | -0.5350648    |
| qf1_loss                | 5.09366e-05   |
| qf2_loss                | 3.9567636e-05 |
| time_elapsed            | 1314          |
| total timesteps         | 255973        |
| value_loss              | 8.040439e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011226491  |
| ent_coef_loss           | -0.16854429   |
| entropy                 | 1.2282255     |
| episodes                | 1004          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 256564        |
| policy_loss             | -0.55375284   |
| qf1_loss                | 5.0975425e-05 |
| qf2_loss                | 5.6150704e-05 |
| time_elapsed            | 1318          |
| total timesteps         | 256664        |
| value_loss              | 0.0001509128  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0010794568   |
| ent_coef_loss           | -0.07034373    |
| entropy                 | 1.2647405      |
| episodes                | 1008           |
| fps                     | 194            |
| mean 100 episode reward | 0.9            |
| n_updates               | 257296         |
| policy_loss             | -0.52301234    |
| qf1_loss                | 3.124455e-05   |
| qf2_loss                | 4.120402e-05   |
| time_elapsed            | 1321           |
| total timesteps         | 257396         |
| value_loss              | 0.000114773764 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011123769  |
| ent_coef_loss           | -1.5575243    |
| entropy                 | 1.4219819     |
| episodes                | 1012          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 258002        |
| policy_loss             | -0.53534395   |
| qf1_loss                | 2.6035414e-05 |
| qf2_loss                | 2.2782566e-05 |
| time_elapsed            | 1325          |
| total timesteps         | 258102        |
| value_loss              | 2.5458396e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011200584  |
| ent_coef_loss           | -4.0849576    |
| entropy                 | 1.2602539     |
| episodes                | 1016          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 258947        |
| policy_loss             | -0.5689065    |
| qf1_loss                | 4.4137018e-05 |
| qf2_loss                | 3.4710807e-05 |
| time_elapsed            | 1330          |
| total timesteps         | 259047        |
| value_loss              | 6.4136984e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001044426   |
| ent_coef_loss           | -0.8866274    |
| entropy                 | 1.4888091     |
| episodes                | 1020          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 259625        |
| policy_loss             | -0.59159      |
| qf1_loss                | 1.999666e-05  |
| qf2_loss                | 1.9373168e-05 |
| time_elapsed            | 1333          |
| total timesteps         | 259725        |
| value_loss              | 3.603538e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011119351  |
| ent_coef_loss           | -2.161222     |
| entropy                 | 1.3027728     |
| episodes                | 1024          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 260477        |
| policy_loss             | -0.48323408   |
| qf1_loss                | 2.3572413e-05 |
| qf2_loss                | 3.2657284e-05 |
| time_elapsed            | 1338          |
| total timesteps         | 260577        |
| value_loss              | 0.00011030269 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011400438  |
| ent_coef_loss           | 3.1093392     |
| entropy                 | 1.4650754     |
| episodes                | 1028          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 261293        |
| policy_loss             | -0.5209708    |
| qf1_loss                | 3.9709717e-05 |
| qf2_loss                | 4.7806967e-05 |
| time_elapsed            | 1342          |
| total timesteps         | 261393        |
| value_loss              | 5.5291697e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011701541  |
| ent_coef_loss           | -3.1731205    |
| entropy                 | 1.4988091     |
| episodes                | 1032          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 261971        |
| policy_loss             | -0.5538579    |
| qf1_loss                | 5.433726e-05  |
| qf2_loss                | 3.8709346e-05 |
| time_elapsed            | 1345          |
| total timesteps         | 262071        |
| value_loss              | 3.7813e-05    |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011426349  |
| ent_coef_loss           | -1.5631244    |
| entropy                 | 1.351527      |
| episodes                | 1036          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 262709        |
| policy_loss             | -0.5149787    |
| qf1_loss                | 1.8815012e-05 |
| qf2_loss                | 1.5855261e-05 |
| time_elapsed            | 1349          |
| total timesteps         | 262809        |
| value_loss              | 4.346365e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011455896  |
| ent_coef_loss           | 1.4970043     |
| entropy                 | 1.4001381     |
| episodes                | 1040          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 263944        |
| policy_loss             | -0.5366358    |
| qf1_loss                | 1.5846319e-05 |
| qf2_loss                | 2.977649e-05  |
| time_elapsed            | 1355          |
| total timesteps         | 264044        |
| value_loss              | 3.8470353e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011461333  |
| ent_coef_loss           | -1.027668     |
| entropy                 | 1.3588686     |
| episodes                | 1044          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 264643        |
| policy_loss             | -0.5522302    |
| qf1_loss                | 0.00013780392 |
| qf2_loss                | 0.00014194021 |
| time_elapsed            | 1359          |
| total timesteps         | 264743        |
| value_loss              | 3.406249e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001163057   |
| ent_coef_loss           | 0.8051596     |
| entropy                 | 1.388834      |
| episodes                | 1048          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 265360        |
| policy_loss             | -0.5029428    |
| qf1_loss                | 3.398991e-05  |
| qf2_loss                | 2.7914093e-05 |
| time_elapsed            | 1363          |
| total timesteps         | 265460        |
| value_loss              | 4.919864e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011260696  |
| ent_coef_loss           | -0.74879456   |
| entropy                 | 1.3778052     |
| episodes                | 1052          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 266033        |
| policy_loss             | -0.5640434    |
| qf1_loss                | 2.127259e-05  |
| qf2_loss                | 2.6646676e-05 |
| time_elapsed            | 1366          |
| total timesteps         | 266133        |
| value_loss              | 4.3345506e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011528274  |
| ent_coef_loss           | -0.18378244   |
| entropy                 | 1.3627111     |
| episodes                | 1056          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 267038        |
| policy_loss             | -0.5026844    |
| qf1_loss                | 4.5241555e-05 |
| qf2_loss                | 3.6755955e-05 |
| time_elapsed            | 1371          |
| total timesteps         | 267138        |
| value_loss              | 5.3385134e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010991113  |
| ent_coef_loss           | -0.33120543   |
| entropy                 | 1.4772186     |
| episodes                | 1060          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 267743        |
| policy_loss             | -0.57440734   |
| qf1_loss                | 5.124078e-05  |
| qf2_loss                | 4.6990914e-05 |
| time_elapsed            | 1375          |
| total timesteps         | 267843        |
| value_loss              | 5.3677955e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0011542124 |
| ent_coef_loss           | -2.230803    |
| entropy                 | 1.3348224    |
| episodes                | 1064         |
| fps                     | 194          |
| mean 100 episode reward | 0.8          |
| n_updates               | 268697       |
| policy_loss             | -0.5206378   |
| qf1_loss                | 6.637071e-05 |
| qf2_loss                | 6.890571e-05 |
| time_elapsed            | 1380         |
| total timesteps         | 268797       |
| value_loss              | 7.83773e-05  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011372244  |
| ent_coef_loss           | -1.3563893    |
| entropy                 | 1.5217168     |
| episodes                | 1068          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 269479        |
| policy_loss             | -0.5607277    |
| qf1_loss                | 2.8617502e-05 |
| qf2_loss                | 2.072522e-05  |
| time_elapsed            | 1384          |
| total timesteps         | 269579        |
| value_loss              | 5.242887e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011526971  |
| ent_coef_loss           | -1.7454827    |
| entropy                 | 1.1539422     |
| episodes                | 1072          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 270188        |
| policy_loss             | -0.54969525   |
| qf1_loss                | 4.434309e-05  |
| qf2_loss                | 6.6977016e-05 |
| time_elapsed            | 1387          |
| total timesteps         | 270288        |
| value_loss              | 6.842561e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010884647  |
| ent_coef_loss           | 2.749889      |
| entropy                 | 1.2268343     |
| episodes                | 1076          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 270864        |
| policy_loss             | -0.49426776   |
| qf1_loss                | 4.5507448e-05 |
| qf2_loss                | 4.318481e-05  |
| time_elapsed            | 1391          |
| total timesteps         | 270964        |
| value_loss              | 6.487047e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001236466   |
| ent_coef_loss           | -1.199425     |
| entropy                 | 1.4618158     |
| episodes                | 1080          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 271706        |
| policy_loss             | -0.47680396   |
| qf1_loss                | 4.4322016e-05 |
| qf2_loss                | 2.611949e-05  |
| time_elapsed            | 1395          |
| total timesteps         | 271806        |
| value_loss              | 4.7401812e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0011428376 |
| ent_coef_loss           | -0.04242623  |
| entropy                 | 1.3253295    |
| episodes                | 1084         |
| fps                     | 194          |
| mean 100 episode reward | 0.7          |
| n_updates               | 272471       |
| policy_loss             | -0.47793055  |
| qf1_loss                | 0.0001788181 |
| qf2_loss                | 0.0002528437 |
| time_elapsed            | 1399         |
| total timesteps         | 272571       |
| value_loss              | 7.90514e-05  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011381455  |
| ent_coef_loss           | 2.956173      |
| entropy                 | 1.4791142     |
| episodes                | 1088          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 273195        |
| policy_loss             | -0.43267447   |
| qf1_loss                | 0.0002094981  |
| qf2_loss                | 4.581295e-05  |
| time_elapsed            | 1403          |
| total timesteps         | 273295        |
| value_loss              | 0.00011030647 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011584935  |
| ent_coef_loss           | -2.5250833    |
| entropy                 | 1.4067338     |
| episodes                | 1092          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 273907        |
| policy_loss             | -0.54969263   |
| qf1_loss                | 3.3201944e-05 |
| qf2_loss                | 2.8337781e-05 |
| time_elapsed            | 1407          |
| total timesteps         | 274007        |
| value_loss              | 2.7236625e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011081855  |
| ent_coef_loss           | -1.8581058    |
| entropy                 | 1.3393846     |
| episodes                | 1096          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 274647        |
| policy_loss             | -0.5229852    |
| qf1_loss                | 6.91186e-05   |
| qf2_loss                | 3.2911998e-05 |
| time_elapsed            | 1411          |
| total timesteps         | 274747        |
| value_loss              | 1.93114e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001094559   |
| ent_coef_loss           | 1.204787      |
| entropy                 | 1.4161828     |
| episodes                | 1100          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 275339        |
| policy_loss             | -0.51507056   |
| qf1_loss                | 2.3154742e-05 |
| qf2_loss                | 2.4663263e-05 |
| time_elapsed            | 1414          |
| total timesteps         | 275439        |
| value_loss              | 2.035963e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0010431394   |
| ent_coef_loss           | -0.02972722    |
| entropy                 | 1.4140805      |
| episodes                | 1104           |
| fps                     | 194            |
| mean 100 episode reward | 0.7            |
| n_updates               | 276154         |
| policy_loss             | -0.53124547    |
| qf1_loss                | 8.866415e-05   |
| qf2_loss                | 0.000110302775 |
| time_elapsed            | 1418           |
| total timesteps         | 276254         |
| value_loss              | 0.00011233598  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011277939  |
| ent_coef_loss           | -0.28879058   |
| entropy                 | 1.2592475     |
| episodes                | 1108          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 276828        |
| policy_loss             | -0.52057564   |
| qf1_loss                | 7.888982e-05  |
| qf2_loss                | 7.230748e-05  |
| time_elapsed            | 1422          |
| total timesteps         | 276928        |
| value_loss              | 2.9370574e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010200159  |
| ent_coef_loss           | 1.6942072     |
| entropy                 | 1.2635844     |
| episodes                | 1112          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 277585        |
| policy_loss             | -0.48515975   |
| qf1_loss                | 5.7472374e-05 |
| qf2_loss                | 3.197356e-05  |
| time_elapsed            | 1426          |
| total timesteps         | 277685        |
| value_loss              | 9.396637e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001088281   |
| ent_coef_loss           | -0.048256874  |
| entropy                 | 1.4225271     |
| episodes                | 1116          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 278566        |
| policy_loss             | -0.49783522   |
| qf1_loss                | 1.960275e-05  |
| qf2_loss                | 2.3008504e-05 |
| time_elapsed            | 1431          |
| total timesteps         | 278666        |
| value_loss              | 5.1379513e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011524146  |
| ent_coef_loss           | -0.965178     |
| entropy                 | 1.3926787     |
| episodes                | 1120          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 279547        |
| policy_loss             | -0.5025058    |
| qf1_loss                | 4.4542325e-05 |
| qf2_loss                | 3.5110417e-05 |
| time_elapsed            | 1436          |
| total timesteps         | 279647        |
| value_loss              | 4.9942653e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001229967   |
| ent_coef_loss           | 1.3062463     |
| entropy                 | 1.466296      |
| episodes                | 1124          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 280524        |
| policy_loss             | -0.49959505   |
| qf1_loss                | 5.590568e-05  |
| qf2_loss                | 4.5548506e-05 |
| time_elapsed            | 1441          |
| total timesteps         | 280624        |
| value_loss              | 4.6138794e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011642305  |
| ent_coef_loss           | -2.2792425    |
| entropy                 | 1.4170588     |
| episodes                | 1128          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 281268        |
| policy_loss             | -0.4842074    |
| qf1_loss                | 4.3538894e-05 |
| qf2_loss                | 3.271889e-05  |
| time_elapsed            | 1445          |
| total timesteps         | 281368        |
| value_loss              | 4.8352624e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011509572  |
| ent_coef_loss           | -2.451509     |
| entropy                 | 1.356286      |
| episodes                | 1132          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 282217        |
| policy_loss             | -0.5461534    |
| qf1_loss                | 4.8581387e-05 |
| qf2_loss                | 5.270477e-05  |
| time_elapsed            | 1450          |
| total timesteps         | 282317        |
| value_loss              | 4.8465154e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010501825  |
| ent_coef_loss           | -2.2954526    |
| entropy                 | 1.2455437     |
| episodes                | 1136          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 283171        |
| policy_loss             | -0.5045773    |
| qf1_loss                | 2.8334713e-05 |
| qf2_loss                | 2.601437e-05  |
| time_elapsed            | 1455          |
| total timesteps         | 283271        |
| value_loss              | 6.461825e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010933487  |
| ent_coef_loss           | 2.673254      |
| entropy                 | 1.3244356     |
| episodes                | 1140          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 283903        |
| policy_loss             | -0.5036093    |
| qf1_loss                | 0.00011929163 |
| qf2_loss                | 6.8640256e-05 |
| time_elapsed            | 1458          |
| total timesteps         | 284003        |
| value_loss              | 6.600827e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0011955182 |
| ent_coef_loss           | 1.0819526    |
| entropy                 | 1.465049     |
| episodes                | 1144         |
| fps                     | 194          |
| mean 100 episode reward | 0.7          |
| n_updates               | 284605       |
| policy_loss             | -0.56029016  |
| qf1_loss                | 3.94491e-05  |
| qf2_loss                | 7.103865e-05 |
| time_elapsed            | 1462         |
| total timesteps         | 284705       |
| value_loss              | 5.556193e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011666697  |
| ent_coef_loss           | -0.5148991    |
| entropy                 | 1.205358      |
| episodes                | 1148          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 285293        |
| policy_loss             | -0.48797864   |
| qf1_loss                | 0.00013419875 |
| qf2_loss                | 0.00013405226 |
| time_elapsed            | 1465          |
| total timesteps         | 285393        |
| value_loss              | 0.00010340332 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011747053  |
| ent_coef_loss           | 0.13664284    |
| entropy                 | 1.3844594     |
| episodes                | 1152          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 286074        |
| policy_loss             | -0.53992635   |
| qf1_loss                | 2.116112e-05  |
| qf2_loss                | 3.8757025e-05 |
| time_elapsed            | 1469          |
| total timesteps         | 286174        |
| value_loss              | 4.7036672e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012280341  |
| ent_coef_loss           | 2.326822      |
| entropy                 | 1.5508374     |
| episodes                | 1156          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 286733        |
| policy_loss             | -0.48354304   |
| qf1_loss                | 3.5128112e-05 |
| qf2_loss                | 3.762875e-05  |
| time_elapsed            | 1473          |
| total timesteps         | 286833        |
| value_loss              | 3.5922778e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011200899  |
| ent_coef_loss           | -0.7278079    |
| entropy                 | 1.3368092     |
| episodes                | 1160          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 287482        |
| policy_loss             | -0.57244223   |
| qf1_loss                | 4.1280808e-05 |
| qf2_loss                | 3.8890972e-05 |
| time_elapsed            | 1477          |
| total timesteps         | 287582        |
| value_loss              | 3.660294e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010668125  |
| ent_coef_loss           | 0.2067945     |
| entropy                 | 1.3755112     |
| episodes                | 1164          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 288220        |
| policy_loss             | -0.52457595   |
| qf1_loss                | 2.4848974e-05 |
| qf2_loss                | 1.8413006e-05 |
| time_elapsed            | 1480          |
| total timesteps         | 288320        |
| value_loss              | 1.8826984e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012140896  |
| ent_coef_loss           | 0.5398973     |
| entropy                 | 1.4424167     |
| episodes                | 1168          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 288945        |
| policy_loss             | -0.5718828    |
| qf1_loss                | 3.6842444e-05 |
| qf2_loss                | 2.1314449e-05 |
| time_elapsed            | 1484          |
| total timesteps         | 289045        |
| value_loss              | 4.6643476e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011869563  |
| ent_coef_loss           | 2.205768      |
| entropy                 | 1.4015448     |
| episodes                | 1172          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 289688        |
| policy_loss             | -0.45671445   |
| qf1_loss                | 2.8111137e-05 |
| qf2_loss                | 3.4506327e-05 |
| time_elapsed            | 1488          |
| total timesteps         | 289788        |
| value_loss              | 5.892684e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011355808  |
| ent_coef_loss           | 0.46045652    |
| entropy                 | 1.2902939     |
| episodes                | 1176          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 290447        |
| policy_loss             | -0.56469774   |
| qf1_loss                | 2.3439805e-05 |
| qf2_loss                | 1.6311267e-05 |
| time_elapsed            | 1492          |
| total timesteps         | 290547        |
| value_loss              | 4.5540124e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001093173   |
| ent_coef_loss           | -2.2379465    |
| entropy                 | 1.4279221     |
| episodes                | 1180          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 291212        |
| policy_loss             | -0.4963454    |
| qf1_loss                | 5.2321255e-05 |
| qf2_loss                | 5.03571e-05   |
| time_elapsed            | 1496          |
| total timesteps         | 291312        |
| value_loss              | 0.00013841208 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010953192  |
| ent_coef_loss           | -0.8421122    |
| entropy                 | 1.2777009     |
| episodes                | 1184          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 291916        |
| policy_loss             | -0.5019671    |
| qf1_loss                | 7.108344e-05  |
| qf2_loss                | 7.57275e-05   |
| time_elapsed            | 1500          |
| total timesteps         | 292016        |
| value_loss              | 4.2659536e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011063596  |
| ent_coef_loss           | 0.5931352     |
| entropy                 | 1.2676059     |
| episodes                | 1188          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 292628        |
| policy_loss             | -0.5338501    |
| qf1_loss                | 0.00014972335 |
| qf2_loss                | 5.0609742e-05 |
| time_elapsed            | 1503          |
| total timesteps         | 292728        |
| value_loss              | 0.00014237592 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0011820582 |
| ent_coef_loss           | 1.4416481    |
| entropy                 | 1.3053241    |
| episodes                | 1192         |
| fps                     | 194          |
| mean 100 episode reward | 0.9          |
| n_updates               | 293337       |
| policy_loss             | -0.5266074   |
| qf1_loss                | 6.197251e-05 |
| qf2_loss                | 6.463288e-05 |
| time_elapsed            | 1507         |
| total timesteps         | 293437       |
| value_loss              | 3.933905e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012124118  |
| ent_coef_loss           | 0.90286446    |
| entropy                 | 1.3598597     |
| episodes                | 1196          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 294034        |
| policy_loss             | -0.606611     |
| qf1_loss                | 7.3456926e-05 |
| qf2_loss                | 7.064367e-05  |
| time_elapsed            | 1510          |
| total timesteps         | 294134        |
| value_loss              | 3.077079e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011875734  |
| ent_coef_loss           | 2.548994      |
| entropy                 | 1.3575389     |
| episodes                | 1200          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 294695        |
| policy_loss             | -0.50025284   |
| qf1_loss                | 0.0004166342  |
| qf2_loss                | 0.00020769869 |
| time_elapsed            | 1514          |
| total timesteps         | 294795        |
| value_loss              | 8.476917e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011442248  |
| ent_coef_loss           | -0.86669785   |
| entropy                 | 1.1734079     |
| episodes                | 1204          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 295412        |
| policy_loss             | -0.4921274    |
| qf1_loss                | 0.00014857206 |
| qf2_loss                | 5.599687e-05  |
| time_elapsed            | 1518          |
| total timesteps         | 295512        |
| value_loss              | 6.5323235e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011210945  |
| ent_coef_loss           | -1.7679956    |
| entropy                 | 1.3356137     |
| episodes                | 1208          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 296150        |
| policy_loss             | -0.5599077    |
| qf1_loss                | 7.400832e-05  |
| qf2_loss                | 0.00014716349 |
| time_elapsed            | 1522          |
| total timesteps         | 296250        |
| value_loss              | 3.7564976e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010519912  |
| ent_coef_loss           | -0.7774949    |
| entropy                 | 1.2059113     |
| episodes                | 1212          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 297149        |
| policy_loss             | -0.56503046   |
| qf1_loss                | 3.8851285e-05 |
| qf2_loss                | 3.372087e-05  |
| time_elapsed            | 1527          |
| total timesteps         | 297249        |
| value_loss              | 9.6585885e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011523168  |
| ent_coef_loss           | 1.0540626     |
| entropy                 | 1.0473447     |
| episodes                | 1216          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 297823        |
| policy_loss             | -0.531029     |
| qf1_loss                | 0.00011963198 |
| qf2_loss                | 7.933509e-05  |
| time_elapsed            | 1530          |
| total timesteps         | 297923        |
| value_loss              | 7.7752564e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001160055   |
| ent_coef_loss           | -1.3590468    |
| entropy                 | 1.2750498     |
| episodes                | 1220          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 298502        |
| policy_loss             | -0.5258439    |
| qf1_loss                | 0.00011649257 |
| qf2_loss                | 0.00013490721 |
| time_elapsed            | 1534          |
| total timesteps         | 298602        |
| value_loss              | 5.371974e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011807181  |
| ent_coef_loss           | 1.8978814     |
| entropy                 | 1.2298894     |
| episodes                | 1224          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 299453        |
| policy_loss             | -0.55233693   |
| qf1_loss                | 0.00042125233 |
| qf2_loss                | 0.00039865696 |
| time_elapsed            | 1539          |
| total timesteps         | 299553        |
| value_loss              | 2.9486388e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012379426  |
| ent_coef_loss           | 0.12652215    |
| entropy                 | 1.3421621     |
| episodes                | 1228          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 300359        |
| policy_loss             | -0.55864644   |
| qf1_loss                | 6.2440544e-05 |
| qf2_loss                | 4.9422615e-05 |
| time_elapsed            | 1543          |
| total timesteps         | 300459        |
| value_loss              | 3.2008797e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011746762  |
| ent_coef_loss           | 1.051575      |
| entropy                 | 1.4117421     |
| episodes                | 1232          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 301059        |
| policy_loss             | -0.5483709    |
| qf1_loss                | 7.4361495e-05 |
| qf2_loss                | 7.600227e-05  |
| time_elapsed            | 1547          |
| total timesteps         | 301159        |
| value_loss              | 7.342388e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0012428227 |
| ent_coef_loss           | -1.2271535   |
| entropy                 | 1.3656017    |
| episodes                | 1236         |
| fps                     | 194          |
| mean 100 episode reward | 0.9          |
| n_updates               | 301964       |
| policy_loss             | -0.43566066  |
| qf1_loss                | 6.981303e-05 |
| qf2_loss                | 7.669727e-05 |
| time_elapsed            | 1552         |
| total timesteps         | 302064       |
| value_loss              | 9.412435e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001224311   |
| ent_coef_loss           | -1.424561     |
| entropy                 | 1.3037728     |
| episodes                | 1240          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 302727        |
| policy_loss             | -0.46241385   |
| qf1_loss                | 0.00011526366 |
| qf2_loss                | 0.00010422441 |
| time_elapsed            | 1556          |
| total timesteps         | 302827        |
| value_loss              | 9.165795e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011948104  |
| ent_coef_loss           | -2.2572165    |
| entropy                 | 1.3747773     |
| episodes                | 1244          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 303387        |
| policy_loss             | -0.4899109    |
| qf1_loss                | 0.0006389042  |
| qf2_loss                | 0.0007797922  |
| time_elapsed            | 1559          |
| total timesteps         | 303487        |
| value_loss              | 0.00011115438 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010922763  |
| ent_coef_loss           | 0.39801466    |
| entropy                 | 1.3825793     |
| episodes                | 1248          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 304414        |
| policy_loss             | -0.53023434   |
| qf1_loss                | 5.9800517e-05 |
| qf2_loss                | 3.400875e-05  |
| time_elapsed            | 1564          |
| total timesteps         | 304514        |
| value_loss              | 0.00010685537 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010996355  |
| ent_coef_loss           | -3.9579453    |
| entropy                 | 1.4008642     |
| episodes                | 1252          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 305203        |
| policy_loss             | -0.5403104    |
| qf1_loss                | 3.7212012e-05 |
| qf2_loss                | 4.1086718e-05 |
| time_elapsed            | 1568          |
| total timesteps         | 305303        |
| value_loss              | 7.8438636e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009675994  |
| ent_coef_loss           | -1.9542046    |
| entropy                 | 1.1599901     |
| episodes                | 1256          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 305993        |
| policy_loss             | -0.49634528   |
| qf1_loss                | 2.4585292e-05 |
| qf2_loss                | 2.7814243e-05 |
| time_elapsed            | 1572          |
| total timesteps         | 306093        |
| value_loss              | 2.779971e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.001078092  |
| ent_coef_loss           | -2.194049    |
| entropy                 | 1.3729664    |
| episodes                | 1260         |
| fps                     | 194          |
| mean 100 episode reward | 0.9          |
| n_updates               | 306785       |
| policy_loss             | -0.5074746   |
| qf1_loss                | 2.950623e-05 |
| qf2_loss                | 2.381573e-05 |
| time_elapsed            | 1576         |
| total timesteps         | 306885       |
| value_loss              | 3.099347e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011197481  |
| ent_coef_loss           | 4.9888954     |
| entropy                 | 1.354605      |
| episodes                | 1264          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 307502        |
| policy_loss             | -0.56476986   |
| qf1_loss                | 0.00012299517 |
| qf2_loss                | 0.00010865602 |
| time_elapsed            | 1580          |
| total timesteps         | 307602        |
| value_loss              | 0.00014712354 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010997566  |
| ent_coef_loss           | 3.0975933     |
| entropy                 | 1.3032585     |
| episodes                | 1268          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 308280        |
| policy_loss             | -0.5020727    |
| qf1_loss                | 8.861449e-05  |
| qf2_loss                | 9.429792e-05  |
| time_elapsed            | 1584          |
| total timesteps         | 308380        |
| value_loss              | 5.8305737e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011012338  |
| ent_coef_loss           | 1.338388      |
| entropy                 | 1.2842491     |
| episodes                | 1272          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 309035        |
| policy_loss             | -0.53973454   |
| qf1_loss                | 5.80408e-05   |
| qf2_loss                | 5.222859e-05  |
| time_elapsed            | 1588          |
| total timesteps         | 309135        |
| value_loss              | 6.2230145e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011378969  |
| ent_coef_loss           | 0.3300755     |
| entropy                 | 1.3989015     |
| episodes                | 1276          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 309703        |
| policy_loss             | -0.5147251    |
| qf1_loss                | 5.4049277e-05 |
| qf2_loss                | 5.7046782e-05 |
| time_elapsed            | 1591          |
| total timesteps         | 309803        |
| value_loss              | 0.00010866144 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010456095  |
| ent_coef_loss           | 1.854333      |
| entropy                 | 1.4717219     |
| episodes                | 1280          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 310421        |
| policy_loss             | -0.4608333    |
| qf1_loss                | 3.725481e-05  |
| qf2_loss                | 3.8643946e-05 |
| time_elapsed            | 1595          |
| total timesteps         | 310521        |
| value_loss              | 6.682277e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010792153  |
| ent_coef_loss           | 4.3466015     |
| entropy                 | 1.4762859     |
| episodes                | 1284          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 311086        |
| policy_loss             | -0.5256711    |
| qf1_loss                | 2.9181194e-05 |
| qf2_loss                | 2.6763551e-05 |
| time_elapsed            | 1599          |
| total timesteps         | 311186        |
| value_loss              | 3.1904885e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009852487  |
| ent_coef_loss           | -1.7633862    |
| entropy                 | 1.2247006     |
| episodes                | 1288          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 311813        |
| policy_loss             | -0.5065606    |
| qf1_loss                | 0.00016723905 |
| qf2_loss                | 9.3135306e-05 |
| time_elapsed            | 1602          |
| total timesteps         | 311913        |
| value_loss              | 8.4589024e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009733496  |
| ent_coef_loss           | 1.1456095     |
| entropy                 | 1.3935364     |
| episodes                | 1292          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 312599        |
| policy_loss             | -0.5609193    |
| qf1_loss                | 1.9983445e-05 |
| qf2_loss                | 2.241139e-05  |
| time_elapsed            | 1607          |
| total timesteps         | 312699        |
| value_loss              | 5.046053e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010287353  |
| ent_coef_loss           | -1.5390823    |
| entropy                 | 1.2175333     |
| episodes                | 1296          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 313269        |
| policy_loss             | -0.49571067   |
| qf1_loss                | 5.787575e-05  |
| qf2_loss                | 3.91502e-05   |
| time_elapsed            | 1610          |
| total timesteps         | 313369        |
| value_loss              | 3.1849777e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011102472  |
| ent_coef_loss           | -1.0764878    |
| entropy                 | 1.3748906     |
| episodes                | 1300          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 313941        |
| policy_loss             | -0.5408215    |
| qf1_loss                | 8.0606624e-05 |
| qf2_loss                | 6.428488e-05  |
| time_elapsed            | 1614          |
| total timesteps         | 314041        |
| value_loss              | 3.38288e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001114481   |
| ent_coef_loss           | -1.5404314    |
| entropy                 | 1.2341484     |
| episodes                | 1304          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 314642        |
| policy_loss             | -0.47701925   |
| qf1_loss                | 0.00029292915 |
| qf2_loss                | 0.0002312832  |
| time_elapsed            | 1617          |
| total timesteps         | 314742        |
| value_loss              | 3.1145253e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010897532  |
| ent_coef_loss           | -0.30768174   |
| entropy                 | 1.2572341     |
| episodes                | 1308          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 315396        |
| policy_loss             | -0.5300962    |
| qf1_loss                | 7.107746e-05  |
| qf2_loss                | 7.3088806e-05 |
| time_elapsed            | 1621          |
| total timesteps         | 315496        |
| value_loss              | 8.184733e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001243505   |
| ent_coef_loss           | -0.6836641    |
| entropy                 | 1.3529537     |
| episodes                | 1312          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 316372        |
| policy_loss             | -0.5420748    |
| qf1_loss                | 0.00010539417 |
| qf2_loss                | 7.859391e-05  |
| time_elapsed            | 1626          |
| total timesteps         | 316472        |
| value_loss              | 2.8785043e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012704089  |
| ent_coef_loss           | 1.6849277     |
| entropy                 | 1.414061      |
| episodes                | 1316          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 317104        |
| policy_loss             | -0.48500514   |
| qf1_loss                | 1.8013558e-05 |
| qf2_loss                | 2.909854e-05  |
| time_elapsed            | 1630          |
| total timesteps         | 317204        |
| value_loss              | 2.6959917e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013143691  |
| ent_coef_loss           | -0.6686484    |
| entropy                 | 1.4560488     |
| episodes                | 1320          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 317921        |
| policy_loss             | -0.47854453   |
| qf1_loss                | 5.290818e-05  |
| qf2_loss                | 3.2841825e-05 |
| time_elapsed            | 1634          |
| total timesteps         | 318021        |
| value_loss              | 3.2463366e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011823829  |
| ent_coef_loss           | 2.117546      |
| entropy                 | 1.2245634     |
| episodes                | 1324          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 318675        |
| policy_loss             | -0.49966764   |
| qf1_loss                | 4.9025544e-05 |
| qf2_loss                | 3.965952e-05  |
| time_elapsed            | 1638          |
| total timesteps         | 318775        |
| value_loss              | 9.557436e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001210229   |
| ent_coef_loss           | -0.21839881   |
| entropy                 | 1.2820284     |
| episodes                | 1328          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 319319        |
| policy_loss             | -0.5118327    |
| qf1_loss                | 2.9959323e-05 |
| qf2_loss                | 3.9888324e-05 |
| time_elapsed            | 1641          |
| total timesteps         | 319419        |
| value_loss              | 7.936935e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0012179583   |
| ent_coef_loss           | 2.8454204      |
| entropy                 | 1.3207327      |
| episodes                | 1332           |
| fps                     | 194            |
| mean 100 episode reward | 0.8            |
| n_updates               | 320010         |
| policy_loss             | -0.5025866     |
| qf1_loss                | 0.00013064385  |
| qf2_loss                | 0.000105598556 |
| time_elapsed            | 1645           |
| total timesteps         | 320110         |
| value_loss              | 0.00011122774  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012130814  |
| ent_coef_loss           | -3.2172844    |
| entropy                 | 1.3520124     |
| episodes                | 1336          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 320743        |
| policy_loss             | -0.52390075   |
| qf1_loss                | 2.9603054e-05 |
| qf2_loss                | 3.004733e-05  |
| time_elapsed            | 1649          |
| total timesteps         | 320843        |
| value_loss              | 3.6946796e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011667581  |
| ent_coef_loss           | 1.8295043     |
| entropy                 | 1.3090963     |
| episodes                | 1340          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 321483        |
| policy_loss             | -0.52229124   |
| qf1_loss                | 2.2509208e-05 |
| qf2_loss                | 3.292411e-05  |
| time_elapsed            | 1652          |
| total timesteps         | 321583        |
| value_loss              | 4.2385527e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011294225  |
| ent_coef_loss           | 2.4605284     |
| entropy                 | 1.295023      |
| episodes                | 1344          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 322199        |
| policy_loss             | -0.5540837    |
| qf1_loss                | 3.478536e-05  |
| qf2_loss                | 2.5314706e-05 |
| time_elapsed            | 1656          |
| total timesteps         | 322299        |
| value_loss              | 3.8447753e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010843344  |
| ent_coef_loss           | 3.516995      |
| entropy                 | 1.2358317     |
| episodes                | 1348          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 322854        |
| policy_loss             | -0.5422965    |
| qf1_loss                | 2.0053552e-05 |
| qf2_loss                | 2.2816143e-05 |
| time_elapsed            | 1659          |
| total timesteps         | 322954        |
| value_loss              | 4.247995e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011160381  |
| ent_coef_loss           | -1.9360908    |
| entropy                 | 1.3361695     |
| episodes                | 1352          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 323793        |
| policy_loss             | -0.54085314   |
| qf1_loss                | 0.00024384365 |
| qf2_loss                | 0.0001987491  |
| time_elapsed            | 1664          |
| total timesteps         | 323893        |
| value_loss              | 8.8707675e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011265626  |
| ent_coef_loss           | -0.67806137   |
| entropy                 | 1.2631009     |
| episodes                | 1356          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 324780        |
| policy_loss             | -0.5318264    |
| qf1_loss                | 1.5331854e-05 |
| qf2_loss                | 2.0122368e-05 |
| time_elapsed            | 1669          |
| total timesteps         | 324880        |
| value_loss              | 3.407026e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001111641   |
| ent_coef_loss           | 5.487793      |
| entropy                 | 1.2225596     |
| episodes                | 1360          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 325445        |
| policy_loss             | -0.5476355    |
| qf1_loss                | 5.2595937e-05 |
| qf2_loss                | 3.5630605e-05 |
| time_elapsed            | 1673          |
| total timesteps         | 325545        |
| value_loss              | 3.571022e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010636252  |
| ent_coef_loss           | -0.19750667   |
| entropy                 | 1.1848714     |
| episodes                | 1364          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 326139        |
| policy_loss             | -0.52721304   |
| qf1_loss                | 9.6684256e-05 |
| qf2_loss                | 0.00046095988 |
| time_elapsed            | 1676          |
| total timesteps         | 326239        |
| value_loss              | 3.0621406e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010694055  |
| ent_coef_loss           | -3.103218     |
| entropy                 | 1.2837908     |
| episodes                | 1368          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 326788        |
| policy_loss             | -0.55169415   |
| qf1_loss                | 2.1505013e-05 |
| qf2_loss                | 1.884362e-05  |
| time_elapsed            | 1680          |
| total timesteps         | 326888        |
| value_loss              | 2.2397624e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010064306  |
| ent_coef_loss           | -1.155034     |
| entropy                 | 1.3291835     |
| episodes                | 1372          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 327441        |
| policy_loss             | -0.54841244   |
| qf1_loss                | 2.5532576e-05 |
| qf2_loss                | 1.9905157e-05 |
| time_elapsed            | 1683          |
| total timesteps         | 327541        |
| value_loss              | 4.4423246e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010245981  |
| ent_coef_loss           | 0.17012465    |
| entropy                 | 1.2133024     |
| episodes                | 1376          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 328179        |
| policy_loss             | -0.5310024    |
| qf1_loss                | 5.9077876e-05 |
| qf2_loss                | 5.7399822e-05 |
| time_elapsed            | 1687          |
| total timesteps         | 328279        |
| value_loss              | 3.931288e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010534013  |
| ent_coef_loss           | 2.2965736     |
| entropy                 | 1.3878994     |
| episodes                | 1380          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 328926        |
| policy_loss             | -0.52789545   |
| qf1_loss                | 3.959023e-05  |
| qf2_loss                | 4.1177314e-05 |
| time_elapsed            | 1691          |
| total timesteps         | 329026        |
| value_loss              | 9.7071534e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010456204  |
| ent_coef_loss           | -2.9880033    |
| entropy                 | 1.2858365     |
| episodes                | 1384          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 329672        |
| policy_loss             | -0.56011546   |
| qf1_loss                | 1.779975e-05  |
| qf2_loss                | 1.6139162e-05 |
| time_elapsed            | 1695          |
| total timesteps         | 329772        |
| value_loss              | 2.9002664e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010577814  |
| ent_coef_loss           | -0.24958998   |
| entropy                 | 1.3001411     |
| episodes                | 1388          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 330467        |
| policy_loss             | -0.5295929    |
| qf1_loss                | 3.7885882e-05 |
| qf2_loss                | 4.84475e-05   |
| time_elapsed            | 1699          |
| total timesteps         | 330567        |
| value_loss              | 0.00011606613 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009965702   |
| ent_coef_loss           | -2.0612206     |
| entropy                 | 1.3709259      |
| episodes                | 1392           |
| fps                     | 194            |
| mean 100 episode reward | 0.8            |
| n_updates               | 331208         |
| policy_loss             | -0.5442372     |
| qf1_loss                | 2.7967693e-05  |
| qf2_loss                | 1.21551975e-05 |
| time_elapsed            | 1702           |
| total timesteps         | 331308         |
| value_loss              | 4.0414365e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094281096 |
| ent_coef_loss           | 5.190916      |
| entropy                 | 1.2499436     |
| episodes                | 1396          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 331948        |
| policy_loss             | -0.579058     |
| qf1_loss                | 6.876493e-05  |
| qf2_loss                | 5.1442843e-05 |
| time_elapsed            | 1706          |
| total timesteps         | 332048        |
| value_loss              | 8.210109e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009824015  |
| ent_coef_loss           | -0.38641495   |
| entropy                 | 1.3074839     |
| episodes                | 1400          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 332830        |
| policy_loss             | -0.5379656    |
| qf1_loss                | 5.3542408e-05 |
| qf2_loss                | 5.6419467e-05 |
| time_elapsed            | 1711          |
| total timesteps         | 332930        |
| value_loss              | 3.0043266e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009649376  |
| ent_coef_loss           | -0.68563175   |
| entropy                 | 1.1939794     |
| episodes                | 1404          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 333500        |
| policy_loss             | -0.5420201    |
| qf1_loss                | 0.00011715719 |
| qf2_loss                | 0.00012301587 |
| time_elapsed            | 1714          |
| total timesteps         | 333600        |
| value_loss              | 2.2338552e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009419823  |
| ent_coef_loss           | -0.88195384   |
| entropy                 | 1.2199416     |
| episodes                | 1408          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 334442        |
| policy_loss             | -0.5068426    |
| qf1_loss                | 3.0420748e-05 |
| qf2_loss                | 3.7698443e-05 |
| time_elapsed            | 1719          |
| total timesteps         | 334542        |
| value_loss              | 2.5868505e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091844297 |
| ent_coef_loss           | -1.1724628    |
| entropy                 | 1.3204772     |
| episodes                | 1412          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 335180        |
| policy_loss             | -0.5516615    |
| qf1_loss                | 1.3780085e-05 |
| qf2_loss                | 1.8951498e-05 |
| time_elapsed            | 1723          |
| total timesteps         | 335280        |
| value_loss              | 1.879804e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093281025 |
| ent_coef_loss           | -1.6993356    |
| entropy                 | 1.2054186     |
| episodes                | 1416          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 335925        |
| policy_loss             | -0.5398569    |
| qf1_loss                | 8.287743e-05  |
| qf2_loss                | 6.198735e-05  |
| time_elapsed            | 1727          |
| total timesteps         | 336025        |
| value_loss              | 1.484103e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091565837 |
| ent_coef_loss           | 0.45912504    |
| entropy                 | 1.2385396     |
| episodes                | 1420          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 336761        |
| policy_loss             | -0.49114266   |
| qf1_loss                | 2.499724e-05  |
| qf2_loss                | 9.031892e-05  |
| time_elapsed            | 1731          |
| total timesteps         | 336861        |
| value_loss              | 0.00017576807 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009891331  |
| ent_coef_loss           | 1.6982844     |
| entropy                 | 1.3572015     |
| episodes                | 1424          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 337426        |
| policy_loss             | -0.49084973   |
| qf1_loss                | 2.3643144e-05 |
| qf2_loss                | 2.9652252e-05 |
| time_elapsed            | 1735          |
| total timesteps         | 337526        |
| value_loss              | 2.624475e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009184421  |
| ent_coef_loss           | -0.018379271  |
| entropy                 | 1.4344571     |
| episodes                | 1428          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 338098        |
| policy_loss             | -0.56552386   |
| qf1_loss                | 2.4580457e-05 |
| qf2_loss                | 1.5578476e-05 |
| time_elapsed            | 1738          |
| total timesteps         | 338198        |
| value_loss              | 2.0215659e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092006876 |
| ent_coef_loss           | -4.4711084    |
| entropy                 | 1.2677033     |
| episodes                | 1432          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 338798        |
| policy_loss             | -0.5168959    |
| qf1_loss                | 0.00018105618 |
| qf2_loss                | 0.00011807196 |
| time_elapsed            | 1742          |
| total timesteps         | 338898        |
| value_loss              | 2.6091071e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009237799   |
| ent_coef_loss           | -2.0451384     |
| entropy                 | 1.1386886      |
| episodes                | 1436           |
| fps                     | 194            |
| mean 100 episode reward | 0.9            |
| n_updates               | 339566         |
| policy_loss             | -0.54824984    |
| qf1_loss                | 6.33599e-05    |
| qf2_loss                | 0.000121815785 |
| time_elapsed            | 1746           |
| total timesteps         | 339666         |
| value_loss              | 7.529462e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009308139  |
| ent_coef_loss           | 0.67418       |
| entropy                 | 1.3142874     |
| episodes                | 1440          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 340325        |
| policy_loss             | -0.5756804    |
| qf1_loss                | 4.2287e-05    |
| qf2_loss                | 3.1982647e-05 |
| time_elapsed            | 1749          |
| total timesteps         | 340425        |
| value_loss              | 2.2974487e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009600054  |
| ent_coef_loss           | 0.38181812    |
| entropy                 | 1.2366083     |
| episodes                | 1444          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 341289        |
| policy_loss             | -0.53108335   |
| qf1_loss                | 4.3978616e-05 |
| qf2_loss                | 3.6793914e-05 |
| time_elapsed            | 1754          |
| total timesteps         | 341389        |
| value_loss              | 7.982274e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008894832  |
| ent_coef_loss           | -2.9013865    |
| entropy                 | 1.2860146     |
| episodes                | 1448          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 342044        |
| policy_loss             | -0.5665847    |
| qf1_loss                | 2.5332874e-05 |
| qf2_loss                | 2.456062e-05  |
| time_elapsed            | 1758          |
| total timesteps         | 342144        |
| value_loss              | 1.7906925e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008967472  |
| ent_coef_loss           | 0.13966024    |
| entropy                 | 1.3119307     |
| episodes                | 1452          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 342780        |
| policy_loss             | -0.539829     |
| qf1_loss                | 3.798077e-05  |
| qf2_loss                | 5.8637946e-05 |
| time_elapsed            | 1762          |
| total timesteps         | 342880        |
| value_loss              | 8.073626e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010095875  |
| ent_coef_loss           | 3.3020153     |
| entropy                 | 1.2991936     |
| episodes                | 1456          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 343717        |
| policy_loss             | -0.48776197   |
| qf1_loss                | 5.066194e-05  |
| qf2_loss                | 5.5106964e-05 |
| time_elapsed            | 1767          |
| total timesteps         | 343817        |
| value_loss              | 4.5418543e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009406452   |
| ent_coef_loss           | -1.7934004     |
| entropy                 | 1.2550118      |
| episodes                | 1460           |
| fps                     | 194            |
| mean 100 episode reward | 0.9            |
| n_updates               | 344403         |
| policy_loss             | -0.56714886    |
| qf1_loss                | 0.000115934825 |
| qf2_loss                | 0.00010257657  |
| time_elapsed            | 1770           |
| total timesteps         | 344503         |
| value_loss              | 4.14208e-05    |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000951524   |
| ent_coef_loss           | 1.0127376     |
| entropy                 | 1.3993614     |
| episodes                | 1464          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 345381        |
| policy_loss             | -0.53719187   |
| qf1_loss                | 4.8897073e-05 |
| qf2_loss                | 4.5472647e-05 |
| time_elapsed            | 1775          |
| total timesteps         | 345481        |
| value_loss              | 4.1133695e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010376748  |
| ent_coef_loss           | 0.36521602    |
| entropy                 | 1.2861397     |
| episodes                | 1468          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 346350        |
| policy_loss             | -0.56281984   |
| qf1_loss                | 3.186881e-05  |
| qf2_loss                | 5.532043e-05  |
| time_elapsed            | 1780          |
| total timesteps         | 346450        |
| value_loss              | 3.7804926e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011103081  |
| ent_coef_loss           | -0.38964105   |
| entropy                 | 1.3522744     |
| episodes                | 1472          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 347033        |
| policy_loss             | -0.58626074   |
| qf1_loss                | 3.7647693e-05 |
| qf2_loss                | 2.0156236e-05 |
| time_elapsed            | 1784          |
| total timesteps         | 347133        |
| value_loss              | 2.3674867e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010889226  |
| ent_coef_loss           | -0.040193856  |
| entropy                 | 1.3235788     |
| episodes                | 1476          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 347758        |
| policy_loss             | -0.6008084    |
| qf1_loss                | 2.842721e-05  |
| qf2_loss                | 2.9035313e-05 |
| time_elapsed            | 1788          |
| total timesteps         | 347858        |
| value_loss              | 3.511747e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001045566   |
| ent_coef_loss           | 0.7361572     |
| entropy                 | 1.2509874     |
| episodes                | 1480          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 348464        |
| policy_loss             | -0.5418534    |
| qf1_loss                | 1.949137e-05  |
| qf2_loss                | 3.0074982e-05 |
| time_elapsed            | 1791          |
| total timesteps         | 348564        |
| value_loss              | 4.476299e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001105138   |
| ent_coef_loss           | 0.6057203     |
| entropy                 | 1.4236957     |
| episodes                | 1484          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 349171        |
| policy_loss             | -0.53153694   |
| qf1_loss                | 1.6215532e-05 |
| qf2_loss                | 1.6141745e-05 |
| time_elapsed            | 1795          |
| total timesteps         | 349271        |
| value_loss              | 3.7339432e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0010058256   |
| ent_coef_loss           | -0.07252568    |
| entropy                 | 1.3203222      |
| episodes                | 1488           |
| fps                     | 194            |
| mean 100 episode reward | 0.9            |
| n_updates               | 349864         |
| policy_loss             | -0.49824306    |
| qf1_loss                | 5.6956378e-05  |
| qf2_loss                | 0.000118551434 |
| time_elapsed            | 1799           |
| total timesteps         | 349964         |
| value_loss              | 0.0001270397   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010903889  |
| ent_coef_loss           | 3.2973356     |
| entropy                 | 1.2257608     |
| episodes                | 1492          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 350521        |
| policy_loss             | -0.5152488    |
| qf1_loss                | 5.335203e-05  |
| qf2_loss                | 2.4647381e-05 |
| time_elapsed            | 1802          |
| total timesteps         | 350621        |
| value_loss              | 6.420279e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010883978  |
| ent_coef_loss           | 0.7269677     |
| entropy                 | 1.4251331     |
| episodes                | 1496          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 351269        |
| policy_loss             | -0.5917469    |
| qf1_loss                | 2.3872466e-05 |
| qf2_loss                | 3.2146916e-05 |
| time_elapsed            | 1806          |
| total timesteps         | 351369        |
| value_loss              | 3.8748698e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011081321  |
| ent_coef_loss           | -1.7244041    |
| entropy                 | 1.3912668     |
| episodes                | 1500          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 351928        |
| policy_loss             | -0.5717391    |
| qf1_loss                | 0.00013459419 |
| qf2_loss                | 0.00011690859 |
| time_elapsed            | 1809          |
| total timesteps         | 352028        |
| value_loss              | 4.21532e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011273262  |
| ent_coef_loss           | -0.98149323   |
| entropy                 | 1.4479926     |
| episodes                | 1504          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 352622        |
| policy_loss             | -0.5352051    |
| qf1_loss                | 2.0926198e-05 |
| qf2_loss                | 1.9411587e-05 |
| time_elapsed            | 1813          |
| total timesteps         | 352722        |
| value_loss              | 3.9343264e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010610139  |
| ent_coef_loss           | 0.6752163     |
| entropy                 | 1.5387015     |
| episodes                | 1508          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 353291        |
| policy_loss             | -0.55212635   |
| qf1_loss                | 3.6164583e-05 |
| qf2_loss                | 4.4816145e-05 |
| time_elapsed            | 1816          |
| total timesteps         | 353391        |
| value_loss              | 2.6820126e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010364944  |
| ent_coef_loss           | 2.183916      |
| entropy                 | 1.4254161     |
| episodes                | 1512          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 354020        |
| policy_loss             | -0.5643399    |
| qf1_loss                | 1.0531396e-05 |
| qf2_loss                | 2.9321931e-05 |
| time_elapsed            | 1820          |
| total timesteps         | 354120        |
| value_loss              | 5.35968e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010682597  |
| ent_coef_loss           | 1.737632      |
| entropy                 | 1.4013462     |
| episodes                | 1516          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 354689        |
| policy_loss             | -0.5910367    |
| qf1_loss                | 3.9350765e-05 |
| qf2_loss                | 5.991793e-05  |
| time_elapsed            | 1824          |
| total timesteps         | 354789        |
| value_loss              | 8.9117726e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010104709  |
| ent_coef_loss           | 1.4285902     |
| entropy                 | 1.3979509     |
| episodes                | 1520          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 355396        |
| policy_loss             | -0.5489507    |
| qf1_loss                | 5.039814e-05  |
| qf2_loss                | 8.6321095e-05 |
| time_elapsed            | 1827          |
| total timesteps         | 355496        |
| value_loss              | 0.00013275104 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001013424   |
| ent_coef_loss           | 1.6997468     |
| entropy                 | 1.270774      |
| episodes                | 1524          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 356155        |
| policy_loss             | -0.5101136    |
| qf1_loss                | 4.0864154e-05 |
| qf2_loss                | 4.901327e-05  |
| time_elapsed            | 1831          |
| total timesteps         | 356255        |
| value_loss              | 5.3313437e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0010717772   |
| ent_coef_loss           | 1.4628108      |
| entropy                 | 1.3260901      |
| episodes                | 1528           |
| fps                     | 194            |
| mean 100 episode reward | 0.8            |
| n_updates               | 357069         |
| policy_loss             | -0.516461      |
| qf1_loss                | 7.234553e-05   |
| qf2_loss                | 0.000105780455 |
| time_elapsed            | 1836           |
| total timesteps         | 357169         |
| value_loss              | 3.5454774e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010315923  |
| ent_coef_loss           | -1.6889946    |
| entropy                 | 1.4719305     |
| episodes                | 1532          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 357777        |
| policy_loss             | -0.5582236    |
| qf1_loss                | 3.6533384e-05 |
| qf2_loss                | 3.0906132e-05 |
| time_elapsed            | 1839          |
| total timesteps         | 357877        |
| value_loss              | 2.701745e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009754507  |
| ent_coef_loss           | -1.704401     |
| entropy                 | 1.43042       |
| episodes                | 1536          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 358489        |
| policy_loss             | -0.55037767   |
| qf1_loss                | 2.0275626e-05 |
| qf2_loss                | 2.6778991e-05 |
| time_elapsed            | 1843          |
| total timesteps         | 358589        |
| value_loss              | 2.3847919e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010432801  |
| ent_coef_loss           | 0.44169086    |
| entropy                 | 1.3289794     |
| episodes                | 1540          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 359175        |
| policy_loss             | -0.51568407   |
| qf1_loss                | 0.00010668812 |
| qf2_loss                | 0.00014389172 |
| time_elapsed            | 1847          |
| total timesteps         | 359275        |
| value_loss              | 5.419937e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009897342  |
| ent_coef_loss           | -1.2328677    |
| entropy                 | 1.3374865     |
| episodes                | 1544          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 359935        |
| policy_loss             | -0.5600885    |
| qf1_loss                | 6.895111e-05  |
| qf2_loss                | 6.159476e-05  |
| time_elapsed            | 1851          |
| total timesteps         | 360035        |
| value_loss              | 7.5885095e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091338507 |
| ent_coef_loss           | 0.75310147    |
| entropy                 | 1.2165039     |
| episodes                | 1548          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 360653        |
| policy_loss             | -0.58060527   |
| qf1_loss                | 0.00011770356 |
| qf2_loss                | 0.00011366692 |
| time_elapsed            | 1854          |
| total timesteps         | 360753        |
| value_loss              | 2.8174389e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009521549  |
| ent_coef_loss           | -2.0483444    |
| entropy                 | 1.3509557     |
| episodes                | 1552          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 361303        |
| policy_loss             | -0.5816671    |
| qf1_loss                | 0.00015560353 |
| qf2_loss                | 0.0001543235  |
| time_elapsed            | 1858          |
| total timesteps         | 361403        |
| value_loss              | 2.9292965e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.000912303    |
| ent_coef_loss           | -1.845656      |
| entropy                 | 1.2006679      |
| episodes                | 1556           |
| fps                     | 194            |
| mean 100 episode reward | 0.9            |
| n_updates               | 361958         |
| policy_loss             | -0.48934615    |
| qf1_loss                | 0.00023898965  |
| qf2_loss                | 0.00011589775  |
| time_elapsed            | 1861           |
| total timesteps         | 362058         |
| value_loss              | 0.000101801634 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009898739  |
| ent_coef_loss           | -3.5907745    |
| entropy                 | 1.2145469     |
| episodes                | 1560          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 362655        |
| policy_loss             | -0.5094523    |
| qf1_loss                | 7.4573945e-05 |
| qf2_loss                | 0.00017866874 |
| time_elapsed            | 1865          |
| total timesteps         | 362755        |
| value_loss              | 3.4496476e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009901316  |
| ent_coef_loss           | -1.2348037    |
| entropy                 | 1.2419639     |
| episodes                | 1564          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 363322        |
| policy_loss             | -0.59421813   |
| qf1_loss                | 3.643783e-05  |
| qf2_loss                | 2.9014125e-05 |
| time_elapsed            | 1868          |
| total timesteps         | 363422        |
| value_loss              | 0.00026914827 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008845194  |
| ent_coef_loss           | 1.9729962     |
| entropy                 | 1.4195614     |
| episodes                | 1568          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 364092        |
| policy_loss             | -0.5434462    |
| qf1_loss                | 2.8524606e-05 |
| qf2_loss                | 3.9820523e-05 |
| time_elapsed            | 1872          |
| total timesteps         | 364192        |
| value_loss              | 3.484411e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089745433 |
| ent_coef_loss           | 3.489307      |
| entropy                 | 1.244233      |
| episodes                | 1572          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 364827        |
| policy_loss             | -0.5836985    |
| qf1_loss                | 0.00011209909 |
| qf2_loss                | 7.567839e-05  |
| time_elapsed            | 1876          |
| total timesteps         | 364927        |
| value_loss              | 6.5616754e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009020093  |
| ent_coef_loss           | -1.9183704    |
| entropy                 | 1.3658617     |
| episodes                | 1576          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 365520        |
| policy_loss             | -0.5488875    |
| qf1_loss                | 4.846075e-05  |
| qf2_loss                | 6.637596e-05  |
| time_elapsed            | 1880          |
| total timesteps         | 365620        |
| value_loss              | 0.00019811065 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090952916 |
| ent_coef_loss           | -2.7339244    |
| entropy                 | 1.3400275     |
| episodes                | 1580          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 366276        |
| policy_loss             | -0.5633655    |
| qf1_loss                | 5.2224063e-05 |
| qf2_loss                | 5.1930954e-05 |
| time_elapsed            | 1883          |
| total timesteps         | 366376        |
| value_loss              | 4.4922475e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085460447 |
| ent_coef_loss           | -2.1237943    |
| entropy                 | 1.23031       |
| episodes                | 1584          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 367024        |
| policy_loss             | -0.54147816   |
| qf1_loss                | 9.7472046e-05 |
| qf2_loss                | 7.584969e-05  |
| time_elapsed            | 1887          |
| total timesteps         | 367124        |
| value_loss              | 4.1697494e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0008432078 |
| ent_coef_loss           | -0.12762189  |
| entropy                 | 1.149278     |
| episodes                | 1588         |
| fps                     | 194          |
| mean 100 episode reward | 0.8          |
| n_updates               | 367861       |
| policy_loss             | -0.51952374  |
| qf1_loss                | 3.547533e-05 |
| qf2_loss                | 4.315955e-05 |
| time_elapsed            | 1892         |
| total timesteps         | 367961       |
| value_loss              | 5.98306e-05  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008937292  |
| ent_coef_loss           | -0.29077148   |
| entropy                 | 1.1613889     |
| episodes                | 1592          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 368645        |
| policy_loss             | -0.52869284   |
| qf1_loss                | 3.697329e-05  |
| qf2_loss                | 6.8593785e-05 |
| time_elapsed            | 1896          |
| total timesteps         | 368745        |
| value_loss              | 3.5359244e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090705696 |
| ent_coef_loss           | 3.2013092     |
| entropy                 | 1.2722013     |
| episodes                | 1596          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 369479        |
| policy_loss             | -0.5312108    |
| qf1_loss                | 3.5114877e-05 |
| qf2_loss                | 1.9086037e-05 |
| time_elapsed            | 1900          |
| total timesteps         | 369579        |
| value_loss              | 1.6338352e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089872535 |
| ent_coef_loss           | -0.6075829    |
| entropy                 | 1.3144743     |
| episodes                | 1600          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 370329        |
| policy_loss             | -0.56412303   |
| qf1_loss                | 1.2343946e-05 |
| qf2_loss                | 1.326737e-05  |
| time_elapsed            | 1904          |
| total timesteps         | 370429        |
| value_loss              | 1.836687e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00088907103 |
| ent_coef_loss           | 1.9669025     |
| entropy                 | 1.2642686     |
| episodes                | 1604          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 371145        |
| policy_loss             | -0.50589705   |
| qf1_loss                | 0.0013717824  |
| qf2_loss                | 0.0014978173  |
| time_elapsed            | 1909          |
| total timesteps         | 371245        |
| value_loss              | 0.00010055055 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089588645 |
| ent_coef_loss           | 2.1707242     |
| entropy                 | 1.3197218     |
| episodes                | 1608          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 371797        |
| policy_loss             | -0.5177766    |
| qf1_loss                | 4.183178e-05  |
| qf2_loss                | 2.1440985e-05 |
| time_elapsed            | 1912          |
| total timesteps         | 371897        |
| value_loss              | 4.1800202e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093319686 |
| ent_coef_loss           | 2.5888574     |
| entropy                 | 1.3953865     |
| episodes                | 1612          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 372475        |
| policy_loss             | -0.532762     |
| qf1_loss                | 3.1671385e-05 |
| qf2_loss                | 2.5959742e-05 |
| time_elapsed            | 1915          |
| total timesteps         | 372575        |
| value_loss              | 2.4740839e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008949966  |
| ent_coef_loss           | -1.1815712    |
| entropy                 | 1.295805      |
| episodes                | 1616          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 373159        |
| policy_loss             | -0.57992995   |
| qf1_loss                | 3.151051e-05  |
| qf2_loss                | 4.0523424e-05 |
| time_elapsed            | 1919          |
| total timesteps         | 373259        |
| value_loss              | 2.8272789e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008282491  |
| ent_coef_loss           | 3.808276      |
| entropy                 | 1.2784992     |
| episodes                | 1620          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 374146        |
| policy_loss             | -0.56404227   |
| qf1_loss                | 4.7533453e-05 |
| qf2_loss                | 0.00010335951 |
| time_elapsed            | 1924          |
| total timesteps         | 374246        |
| value_loss              | 8.297224e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000781047   |
| ent_coef_loss           | 4.461326      |
| entropy                 | 1.254065      |
| episodes                | 1624          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 375079        |
| policy_loss             | -0.53744197   |
| qf1_loss                | 4.4059667e-05 |
| qf2_loss                | 4.153028e-05  |
| time_elapsed            | 1929          |
| total timesteps         | 375179        |
| value_loss              | 3.6322977e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00084038556 |
| ent_coef_loss           | 1.1746818     |
| entropy                 | 1.1099741     |
| episodes                | 1628          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 375841        |
| policy_loss             | -0.59070694   |
| qf1_loss                | 0.00011516568 |
| qf2_loss                | 0.00014393913 |
| time_elapsed            | 1933          |
| total timesteps         | 375941        |
| value_loss              | 4.0054823e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009136364  |
| ent_coef_loss           | -0.6119181    |
| entropy                 | 1.2571914     |
| episodes                | 1632          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 376532        |
| policy_loss             | -0.56496286   |
| qf1_loss                | 9.9095065e-05 |
| qf2_loss                | 0.00011729565 |
| time_elapsed            | 1936          |
| total timesteps         | 376632        |
| value_loss              | 4.4415778e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009323753  |
| ent_coef_loss           | 1.1272589     |
| entropy                 | 1.3901242     |
| episodes                | 1636          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 377329        |
| policy_loss             | -0.53357244   |
| qf1_loss                | 3.0790823e-05 |
| qf2_loss                | 2.6690323e-05 |
| time_elapsed            | 1940          |
| total timesteps         | 377429        |
| value_loss              | 4.0906038e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089680497 |
| ent_coef_loss           | -1.5557082    |
| entropy                 | 1.2879738     |
| episodes                | 1640          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 378270        |
| policy_loss             | -0.5588335    |
| qf1_loss                | 0.0001622539  |
| qf2_loss                | 0.00028646228 |
| time_elapsed            | 1945          |
| total timesteps         | 378370        |
| value_loss              | 6.2746636e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000941641   |
| ent_coef_loss           | -1.5869088    |
| entropy                 | 1.3130968     |
| episodes                | 1644          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 378927        |
| policy_loss             | -0.5696683    |
| qf1_loss                | 2.4625566e-05 |
| qf2_loss                | 2.5309986e-05 |
| time_elapsed            | 1949          |
| total timesteps         | 379027        |
| value_loss              | 2.474607e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009193307  |
| ent_coef_loss           | 2.0096936     |
| entropy                 | 1.2547851     |
| episodes                | 1648          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 379521        |
| policy_loss             | -0.50627005   |
| qf1_loss                | 5.798041e-05  |
| qf2_loss                | 6.7008965e-05 |
| time_elapsed            | 1952          |
| total timesteps         | 379621        |
| value_loss              | 7.949941e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089709664 |
| ent_coef_loss           | -0.833128     |
| entropy                 | 1.1648469     |
| episodes                | 1652          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 380056        |
| policy_loss             | -0.51862633   |
| qf1_loss                | 6.047793e-05  |
| qf2_loss                | 3.3501452e-05 |
| time_elapsed            | 1955          |
| total timesteps         | 380156        |
| value_loss              | 4.3897864e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008351217  |
| ent_coef_loss           | -1.309186     |
| entropy                 | 1.0755258     |
| episodes                | 1656          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 380744        |
| policy_loss             | -0.5027111    |
| qf1_loss                | 3.4617096e-05 |
| qf2_loss                | 5.1807572e-05 |
| time_elapsed            | 1958          |
| total timesteps         | 380844        |
| value_loss              | 0.00012116031 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008294438  |
| ent_coef_loss           | -0.48938698   |
| entropy                 | 1.1812141     |
| episodes                | 1660          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 381449        |
| policy_loss             | -0.5385816    |
| qf1_loss                | 4.5971407e-05 |
| qf2_loss                | 3.251971e-05  |
| time_elapsed            | 1962          |
| total timesteps         | 381549        |
| value_loss              | 6.655115e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00076869526 |
| ent_coef_loss           | -0.6205777    |
| entropy                 | 1.1123247     |
| episodes                | 1664          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 382228        |
| policy_loss             | -0.53087384   |
| qf1_loss                | 5.025028e-05  |
| qf2_loss                | 0.00010146644 |
| time_elapsed            | 1966          |
| total timesteps         | 382328        |
| value_loss              | 0.00013646406 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008212085  |
| ent_coef_loss           | 0.025432438   |
| entropy                 | 1.0576342     |
| episodes                | 1668          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 383147        |
| policy_loss             | -0.5518858    |
| qf1_loss                | 4.8907692e-05 |
| qf2_loss                | 2.7946902e-05 |
| time_elapsed            | 1971          |
| total timesteps         | 383247        |
| value_loss              | 6.0496845e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008976829  |
| ent_coef_loss           | -0.3498609    |
| entropy                 | 1.0420821     |
| episodes                | 1672          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 383861        |
| policy_loss             | -0.54484284   |
| qf1_loss                | 7.9989826e-05 |
| qf2_loss                | 0.00026457768 |
| time_elapsed            | 1974          |
| total timesteps         | 383961        |
| value_loss              | 6.44405e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008382656  |
| ent_coef_loss           | 1.9811366     |
| entropy                 | 1.2251849     |
| episodes                | 1676          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 384586        |
| policy_loss             | -0.5177553    |
| qf1_loss                | 0.00038478556 |
| qf2_loss                | 0.0006289294  |
| time_elapsed            | 1978          |
| total timesteps         | 384686        |
| value_loss              | 0.0001470887  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00080853474 |
| ent_coef_loss           | -1.0882604    |
| entropy                 | 1.0658561     |
| episodes                | 1680          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 385250        |
| policy_loss             | -0.53490543   |
| qf1_loss                | 7.8444275e-05 |
| qf2_loss                | 6.848674e-05  |
| time_elapsed            | 1981          |
| total timesteps         | 385350        |
| value_loss              | 7.635738e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008096138  |
| ent_coef_loss           | 0.99894345    |
| entropy                 | 1.0849298     |
| episodes                | 1684          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 385884        |
| policy_loss             | -0.49698964   |
| qf1_loss                | 3.0830597e-05 |
| qf2_loss                | 5.4313325e-05 |
| time_elapsed            | 1985          |
| total timesteps         | 385984        |
| value_loss              | 9.706379e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007719464  |
| ent_coef_loss           | -2.3771005    |
| entropy                 | 0.9498256     |
| episodes                | 1688          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 386530        |
| policy_loss             | -0.55436015   |
| qf1_loss                | 3.5097368e-05 |
| qf2_loss                | 3.2686585e-05 |
| time_elapsed            | 1988          |
| total timesteps         | 386630        |
| value_loss              | 6.066085e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007689358  |
| ent_coef_loss           | 0.7243524     |
| entropy                 | 1.1670291     |
| episodes                | 1692          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 387230        |
| policy_loss             | -0.54844224   |
| qf1_loss                | 6.381133e-05  |
| qf2_loss                | 8.335926e-05  |
| time_elapsed            | 1992          |
| total timesteps         | 387330        |
| value_loss              | 4.8659014e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007918561  |
| ent_coef_loss           | 3.7224762     |
| entropy                 | 1.1149763     |
| episodes                | 1696          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 387910        |
| policy_loss             | -0.59677494   |
| qf1_loss                | 0.0002398647  |
| qf2_loss                | 0.00010868831 |
| time_elapsed            | 1995          |
| total timesteps         | 388010        |
| value_loss              | 4.7162248e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00076985697 |
| ent_coef_loss           | 2.3382754     |
| entropy                 | 1.000319      |
| episodes                | 1700          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 388630        |
| policy_loss             | -0.5167957    |
| qf1_loss                | 4.4829754e-05 |
| qf2_loss                | 3.986484e-05  |
| time_elapsed            | 1999          |
| total timesteps         | 388730        |
| value_loss              | 0.00011754425 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007628183  |
| ent_coef_loss           | 3.9540977     |
| entropy                 | 1.2207432     |
| episodes                | 1704          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 389477        |
| policy_loss             | -0.53354454   |
| qf1_loss                | 9.0135356e-05 |
| qf2_loss                | 7.5068085e-05 |
| time_elapsed            | 2003          |
| total timesteps         | 389577        |
| value_loss              | 0.00011124157 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087033963 |
| ent_coef_loss           | -1.8498278    |
| entropy                 | 1.1939082     |
| episodes                | 1708          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 390235        |
| policy_loss             | -0.55295956   |
| qf1_loss                | 7.311416e-05  |
| qf2_loss                | 7.559266e-05  |
| time_elapsed            | 2007          |
| total timesteps         | 390335        |
| value_loss              | 5.178847e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00082828937 |
| ent_coef_loss           | 5.4165516     |
| entropy                 | 1.0981581     |
| episodes                | 1712          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 391071        |
| policy_loss             | -0.52746487   |
| qf1_loss                | 4.6543988e-05 |
| qf2_loss                | 6.435895e-05  |
| time_elapsed            | 2011          |
| total timesteps         | 391171        |
| value_loss              | 0.00010451511 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00081536936 |
| ent_coef_loss           | 1.6393849     |
| entropy                 | 1.181483      |
| episodes                | 1716          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 391782        |
| policy_loss             | -0.5303656    |
| qf1_loss                | 1.9745788e-05 |
| qf2_loss                | 3.7424164e-05 |
| time_elapsed            | 2015          |
| total timesteps         | 391882        |
| value_loss              | 4.229634e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085009634 |
| ent_coef_loss           | 1.1736206     |
| entropy                 | 1.2796152     |
| episodes                | 1720          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 392466        |
| policy_loss             | -0.5945598    |
| qf1_loss                | 2.741267e-05  |
| qf2_loss                | 3.0294013e-05 |
| time_elapsed            | 2019          |
| total timesteps         | 392566        |
| value_loss              | 5.260985e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00079145137 |
| ent_coef_loss           | -3.590178     |
| entropy                 | 1.0764215     |
| episodes                | 1724          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 393161        |
| policy_loss             | -0.58087116   |
| qf1_loss                | 2.720793e-05  |
| qf2_loss                | 2.380191e-05  |
| time_elapsed            | 2022          |
| total timesteps         | 393261        |
| value_loss              | 3.8218506e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0007573279 |
| ent_coef_loss           | 0.5834814    |
| entropy                 | 1.1672714    |
| episodes                | 1728         |
| fps                     | 194          |
| mean 100 episode reward | 0.8          |
| n_updates               | 393845       |
| policy_loss             | -0.5574903   |
| qf1_loss                | 7.361065e-05 |
| qf2_loss                | 8.105024e-05 |
| time_elapsed            | 2026         |
| total timesteps         | 393945       |
| value_loss              | 4.148331e-05 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0008077486 |
| ent_coef_loss           | 0.40190744   |
| entropy                 | 1.2008853    |
| episodes                | 1732         |
| fps                     | 194          |
| mean 100 episode reward | 0.8          |
| n_updates               | 394542       |
| policy_loss             | -0.53529155  |
| qf1_loss                | 7.624767e-05 |
| qf2_loss                | 5.145519e-05 |
| time_elapsed            | 2029         |
| total timesteps         | 394642       |
| value_loss              | 8.817093e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090124534 |
| ent_coef_loss           | 1.1753933     |
| entropy                 | 1.2601243     |
| episodes                | 1736          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 395270        |
| policy_loss             | -0.51437914   |
| qf1_loss                | 4.47938e-05   |
| qf2_loss                | 3.8056398e-05 |
| time_elapsed            | 2033          |
| total timesteps         | 395370        |
| value_loss              | 4.1460135e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00083756796 |
| ent_coef_loss           | 3.315442      |
| entropy                 | 1.0278018     |
| episodes                | 1740          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 395920        |
| policy_loss             | -0.51588273   |
| qf1_loss                | 4.5213572e-05 |
| qf2_loss                | 4.584774e-05  |
| time_elapsed            | 2036          |
| total timesteps         | 396020        |
| value_loss              | 3.8499697e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000813347   |
| ent_coef_loss           | -0.17056203   |
| entropy                 | 1.2459698     |
| episodes                | 1744          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 396562        |
| policy_loss             | -0.54834056   |
| qf1_loss                | 6.404561e-05  |
| qf2_loss                | 0.00012417167 |
| time_elapsed            | 2040          |
| total timesteps         | 396662        |
| value_loss              | 0.00017246474 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00083446654 |
| ent_coef_loss           | 0.18519092    |
| entropy                 | 1.3304968     |
| episodes                | 1748          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 397640        |
| policy_loss             | -0.55145276   |
| qf1_loss                | 4.0743886e-05 |
| qf2_loss                | 4.0737064e-05 |
| time_elapsed            | 2045          |
| total timesteps         | 397740        |
| value_loss              | 2.6393573e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007822516  |
| ent_coef_loss           | 2.410784      |
| entropy                 | 0.9970445     |
| episodes                | 1752          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 398361        |
| policy_loss             | -0.46868706   |
| qf1_loss                | 0.00013744886 |
| qf2_loss                | 6.5178545e-05 |
| time_elapsed            | 2049          |
| total timesteps         | 398461        |
| value_loss              | 7.452957e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008226842  |
| ent_coef_loss           | -1.5519118    |
| entropy                 | 1.0630963     |
| episodes                | 1756          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 399331        |
| policy_loss             | -0.4698406    |
| qf1_loss                | 4.418551e-05  |
| qf2_loss                | 4.0949006e-05 |
| time_elapsed            | 2054          |
| total timesteps         | 399431        |
| value_loss              | 4.210522e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090414693 |
| ent_coef_loss           | -0.53476727   |
| entropy                 | 1.2515169     |
| episodes                | 1760          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 400152        |
| policy_loss             | -0.5673028    |
| qf1_loss                | 3.8501283e-05 |
| qf2_loss                | 4.9459155e-05 |
| time_elapsed            | 2058          |
| total timesteps         | 400252        |
| value_loss              | 4.1094347e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090921996 |
| ent_coef_loss           | 1.6629922     |
| entropy                 | 1.0283202     |
| episodes                | 1764          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 400829        |
| policy_loss             | -0.50503016   |
| qf1_loss                | 6.164082e-05  |
| qf2_loss                | 5.2489144e-05 |
| time_elapsed            | 2062          |
| total timesteps         | 400929        |
| value_loss              | 8.537158e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009294018  |
| ent_coef_loss           | -0.28727657   |
| entropy                 | 1.1276153     |
| episodes                | 1768          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 401578        |
| policy_loss             | -0.54644215   |
| qf1_loss                | 5.97944e-05   |
| qf2_loss                | 5.887367e-05  |
| time_elapsed            | 2066          |
| total timesteps         | 401678        |
| value_loss              | 6.7060726e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0009676566 |
| ent_coef_loss           | -2.149651    |
| entropy                 | 1.2116231    |
| episodes                | 1772         |
| fps                     | 194          |
| mean 100 episode reward | 0.8          |
| n_updates               | 402310       |
| policy_loss             | -0.55202293  |
| qf1_loss                | 3.72606e-05  |
| qf2_loss                | 3.086791e-05 |
| time_elapsed            | 2069         |
| total timesteps         | 402410       |
| value_loss              | 8.049636e-05 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.001047841  |
| ent_coef_loss           | 1.8681717    |
| entropy                 | 1.2798897    |
| episodes                | 1776         |
| fps                     | 194          |
| mean 100 episode reward | 0.8          |
| n_updates               | 402986       |
| policy_loss             | -0.54792917  |
| qf1_loss                | 5.131847e-05 |
| qf2_loss                | 2.319094e-05 |
| time_elapsed            | 2073         |
| total timesteps         | 403086       |
| value_loss              | 7.157874e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009917207  |
| ent_coef_loss           | 1.235436      |
| entropy                 | 1.3683181     |
| episodes                | 1780          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 403688        |
| policy_loss             | -0.53363657   |
| qf1_loss                | 3.2142314e-05 |
| qf2_loss                | 2.883293e-05  |
| time_elapsed            | 2076          |
| total timesteps         | 403788        |
| value_loss              | 4.4881737e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009928615  |
| ent_coef_loss           | 2.9631348     |
| entropy                 | 1.1826568     |
| episodes                | 1784          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 404382        |
| policy_loss             | -0.52303207   |
| qf1_loss                | 5.6482568e-05 |
| qf2_loss                | 7.163235e-05  |
| time_elapsed            | 2080          |
| total timesteps         | 404482        |
| value_loss              | 6.1763145e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009770078  |
| ent_coef_loss           | 0.22431535    |
| entropy                 | 1.2254715     |
| episodes                | 1788          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 405351        |
| policy_loss             | -0.55146897   |
| qf1_loss                | 7.219613e-05  |
| qf2_loss                | 2.8422277e-05 |
| time_elapsed            | 2085          |
| total timesteps         | 405451        |
| value_loss              | 8.562535e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009446443  |
| ent_coef_loss           | -0.3702274    |
| entropy                 | 1.2484169     |
| episodes                | 1792          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 406052        |
| policy_loss             | -0.53565687   |
| qf1_loss                | 4.961821e-05  |
| qf2_loss                | 3.1157582e-05 |
| time_elapsed            | 2089          |
| total timesteps         | 406152        |
| value_loss              | 9.620152e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091928244 |
| ent_coef_loss           | -2.056738     |
| entropy                 | 1.0664196     |
| episodes                | 1796          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 406763        |
| policy_loss             | -0.5137397    |
| qf1_loss                | 5.687221e-05  |
| qf2_loss                | 4.898545e-05  |
| time_elapsed            | 2092          |
| total timesteps         | 406863        |
| value_loss              | 6.3603e-05    |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0009864742 |
| ent_coef_loss           | -0.86740816  |
| entropy                 | 0.9879997    |
| episodes                | 1800         |
| fps                     | 194          |
| mean 100 episode reward | 0.8          |
| n_updates               | 407758       |
| policy_loss             | -0.49633762  |
| qf1_loss                | 0.0006260227 |
| qf2_loss                | 0.0006234456 |
| time_elapsed            | 2097         |
| total timesteps         | 407858       |
| value_loss              | 8.521869e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010600288  |
| ent_coef_loss           | -0.77065897   |
| entropy                 | 1.2938781     |
| episodes                | 1804          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 408743        |
| policy_loss             | -0.54127854   |
| qf1_loss                | 4.637389e-05  |
| qf2_loss                | 3.3787444e-05 |
| time_elapsed            | 2102          |
| total timesteps         | 408843        |
| value_loss              | 5.549111e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011475929  |
| ent_coef_loss           | -1.7238116    |
| entropy                 | 1.3160989     |
| episodes                | 1808          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 409757        |
| policy_loss             | -0.5278934    |
| qf1_loss                | 4.122062e-05  |
| qf2_loss                | 4.7867597e-05 |
| time_elapsed            | 2108          |
| total timesteps         | 409857        |
| value_loss              | 6.812776e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010376313  |
| ent_coef_loss           | -1.6245868    |
| entropy                 | 1.2404681     |
| episodes                | 1812          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 410737        |
| policy_loss             | -0.5523968    |
| qf1_loss                | 4.5856996e-05 |
| qf2_loss                | 3.553483e-05  |
| time_elapsed            | 2113          |
| total timesteps         | 410837        |
| value_loss              | 3.963762e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095903676 |
| ent_coef_loss           | -0.92045826   |
| entropy                 | 1.1967194     |
| episodes                | 1816          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 411489        |
| policy_loss             | -0.5081052    |
| qf1_loss                | 2.8323693e-05 |
| qf2_loss                | 4.5469948e-05 |
| time_elapsed            | 2117          |
| total timesteps         | 411589        |
| value_loss              | 5.579451e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010637941  |
| ent_coef_loss           | 1.8520212     |
| entropy                 | 1.0701891     |
| episodes                | 1820          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 412184        |
| policy_loss             | -0.5340692    |
| qf1_loss                | 0.00024407849 |
| qf2_loss                | 4.8179623e-05 |
| time_elapsed            | 2120          |
| total timesteps         | 412284        |
| value_loss              | 0.00025187444 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010733309  |
| ent_coef_loss           | 0.65280735    |
| entropy                 | 1.1258341     |
| episodes                | 1824          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 412884        |
| policy_loss             | -0.5248144    |
| qf1_loss                | 9.575083e-05  |
| qf2_loss                | 0.00010641321 |
| time_elapsed            | 2124          |
| total timesteps         | 412984        |
| value_loss              | 0.0004442275  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097499584 |
| ent_coef_loss           | 0.09577018    |
| entropy                 | 1.0938996     |
| episodes                | 1828          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 413582        |
| policy_loss             | -0.50625175   |
| qf1_loss                | 9.28865e-05   |
| qf2_loss                | 6.7882786e-05 |
| time_elapsed            | 2128          |
| total timesteps         | 413682        |
| value_loss              | 4.174964e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009971991  |
| ent_coef_loss           | -1.7371883    |
| entropy                 | 1.0614171     |
| episodes                | 1832          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 414323        |
| policy_loss             | -0.46683294   |
| qf1_loss                | 7.527763e-05  |
| qf2_loss                | 4.0126797e-05 |
| time_elapsed            | 2131          |
| total timesteps         | 414423        |
| value_loss              | 6.8885805e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010385767  |
| ent_coef_loss           | 0.28884172    |
| entropy                 | 1.1239612     |
| episodes                | 1836          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 415031        |
| policy_loss             | -0.515221     |
| qf1_loss                | 5.5174543e-05 |
| qf2_loss                | 3.1632168e-05 |
| time_elapsed            | 2135          |
| total timesteps         | 415131        |
| value_loss              | 7.63441e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009757158  |
| ent_coef_loss           | 2.9305367     |
| entropy                 | 1.0268544     |
| episodes                | 1840          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 415794        |
| policy_loss             | -0.48312283   |
| qf1_loss                | 4.56511e-05   |
| qf2_loss                | 2.5919417e-05 |
| time_elapsed            | 2139          |
| total timesteps         | 415894        |
| value_loss              | 4.8456128e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009849974  |
| ent_coef_loss           | 1.0280994     |
| entropy                 | 1.0206947     |
| episodes                | 1844          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 416870        |
| policy_loss             | -0.50354683   |
| qf1_loss                | 4.0761493e-05 |
| qf2_loss                | 4.9860406e-05 |
| time_elapsed            | 2145          |
| total timesteps         | 416970        |
| value_loss              | 5.135568e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.001039523  |
| ent_coef_loss           | -0.4354984   |
| entropy                 | 1.1027386    |
| episodes                | 1848         |
| fps                     | 194          |
| mean 100 episode reward | 0.7          |
| n_updates               | 417646       |
| policy_loss             | -0.5316802   |
| qf1_loss                | 8.416465e-05 |
| qf2_loss                | 7.762969e-05 |
| time_elapsed            | 2149         |
| total timesteps         | 417746       |
| value_loss              | 5.081053e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009879415  |
| ent_coef_loss           | -2.89746      |
| entropy                 | 1.1108217     |
| episodes                | 1852          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 418653        |
| policy_loss             | -0.49995685   |
| qf1_loss                | 2.9674175e-05 |
| qf2_loss                | 6.7659836e-05 |
| time_elapsed            | 2154          |
| total timesteps         | 418753        |
| value_loss              | 4.1052335e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009237742  |
| ent_coef_loss           | -2.5930235    |
| entropy                 | 1.1217139     |
| episodes                | 1856          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 419536        |
| policy_loss             | -0.52936816   |
| qf1_loss                | 3.1496187e-05 |
| qf2_loss                | 6.888322e-05  |
| time_elapsed            | 2158          |
| total timesteps         | 419636        |
| value_loss              | 5.0265062e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010728096  |
| ent_coef_loss           | -2.9984233    |
| entropy                 | 1.2464479     |
| episodes                | 1860          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 420528        |
| policy_loss             | -0.49279785   |
| qf1_loss                | 3.7088364e-05 |
| qf2_loss                | 3.916863e-05  |
| time_elapsed            | 2163          |
| total timesteps         | 420628        |
| value_loss              | 6.496234e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010707714  |
| ent_coef_loss           | 1.0138559     |
| entropy                 | 1.1952939     |
| episodes                | 1864          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 421251        |
| policy_loss             | -0.55395895   |
| qf1_loss                | 4.5989913e-05 |
| qf2_loss                | 3.0596686e-05 |
| time_elapsed            | 2167          |
| total timesteps         | 421351        |
| value_loss              | 3.883021e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011318485  |
| ent_coef_loss           | 0.19617686    |
| entropy                 | 1.0192318     |
| episodes                | 1868          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 421985        |
| policy_loss             | -0.4679943    |
| qf1_loss                | 0.000116003   |
| qf2_loss                | 9.19937e-05   |
| time_elapsed            | 2171          |
| total timesteps         | 422085        |
| value_loss              | 0.00020482339 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010881788  |
| ent_coef_loss           | -1.2898793    |
| entropy                 | 1.1822644     |
| episodes                | 1872          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 422685        |
| policy_loss             | -0.5000725    |
| qf1_loss                | 3.5358546e-05 |
| qf2_loss                | 4.219448e-05  |
| time_elapsed            | 2174          |
| total timesteps         | 422785        |
| value_loss              | 2.1476442e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012405036  |
| ent_coef_loss           | 1.8674593     |
| entropy                 | 1.430265      |
| episodes                | 1876          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 423412        |
| policy_loss             | -0.44027078   |
| qf1_loss                | 6.429111e-05  |
| qf2_loss                | 9.58255e-05   |
| time_elapsed            | 2178          |
| total timesteps         | 423512        |
| value_loss              | 5.1354335e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011019056  |
| ent_coef_loss           | 0.17837048    |
| entropy                 | 1.2602363     |
| episodes                | 1880          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 424546        |
| policy_loss             | -0.51877296   |
| qf1_loss                | 6.19357e-05   |
| qf2_loss                | 8.554588e-05  |
| time_elapsed            | 2184          |
| total timesteps         | 424646        |
| value_loss              | 8.0003396e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011569946  |
| ent_coef_loss           | -0.7672787    |
| entropy                 | 1.1783457     |
| episodes                | 1884          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 425347        |
| policy_loss             | -0.49010655   |
| qf1_loss                | 0.0001109898  |
| qf2_loss                | 9.3730036e-05 |
| time_elapsed            | 2188          |
| total timesteps         | 425447        |
| value_loss              | 8.770144e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011143354  |
| ent_coef_loss           | -1.636217     |
| entropy                 | 1.079287      |
| episodes                | 1888          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 426089        |
| policy_loss             | -0.5006817    |
| qf1_loss                | 0.0004953249  |
| qf2_loss                | 0.00018628358 |
| time_elapsed            | 2192          |
| total timesteps         | 426189        |
| value_loss              | 7.775704e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011341262  |
| ent_coef_loss           | -0.029867053  |
| entropy                 | 0.90688026    |
| episodes                | 1892          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 426832        |
| policy_loss             | -0.40945375   |
| qf1_loss                | 0.0002822345  |
| qf2_loss                | 0.00016319832 |
| time_elapsed            | 2196          |
| total timesteps         | 426932        |
| value_loss              | 9.182883e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011244062  |
| ent_coef_loss           | -0.27840763   |
| entropy                 | 1.2284741     |
| episodes                | 1896          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 427656        |
| policy_loss             | -0.5662774    |
| qf1_loss                | 3.7318463e-05 |
| qf2_loss                | 3.7147103e-05 |
| time_elapsed            | 2200          |
| total timesteps         | 427756        |
| value_loss              | 7.071599e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011168648  |
| ent_coef_loss           | 5.128047      |
| entropy                 | 1.1977894     |
| episodes                | 1900          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 428463        |
| policy_loss             | -0.53792024   |
| qf1_loss                | 7.958999e-05  |
| qf2_loss                | 0.00017325049 |
| time_elapsed            | 2204          |
| total timesteps         | 428563        |
| value_loss              | 9.534487e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010187327  |
| ent_coef_loss           | 1.6229043     |
| entropy                 | 1.124675      |
| episodes                | 1904          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 429264        |
| policy_loss             | -0.5089644    |
| qf1_loss                | 0.0002947353  |
| qf2_loss                | 0.00028824143 |
| time_elapsed            | 2208          |
| total timesteps         | 429364        |
| value_loss              | 9.16116e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010079165  |
| ent_coef_loss           | 3.0070326     |
| entropy                 | 0.94673085    |
| episodes                | 1908          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 430519        |
| policy_loss             | -0.37800223   |
| qf1_loss                | 0.00033690553 |
| qf2_loss                | 0.00035340412 |
| time_elapsed            | 2215          |
| total timesteps         | 430619        |
| value_loss              | 8.814437e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010068477  |
| ent_coef_loss           | 1.6887445     |
| entropy                 | 1.0000143     |
| episodes                | 1912          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 431269        |
| policy_loss             | -0.44833967   |
| qf1_loss                | 0.0002931082  |
| qf2_loss                | 0.00021759805 |
| time_elapsed            | 2219          |
| total timesteps         | 431369        |
| value_loss              | 7.533413e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010242963  |
| ent_coef_loss           | 1.3525529     |
| entropy                 | 1.1564355     |
| episodes                | 1916          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 431976        |
| policy_loss             | -0.4755192    |
| qf1_loss                | 5.010382e-05  |
| qf2_loss                | 6.130946e-05  |
| time_elapsed            | 2222          |
| total timesteps         | 432076        |
| value_loss              | 3.4489807e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0010144837   |
| ent_coef_loss           | -0.9511496     |
| entropy                 | 1.1691539      |
| episodes                | 1920           |
| fps                     | 194            |
| mean 100 episode reward | 0.7            |
| n_updates               | 432676         |
| policy_loss             | -0.51597714    |
| qf1_loss                | 0.000118964956 |
| qf2_loss                | 9.502328e-05   |
| time_elapsed            | 2226           |
| total timesteps         | 432776         |
| value_loss              | 7.803436e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009844053  |
| ent_coef_loss           | 0.52505493    |
| entropy                 | 0.92807823    |
| episodes                | 1924          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 433353        |
| policy_loss             | -0.46295887   |
| qf1_loss                | 9.848758e-05  |
| qf2_loss                | 0.00016526367 |
| time_elapsed            | 2229          |
| total timesteps         | 433453        |
| value_loss              | 0.0001353427  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00088421453 |
| ent_coef_loss           | 1.0001936     |
| entropy                 | 1.1047244     |
| episodes                | 1928          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 434069        |
| policy_loss             | -0.4957143    |
| qf1_loss                | 4.9927057e-05 |
| qf2_loss                | 5.9448954e-05 |
| time_elapsed            | 2233          |
| total timesteps         | 434169        |
| value_loss              | 5.0534793e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085486367 |
| ent_coef_loss           | -1.1784775    |
| entropy                 | 1.0501351     |
| episodes                | 1932          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 435018        |
| policy_loss             | -0.49320525   |
| qf1_loss                | 5.688316e-05  |
| qf2_loss                | 5.5746386e-05 |
| time_elapsed            | 2238          |
| total timesteps         | 435118        |
| value_loss              | 4.6097863e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008596295  |
| ent_coef_loss           | -1.548058     |
| entropy                 | 1.1269472     |
| episodes                | 1936          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 435766        |
| policy_loss             | -0.5395192    |
| qf1_loss                | 0.00015827507 |
| qf2_loss                | 0.00019734894 |
| time_elapsed            | 2242          |
| total timesteps         | 435866        |
| value_loss              | 6.843591e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008402349  |
| ent_coef_loss           | -0.018142939  |
| entropy                 | 1.0639288     |
| episodes                | 1940          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 436645        |
| policy_loss             | -0.507135     |
| qf1_loss                | 5.0376075e-05 |
| qf2_loss                | 3.368972e-05  |
| time_elapsed            | 2246          |
| total timesteps         | 436745        |
| value_loss              | 4.237408e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087336905 |
| ent_coef_loss           | 1.1321537     |
| entropy                 | 0.8986397     |
| episodes                | 1944          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 437394        |
| policy_loss             | -0.4575613    |
| qf1_loss                | 0.00013378114 |
| qf2_loss                | 7.806356e-05  |
| time_elapsed            | 2250          |
| total timesteps         | 437494        |
| value_loss              | 0.0001061926  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091148505 |
| ent_coef_loss           | -1.5187725    |
| entropy                 | 1.0296545     |
| episodes                | 1948          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 438059        |
| policy_loss             | -0.55155      |
| qf1_loss                | 3.8262333e-05 |
| qf2_loss                | 5.4033117e-05 |
| time_elapsed            | 2254          |
| total timesteps         | 438159        |
| value_loss              | 6.4576554e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008814072  |
| ent_coef_loss           | -0.20048982   |
| entropy                 | 1.1722758     |
| episodes                | 1952          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 438795        |
| policy_loss             | -0.5007662    |
| qf1_loss                | 8.074682e-05  |
| qf2_loss                | 0.000101675   |
| time_elapsed            | 2258          |
| total timesteps         | 438895        |
| value_loss              | 4.4033557e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008276948  |
| ent_coef_loss           | -1.7007087    |
| entropy                 | 1.1427828     |
| episodes                | 1956          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 439521        |
| policy_loss             | -0.5384915    |
| qf1_loss                | 1.430633e-05  |
| qf2_loss                | 3.370533e-05  |
| time_elapsed            | 2261          |
| total timesteps         | 439621        |
| value_loss              | 2.3376975e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0008934948   |
| ent_coef_loss           | -0.64062226    |
| entropy                 | 1.1698298      |
| episodes                | 1960           |
| fps                     | 194            |
| mean 100 episode reward | 0.8            |
| n_updates               | 440229         |
| policy_loss             | -0.5493331     |
| qf1_loss                | 0.000109673056 |
| qf2_loss                | 7.070125e-05   |
| time_elapsed            | 2265           |
| total timesteps         | 440329         |
| value_loss              | 7.925988e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009026952  |
| ent_coef_loss           | -0.0072745234 |
| entropy                 | 1.2322936     |
| episodes                | 1964          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 440965        |
| policy_loss             | -0.55673593   |
| qf1_loss                | 2.7248643e-05 |
| qf2_loss                | 1.8559116e-05 |
| time_elapsed            | 2269          |
| total timesteps         | 441065        |
| value_loss              | 4.100495e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095087994 |
| ent_coef_loss           | -1.3165407    |
| entropy                 | 1.1101382     |
| episodes                | 1968          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 441683        |
| policy_loss             | -0.54819095   |
| qf1_loss                | 3.240323e-05  |
| qf2_loss                | 2.408081e-05  |
| time_elapsed            | 2273          |
| total timesteps         | 441783        |
| value_loss              | 7.584239e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009852679   |
| ent_coef_loss           | 0.16377652     |
| entropy                 | 1.2443392      |
| episodes                | 1972           |
| fps                     | 194            |
| mean 100 episode reward | 0.8            |
| n_updates               | 442459         |
| policy_loss             | -0.5299421     |
| qf1_loss                | 6.136115e-05   |
| qf2_loss                | 0.000121709825 |
| time_elapsed            | 2276           |
| total timesteps         | 442559         |
| value_loss              | 4.5571767e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009454058  |
| ent_coef_loss           | -0.81287503   |
| entropy                 | 0.97540504    |
| episodes                | 1976          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 443397        |
| policy_loss             | -0.55689085   |
| qf1_loss                | 0.00037817936 |
| qf2_loss                | 0.00044466558 |
| time_elapsed            | 2281          |
| total timesteps         | 443497        |
| value_loss              | 3.3664695e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000982529   |
| ent_coef_loss           | -1.6492764    |
| entropy                 | 1.0054483     |
| episodes                | 1980          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 444240        |
| policy_loss             | -0.49702084   |
| qf1_loss                | 4.5025663e-05 |
| qf2_loss                | 3.696933e-05  |
| time_elapsed            | 2286          |
| total timesteps         | 444340        |
| value_loss              | 5.035924e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009901137  |
| ent_coef_loss           | -0.2770921    |
| entropy                 | 0.9625705     |
| episodes                | 1984          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 444976        |
| policy_loss             | -0.50422484   |
| qf1_loss                | 4.05759e-05   |
| qf2_loss                | 7.109813e-05  |
| time_elapsed            | 2289          |
| total timesteps         | 445076        |
| value_loss              | 0.00014271782 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001024907   |
| ent_coef_loss           | -0.31648445   |
| entropy                 | 1.128824      |
| episodes                | 1988          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 445714        |
| policy_loss             | -0.46698147   |
| qf1_loss                | 0.00018203625 |
| qf2_loss                | 0.00025026398 |
| time_elapsed            | 2293          |
| total timesteps         | 445814        |
| value_loss              | 0.00018827207 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010666563  |
| ent_coef_loss           | 0.822946      |
| entropy                 | 1.1434144     |
| episodes                | 1992          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 446480        |
| policy_loss             | -0.5393536    |
| qf1_loss                | 3.7579845e-05 |
| qf2_loss                | 7.975027e-05  |
| time_elapsed            | 2297          |
| total timesteps         | 446580        |
| value_loss              | 0.0010119237  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001015658   |
| ent_coef_loss           | -0.08891657   |
| entropy                 | 1.2293497     |
| episodes                | 1996          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 447297        |
| policy_loss             | -0.5613847    |
| qf1_loss                | 4.8631176e-05 |
| qf2_loss                | 4.335127e-05  |
| time_elapsed            | 2301          |
| total timesteps         | 447397        |
| value_loss              | 3.9921768e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093765464 |
| ent_coef_loss           | 2.2627587     |
| entropy                 | 1.1532058     |
| episodes                | 2000          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 447980        |
| policy_loss             | -0.52240425   |
| qf1_loss                | 9.103293e-05  |
| qf2_loss                | 9.1630965e-05 |
| time_elapsed            | 2305          |
| total timesteps         | 448080        |
| value_loss              | 5.72206e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009845025  |
| ent_coef_loss           | -2.0253057    |
| entropy                 | 1.2522485     |
| episodes                | 2004          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 448690        |
| policy_loss             | -0.5497853    |
| qf1_loss                | 3.344289e-05  |
| qf2_loss                | 4.2042513e-05 |
| time_elapsed            | 2309          |
| total timesteps         | 448790        |
| value_loss              | 4.6849927e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095894164 |
| ent_coef_loss           | -2.339048     |
| entropy                 | 1.2702577     |
| episodes                | 2008          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 449370        |
| policy_loss             | -0.58616966   |
| qf1_loss                | 3.5529036e-05 |
| qf2_loss                | 4.0411083e-05 |
| time_elapsed            | 2312          |
| total timesteps         | 449470        |
| value_loss              | 2.5695503e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008577787  |
| ent_coef_loss           | -0.68351454   |
| entropy                 | 1.1911808     |
| episodes                | 2012          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 450351        |
| policy_loss             | -0.56187207   |
| qf1_loss                | 7.708468e-05  |
| qf2_loss                | 5.5903736e-05 |
| time_elapsed            | 2317          |
| total timesteps         | 450451        |
| value_loss              | 4.067018e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00088929577 |
| ent_coef_loss           | -0.90570945   |
| entropy                 | 1.2018266     |
| episodes                | 2016          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 451081        |
| policy_loss             | -0.5360019    |
| qf1_loss                | 0.00015948125 |
| qf2_loss                | 0.00014403943 |
| time_elapsed            | 2321          |
| total timesteps         | 451181        |
| value_loss              | 5.4407552e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009153471   |
| ent_coef_loss           | 2.5990858      |
| entropy                 | 1.122124       |
| episodes                | 2020           |
| fps                     | 194            |
| mean 100 episode reward | 0.8            |
| n_updates               | 452005         |
| policy_loss             | -0.46617395    |
| qf1_loss                | 0.0010105026   |
| qf2_loss                | 0.0010417419   |
| time_elapsed            | 2326           |
| total timesteps         | 452105         |
| value_loss              | 0.000119029806 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008864334  |
| ent_coef_loss           | 0.64392614    |
| entropy                 | 1.1983321     |
| episodes                | 2024          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 452751        |
| policy_loss             | -0.510702     |
| qf1_loss                | 0.00023587962 |
| qf2_loss                | 0.00024511808 |
| time_elapsed            | 2330          |
| total timesteps         | 452851        |
| value_loss              | 4.614548e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008728894  |
| ent_coef_loss           | -1.0572963    |
| entropy                 | 0.92248124    |
| episodes                | 2028          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 453715        |
| policy_loss             | -0.5385033    |
| qf1_loss                | 0.00014743042 |
| qf2_loss                | 0.00021493556 |
| time_elapsed            | 2335          |
| total timesteps         | 453815        |
| value_loss              | 4.3518754e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008007972  |
| ent_coef_loss           | 1.3383611     |
| entropy                 | 0.9627879     |
| episodes                | 2032          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 454660        |
| policy_loss             | -0.47374606   |
| qf1_loss                | 5.2225383e-05 |
| qf2_loss                | 4.476511e-05  |
| time_elapsed            | 2340          |
| total timesteps         | 454760        |
| value_loss              | 9.657853e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008600965  |
| ent_coef_loss           | -2.8387222    |
| entropy                 | 0.99575794    |
| episodes                | 2036          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 455371        |
| policy_loss             | -0.5259344    |
| qf1_loss                | 3.084599e-05  |
| qf2_loss                | 2.1885036e-05 |
| time_elapsed            | 2343          |
| total timesteps         | 455471        |
| value_loss              | 2.4056746e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00078365795 |
| ent_coef_loss           | 0.8400377     |
| entropy                 | 0.8680908     |
| episodes                | 2040          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 456127        |
| policy_loss             | -0.5383582    |
| qf1_loss                | 5.593628e-05  |
| qf2_loss                | 4.1686933e-05 |
| time_elapsed            | 2347          |
| total timesteps         | 456227        |
| value_loss              | 8.684379e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00088057417 |
| ent_coef_loss           | -0.5408284    |
| entropy                 | 1.0521023     |
| episodes                | 2044          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 457183        |
| policy_loss             | -0.5547193    |
| qf1_loss                | 2.2548365e-05 |
| qf2_loss                | 4.5493383e-05 |
| time_elapsed            | 2352          |
| total timesteps         | 457283        |
| value_loss              | 2.5255862e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00080100266 |
| ent_coef_loss           | -0.40830457   |
| entropy                 | 0.7745075     |
| episodes                | 2048          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 457933        |
| policy_loss             | -0.50340086   |
| qf1_loss                | 0.0002623604  |
| qf2_loss                | 0.0002141525  |
| time_elapsed            | 2356          |
| total timesteps         | 458033        |
| value_loss              | 0.00014695774 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008368789  |
| ent_coef_loss           | 1.2567736     |
| entropy                 | 0.81751025    |
| episodes                | 2052          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 458660        |
| policy_loss             | -0.5113573    |
| qf1_loss                | 7.5348995e-05 |
| qf2_loss                | 6.644233e-05  |
| time_elapsed            | 2360          |
| total timesteps         | 458760        |
| value_loss              | 5.3498563e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008837273  |
| ent_coef_loss           | -0.82459044   |
| entropy                 | 0.717083      |
| episodes                | 2056          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 459359        |
| policy_loss             | -0.50792277   |
| qf1_loss                | 5.9966962e-05 |
| qf2_loss                | 8.814929e-05  |
| time_elapsed            | 2364          |
| total timesteps         | 459459        |
| value_loss              | 6.699802e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008696265  |
| ent_coef_loss           | 0.7683312     |
| entropy                 | 0.81180096    |
| episodes                | 2060          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 460119        |
| policy_loss             | -0.5428725    |
| qf1_loss                | 0.000208538   |
| qf2_loss                | 0.00016522137 |
| time_elapsed            | 2368          |
| total timesteps         | 460219        |
| value_loss              | 3.6661695e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000937297   |
| ent_coef_loss           | -3.814824     |
| entropy                 | 1.0143464     |
| episodes                | 2064          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 461091        |
| policy_loss             | -0.5015098    |
| qf1_loss                | 3.1879397e-05 |
| qf2_loss                | 3.5021276e-05 |
| time_elapsed            | 2373          |
| total timesteps         | 461191        |
| value_loss              | 5.3154454e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008943409  |
| ent_coef_loss           | -1.7451105    |
| entropy                 | 1.0022768     |
| episodes                | 2068          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 461757        |
| policy_loss             | -0.50746846   |
| qf1_loss                | 3.1736017e-05 |
| qf2_loss                | 4.9296505e-05 |
| time_elapsed            | 2376          |
| total timesteps         | 461857        |
| value_loss              | 6.356702e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008782221  |
| ent_coef_loss           | 0.89370525    |
| entropy                 | 1.102437      |
| episodes                | 2072          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 462500        |
| policy_loss             | -0.5417099    |
| qf1_loss                | 2.9414081e-05 |
| qf2_loss                | 5.216507e-05  |
| time_elapsed            | 2380          |
| total timesteps         | 462600        |
| value_loss              | 5.0521925e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089372834 |
| ent_coef_loss           | 2.1053412     |
| entropy                 | 0.98074925    |
| episodes                | 2076          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 463262        |
| policy_loss             | -0.5690886    |
| qf1_loss                | 4.8739843e-05 |
| qf2_loss                | 2.8743978e-05 |
| time_elapsed            | 2384          |
| total timesteps         | 463362        |
| value_loss              | 2.9024202e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010072588  |
| ent_coef_loss           | 1.2960625     |
| entropy                 | 0.9712249     |
| episodes                | 2080          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 463831        |
| policy_loss             | -0.50961024   |
| qf1_loss                | 5.5095712e-05 |
| qf2_loss                | 5.1764495e-05 |
| time_elapsed            | 2387          |
| total timesteps         | 463931        |
| value_loss              | 0.00019572844 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010147465  |
| ent_coef_loss           | 1.3458775     |
| entropy                 | 0.86775935    |
| episodes                | 2084          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 464526        |
| policy_loss             | -0.4817199    |
| qf1_loss                | 4.6029076e-05 |
| qf2_loss                | 6.704396e-05  |
| time_elapsed            | 2391          |
| total timesteps         | 464626        |
| value_loss              | 0.00021267013 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009880263  |
| ent_coef_loss           | -0.8299716    |
| entropy                 | 1.1524029     |
| episodes                | 2088          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 465256        |
| policy_loss             | -0.54862577   |
| qf1_loss                | 4.40771e-05   |
| qf2_loss                | 2.344169e-05  |
| time_elapsed            | 2394          |
| total timesteps         | 465356        |
| value_loss              | 3.8474347e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010257132  |
| ent_coef_loss           | -0.48778614   |
| entropy                 | 0.91192853    |
| episodes                | 2092          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 465934        |
| policy_loss             | -0.49400267   |
| qf1_loss                | 7.948994e-05  |
| qf2_loss                | 7.881423e-05  |
| time_elapsed            | 2398          |
| total timesteps         | 466034        |
| value_loss              | 4.6659432e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009906772  |
| ent_coef_loss           | -0.90278095   |
| entropy                 | 1.0561676     |
| episodes                | 2096          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 466698        |
| policy_loss             | -0.54382217   |
| qf1_loss                | 2.9908122e-05 |
| qf2_loss                | 3.0471267e-05 |
| time_elapsed            | 2402          |
| total timesteps         | 466798        |
| value_loss              | 5.004514e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010036677  |
| ent_coef_loss           | -0.48470694   |
| entropy                 | 1.1276981     |
| episodes                | 2100          |
| fps                     | 194           |
| mean 100 episode reward | 0.7           |
| n_updates               | 467414        |
| policy_loss             | -0.53621113   |
| qf1_loss                | 4.2998552e-05 |
| qf2_loss                | 4.712621e-05  |
| time_elapsed            | 2405          |
| total timesteps         | 467514        |
| value_loss              | 7.250096e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010630639  |
| ent_coef_loss           | 1.2644774     |
| entropy                 | 1.0414861     |
| episodes                | 2104          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 468296        |
| policy_loss             | -0.61024433   |
| qf1_loss                | 3.6310248e-05 |
| qf2_loss                | 4.37005e-05   |
| time_elapsed            | 2410          |
| total timesteps         | 468396        |
| value_loss              | 5.9478778e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011053119  |
| ent_coef_loss           | 5.061578      |
| entropy                 | 1.0919038     |
| episodes                | 2108          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 469026        |
| policy_loss             | -0.48275876   |
| qf1_loss                | 4.680532e-05  |
| qf2_loss                | 4.1136474e-05 |
| time_elapsed            | 2414          |
| total timesteps         | 469126        |
| value_loss              | 7.1412825e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010852702  |
| ent_coef_loss           | 0.82939875    |
| entropy                 | 1.1415999     |
| episodes                | 2112          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 469749        |
| policy_loss             | -0.45907918   |
| qf1_loss                | 4.877676e-05  |
| qf2_loss                | 3.6555393e-05 |
| time_elapsed            | 2418          |
| total timesteps         | 469849        |
| value_loss              | 4.7414458e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010636237  |
| ent_coef_loss           | 0.957708      |
| entropy                 | 0.979363      |
| episodes                | 2116          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 470518        |
| policy_loss             | -0.5327022    |
| qf1_loss                | 3.0180516e-05 |
| qf2_loss                | 3.3636996e-05 |
| time_elapsed            | 2422          |
| total timesteps         | 470618        |
| value_loss              | 5.148811e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011545663  |
| ent_coef_loss           | 1.141295      |
| entropy                 | 1.1938446     |
| episodes                | 2120          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 471547        |
| policy_loss             | -0.5267577    |
| qf1_loss                | 2.2207987e-05 |
| qf2_loss                | 1.983325e-05  |
| time_elapsed            | 2427          |
| total timesteps         | 471647        |
| value_loss              | 2.6898204e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012453903  |
| ent_coef_loss           | 1.4067044     |
| entropy                 | 1.0244305     |
| episodes                | 2124          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 472331        |
| policy_loss             | -0.4617046    |
| qf1_loss                | 3.840149e-05  |
| qf2_loss                | 5.7609348e-05 |
| time_elapsed            | 2431          |
| total timesteps         | 472431        |
| value_loss              | 7.218692e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013105103  |
| ent_coef_loss           | 0.30712166    |
| entropy                 | 1.0563602     |
| episodes                | 2128          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 473040        |
| policy_loss             | -0.5344318    |
| qf1_loss                | 3.295077e-05  |
| qf2_loss                | 3.5671575e-05 |
| time_elapsed            | 2435          |
| total timesteps         | 473140        |
| value_loss              | 9.728374e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012354811  |
| ent_coef_loss           | -0.33531517   |
| entropy                 | 1.0820055     |
| episodes                | 2132          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 474007        |
| policy_loss             | -0.49609095   |
| qf1_loss                | 7.4848176e-05 |
| qf2_loss                | 3.24101e-05   |
| time_elapsed            | 2439          |
| total timesteps         | 474107        |
| value_loss              | 5.046835e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013378459  |
| ent_coef_loss           | -2.7482402    |
| entropy                 | 1.2366056     |
| episodes                | 2136          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 474686        |
| policy_loss             | -0.5746811    |
| qf1_loss                | 3.9429484e-05 |
| qf2_loss                | 5.5593104e-05 |
| time_elapsed            | 2443          |
| total timesteps         | 474786        |
| value_loss              | 9.941717e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0012170526 |
| ent_coef_loss           | -0.9793148   |
| entropy                 | 0.8948039    |
| episodes                | 2140         |
| fps                     | 194          |
| mean 100 episode reward | 0.8          |
| n_updates               | 475880       |
| policy_loss             | -0.4735424   |
| qf1_loss                | 0.0045297416 |
| qf2_loss                | 0.0046688756 |
| time_elapsed            | 2449         |
| total timesteps         | 475980       |
| value_loss              | 8.495375e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011131113  |
| ent_coef_loss           | -1.6910374    |
| entropy                 | 1.1519616     |
| episodes                | 2144          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 476703        |
| policy_loss             | -0.507185     |
| qf1_loss                | 4.5763998e-05 |
| qf2_loss                | 3.36826e-05   |
| time_elapsed            | 2453          |
| total timesteps         | 476803        |
| value_loss              | 5.2622483e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011293552  |
| ent_coef_loss           | -1.7070994    |
| entropy                 | 1.1614172     |
| episodes                | 2148          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 477614        |
| policy_loss             | -0.46831042   |
| qf1_loss                | 8.006143e-05  |
| qf2_loss                | 4.6603207e-05 |
| time_elapsed            | 2458          |
| total timesteps         | 477714        |
| value_loss              | 2.8178734e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0011821592 |
| ent_coef_loss           | -0.35772294  |
| entropy                 | 1.231719     |
| episodes                | 2152         |
| fps                     | 194          |
| mean 100 episode reward | 0.8          |
| n_updates               | 478311       |
| policy_loss             | -0.44216615  |
| qf1_loss                | 4.472877e-05 |
| qf2_loss                | 3.291797e-05 |
| time_elapsed            | 2462         |
| total timesteps         | 478411       |
| value_loss              | 6.594592e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011818976  |
| ent_coef_loss           | -0.7537597    |
| entropy                 | 1.1899021     |
| episodes                | 2156          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 479226        |
| policy_loss             | -0.49279338   |
| qf1_loss                | 0.00024348382 |
| qf2_loss                | 0.0002997045  |
| time_elapsed            | 2466          |
| total timesteps         | 479326        |
| value_loss              | 0.00011305688 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010580034  |
| ent_coef_loss           | 3.9978185     |
| entropy                 | 1.0867867     |
| episodes                | 2160          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 479993        |
| policy_loss             | -0.48738605   |
| qf1_loss                | 2.3157787e-05 |
| qf2_loss                | 2.6459837e-05 |
| time_elapsed            | 2470          |
| total timesteps         | 480093        |
| value_loss              | 2.4608711e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011180318  |
| ent_coef_loss           | 0.9412018     |
| entropy                 | 1.2632315     |
| episodes                | 2164          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 480805        |
| policy_loss             | -0.49923566   |
| qf1_loss                | 5.3135678e-05 |
| qf2_loss                | 6.243358e-05  |
| time_elapsed            | 2475          |
| total timesteps         | 480905        |
| value_loss              | 0.00011133647 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010996171  |
| ent_coef_loss           | 0.8829801     |
| entropy                 | 1.184611      |
| episodes                | 2168          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 481656        |
| policy_loss             | -0.52926314   |
| qf1_loss                | 4.059728e-05  |
| qf2_loss                | 3.6369605e-05 |
| time_elapsed            | 2479          |
| total timesteps         | 481756        |
| value_loss              | 6.7396955e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010502756  |
| ent_coef_loss           | 1.9725585     |
| entropy                 | 1.2098083     |
| episodes                | 2172          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 482410        |
| policy_loss             | -0.4863507    |
| qf1_loss                | 8.5999825e-05 |
| qf2_loss                | 1.9507755e-05 |
| time_elapsed            | 2483          |
| total timesteps         | 482510        |
| value_loss              | 5.317596e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0009976067 |
| ent_coef_loss           | 1.6056263    |
| entropy                 | 0.8429466    |
| episodes                | 2176         |
| fps                     | 194          |
| mean 100 episode reward | 0.8          |
| n_updates               | 483119       |
| policy_loss             | -0.49735624  |
| qf1_loss                | 5.666181e-05 |
| qf2_loss                | 6.098965e-05 |
| time_elapsed            | 2486         |
| total timesteps         | 483219       |
| value_loss              | 5.722029e-05 |
------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0010329755   |
| ent_coef_loss           | -0.5803651     |
| entropy                 | 1.1854825      |
| episodes                | 2180           |
| fps                     | 194            |
| mean 100 episode reward | 0.9            |
| n_updates               | 483783         |
| policy_loss             | -0.52037185    |
| qf1_loss                | 3.358278e-05   |
| qf2_loss                | 2.6047286e-05  |
| time_elapsed            | 2490           |
| total timesteps         | 483883         |
| value_loss              | 0.000106221814 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010223463  |
| ent_coef_loss           | 0.018533766   |
| entropy                 | 1.2775981     |
| episodes                | 2184          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 484534        |
| policy_loss             | -0.5434214    |
| qf1_loss                | 3.071316e-05  |
| qf2_loss                | 1.8549725e-05 |
| time_elapsed            | 2494          |
| total timesteps         | 484634        |
| value_loss              | 3.0638614e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010020285  |
| ent_coef_loss           | 0.19599473    |
| entropy                 | 1.0250876     |
| episodes                | 2188          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 485281        |
| policy_loss             | -0.48459285   |
| qf1_loss                | 2.9804796e-05 |
| qf2_loss                | 3.4503664e-05 |
| time_elapsed            | 2498          |
| total timesteps         | 485381        |
| value_loss              | 5.1579027e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009894959  |
| ent_coef_loss           | -1.1496017    |
| entropy                 | 1.1123341     |
| episodes                | 2192          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 485971        |
| policy_loss             | -0.5257124    |
| qf1_loss                | 0.00023677171 |
| qf2_loss                | 0.00020849745 |
| time_elapsed            | 2501          |
| total timesteps         | 486071        |
| value_loss              | 0.00030539633 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010350829  |
| ent_coef_loss           | 0.1590437     |
| entropy                 | 1.179166      |
| episodes                | 2196          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 486717        |
| policy_loss             | -0.5640155    |
| qf1_loss                | 4.7575988e-05 |
| qf2_loss                | 5.1499963e-05 |
| time_elapsed            | 2505          |
| total timesteps         | 486817        |
| value_loss              | 7.571189e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010207399  |
| ent_coef_loss           | 0.012671679   |
| entropy                 | 1.1396801     |
| episodes                | 2200          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 487425        |
| policy_loss             | -0.5582602    |
| qf1_loss                | 5.5317218e-05 |
| qf2_loss                | 5.4913562e-05 |
| time_elapsed            | 2509          |
| total timesteps         | 487525        |
| value_loss              | 4.9208225e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009643203  |
| ent_coef_loss           | -1.6348159    |
| entropy                 | 1.2469097     |
| episodes                | 2204          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 488128        |
| policy_loss             | -0.5670794    |
| qf1_loss                | 5.2439493e-05 |
| qf2_loss                | 2.9523304e-05 |
| time_elapsed            | 2512          |
| total timesteps         | 488228        |
| value_loss              | 8.345836e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010467368  |
| ent_coef_loss           | 1.2861081     |
| entropy                 | 1.1551952     |
| episodes                | 2208          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 488868        |
| policy_loss             | -0.5181537    |
| qf1_loss                | 4.8067937e-05 |
| qf2_loss                | 6.497388e-05  |
| time_elapsed            | 2516          |
| total timesteps         | 488968        |
| value_loss              | 3.9476843e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009587455  |
| ent_coef_loss           | 2.5546532     |
| entropy                 | 1.2138038     |
| episodes                | 2212          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 489710        |
| policy_loss             | -0.56688994   |
| qf1_loss                | 4.2490377e-05 |
| qf2_loss                | 3.6013887e-05 |
| time_elapsed            | 2521          |
| total timesteps         | 489810        |
| value_loss              | 3.0977426e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000898135   |
| ent_coef_loss           | -3.5241604    |
| entropy                 | 1.2362642     |
| episodes                | 2216          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 490452        |
| policy_loss             | -0.53522086   |
| qf1_loss                | 5.9871574e-05 |
| qf2_loss                | 3.7549507e-05 |
| time_elapsed            | 2524          |
| total timesteps         | 490552        |
| value_loss              | 3.5237637e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087134825 |
| ent_coef_loss           | -0.1777237    |
| entropy                 | 1.2683549     |
| episodes                | 2220          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 491128        |
| policy_loss             | -0.585595     |
| qf1_loss                | 1.831328e-05  |
| qf2_loss                | 1.3946852e-05 |
| time_elapsed            | 2528          |
| total timesteps         | 491228        |
| value_loss              | 3.7709986e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009278626  |
| ent_coef_loss           | 4.4262013     |
| entropy                 | 1.1362895     |
| episodes                | 2224          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 491941        |
| policy_loss             | -0.51518756   |
| qf1_loss                | 0.00013929917 |
| qf2_loss                | 0.0001262246  |
| time_elapsed            | 2532          |
| total timesteps         | 492041        |
| value_loss              | 0.00010387132 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089369726 |
| ent_coef_loss           | 2.0184445     |
| entropy                 | 1.0844909     |
| episodes                | 2228          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 492672        |
| policy_loss             | -0.52260995   |
| qf1_loss                | 3.4900684e-05 |
| qf2_loss                | 3.2009535e-05 |
| time_elapsed            | 2536          |
| total timesteps         | 492772        |
| value_loss              | 7.36253e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085585524 |
| ent_coef_loss           | -3.1415083    |
| entropy                 | 1.1244457     |
| episodes                | 2232          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 493384        |
| policy_loss             | -0.54863524   |
| qf1_loss                | 2.5218797e-05 |
| qf2_loss                | 8.641486e-05  |
| time_elapsed            | 2540          |
| total timesteps         | 493484        |
| value_loss              | 0.00021398923 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086698163 |
| ent_coef_loss           | -0.42252743   |
| entropy                 | 1.1243635     |
| episodes                | 2236          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 494026        |
| policy_loss             | -0.54326      |
| qf1_loss                | 5.3472733e-05 |
| qf2_loss                | 4.0080486e-05 |
| time_elapsed            | 2543          |
| total timesteps         | 494126        |
| value_loss              | 3.036744e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00077975605 |
| ent_coef_loss           | 0.36297727    |
| entropy                 | 1.3390193     |
| episodes                | 2240          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 494892        |
| policy_loss             | -0.52875966   |
| qf1_loss                | 3.4300632e-05 |
| qf2_loss                | 3.478471e-05  |
| time_elapsed            | 2547          |
| total timesteps         | 494992        |
| value_loss              | 5.480506e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00080689706 |
| ent_coef_loss           | -0.27585912   |
| entropy                 | 1.150442      |
| episodes                | 2244          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 495730        |
| policy_loss             | -0.5273804    |
| qf1_loss                | 2.7655184e-05 |
| qf2_loss                | 2.6380061e-05 |
| time_elapsed            | 2552          |
| total timesteps         | 495830        |
| value_loss              | 3.7091355e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008207865  |
| ent_coef_loss           | 1.3794228     |
| entropy                 | 0.8860675     |
| episodes                | 2248          |
| fps                     | 194           |
| mean 100 episode reward | 0.9           |
| n_updates               | 496484        |
| policy_loss             | -0.48709482   |
| qf1_loss                | 4.908331e-05  |
| qf2_loss                | 2.8474937e-05 |
| time_elapsed            | 2555          |
| total timesteps         | 496584        |
| value_loss              | 6.205328e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007753584  |
| ent_coef_loss           | -0.77274716   |
| entropy                 | 1.1474265     |
| episodes                | 2252          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 497073        |
| policy_loss             | -0.5834982    |
| qf1_loss                | 1.6581798e-05 |
| qf2_loss                | 1.0627279e-05 |
| time_elapsed            | 2558          |
| total timesteps         | 497173        |
| value_loss              | 3.0369345e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00079817016 |
| ent_coef_loss           | 2.7765658     |
| entropy                 | 1.1383498     |
| episodes                | 2256          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 497762        |
| policy_loss             | -0.55418456   |
| qf1_loss                | 2.332889e-05  |
| qf2_loss                | 2.0300202e-05 |
| time_elapsed            | 2562          |
| total timesteps         | 497862        |
| value_loss              | 2.6479465e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00088138954 |
| ent_coef_loss           | -1.8018259    |
| entropy                 | 1.1289124     |
| episodes                | 2260          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 498570        |
| policy_loss             | -0.5851562    |
| qf1_loss                | 9.839392e-05  |
| qf2_loss                | 2.3809436e-05 |
| time_elapsed            | 2566          |
| total timesteps         | 498670        |
| value_loss              | 3.5219295e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00080288824 |
| ent_coef_loss           | 1.100076      |
| entropy                 | 0.92387605    |
| episodes                | 2264          |
| fps                     | 194           |
| mean 100 episode reward | 0.8           |
| n_updates               | 499347        |
| policy_loss             | -0.5682908    |
| qf1_loss                | 6.64974e-05   |
| qf2_loss                | 6.028716e-05  |
| time_elapsed            | 2570          |
| total timesteps         | 499447        |
| value_loss              | 5.340801e-05  |
-------------------------------------------
>>>>> End testing <<<<< decay:_0__nn_layers:_[64__64]
Final weights saved at:  /home/admin/tensorboard_logs/sac_decay:_0__nn_layers:_[64__64]/stable_baselines.pkl
TEST COMMAND: python3 py3_learning.py --test --weights  /home/admin/tensorboard_logs/sac_decay:_0__nn_layers:_[64__64]/stable_baselines.pkl
Starting test with params: {'nn_layers': [512, 256, 128]}
Namespace(draw_screen=False, env_config='configs/env.config', policy='multi_human_rl', policy_config='configs/policy.config', test=False, train_config='configs/train.config', weights=None)
Gym environment created.
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.54352766   |
| ent_coef_loss           | -2.0552883   |
| entropy                 | 2.6006825    |
| episodes                | 4            |
| fps                     | 191          |
| mean 100 episode reward | -0.1         |
| n_updates               | 1220         |
| policy_loss             | -5.2710066   |
| qf1_loss                | 0.002479468  |
| qf2_loss                | 0.0028789404 |
| time_elapsed            | 6            |
| total timesteps         | 1320         |
| value_loss              | 0.005942839  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.2255988    |
| ent_coef_loss           | -4.9180517   |
| entropy                 | 2.7066488    |
| episodes                | 8            |
| fps                     | 192          |
| mean 100 episode reward | -0.1         |
| n_updates               | 2980         |
| policy_loss             | -8.469685    |
| qf1_loss                | 0.0044855643 |
| qf2_loss                | 0.005250236  |
| time_elapsed            | 15           |
| total timesteps         | 3080         |
| value_loss              | 0.014540642  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.093967     |
| ent_coef_loss           | -7.7720957   |
| entropy                 | 2.716731     |
| episodes                | 12           |
| fps                     | 191          |
| mean 100 episode reward | -0.1         |
| n_updates               | 4740         |
| policy_loss             | -8.841097    |
| qf1_loss                | 0.0023200035 |
| qf2_loss                | 0.0029443854 |
| time_elapsed            | 25           |
| total timesteps         | 4840         |
| value_loss              | 0.006804662  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.03974194   |
| ent_coef_loss           | -9.806084    |
| entropy                 | 2.9921975    |
| episodes                | 16           |
| fps                     | 192          |
| mean 100 episode reward | -0.1         |
| n_updates               | 6500         |
| policy_loss             | -8.432138    |
| qf1_loss                | 0.024159184  |
| qf2_loss                | 0.022457957  |
| time_elapsed            | 34           |
| total timesteps         | 6600         |
| value_loss              | 0.0155736115 |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0005      |
| ent_coef                | 0.021876873 |
| ent_coef_loss           | -3.6678977  |
| entropy                 | 2.850493    |
| episodes                | 20          |
| fps                     | 192         |
| mean 100 episode reward | -0.1        |
| n_updates               | 8260        |
| policy_loss             | -8.087196   |
| qf1_loss                | 0.01002085  |
| qf2_loss                | 0.010467684 |
| time_elapsed            | 43          |
| total timesteps         | 8360        |
| value_loss              | 0.023030873 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0131158    |
| ent_coef_loss           | -5.5279484   |
| entropy                 | 2.699355     |
| episodes                | 24           |
| fps                     | 191          |
| mean 100 episode reward | -0.2         |
| n_updates               | 9617         |
| policy_loss             | -7.7184567   |
| qf1_loss                | 0.0076425513 |
| qf2_loss                | 0.0060283765 |
| time_elapsed            | 50           |
| total timesteps         | 9717         |
| value_loss              | 0.013341999  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0083689215 |
| ent_coef_loss           | -2.894923    |
| entropy                 | 1.6796477    |
| episodes                | 28           |
| fps                     | 191          |
| mean 100 episode reward | -0.2         |
| n_updates               | 11377        |
| policy_loss             | -6.8403234   |
| qf1_loss                | 0.014483667  |
| qf2_loss                | 0.015372759  |
| time_elapsed            | 59           |
| total timesteps         | 11477        |
| value_loss              | 0.012667328  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.005509323  |
| ent_coef_loss           | -3.6966624   |
| entropy                 | 0.27189738   |
| episodes                | 32           |
| fps                     | 191          |
| mean 100 episode reward | -0.2         |
| n_updates               | 13137        |
| policy_loss             | -6.3479548   |
| qf1_loss                | 0.32975858   |
| qf2_loss                | 0.32734635   |
| time_elapsed            | 68           |
| total timesteps         | 13237        |
| value_loss              | 0.0014440176 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.004635954  |
| ent_coef_loss           | 0.39527497   |
| entropy                 | -0.43186486  |
| episodes                | 36           |
| fps                     | 191          |
| mean 100 episode reward | -0.2         |
| n_updates               | 14897        |
| policy_loss             | -5.7223477   |
| qf1_loss                | 0.0025888355 |
| qf2_loss                | 0.0029483777 |
| time_elapsed            | 78           |
| total timesteps         | 14997        |
| value_loss              | 0.014864678  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.004349526  |
| ent_coef_loss           | -1.4948406   |
| entropy                 | -0.42618954  |
| episodes                | 40           |
| fps                     | 191          |
| mean 100 episode reward | -0.2         |
| n_updates               | 16657        |
| policy_loss             | -5.239127    |
| qf1_loss                | 0.0010790187 |
| qf2_loss                | 0.0012727515 |
| time_elapsed            | 87           |
| total timesteps         | 16757        |
| value_loss              | 0.0006687677 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.004047492  |
| ent_coef_loss           | 4.2513895    |
| entropy                 | -0.107491516 |
| episodes                | 44           |
| fps                     | 192          |
| mean 100 episode reward | -0.2         |
| n_updates               | 18417        |
| policy_loss             | -4.6333504   |
| qf1_loss                | 0.0023941868 |
| qf2_loss                | 0.0019928557 |
| time_elapsed            | 96           |
| total timesteps         | 18517        |
| value_loss              | 0.0038751836 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0037572882 |
| ent_coef_loss           | -2.8996172   |
| entropy                 | 0.41835135   |
| episodes                | 48           |
| fps                     | 191          |
| mean 100 episode reward | -0.3         |
| n_updates               | 19469        |
| policy_loss             | -4.4406433   |
| qf1_loss                | 0.0035350148 |
| qf2_loss                | 0.0025873596 |
| time_elapsed            | 101          |
| total timesteps         | 19569        |
| value_loss              | 0.00664829   |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0033210423 |
| ent_coef_loss           | 0.93356735   |
| entropy                 | -0.16780058  |
| episodes                | 52           |
| fps                     | 191          |
| mean 100 episode reward | -0.2         |
| n_updates               | 21229        |
| policy_loss             | -4.0314074   |
| qf1_loss                | 0.0024855598 |
| qf2_loss                | 0.0023300953 |
| time_elapsed            | 111          |
| total timesteps         | 21329        |
| value_loss              | 0.005182737  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0030829923 |
| ent_coef_loss           | -1.4112427   |
| entropy                 | 0.25784022   |
| episodes                | 56           |
| fps                     | 191          |
| mean 100 episode reward | -0.2         |
| n_updates               | 22989        |
| policy_loss             | -3.5340672   |
| qf1_loss                | 0.0011157083 |
| qf2_loss                | 0.0012381956 |
| time_elapsed            | 120          |
| total timesteps         | 23089        |
| value_loss              | 0.001859109  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0025852034 |
| ent_coef_loss           | -2.0389998   |
| entropy                 | 0.18261455   |
| episodes                | 60           |
| fps                     | 191          |
| mean 100 episode reward | -0.3         |
| n_updates               | 24749        |
| policy_loss             | -3.5696769   |
| qf1_loss                | 0.0011046284 |
| qf2_loss                | 0.0011455409 |
| time_elapsed            | 129          |
| total timesteps         | 24849        |
| value_loss              | 0.0035328264 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0024052812  |
| ent_coef_loss           | -0.93365026   |
| entropy                 | -0.49560556   |
| episodes                | 64            |
| fps                     | 191           |
| mean 100 episode reward | -0.2          |
| n_updates               | 26509         |
| policy_loss             | -3.0408244    |
| qf1_loss                | 0.0010004189  |
| qf2_loss                | 0.0011491773  |
| time_elapsed            | 138           |
| total timesteps         | 26609         |
| value_loss              | 0.00038097624 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0020486873  |
| ent_coef_loss           | -1.6516466    |
| entropy                 | -0.44158894   |
| episodes                | 68            |
| fps                     | 191           |
| mean 100 episode reward | -0.2          |
| n_updates               | 27925         |
| policy_loss             | -2.8127978    |
| qf1_loss                | 0.0005122988  |
| qf2_loss                | 0.00054869865 |
| time_elapsed            | 146           |
| total timesteps         | 28025         |
| value_loss              | 0.0011869742  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0019568258  |
| ent_coef_loss           | -2.4857755    |
| entropy                 | -0.17816696   |
| episodes                | 72            |
| fps                     | 191           |
| mean 100 episode reward | -0.2          |
| n_updates               | 29685         |
| policy_loss             | -2.5241146    |
| qf1_loss                | 0.00087018433 |
| qf2_loss                | 0.0007003958  |
| time_elapsed            | 155           |
| total timesteps         | 29785         |
| value_loss              | 0.0020022262  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0016557337 |
| ent_coef_loss           | -3.3405035   |
| entropy                 | -0.3238489   |
| episodes                | 76           |
| fps                     | 191          |
| mean 100 episode reward | -0.2         |
| n_updates               | 31445        |
| policy_loss             | -2.4250445   |
| qf1_loss                | 0.0005662912 |
| qf2_loss                | 0.0005586032 |
| time_elapsed            | 164          |
| total timesteps         | 31545        |
| value_loss              | 0.0002598933 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0015407583  |
| ent_coef_loss           | 0.5287231     |
| entropy                 | -0.7610707    |
| episodes                | 80            |
| fps                     | 191           |
| mean 100 episode reward | -0.3          |
| n_updates               | 32829         |
| policy_loss             | -2.2495403    |
| qf1_loss                | 0.00049460016 |
| qf2_loss                | 0.00052031927 |
| time_elapsed            | 171           |
| total timesteps         | 32929         |
| value_loss              | 0.001053993   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013272733  |
| ent_coef_loss           | -1.4491409    |
| entropy                 | -0.79670966   |
| episodes                | 84            |
| fps                     | 191           |
| mean 100 episode reward | -0.3          |
| n_updates               | 34589         |
| policy_loss             | -2.027044     |
| qf1_loss                | 0.00035784824 |
| qf2_loss                | 0.0003626019  |
| time_elapsed            | 180           |
| total timesteps         | 34689         |
| value_loss              | 0.00022982803 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012507321  |
| ent_coef_loss           | -0.275599     |
| entropy                 | -0.78875923   |
| episodes                | 88            |
| fps                     | 191           |
| mean 100 episode reward | -0.3          |
| n_updates               | 36023         |
| policy_loss             | -1.8773303    |
| qf1_loss                | 0.00016937316 |
| qf2_loss                | 0.00010617325 |
| time_elapsed            | 188           |
| total timesteps         | 36123         |
| value_loss              | 6.36021e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012514134  |
| ent_coef_loss           | -0.22860676   |
| entropy                 | -0.51860285   |
| episodes                | 92            |
| fps                     | 191           |
| mean 100 episode reward | -0.3          |
| n_updates               | 37256         |
| policy_loss             | -1.7602704    |
| qf1_loss                | 0.00031081718 |
| qf2_loss                | 0.00020231491 |
| time_elapsed            | 194           |
| total timesteps         | 37356         |
| value_loss              | 0.00013977554 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.000969449  |
| ent_coef_loss           | -0.75744194  |
| entropy                 | -0.5131345   |
| episodes                | 96           |
| fps                     | 191          |
| mean 100 episode reward | -0.4         |
| n_updates               | 39016        |
| policy_loss             | -1.564052    |
| qf1_loss                | 0.006642792  |
| qf2_loss                | 0.006637543  |
| time_elapsed            | 203          |
| total timesteps         | 39116        |
| value_loss              | 0.0023772132 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009571609  |
| ent_coef_loss           | 1.3035532     |
| entropy                 | -0.68110275   |
| episodes                | 100           |
| fps                     | 191           |
| mean 100 episode reward | -0.4          |
| n_updates               | 40578         |
| policy_loss             | -1.4513035    |
| qf1_loss                | 0.0004273733  |
| qf2_loss                | 0.00032898659 |
| time_elapsed            | 211           |
| total timesteps         | 40678         |
| value_loss              | 0.00028032722 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009937377  |
| ent_coef_loss           | 0.004274845   |
| entropy                 | 0.39299184    |
| episodes                | 104           |
| fps                     | 191           |
| mean 100 episode reward | -0.4          |
| n_updates               | 42338         |
| policy_loss             | -1.2856977    |
| qf1_loss                | 0.00012743862 |
| qf2_loss                | 0.00010223397 |
| time_elapsed            | 221           |
| total timesteps         | 42438         |
| value_loss              | 9.1951995e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007652458  |
| ent_coef_loss           | 5.097572      |
| entropy                 | 0.1886152     |
| episodes                | 108           |
| fps                     | 191           |
| mean 100 episode reward | -0.5          |
| n_updates               | 44041         |
| policy_loss             | -1.1754661    |
| qf1_loss                | 0.00012838635 |
| qf2_loss                | 0.0001531151  |
| time_elapsed            | 230           |
| total timesteps         | 44141         |
| value_loss              | 0.00011393009 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008210817  |
| ent_coef_loss           | -0.87037593   |
| entropy                 | -0.21241847   |
| episodes                | 112           |
| fps                     | 191           |
| mean 100 episode reward | -0.5          |
| n_updates               | 45546         |
| policy_loss             | -1.0354517    |
| qf1_loss                | 0.0001121636  |
| qf2_loss                | 7.896825e-05  |
| time_elapsed            | 237           |
| total timesteps         | 45646         |
| value_loss              | 8.5164225e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0008550435 |
| ent_coef_loss           | -1.6111925   |
| entropy                 | 0.13977596   |
| episodes                | 116          |
| fps                     | 191          |
| mean 100 episode reward | -0.5         |
| n_updates               | 47031        |
| policy_loss             | -0.98594403  |
| qf1_loss                | 0.0040939003 |
| qf2_loss                | 0.0040283236 |
| time_elapsed            | 245          |
| total timesteps         | 47131        |
| value_loss              | 0.0001526416 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00081982743 |
| ent_coef_loss           | 1.4344928     |
| entropy                 | -0.48483178   |
| episodes                | 120           |
| fps                     | 191           |
| mean 100 episode reward | -0.6          |
| n_updates               | 48463         |
| policy_loss             | -0.9085855    |
| qf1_loss                | 0.007017904   |
| qf2_loss                | 0.006880805   |
| time_elapsed            | 252           |
| total timesteps         | 48563         |
| value_loss              | 4.4110096e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008505464  |
| ent_coef_loss           | -7.292515     |
| entropy                 | 0.0734775     |
| episodes                | 124           |
| fps                     | 191           |
| mean 100 episode reward | -0.6          |
| n_updates               | 49948         |
| policy_loss             | -0.8041554    |
| qf1_loss                | 0.00036921987 |
| qf2_loss                | 0.00077948294 |
| time_elapsed            | 260           |
| total timesteps         | 50048         |
| value_loss              | 0.000601377   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008236439  |
| ent_coef_loss           | -6.241203     |
| entropy                 | 0.16085282    |
| episodes                | 128           |
| fps                     | 191           |
| mean 100 episode reward | -0.7          |
| n_updates               | 51126         |
| policy_loss             | -0.751729     |
| qf1_loss                | 6.197743e-05  |
| qf2_loss                | 8.389517e-05  |
| time_elapsed            | 267           |
| total timesteps         | 51226         |
| value_loss              | 0.00025637017 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00071085844 |
| ent_coef_loss           | 2.834446      |
| entropy                 | 0.7829049     |
| episodes                | 132           |
| fps                     | 191           |
| mean 100 episode reward | -0.8          |
| n_updates               | 52886         |
| policy_loss             | -0.6392229    |
| qf1_loss                | 0.00013809485 |
| qf2_loss                | 0.00014680627 |
| time_elapsed            | 276           |
| total timesteps         | 52986         |
| value_loss              | 0.00016455873 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00078675436 |
| ent_coef_loss           | 8.992313      |
| entropy                 | 0.61041874    |
| episodes                | 136           |
| fps                     | 191           |
| mean 100 episode reward | -0.8          |
| n_updates               | 54646         |
| policy_loss             | -0.59429      |
| qf1_loss                | 5.294516e-05  |
| qf2_loss                | 6.686493e-05  |
| time_elapsed            | 285           |
| total timesteps         | 54746         |
| value_loss              | 0.00029216183 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0008732383 |
| ent_coef_loss           | -0.24028501  |
| entropy                 | 0.8225108    |
| episodes                | 140          |
| fps                     | 191          |
| mean 100 episode reward | -0.8         |
| n_updates               | 56406        |
| policy_loss             | -0.5263791   |
| qf1_loss                | 7.988814e-05 |
| qf2_loss                | 8.739788e-05 |
| time_elapsed            | 294          |
| total timesteps         | 56506        |
| value_loss              | 8.354858e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007176927  |
| ent_coef_loss           | -1.1097394    |
| entropy                 | -0.40814716   |
| episodes                | 144           |
| fps                     | 191           |
| mean 100 episode reward | -0.8          |
| n_updates               | 58166         |
| policy_loss             | -0.45526898   |
| qf1_loss                | 0.00066001393 |
| qf2_loss                | 0.00059820246 |
| time_elapsed            | 303           |
| total timesteps         | 58266         |
| value_loss              | 4.852457e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00064112426 |
| ent_coef_loss           | -0.44225985   |
| entropy                 | -0.19021545   |
| episodes                | 148           |
| fps                     | 191           |
| mean 100 episode reward | -0.8          |
| n_updates               | 59926         |
| policy_loss             | -0.38340682   |
| qf1_loss                | 0.008721286   |
| qf2_loss                | 0.0082691675  |
| time_elapsed            | 312           |
| total timesteps         | 60026         |
| value_loss              | 4.6392124e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0005559058  |
| ent_coef_loss           | -2.997565     |
| entropy                 | -0.6364728    |
| episodes                | 152           |
| fps                     | 191           |
| mean 100 episode reward | -0.8          |
| n_updates               | 61686         |
| policy_loss             | -0.34959272   |
| qf1_loss                | 5.8622783e-05 |
| qf2_loss                | 5.2975694e-05 |
| time_elapsed            | 322           |
| total timesteps         | 61786         |
| value_loss              | 3.2235894e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0005968565  |
| ent_coef_loss           | 1.9350216     |
| entropy                 | -0.24153745   |
| episodes                | 156           |
| fps                     | 191           |
| mean 100 episode reward | -0.8          |
| n_updates               | 63446         |
| policy_loss             | -0.2544192    |
| qf1_loss                | 5.0637987e-05 |
| qf2_loss                | 6.160165e-05  |
| time_elapsed            | 331           |
| total timesteps         | 63546         |
| value_loss              | 4.6647972e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00050943287 |
| ent_coef_loss           | 1.9559474     |
| entropy                 | -0.03329472   |
| episodes                | 160           |
| fps                     | 191           |
| mean 100 episode reward | -0.8          |
| n_updates               | 64892         |
| policy_loss             | -0.2559054    |
| qf1_loss                | 3.5677258e-05 |
| qf2_loss                | 5.0105053e-05 |
| time_elapsed            | 338           |
| total timesteps         | 64992         |
| value_loss              | 6.158643e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00047017034 |
| ent_coef_loss           | 0.691755      |
| entropy                 | -0.2875144    |
| episodes                | 164           |
| fps                     | 191           |
| mean 100 episode reward | -0.8          |
| n_updates               | 66454         |
| policy_loss             | -0.20764092   |
| qf1_loss                | 4.7224952e-05 |
| qf2_loss                | 5.431602e-05  |
| time_elapsed            | 347           |
| total timesteps         | 66554         |
| value_loss              | 8.547197e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00052347826 |
| ent_coef_loss           | -0.24282587   |
| entropy                 | 0.21922722    |
| episodes                | 168           |
| fps                     | 191           |
| mean 100 episode reward | -0.8          |
| n_updates               | 68214         |
| policy_loss             | -0.16225518   |
| qf1_loss                | 9.0061585e-05 |
| qf2_loss                | 8.3293635e-05 |
| time_elapsed            | 356           |
| total timesteps         | 68314         |
| value_loss              | 8.2880186e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007719022  |
| ent_coef_loss           | -1.3558596    |
| entropy                 | 0.23346126    |
| episodes                | 172           |
| fps                     | 191           |
| mean 100 episode reward | -0.8          |
| n_updates               | 69974         |
| policy_loss             | -0.13587274   |
| qf1_loss                | 2.7698487e-05 |
| qf2_loss                | 2.3855064e-05 |
| time_elapsed            | 365           |
| total timesteps         | 70074         |
| value_loss              | 4.12554e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000704757   |
| ent_coef_loss           | 1.23852       |
| entropy                 | 0.35894737    |
| episodes                | 176           |
| fps                     | 191           |
| mean 100 episode reward | -0.8          |
| n_updates               | 71734         |
| policy_loss             | -0.119561344  |
| qf1_loss                | 0.00012815044 |
| qf2_loss                | 0.00013606876 |
| time_elapsed            | 374           |
| total timesteps         | 71834         |
| value_loss              | 0.00017561362 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006967187  |
| ent_coef_loss           | -3.936328     |
| entropy                 | 0.5782416     |
| episodes                | 180           |
| fps                     | 191           |
| mean 100 episode reward | -0.8          |
| n_updates               | 73462         |
| policy_loss             | -0.11401367   |
| qf1_loss                | 4.7331676e-05 |
| qf2_loss                | 3.5480298e-05 |
| time_elapsed            | 383           |
| total timesteps         | 73562         |
| value_loss              | 5.2239513e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0005398383  |
| ent_coef_loss           | -2.8855076    |
| entropy                 | -0.18470895   |
| episodes                | 184           |
| fps                     | 191           |
| mean 100 episode reward | -0.8          |
| n_updates               | 75222         |
| policy_loss             | -0.10534415   |
| qf1_loss                | 0.00094721006 |
| qf2_loss                | 0.00092599425 |
| time_elapsed            | 392           |
| total timesteps         | 75322         |
| value_loss              | 7.27467e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00051003444 |
| ent_coef_loss           | 3.5665298     |
| entropy                 | 0.19552362    |
| episodes                | 188           |
| fps                     | 191           |
| mean 100 episode reward | -0.7          |
| n_updates               | 76982         |
| policy_loss             | -0.10904726   |
| qf1_loss                | 6.9044385e-05 |
| qf2_loss                | 0.00011169768 |
| time_elapsed            | 402           |
| total timesteps         | 77082         |
| value_loss              | 0.00013344953 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00050188345 |
| ent_coef_loss           | -3.075127     |
| entropy                 | -0.090566285  |
| episodes                | 192           |
| fps                     | 191           |
| mean 100 episode reward | -0.7          |
| n_updates               | 78519         |
| policy_loss             | -0.10039915   |
| qf1_loss                | 3.2504355e-05 |
| qf2_loss                | 5.291671e-05  |
| time_elapsed            | 410           |
| total timesteps         | 78619         |
| value_loss              | 6.371566e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00046394413 |
| ent_coef_loss           | -1.539247     |
| entropy                 | 0.2462137     |
| episodes                | 196           |
| fps                     | 191           |
| mean 100 episode reward | -0.7          |
| n_updates               | 80279         |
| policy_loss             | -0.08238304   |
| qf1_loss                | 0.00029082317 |
| qf2_loss                | 0.00022859157 |
| time_elapsed            | 419           |
| total timesteps         | 80379         |
| value_loss              | 0.00012573114 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00045193033 |
| ent_coef_loss           | -1.617777     |
| entropy                 | -0.0646192    |
| episodes                | 200           |
| fps                     | 191           |
| mean 100 episode reward | -0.6          |
| n_updates               | 82039         |
| policy_loss             | -0.08209687   |
| qf1_loss                | 0.00039374316 |
| qf2_loss                | 0.0005319421  |
| time_elapsed            | 428           |
| total timesteps         | 82139         |
| value_loss              | 0.0001200165  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00044793234 |
| ent_coef_loss           | 4.796755      |
| entropy                 | 0.10687362    |
| episodes                | 204           |
| fps                     | 191           |
| mean 100 episode reward | -0.6          |
| n_updates               | 83196         |
| policy_loss             | -0.074878365  |
| qf1_loss                | 0.00081864325 |
| qf2_loss                | 0.00066049444 |
| time_elapsed            | 434           |
| total timesteps         | 83296         |
| value_loss              | 5.5780005e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00039048996 |
| ent_coef_loss           | 0.46535563    |
| entropy                 | -0.072438635  |
| episodes                | 208           |
| fps                     | 191           |
| mean 100 episode reward | -0.5          |
| n_updates               | 84606         |
| policy_loss             | -0.08618334   |
| qf1_loss                | 4.067476e-05  |
| qf2_loss                | 5.7060177e-05 |
| time_elapsed            | 442           |
| total timesteps         | 84706         |
| value_loss              | 9.6031814e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0005089143  |
| ent_coef_loss           | 2.4438658     |
| entropy                 | 0.23831254    |
| episodes                | 212           |
| fps                     | 191           |
| mean 100 episode reward | -0.5          |
| n_updates               | 86190         |
| policy_loss             | -0.052964002  |
| qf1_loss                | 3.527021e-05  |
| qf2_loss                | 2.7317798e-05 |
| time_elapsed            | 450           |
| total timesteps         | 86290         |
| value_loss              | 5.677446e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0003594377  |
| ent_coef_loss           | -0.80316496   |
| entropy                 | -0.13020279   |
| episodes                | 216           |
| fps                     | 191           |
| mean 100 episode reward | -0.5          |
| n_updates               | 87760         |
| policy_loss             | -0.053152308  |
| qf1_loss                | 0.00011718603 |
| qf2_loss                | 8.5757136e-05 |
| time_elapsed            | 458           |
| total timesteps         | 87860         |
| value_loss              | 5.719406e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0003569665  |
| ent_coef_loss           | -1.4282845    |
| entropy                 | 0.24672122    |
| episodes                | 220           |
| fps                     | 191           |
| mean 100 episode reward | -0.4          |
| n_updates               | 89520         |
| policy_loss             | -0.04117713   |
| qf1_loss                | 3.609307e-05  |
| qf2_loss                | 4.8211434e-05 |
| time_elapsed            | 468           |
| total timesteps         | 89620         |
| value_loss              | 6.1262246e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0003742165  |
| ent_coef_loss           | -0.29672658   |
| entropy                 | -0.06293311   |
| episodes                | 224           |
| fps                     | 191           |
| mean 100 episode reward | -0.3          |
| n_updates               | 90893         |
| policy_loss             | -0.03682886   |
| qf1_loss                | 5.5896086e-05 |
| qf2_loss                | 8.4555395e-05 |
| time_elapsed            | 475           |
| total timesteps         | 90993         |
| value_loss              | 0.000111607   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00042611052 |
| ent_coef_loss           | 2.7099457     |
| entropy                 | -0.10520865   |
| episodes                | 228           |
| fps                     | 191           |
| mean 100 episode reward | -0.2          |
| n_updates               | 92653         |
| policy_loss             | -0.048963122  |
| qf1_loss                | 0.00047509832 |
| qf2_loss                | 0.000462691   |
| time_elapsed            | 484           |
| total timesteps         | 92753         |
| value_loss              | 5.2403484e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00047044686 |
| ent_coef_loss           | 2.0566907     |
| entropy                 | 0.08331461    |
| episodes                | 232           |
| fps                     | 191           |
| mean 100 episode reward | -0.2          |
| n_updates               | 94413         |
| policy_loss             | -0.039534353  |
| qf1_loss                | 0.00016600455 |
| qf2_loss                | 0.00015758949 |
| time_elapsed            | 493           |
| total timesteps         | 94513         |
| value_loss              | 5.204856e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0005943119  |
| ent_coef_loss           | -1.0321803    |
| entropy                 | 0.28972128    |
| episodes                | 236           |
| fps                     | 191           |
| mean 100 episode reward | -0.2          |
| n_updates               | 96173         |
| policy_loss             | -0.08896042   |
| qf1_loss                | 3.3544875e-05 |
| qf2_loss                | 4.4521752e-05 |
| time_elapsed            | 502           |
| total timesteps         | 96273         |
| value_loss              | 5.434001e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0005912073  |
| ent_coef_loss           | 2.5429919     |
| entropy                 | 0.3719085     |
| episodes                | 240           |
| fps                     | 191           |
| mean 100 episode reward | -0.2          |
| n_updates               | 97705         |
| policy_loss             | -0.07091909   |
| qf1_loss                | 0.0019054932  |
| qf2_loss                | 0.0019607362  |
| time_elapsed            | 510           |
| total timesteps         | 97805         |
| value_loss              | 7.2907584e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007330571  |
| ent_coef_loss           | -2.3108156    |
| entropy                 | 0.6746504     |
| episodes                | 244           |
| fps                     | 191           |
| mean 100 episode reward | -0.1          |
| n_updates               | 99194         |
| policy_loss             | -0.055564485  |
| qf1_loss                | 4.6746532e-05 |
| qf2_loss                | 4.613195e-05  |
| time_elapsed            | 518           |
| total timesteps         | 99294         |
| value_loss              | 3.3688048e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000793029   |
| ent_coef_loss           | 1.5059222     |
| entropy                 | 0.6465095     |
| episodes                | 248           |
| fps                     | 191           |
| mean 100 episode reward | -0.1          |
| n_updates               | 100744        |
| policy_loss             | -0.11434387   |
| qf1_loss                | 3.5642108e-05 |
| qf2_loss                | 3.7403355e-05 |
| time_elapsed            | 526           |
| total timesteps         | 100844        |
| value_loss              | 9.823088e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007127466  |
| ent_coef_loss           | -2.225642     |
| entropy                 | 0.75879455    |
| episodes                | 252           |
| fps                     | 191           |
| mean 100 episode reward | -0.1          |
| n_updates               | 101789        |
| policy_loss             | -0.11327431   |
| qf1_loss                | 8.588806e-05  |
| qf2_loss                | 8.012069e-05  |
| time_elapsed            | 532           |
| total timesteps         | 101889        |
| value_loss              | 0.00017803918 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007043058  |
| ent_coef_loss           | 1.0458833     |
| entropy                 | 0.42179668    |
| episodes                | 256           |
| fps                     | 191           |
| mean 100 episode reward | -0            |
| n_updates               | 103002        |
| policy_loss             | -0.07849913   |
| qf1_loss                | 0.0002885416  |
| qf2_loss                | 0.0002687907  |
| time_elapsed            | 538           |
| total timesteps         | 103102        |
| value_loss              | 5.6362507e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00061448105 |
| ent_coef_loss           | -3.5279784    |
| entropy                 | 0.51342154    |
| episodes                | 260           |
| fps                     | 191           |
| mean 100 episode reward | -0.1          |
| n_updates               | 104533        |
| policy_loss             | -0.12776421   |
| qf1_loss                | 0.00069607835 |
| qf2_loss                | 0.0009460701  |
| time_elapsed            | 546           |
| total timesteps         | 104633        |
| value_loss              | 0.00010734381 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007846762  |
| ent_coef_loss           | 4.823824      |
| entropy                 | 0.80624783    |
| episodes                | 264           |
| fps                     | 191           |
| mean 100 episode reward | -0            |
| n_updates               | 106096        |
| policy_loss             | -0.12517945   |
| qf1_loss                | 7.499788e-05  |
| qf2_loss                | 8.164684e-05  |
| time_elapsed            | 554           |
| total timesteps         | 106196        |
| value_loss              | 4.6000998e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00075919175 |
| ent_coef_loss           | 0.6409536     |
| entropy                 | 0.62414384    |
| episodes                | 268           |
| fps                     | 191           |
| mean 100 episode reward | 0             |
| n_updates               | 107579        |
| policy_loss             | -0.12195338   |
| qf1_loss                | 8.995313e-05  |
| qf2_loss                | 8.231657e-05  |
| time_elapsed            | 562           |
| total timesteps         | 107679        |
| value_loss              | 6.6519664e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.000838264    |
| ent_coef_loss           | -3.6440625     |
| entropy                 | 0.5226033      |
| episodes                | 272            |
| fps                     | 191            |
| mean 100 episode reward | 0              |
| n_updates               | 109339         |
| policy_loss             | -0.0894201     |
| qf1_loss                | 6.200239e-05   |
| qf2_loss                | 6.1047685e-05  |
| time_elapsed            | 571            |
| total timesteps         | 109439         |
| value_loss              | 0.000118151605 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091249007 |
| ent_coef_loss           | -1.4655823    |
| entropy                 | 1.0979979     |
| episodes                | 276           |
| fps                     | 191           |
| mean 100 episode reward | 0             |
| n_updates               | 111099        |
| policy_loss             | -0.12280167   |
| qf1_loss                | 3.333729e-05  |
| qf2_loss                | 4.240738e-05  |
| time_elapsed            | 580           |
| total timesteps         | 111199        |
| value_loss              | 7.996647e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0007129655 |
| ent_coef_loss           | -0.2213645   |
| entropy                 | 0.5538321    |
| episodes                | 280          |
| fps                     | 191          |
| mean 100 episode reward | 0            |
| n_updates               | 112614       |
| policy_loss             | -0.12626255  |
| qf1_loss                | 0.0044788285 |
| qf2_loss                | 0.0056389244 |
| time_elapsed            | 589          |
| total timesteps         | 112714       |
| value_loss              | 6.621955e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008171956  |
| ent_coef_loss           | -1.8232478    |
| entropy                 | 0.4679153     |
| episodes                | 284           |
| fps                     | 191           |
| mean 100 episode reward | -0            |
| n_updates               | 114374        |
| policy_loss             | -0.17151678   |
| qf1_loss                | 6.4478074e-05 |
| qf2_loss                | 9.910893e-05  |
| time_elapsed            | 598           |
| total timesteps         | 114474        |
| value_loss              | 0.00011951612 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00081668573 |
| ent_coef_loss           | -2.383561     |
| entropy                 | 0.3278705     |
| episodes                | 288           |
| fps                     | 191           |
| mean 100 episode reward | -0            |
| n_updates               | 116134        |
| policy_loss             | -0.13353077   |
| qf1_loss                | 0.00041637488 |
| qf2_loss                | 9.817253e-05  |
| time_elapsed            | 607           |
| total timesteps         | 116234        |
| value_loss              | 0.00015895726 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008294968  |
| ent_coef_loss           | -0.41309577   |
| entropy                 | 0.44857705    |
| episodes                | 292           |
| fps                     | 191           |
| mean 100 episode reward | -0            |
| n_updates               | 117461        |
| policy_loss             | -0.18819928   |
| qf1_loss                | 8.3336745e-05 |
| qf2_loss                | 0.00010983668 |
| time_elapsed            | 614           |
| total timesteps         | 117561        |
| value_loss              | 0.00021302052 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008636724  |
| ent_coef_loss           | 1.0251629     |
| entropy                 | 0.14022107    |
| episodes                | 296           |
| fps                     | 191           |
| mean 100 episode reward | 0             |
| n_updates               | 118347        |
| policy_loss             | -0.11739235   |
| qf1_loss                | 0.0006344555  |
| qf2_loss                | 0.00012632714 |
| time_elapsed            | 618           |
| total timesteps         | 118447        |
| value_loss              | 0.0005065457  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008522186  |
| ent_coef_loss           | -0.13053909   |
| entropy                 | 0.31790942    |
| episodes                | 300           |
| fps                     | 191           |
| mean 100 episode reward | 0             |
| n_updates               | 119536        |
| policy_loss             | -0.23653853   |
| qf1_loss                | 8.4720654e-05 |
| qf2_loss                | 4.1971827e-05 |
| time_elapsed            | 625           |
| total timesteps         | 119636        |
| value_loss              | 7.23613e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091155287 |
| ent_coef_loss           | 0.045114756   |
| entropy                 | 0.4370958     |
| episodes                | 304           |
| fps                     | 191           |
| mean 100 episode reward | 0             |
| n_updates               | 120759        |
| policy_loss             | -0.13918895   |
| qf1_loss                | 0.0015718694  |
| qf2_loss                | 0.0017237174  |
| time_elapsed            | 631           |
| total timesteps         | 120859        |
| value_loss              | 0.00013927979 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008864892  |
| ent_coef_loss           | -0.8536922    |
| entropy                 | 0.3935871     |
| episodes                | 308           |
| fps                     | 191           |
| mean 100 episode reward | 0             |
| n_updates               | 122260        |
| policy_loss             | -0.18358412   |
| qf1_loss                | 8.774492e-05  |
| qf2_loss                | 7.7314086e-05 |
| time_elapsed            | 639           |
| total timesteps         | 122360        |
| value_loss              | 0.00015878037 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008819983  |
| ent_coef_loss           | 0.3220359     |
| entropy                 | 0.51204175    |
| episodes                | 312           |
| fps                     | 191           |
| mean 100 episode reward | 0.1           |
| n_updates               | 123776        |
| policy_loss             | -0.17896755   |
| qf1_loss                | 0.00018762329 |
| qf2_loss                | 0.00016272366 |
| time_elapsed            | 647           |
| total timesteps         | 123876        |
| value_loss              | 9.260319e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00082839007 |
| ent_coef_loss           | -4.451375     |
| entropy                 | 0.45249483    |
| episodes                | 316           |
| fps                     | 191           |
| mean 100 episode reward | 0.1           |
| n_updates               | 125121        |
| policy_loss             | -0.2052475    |
| qf1_loss                | 4.0538736e-05 |
| qf2_loss                | 6.461772e-05  |
| time_elapsed            | 654           |
| total timesteps         | 125221        |
| value_loss              | 6.461912e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085542887 |
| ent_coef_loss           | -2.3042183    |
| entropy                 | 0.23916513    |
| episodes                | 320           |
| fps                     | 191           |
| mean 100 episode reward | 0.1           |
| n_updates               | 126544        |
| policy_loss             | -0.2657478    |
| qf1_loss                | 4.2987565e-05 |
| qf2_loss                | 9.7999255e-05 |
| time_elapsed            | 661           |
| total timesteps         | 126644        |
| value_loss              | 8.515521e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000879138   |
| ent_coef_loss           | 2.1203814     |
| entropy                 | 0.71597964    |
| episodes                | 324           |
| fps                     | 191           |
| mean 100 episode reward | 0.1           |
| n_updates               | 127697        |
| policy_loss             | -0.1913577    |
| qf1_loss                | 8.284168e-05  |
| qf2_loss                | 9.011944e-05  |
| time_elapsed            | 667           |
| total timesteps         | 127797        |
| value_loss              | 0.00010131033 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000821871   |
| ent_coef_loss           | -0.77750707   |
| entropy                 | 0.39200693    |
| episodes                | 328           |
| fps                     | 191           |
| mean 100 episode reward | 0.1           |
| n_updates               | 128715        |
| policy_loss             | -0.20237193   |
| qf1_loss                | 0.00013064971 |
| qf2_loss                | 8.8120214e-05 |
| time_elapsed            | 673           |
| total timesteps         | 128815        |
| value_loss              | 7.628424e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000724506   |
| ent_coef_loss           | 0.65320224    |
| entropy                 | -0.033053286  |
| episodes                | 332           |
| fps                     | 191           |
| mean 100 episode reward | 0.2           |
| n_updates               | 129956        |
| policy_loss             | -0.20111442   |
| qf1_loss                | 0.00014050915 |
| qf2_loss                | 0.00010049253 |
| time_elapsed            | 679           |
| total timesteps         | 130056        |
| value_loss              | 8.028041e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00078895624 |
| ent_coef_loss           | -0.43134624   |
| entropy                 | 0.26436394    |
| episodes                | 336           |
| fps                     | 191           |
| mean 100 episode reward | 0.2           |
| n_updates               | 131433        |
| policy_loss             | -0.20721956   |
| qf1_loss                | 0.00023653645 |
| qf2_loss                | 7.0967086e-05 |
| time_elapsed            | 687           |
| total timesteps         | 131533        |
| value_loss              | 4.7642898e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007717197  |
| ent_coef_loss           | 2.8817673     |
| entropy                 | 0.29388952    |
| episodes                | 340           |
| fps                     | 191           |
| mean 100 episode reward | 0.2           |
| n_updates               | 132734        |
| policy_loss             | -0.22416049   |
| qf1_loss                | 0.00011606102 |
| qf2_loss                | 0.00018791901 |
| time_elapsed            | 694           |
| total timesteps         | 132834        |
| value_loss              | 0.00013619963 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089380034 |
| ent_coef_loss           | 0.06186852    |
| entropy                 | 0.4810366     |
| episodes                | 344           |
| fps                     | 191           |
| mean 100 episode reward | 0.2           |
| n_updates               | 134076        |
| policy_loss             | -0.23354451   |
| qf1_loss                | 5.9951064e-05 |
| qf2_loss                | 7.557031e-05  |
| time_elapsed            | 701           |
| total timesteps         | 134176        |
| value_loss              | 6.5173306e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007936997  |
| ent_coef_loss           | -0.7822999    |
| entropy                 | 0.28115186    |
| episodes                | 348           |
| fps                     | 191           |
| mean 100 episode reward | 0.2           |
| n_updates               | 135130        |
| policy_loss             | -0.26095247   |
| qf1_loss                | 0.00023829401 |
| qf2_loss                | 0.00019346274 |
| time_elapsed            | 706           |
| total timesteps         | 135230        |
| value_loss              | 4.636922e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00079711014 |
| ent_coef_loss           | -0.13314867   |
| entropy                 | 0.37354812    |
| episodes                | 352           |
| fps                     | 191           |
| mean 100 episode reward | 0.2           |
| n_updates               | 136038        |
| policy_loss             | -0.23242727   |
| qf1_loss                | 9.0759466e-05 |
| qf2_loss                | 9.126893e-05  |
| time_elapsed            | 711           |
| total timesteps         | 136138        |
| value_loss              | 4.013234e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085323676 |
| ent_coef_loss           | -0.5216145    |
| entropy                 | 0.49746907    |
| episodes                | 356           |
| fps                     | 191           |
| mean 100 episode reward | 0.2           |
| n_updates               | 137047        |
| policy_loss             | -0.26466626   |
| qf1_loss                | 4.1643674e-05 |
| qf2_loss                | 5.16866e-05   |
| time_elapsed            | 716           |
| total timesteps         | 137147        |
| value_loss              | 5.047759e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090441166 |
| ent_coef_loss           | 0.44986683    |
| entropy                 | 0.544067      |
| episodes                | 360           |
| fps                     | 191           |
| mean 100 episode reward | 0.3           |
| n_updates               | 138240        |
| policy_loss             | -0.229836     |
| qf1_loss                | 0.0017890126  |
| qf2_loss                | 0.0017678085  |
| time_elapsed            | 723           |
| total timesteps         | 138340        |
| value_loss              | 7.469251e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007286635  |
| ent_coef_loss           | -0.7952895    |
| entropy                 | 0.31514183    |
| episodes                | 364           |
| fps                     | 191           |
| mean 100 episode reward | 0.3           |
| n_updates               | 139177        |
| policy_loss             | -0.2361961    |
| qf1_loss                | 0.00048223665 |
| qf2_loss                | 0.0004578374  |
| time_elapsed            | 728           |
| total timesteps         | 139277        |
| value_loss              | 0.00014589126 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00070883665 |
| ent_coef_loss           | 2.115099      |
| entropy                 | 0.27369022    |
| episodes                | 368           |
| fps                     | 191           |
| mean 100 episode reward | 0.3           |
| n_updates               | 140039        |
| policy_loss             | -0.30444515   |
| qf1_loss                | 3.486591e-05  |
| qf2_loss                | 2.754361e-05  |
| time_elapsed            | 732           |
| total timesteps         | 140139        |
| value_loss              | 0.000102794   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00079701707 |
| ent_coef_loss           | -0.55099857   |
| entropy                 | 0.48357725    |
| episodes                | 372           |
| fps                     | 191           |
| mean 100 episode reward | 0.3           |
| n_updates               | 140913        |
| policy_loss             | -0.28491953   |
| qf1_loss                | 7.768078e-05  |
| qf2_loss                | 6.275519e-05  |
| time_elapsed            | 737           |
| total timesteps         | 141013        |
| value_loss              | 9.565876e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00080791925 |
| ent_coef_loss           | -0.49168634   |
| entropy                 | 0.91417813    |
| episodes                | 376           |
| fps                     | 191           |
| mean 100 episode reward | 0.4           |
| n_updates               | 141979        |
| policy_loss             | -0.2373545    |
| qf1_loss                | 9.263227e-05  |
| qf2_loss                | 8.995524e-05  |
| time_elapsed            | 742           |
| total timesteps         | 142079        |
| value_loss              | 8.778078e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008236584  |
| ent_coef_loss           | 1.9657137     |
| entropy                 | 0.37128636    |
| episodes                | 380           |
| fps                     | 191           |
| mean 100 episode reward | 0.4           |
| n_updates               | 143408        |
| policy_loss             | -0.24159652   |
| qf1_loss                | 6.8656605e-05 |
| qf2_loss                | 7.084217e-05  |
| time_elapsed            | 750           |
| total timesteps         | 143508        |
| value_loss              | 0.00010652622 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00070735306 |
| ent_coef_loss           | 0.6545325     |
| entropy                 | 0.35258836    |
| episodes                | 384           |
| fps                     | 191           |
| mean 100 episode reward | 0.4           |
| n_updates               | 144736        |
| policy_loss             | -0.26635042   |
| qf1_loss                | 0.00031377023 |
| qf2_loss                | 0.00049284444 |
| time_elapsed            | 757           |
| total timesteps         | 144836        |
| value_loss              | 9.203429e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007570022  |
| ent_coef_loss           | 1.6711888     |
| entropy                 | 0.7143584     |
| episodes                | 388           |
| fps                     | 191           |
| mean 100 episode reward | 0.4           |
| n_updates               | 145796        |
| policy_loss             | -0.26142102   |
| qf1_loss                | 5.7737157e-05 |
| qf2_loss                | 8.959837e-05  |
| time_elapsed            | 762           |
| total timesteps         | 145896        |
| value_loss              | 8.5778214e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0008496919 |
| ent_coef_loss           | -3.5582545   |
| entropy                 | 0.5596262    |
| episodes                | 392          |
| fps                     | 191          |
| mean 100 episode reward | 0.5          |
| n_updates               | 146781       |
| policy_loss             | -0.26276746  |
| qf1_loss                | 7.96843e-05  |
| qf2_loss                | 5.486875e-05 |
| time_elapsed            | 767          |
| total timesteps         | 146881       |
| value_loss              | 4.28e-05     |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.000835113  |
| ent_coef_loss           | 1.8110592    |
| entropy                 | 0.5284646    |
| episodes                | 396          |
| fps                     | 191          |
| mean 100 episode reward | 0.5          |
| n_updates               | 147838       |
| policy_loss             | -0.25595134  |
| qf1_loss                | 0.0017468376 |
| qf2_loss                | 0.0010278872 |
| time_elapsed            | 773          |
| total timesteps         | 147938       |
| value_loss              | 8.506107e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009077177  |
| ent_coef_loss           | -1.1452762    |
| entropy                 | 0.8291235     |
| episodes                | 400           |
| fps                     | 191           |
| mean 100 episode reward | 0.5           |
| n_updates               | 148606        |
| policy_loss             | -0.2795174    |
| qf1_loss                | 6.3594314e-05 |
| qf2_loss                | 0.00011937015 |
| time_elapsed            | 777           |
| total timesteps         | 148706        |
| value_loss              | 6.546825e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086714205 |
| ent_coef_loss           | 4.2647076     |
| entropy                 | 0.6448268     |
| episodes                | 404           |
| fps                     | 191           |
| mean 100 episode reward | 0.5           |
| n_updates               | 149483        |
| policy_loss             | -0.28421408   |
| qf1_loss                | 8.8172994e-05 |
| qf2_loss                | 5.3616786e-05 |
| time_elapsed            | 782           |
| total timesteps         | 149583        |
| value_loss              | 9.830289e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008893411  |
| ent_coef_loss           | 1.7383572     |
| entropy                 | 0.71491706    |
| episodes                | 408           |
| fps                     | 191           |
| mean 100 episode reward | 0.5           |
| n_updates               | 150275        |
| policy_loss             | -0.28311506   |
| qf1_loss                | 0.00094996986 |
| qf2_loss                | 0.0008087588  |
| time_elapsed            | 786           |
| total timesteps         | 150375        |
| value_loss              | 9.8323326e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00084864197 |
| ent_coef_loss           | 1.6451088     |
| entropy                 | 0.6311618     |
| episodes                | 412           |
| fps                     | 191           |
| mean 100 episode reward | 0.6           |
| n_updates               | 151056        |
| policy_loss             | -0.3257185    |
| qf1_loss                | 6.5923065e-05 |
| qf2_loss                | 5.2443313e-05 |
| time_elapsed            | 790           |
| total timesteps         | 151156        |
| value_loss              | 6.707774e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0009784829 |
| ent_coef_loss           | -2.341526    |
| entropy                 | 0.7465704    |
| episodes                | 416          |
| fps                     | 191          |
| mean 100 episode reward | 0.6          |
| n_updates               | 151957       |
| policy_loss             | -0.26336777  |
| qf1_loss                | 8.457311e-05 |
| qf2_loss                | 9.088662e-05 |
| time_elapsed            | 794          |
| total timesteps         | 152057       |
| value_loss              | 9.892922e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096662773 |
| ent_coef_loss           | 0.22112572    |
| entropy                 | 0.7566769     |
| episodes                | 420           |
| fps                     | 191           |
| mean 100 episode reward | 0.6           |
| n_updates               | 152677        |
| policy_loss             | -0.260167     |
| qf1_loss                | 0.000129861   |
| qf2_loss                | 8.902701e-05  |
| time_elapsed            | 798           |
| total timesteps         | 152777        |
| value_loss              | 0.00034161724 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001030408   |
| ent_coef_loss           | 0.7446874     |
| entropy                 | 0.89910984    |
| episodes                | 424           |
| fps                     | 191           |
| mean 100 episode reward | 0.7           |
| n_updates               | 153416        |
| policy_loss             | -0.30252886   |
| qf1_loss                | 5.696034e-05  |
| qf2_loss                | 5.5765733e-05 |
| time_elapsed            | 802           |
| total timesteps         | 153516        |
| value_loss              | 5.996888e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009965564  |
| ent_coef_loss           | 2.5379562     |
| entropy                 | 0.73760355    |
| episodes                | 428           |
| fps                     | 191           |
| mean 100 episode reward | 0.7           |
| n_updates               | 154143        |
| policy_loss             | -0.31541106   |
| qf1_loss                | 0.00011008133 |
| qf2_loss                | 0.00023397506 |
| time_elapsed            | 806           |
| total timesteps         | 154243        |
| value_loss              | 0.0002605404  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009868247  |
| ent_coef_loss           | -4.354661     |
| entropy                 | 0.6221929     |
| episodes                | 432           |
| fps                     | 191           |
| mean 100 episode reward | 0.7           |
| n_updates               | 155270        |
| policy_loss             | -0.29398912   |
| qf1_loss                | 8.3600746e-05 |
| qf2_loss                | 5.371941e-05  |
| time_elapsed            | 812           |
| total timesteps         | 155370        |
| value_loss              | 5.3601718e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009444862  |
| ent_coef_loss           | 1.1280022     |
| entropy                 | 0.6247767     |
| episodes                | 436           |
| fps                     | 191           |
| mean 100 episode reward | 0.7           |
| n_updates               | 156184        |
| policy_loss             | -0.32157344   |
| qf1_loss                | 3.8090875e-05 |
| qf2_loss                | 3.395562e-05  |
| time_elapsed            | 817           |
| total timesteps         | 156284        |
| value_loss              | 5.5120712e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010671595  |
| ent_coef_loss           | 0.419841      |
| entropy                 | 0.7158667     |
| episodes                | 440           |
| fps                     | 191           |
| mean 100 episode reward | 0.7           |
| n_updates               | 157055        |
| policy_loss             | -0.37344435   |
| qf1_loss                | 4.1099614e-05 |
| qf2_loss                | 5.9873375e-05 |
| time_elapsed            | 821           |
| total timesteps         | 157155        |
| value_loss              | 0.0001387929  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000954658   |
| ent_coef_loss           | -0.016821891  |
| entropy                 | 0.88413036    |
| episodes                | 444           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 157883        |
| policy_loss             | -0.30078942   |
| qf1_loss                | 0.00061957113 |
| qf2_loss                | 0.0006113243  |
| time_elapsed            | 825           |
| total timesteps         | 157983        |
| value_loss              | 4.133489e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009842692  |
| ent_coef_loss           | 2.1187482     |
| entropy                 | 0.97651184    |
| episodes                | 448           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 158559        |
| policy_loss             | -0.3397407    |
| qf1_loss                | 7.7791745e-05 |
| qf2_loss                | 5.7724847e-05 |
| time_elapsed            | 829           |
| total timesteps         | 158659        |
| value_loss              | 6.063869e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010061384  |
| ent_coef_loss           | 0.41208354    |
| entropy                 | 0.9015725     |
| episodes                | 452           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 159297        |
| policy_loss             | -0.33246896   |
| qf1_loss                | 0.0008491158  |
| qf2_loss                | 0.00081746496 |
| time_elapsed            | 833           |
| total timesteps         | 159397        |
| value_loss              | 8.444507e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010363985  |
| ent_coef_loss           | 1.4899528     |
| entropy                 | 0.7249712     |
| episodes                | 456           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 160016        |
| policy_loss             | -0.3530017    |
| qf1_loss                | 5.3360847e-05 |
| qf2_loss                | 4.196239e-05  |
| time_elapsed            | 837           |
| total timesteps         | 160116        |
| value_loss              | 9.1281174e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011116383  |
| ent_coef_loss           | -0.72482264   |
| entropy                 | 0.7807559     |
| episodes                | 460           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 160771        |
| policy_loss             | -0.33818877   |
| qf1_loss                | 7.414081e-05  |
| qf2_loss                | 4.0559396e-05 |
| time_elapsed            | 841           |
| total timesteps         | 160871        |
| value_loss              | 0.00012974933 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010940684  |
| ent_coef_loss           | -1.3733488    |
| entropy                 | 1.0700275     |
| episodes                | 464           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 161794        |
| policy_loss             | -0.32670125   |
| qf1_loss                | 0.0006897728  |
| qf2_loss                | 0.00073197763 |
| time_elapsed            | 846           |
| total timesteps         | 161894        |
| value_loss              | 0.0001048603  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010937122  |
| ent_coef_loss           | -0.7791607    |
| entropy                 | 0.86933523    |
| episodes                | 468           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 162880        |
| policy_loss             | -0.37032703   |
| qf1_loss                | 4.2376312e-05 |
| qf2_loss                | 4.9564456e-05 |
| time_elapsed            | 852           |
| total timesteps         | 162980        |
| value_loss              | 4.6088804e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010478914  |
| ent_coef_loss           | -2.136783     |
| entropy                 | 1.1044589     |
| episodes                | 472           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 163875        |
| policy_loss             | -0.39756447   |
| qf1_loss                | 0.0040501715  |
| qf2_loss                | 0.0043165856  |
| time_elapsed            | 857           |
| total timesteps         | 163975        |
| value_loss              | 6.6609646e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010683988  |
| ent_coef_loss           | -3.1536894    |
| entropy                 | 1.0344188     |
| episodes                | 476           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 164732        |
| policy_loss             | -0.40922356   |
| qf1_loss                | 3.808643e-05  |
| qf2_loss                | 4.315028e-05  |
| time_elapsed            | 861           |
| total timesteps         | 164832        |
| value_loss              | 4.2330576e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010114968  |
| ent_coef_loss           | 2.2973204     |
| entropy                 | 0.7217876     |
| episodes                | 480           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 165469        |
| policy_loss             | -0.42428166   |
| qf1_loss                | 8.382289e-05  |
| qf2_loss                | 8.281351e-05  |
| time_elapsed            | 865           |
| total timesteps         | 165569        |
| value_loss              | 0.00012868374 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0010366506   |
| ent_coef_loss           | -0.17418927    |
| entropy                 | 0.7421711      |
| episodes                | 484            |
| fps                     | 191            |
| mean 100 episode reward | 0.8            |
| n_updates               | 166195         |
| policy_loss             | -0.4307835     |
| qf1_loss                | 0.0006109408   |
| qf2_loss                | 0.0006923417   |
| time_elapsed            | 869            |
| total timesteps         | 166295         |
| value_loss              | 0.000104405684 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010499206  |
| ent_coef_loss           | 1.9564008     |
| entropy                 | 0.86699057    |
| episodes                | 488           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 166902        |
| policy_loss             | -0.4236911    |
| qf1_loss                | 0.00020249363 |
| qf2_loss                | 0.00026275113 |
| time_elapsed            | 873           |
| total timesteps         | 167002        |
| value_loss              | 0.00024114359 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0009963525 |
| ent_coef_loss           | -2.6178446   |
| entropy                 | 0.7887161    |
| episodes                | 492          |
| fps                     | 191          |
| mean 100 episode reward | 0.9          |
| n_updates               | 167624       |
| policy_loss             | -0.40299872  |
| qf1_loss                | 7.295931e-05 |
| qf2_loss                | 4.515324e-05 |
| time_elapsed            | 876          |
| total timesteps         | 167724       |
| value_loss              | 9.172984e-05 |
------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0010452949   |
| ent_coef_loss           | 1.0855808      |
| entropy                 | 0.88696265     |
| episodes                | 496            |
| fps                     | 191            |
| mean 100 episode reward | 0.8            |
| n_updates               | 168503         |
| policy_loss             | -0.4205413     |
| qf1_loss                | 0.000111191664 |
| qf2_loss                | 0.00010481711  |
| time_elapsed            | 881            |
| total timesteps         | 168603         |
| value_loss              | 6.4878055e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010290454  |
| ent_coef_loss           | 2.229768      |
| entropy                 | 1.0332079     |
| episodes                | 500           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 169150        |
| policy_loss             | -0.5160682    |
| qf1_loss                | 0.00046852377 |
| qf2_loss                | 0.0005533492  |
| time_elapsed            | 884           |
| total timesteps         | 169250        |
| value_loss              | 7.279577e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010187157  |
| ent_coef_loss           | 0.25761104    |
| entropy                 | 0.99315846    |
| episodes                | 504           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 169896        |
| policy_loss             | -0.40740994   |
| qf1_loss                | 5.0589046e-05 |
| qf2_loss                | 2.6669437e-05 |
| time_elapsed            | 888           |
| total timesteps         | 169996        |
| value_loss              | 3.473965e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009957466  |
| ent_coef_loss           | -0.06998539   |
| entropy                 | 0.8471548     |
| episodes                | 508           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 170573        |
| policy_loss             | -0.4745495    |
| qf1_loss                | 4.2925352e-05 |
| qf2_loss                | 3.8561335e-05 |
| time_elapsed            | 892           |
| total timesteps         | 170673        |
| value_loss              | 6.0662365e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009791219  |
| ent_coef_loss           | -2.6237755    |
| entropy                 | 0.9209806     |
| episodes                | 512           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 171335        |
| policy_loss             | -0.4206897    |
| qf1_loss                | 0.0010421536  |
| qf2_loss                | 0.0011098842  |
| time_elapsed            | 896           |
| total timesteps         | 171435        |
| value_loss              | 0.00011800173 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010503498  |
| ent_coef_loss           | -1.3759558    |
| entropy                 | 0.9568789     |
| episodes                | 516           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 172068        |
| policy_loss             | -0.5122412    |
| qf1_loss                | 3.554637e-05  |
| qf2_loss                | 3.8205144e-05 |
| time_elapsed            | 900           |
| total timesteps         | 172168        |
| value_loss              | 8.198853e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0010487712   |
| ent_coef_loss           | -2.737253      |
| entropy                 | 0.9400679      |
| episodes                | 520            |
| fps                     | 191            |
| mean 100 episode reward | 0.8            |
| n_updates               | 172859         |
| policy_loss             | -0.49128434    |
| qf1_loss                | 0.00010990273  |
| qf2_loss                | 0.000101272504 |
| time_elapsed            | 904            |
| total timesteps         | 172959         |
| value_loss              | 0.00023112641  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097302895 |
| ent_coef_loss           | 1.9127423     |
| entropy                 | 1.1931483     |
| episodes                | 524           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 173682        |
| policy_loss             | -0.48412687   |
| qf1_loss                | 0.0008857484  |
| qf2_loss                | 0.00094267254 |
| time_elapsed            | 908           |
| total timesteps         | 173782        |
| value_loss              | 4.9308102e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010209258  |
| ent_coef_loss           | 1.8682272     |
| entropy                 | 1.1566961     |
| episodes                | 528           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 174443        |
| policy_loss             | -0.46470064   |
| qf1_loss                | 0.00010179315 |
| qf2_loss                | 0.00019755162 |
| time_elapsed            | 912           |
| total timesteps         | 174543        |
| value_loss              | 9.752755e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010906894  |
| ent_coef_loss           | -1.3820696    |
| entropy                 | 1.1125495     |
| episodes                | 532           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 175096        |
| policy_loss             | -0.49492562   |
| qf1_loss                | 0.00016248076 |
| qf2_loss                | 0.00012080298 |
| time_elapsed            | 915           |
| total timesteps         | 175196        |
| value_loss              | 0.00024599797 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0009991658 |
| ent_coef_loss           | -0.55553925  |
| entropy                 | 1.213876     |
| episodes                | 536          |
| fps                     | 191          |
| mean 100 episode reward | 0.8          |
| n_updates               | 175843       |
| policy_loss             | -0.5148822   |
| qf1_loss                | 4.515837e-05 |
| qf2_loss                | 4.328669e-05 |
| time_elapsed            | 920          |
| total timesteps         | 175943       |
| value_loss              | 7.07377e-05  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0009852229 |
| ent_coef_loss           | 1.3489177    |
| entropy                 | 1.2374983    |
| episodes                | 540          |
| fps                     | 191          |
| mean 100 episode reward | 0.8          |
| n_updates               | 176510       |
| policy_loss             | -0.47040734  |
| qf1_loss                | 7.706837e-05 |
| qf2_loss                | 6.359802e-05 |
| time_elapsed            | 923          |
| total timesteps         | 176610       |
| value_loss              | 7.292311e-05 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010173137 |
| ent_coef_loss           | 0.51038015   |
| entropy                 | 1.1270587    |
| episodes                | 544          |
| fps                     | 191          |
| mean 100 episode reward | 0.8          |
| n_updates               | 177193       |
| policy_loss             | -0.4272303   |
| qf1_loss                | 5.113524e-05 |
| qf2_loss                | 4.712875e-05 |
| time_elapsed            | 927          |
| total timesteps         | 177293       |
| value_loss              | 0.0001795638 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010334548  |
| ent_coef_loss           | -2.2269158    |
| entropy                 | 1.1154859     |
| episodes                | 548           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 177886        |
| policy_loss             | -0.4859029    |
| qf1_loss                | 4.3231496e-05 |
| qf2_loss                | 6.2207626e-05 |
| time_elapsed            | 930           |
| total timesteps         | 177986        |
| value_loss              | 4.8385216e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009939444  |
| ent_coef_loss           | 0.6970892     |
| entropy                 | 1.198256      |
| episodes                | 552           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 178636        |
| policy_loss             | -0.48425406   |
| qf1_loss                | 5.7063913e-05 |
| qf2_loss                | 5.2229767e-05 |
| time_elapsed            | 934           |
| total timesteps         | 178736        |
| value_loss              | 6.0800437e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010414615  |
| ent_coef_loss           | 2.4489536     |
| entropy                 | 1.1852468     |
| episodes                | 556           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 179319        |
| policy_loss             | -0.53758657   |
| qf1_loss                | 7.4498224e-05 |
| qf2_loss                | 7.31221e-05   |
| time_elapsed            | 938           |
| total timesteps         | 179419        |
| value_loss              | 6.302333e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009288112   |
| ent_coef_loss           | -3.5187085     |
| entropy                 | 1.0088099      |
| episodes                | 560            |
| fps                     | 191            |
| mean 100 episode reward | 0.8            |
| n_updates               | 180026         |
| policy_loss             | -0.43838388    |
| qf1_loss                | 0.000104392646 |
| qf2_loss                | 7.299015e-05   |
| time_elapsed            | 941            |
| total timesteps         | 180126         |
| value_loss              | 9.60458e-05    |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086729095 |
| ent_coef_loss           | -2.0247035    |
| entropy                 | 1.0399232     |
| episodes                | 564           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 180687        |
| policy_loss             | -0.49693972   |
| qf1_loss                | 0.00014893018 |
| qf2_loss                | 0.00013483802 |
| time_elapsed            | 945           |
| total timesteps         | 180787        |
| value_loss              | 7.075687e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00092882715  |
| ent_coef_loss           | -1.0940994     |
| entropy                 | 0.96795523     |
| episodes                | 568            |
| fps                     | 191            |
| mean 100 episode reward | 0.8            |
| n_updates               | 181334         |
| policy_loss             | -0.5152632     |
| qf1_loss                | 5.379222e-05   |
| qf2_loss                | 0.000101988306 |
| time_elapsed            | 948            |
| total timesteps         | 181434         |
| value_loss              | 9.5160656e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008883553  |
| ent_coef_loss           | -0.5515703    |
| entropy                 | 1.2607238     |
| episodes                | 572           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 182064        |
| policy_loss             | -0.54270124   |
| qf1_loss                | 4.9670758e-05 |
| qf2_loss                | 5.784156e-05  |
| time_elapsed            | 952           |
| total timesteps         | 182164        |
| value_loss              | 6.606685e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00081536744 |
| ent_coef_loss           | 2.6353433     |
| entropy                 | 1.1362154     |
| episodes                | 576           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 182912        |
| policy_loss             | -0.58152354   |
| qf1_loss                | 4.687868e-05  |
| qf2_loss                | 4.1273073e-05 |
| time_elapsed            | 957           |
| total timesteps         | 183012        |
| value_loss              | 4.2814507e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092514907 |
| ent_coef_loss           | -1.5447738    |
| entropy                 | 1.1810672     |
| episodes                | 580           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 183676        |
| policy_loss             | -0.49020028   |
| qf1_loss                | 7.897141e-05  |
| qf2_loss                | 5.781767e-05  |
| time_elapsed            | 961           |
| total timesteps         | 183776        |
| value_loss              | 0.00012429626 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009089369  |
| ent_coef_loss           | -3.7438288    |
| entropy                 | 1.3389065     |
| episodes                | 584           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 184290        |
| policy_loss             | -0.54085803   |
| qf1_loss                | 5.633617e-05  |
| qf2_loss                | 3.9638235e-05 |
| time_elapsed            | 964           |
| total timesteps         | 184390        |
| value_loss              | 0.00010923069 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008614169  |
| ent_coef_loss           | -1.8697486    |
| entropy                 | 1.1172093     |
| episodes                | 588           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 184989        |
| policy_loss             | -0.5111947    |
| qf1_loss                | 2.918988e-05  |
| qf2_loss                | 2.8572475e-05 |
| time_elapsed            | 967           |
| total timesteps         | 185089        |
| value_loss              | 3.0275725e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009170942  |
| ent_coef_loss           | 0.90913177    |
| entropy                 | 1.0737765     |
| episodes                | 592           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 185641        |
| policy_loss             | -0.5448995    |
| qf1_loss                | 2.4235225e-05 |
| qf2_loss                | 0.00011425645 |
| time_elapsed            | 971           |
| total timesteps         | 185741        |
| value_loss              | 0.00015447418 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000882013   |
| ent_coef_loss           | -2.0203605    |
| entropy                 | 1.0081098     |
| episodes                | 596           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 186342        |
| policy_loss             | -0.5251175    |
| qf1_loss                | 2.9753477e-05 |
| qf2_loss                | 2.8239047e-05 |
| time_elapsed            | 974           |
| total timesteps         | 186442        |
| value_loss              | 6.3885105e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008961159  |
| ent_coef_loss           | 0.3621204     |
| entropy                 | 1.1435931     |
| episodes                | 600           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 186996        |
| policy_loss             | -0.54003584   |
| qf1_loss                | 3.0504692e-05 |
| qf2_loss                | 6.5305896e-05 |
| time_elapsed            | 978           |
| total timesteps         | 187096        |
| value_loss              | 7.591658e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089676434 |
| ent_coef_loss           | 4.1297936     |
| entropy                 | 1.1624244     |
| episodes                | 604           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 187655        |
| policy_loss             | -0.52431715   |
| qf1_loss                | 2.899049e-05  |
| qf2_loss                | 4.511094e-05  |
| time_elapsed            | 982           |
| total timesteps         | 187755        |
| value_loss              | 4.1846397e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085901486 |
| ent_coef_loss           | -0.3131829    |
| entropy                 | 1.1660888     |
| episodes                | 608           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 188289        |
| policy_loss             | -0.5539723    |
| qf1_loss                | 0.00010548826 |
| qf2_loss                | 0.00011713381 |
| time_elapsed            | 985           |
| total timesteps         | 188389        |
| value_loss              | 6.763996e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086739927 |
| ent_coef_loss           | -0.7479288    |
| entropy                 | 1.2157619     |
| episodes                | 612           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 188962        |
| policy_loss             | -0.54733104   |
| qf1_loss                | 0.00034269775 |
| qf2_loss                | 0.00035486766 |
| time_elapsed            | 988           |
| total timesteps         | 189062        |
| value_loss              | 2.670803e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008117643  |
| ent_coef_loss           | -0.31755832   |
| entropy                 | 1.0926443     |
| episodes                | 616           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 189665        |
| policy_loss             | -0.55319417   |
| qf1_loss                | 0.00011870627 |
| qf2_loss                | 0.00015842308 |
| time_elapsed            | 992           |
| total timesteps         | 189765        |
| value_loss              | 0.00040842625 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008694607  |
| ent_coef_loss           | 0.38255847    |
| entropy                 | 0.9807535     |
| episodes                | 620           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 190327        |
| policy_loss             | -0.5864576    |
| qf1_loss                | 5.706129e-05  |
| qf2_loss                | 5.5804383e-05 |
| time_elapsed            | 995           |
| total timesteps         | 190427        |
| value_loss              | 3.9333452e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008019233  |
| ent_coef_loss           | -0.51946294   |
| entropy                 | 0.81608415    |
| episodes                | 624           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 191091        |
| policy_loss             | -0.5497438    |
| qf1_loss                | 6.81086e-05   |
| qf2_loss                | 0.00010468545 |
| time_elapsed            | 999           |
| total timesteps         | 191191        |
| value_loss              | 4.515863e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00078825606 |
| ent_coef_loss           | 1.4961224     |
| entropy                 | 0.999202      |
| episodes                | 628           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 191785        |
| policy_loss             | -0.508885     |
| qf1_loss                | 0.0001132021  |
| qf2_loss                | 9.5140094e-05 |
| time_elapsed            | 1003          |
| total timesteps         | 191885        |
| value_loss              | 0.00015976149 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0007918002 |
| ent_coef_loss           | 3.7305205    |
| entropy                 | 0.82534      |
| episodes                | 632          |
| fps                     | 191          |
| mean 100 episode reward | 0.8          |
| n_updates               | 192408       |
| policy_loss             | -0.6000775   |
| qf1_loss                | 8.992542e-05 |
| qf2_loss                | 6.591076e-05 |
| time_elapsed            | 1006         |
| total timesteps         | 192508       |
| value_loss              | 8.554756e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007972546  |
| ent_coef_loss           | -2.746881     |
| entropy                 | 1.2101442     |
| episodes                | 636           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 193061        |
| policy_loss             | -0.57368326   |
| qf1_loss                | 0.00023297325 |
| qf2_loss                | 0.00024658936 |
| time_elapsed            | 1009          |
| total timesteps         | 193161        |
| value_loss              | 4.2055737e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008587351  |
| ent_coef_loss           | -1.0653739    |
| entropy                 | 1.1236005     |
| episodes                | 640           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 193687        |
| policy_loss             | -0.56244856   |
| qf1_loss                | 1.422549e-05  |
| qf2_loss                | 2.0777808e-05 |
| time_elapsed            | 1013          |
| total timesteps         | 193787        |
| value_loss              | 1.9453835e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087699137 |
| ent_coef_loss           | -0.94813836   |
| entropy                 | 1.1172744     |
| episodes                | 644           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 194323        |
| policy_loss             | -0.5916456    |
| qf1_loss                | 6.9750095e-05 |
| qf2_loss                | 6.293443e-05  |
| time_elapsed            | 1016          |
| total timesteps         | 194423        |
| value_loss              | 8.44194e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00078555965 |
| ent_coef_loss           | -0.19694293   |
| entropy                 | 1.1408942     |
| episodes                | 648           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 195002        |
| policy_loss             | -0.6109419    |
| qf1_loss                | 2.4654853e-05 |
| qf2_loss                | 2.9895406e-05 |
| time_elapsed            | 1020          |
| total timesteps         | 195102        |
| value_loss              | 5.1186777e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007174084  |
| ent_coef_loss           | -0.46358478   |
| entropy                 | 1.0091279     |
| episodes                | 652           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 195782        |
| policy_loss             | -0.51188314   |
| qf1_loss                | 0.00014133193 |
| qf2_loss                | 0.0001628539  |
| time_elapsed            | 1024          |
| total timesteps         | 195882        |
| value_loss              | 8.052098e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00077945046 |
| ent_coef_loss           | -0.4638583    |
| entropy                 | 1.047631      |
| episodes                | 656           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 196450        |
| policy_loss             | -0.575682     |
| qf1_loss                | 3.0755884e-05 |
| qf2_loss                | 4.879258e-05  |
| time_elapsed            | 1027          |
| total timesteps         | 196550        |
| value_loss              | 3.972768e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007960569  |
| ent_coef_loss           | 2.6221921     |
| entropy                 | 1.2707086     |
| episodes                | 660           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 197130        |
| policy_loss             | -0.60561895   |
| qf1_loss                | 1.7151864e-05 |
| qf2_loss                | 2.12562e-05   |
| time_elapsed            | 1031          |
| total timesteps         | 197230        |
| value_loss              | 2.4879479e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00082547846 |
| ent_coef_loss           | 0.40965068    |
| entropy                 | 1.176672      |
| episodes                | 664           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 197840        |
| policy_loss             | -0.5572411    |
| qf1_loss                | 2.0766656e-05 |
| qf2_loss                | 2.2283828e-05 |
| time_elapsed            | 1035          |
| total timesteps         | 197940        |
| value_loss              | 3.165631e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008156318  |
| ent_coef_loss           | 0.7003482     |
| entropy                 | 1.1842953     |
| episodes                | 668           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 198546        |
| policy_loss             | -0.6260638    |
| qf1_loss                | 1.679557e-05  |
| qf2_loss                | 2.3891738e-05 |
| time_elapsed            | 1038          |
| total timesteps         | 198646        |
| value_loss              | 1.868523e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008278613  |
| ent_coef_loss           | 4.41195       |
| entropy                 | 1.1862421     |
| episodes                | 672           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 199229        |
| policy_loss             | -0.54719025   |
| qf1_loss                | 2.7272912e-05 |
| qf2_loss                | 3.1139738e-05 |
| time_elapsed            | 1042          |
| total timesteps         | 199329        |
| value_loss              | 5.308605e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000871517   |
| ent_coef_loss           | -0.8607249    |
| entropy                 | 1.1479706     |
| episodes                | 676           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 199948        |
| policy_loss             | -0.5880891    |
| qf1_loss                | 2.5390811e-05 |
| qf2_loss                | 2.0756586e-05 |
| time_elapsed            | 1046          |
| total timesteps         | 200048        |
| value_loss              | 1.7232891e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093235355 |
| ent_coef_loss           | -2.455254     |
| entropy                 | 1.2299881     |
| episodes                | 680           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 200636        |
| policy_loss             | -0.5809769    |
| qf1_loss                | 2.5224534e-05 |
| qf2_loss                | 5.0451912e-05 |
| time_elapsed            | 1049          |
| total timesteps         | 200736        |
| value_loss              | 0.0001089812  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093273463 |
| ent_coef_loss           | 1.7130538     |
| entropy                 | 1.2971997     |
| episodes                | 684           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 201304        |
| policy_loss             | -0.60617214   |
| qf1_loss                | 1.634136e-05  |
| qf2_loss                | 1.8383591e-05 |
| time_elapsed            | 1053          |
| total timesteps         | 201404        |
| value_loss              | 2.0333115e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008712174  |
| ent_coef_loss           | -0.3281737    |
| entropy                 | 1.4247632     |
| episodes                | 688           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 201962        |
| policy_loss             | -0.598912     |
| qf1_loss                | 1.4599331e-05 |
| qf2_loss                | 1.755005e-05  |
| time_elapsed            | 1056          |
| total timesteps         | 202062        |
| value_loss              | 2.9147624e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090739917 |
| ent_coef_loss           | 0.4318758     |
| entropy                 | 1.1506742     |
| episodes                | 692           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 202605        |
| policy_loss             | -0.5660073    |
| qf1_loss                | 1.7958128e-05 |
| qf2_loss                | 1.8741717e-05 |
| time_elapsed            | 1060          |
| total timesteps         | 202705        |
| value_loss              | 3.4879547e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089436653 |
| ent_coef_loss           | 0.6249841     |
| entropy                 | 1.2957972     |
| episodes                | 696           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 203275        |
| policy_loss             | -0.56778073   |
| qf1_loss                | 1.7843591e-05 |
| qf2_loss                | 1.7908562e-05 |
| time_elapsed            | 1063          |
| total timesteps         | 203375        |
| value_loss              | 2.975347e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091595267 |
| ent_coef_loss           | 2.5395494     |
| entropy                 | 1.290533      |
| episodes                | 700           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 203918        |
| policy_loss             | -0.57806534   |
| qf1_loss                | 5.4413005e-05 |
| qf2_loss                | 5.3001557e-05 |
| time_elapsed            | 1067          |
| total timesteps         | 204018        |
| value_loss              | 4.035219e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008812311  |
| ent_coef_loss           | -0.3438965    |
| entropy                 | 1.3707484     |
| episodes                | 704           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 204585        |
| policy_loss             | -0.6351628    |
| qf1_loss                | 4.4222164e-05 |
| qf2_loss                | 4.1335068e-05 |
| time_elapsed            | 1070          |
| total timesteps         | 204685        |
| value_loss              | 4.046917e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087792776 |
| ent_coef_loss           | 0.50037545    |
| entropy                 | 1.3615468     |
| episodes                | 708           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 205331        |
| policy_loss             | -0.6327046    |
| qf1_loss                | 9.247704e-05  |
| qf2_loss                | 8.231745e-05  |
| time_elapsed            | 1074          |
| total timesteps         | 205431        |
| value_loss              | 4.302683e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009384647  |
| ent_coef_loss           | -0.6832663    |
| entropy                 | 1.2735336     |
| episodes                | 712           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 206014        |
| policy_loss             | -0.58290833   |
| qf1_loss                | 2.8831342e-05 |
| qf2_loss                | 2.0533531e-05 |
| time_elapsed            | 1078          |
| total timesteps         | 206114        |
| value_loss              | 4.000508e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091919827 |
| ent_coef_loss           | -2.635593     |
| entropy                 | 1.1776049     |
| episodes                | 716           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 206739        |
| policy_loss             | -0.6408563    |
| qf1_loss                | 2.3688683e-05 |
| qf2_loss                | 1.8181938e-05 |
| time_elapsed            | 1082          |
| total timesteps         | 206839        |
| value_loss              | 4.9456263e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008916919  |
| ent_coef_loss           | -2.0721817    |
| entropy                 | 1.2459259     |
| episodes                | 720           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 207391        |
| policy_loss             | -0.5423646    |
| qf1_loss                | 4.7782414e-05 |
| qf2_loss                | 5.725814e-05  |
| time_elapsed            | 1085          |
| total timesteps         | 207491        |
| value_loss              | 4.593344e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0008773461 |
| ent_coef_loss           | 1.466644     |
| entropy                 | 1.333854     |
| episodes                | 724          |
| fps                     | 191          |
| mean 100 episode reward | 0.9          |
| n_updates               | 208065       |
| policy_loss             | -0.6452557   |
| qf1_loss                | 7.325699e-05 |
| qf2_loss                | 8.293748e-05 |
| time_elapsed            | 1089         |
| total timesteps         | 208165       |
| value_loss              | 2.973122e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008530496  |
| ent_coef_loss           | 0.1856513     |
| entropy                 | 1.4415594     |
| episodes                | 728           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 208765        |
| policy_loss             | -0.6185504    |
| qf1_loss                | 3.9516464e-05 |
| qf2_loss                | 4.47745e-05   |
| time_elapsed            | 1092          |
| total timesteps         | 208865        |
| value_loss              | 4.1591484e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008299819  |
| ent_coef_loss           | 4.2374735     |
| entropy                 | 1.3447397     |
| episodes                | 732           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 209447        |
| policy_loss             | -0.56898403   |
| qf1_loss                | 4.9862923e-05 |
| qf2_loss                | 4.901951e-05  |
| time_elapsed            | 1096          |
| total timesteps         | 209547        |
| value_loss              | 5.0527407e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000773425   |
| ent_coef_loss           | 2.7832599     |
| entropy                 | 1.2425274     |
| episodes                | 736           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 210149        |
| policy_loss             | -0.55623794   |
| qf1_loss                | 3.380774e-05  |
| qf2_loss                | 2.777061e-05  |
| time_elapsed            | 1100          |
| total timesteps         | 210249        |
| value_loss              | 2.5881567e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008163801  |
| ent_coef_loss           | -2.4460015    |
| entropy                 | 1.3032119     |
| episodes                | 740           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 210821        |
| policy_loss             | -0.5875205    |
| qf1_loss                | 1.815184e-05  |
| qf2_loss                | 3.9016817e-05 |
| time_elapsed            | 1103          |
| total timesteps         | 210921        |
| value_loss              | 4.128431e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008402922  |
| ent_coef_loss           | 1.5694859     |
| entropy                 | 1.2137387     |
| episodes                | 744           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 211517        |
| policy_loss             | -0.6032259    |
| qf1_loss                | 0.00010692926 |
| qf2_loss                | 0.00010616363 |
| time_elapsed            | 1107          |
| total timesteps         | 211617        |
| value_loss              | 6.4065374e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086075254 |
| ent_coef_loss           | -2.5963938    |
| entropy                 | 1.186223      |
| episodes                | 748           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 212176        |
| policy_loss             | -0.6456431    |
| qf1_loss                | 7.624707e-05  |
| qf2_loss                | 7.241504e-05  |
| time_elapsed            | 1110          |
| total timesteps         | 212276        |
| value_loss              | 4.0550018e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000820947   |
| ent_coef_loss           | 1.6838057     |
| entropy                 | 1.3598634     |
| episodes                | 752           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 212871        |
| policy_loss             | -0.631538     |
| qf1_loss                | 2.1980692e-05 |
| qf2_loss                | 1.9876972e-05 |
| time_elapsed            | 1114          |
| total timesteps         | 212971        |
| value_loss              | 2.808263e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0007963674   |
| ent_coef_loss           | -0.0061098337  |
| entropy                 | 1.1543524      |
| episodes                | 756            |
| fps                     | 191            |
| mean 100 episode reward | 0.9            |
| n_updates               | 213529         |
| policy_loss             | -0.6537442     |
| qf1_loss                | 0.00012816224  |
| qf2_loss                | 0.000101439495 |
| time_elapsed            | 1117           |
| total timesteps         | 213629         |
| value_loss              | 4.0606872e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086362875 |
| ent_coef_loss           | 1.5369631     |
| entropy                 | 1.212565      |
| episodes                | 760           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 214096        |
| policy_loss             | -0.54173434   |
| qf1_loss                | 5.0439146e-05 |
| qf2_loss                | 2.2346445e-05 |
| time_elapsed            | 1120          |
| total timesteps         | 214196        |
| value_loss              | 6.218728e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087026786 |
| ent_coef_loss           | -3.9944682    |
| entropy                 | 1.419733      |
| episodes                | 764           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 214743        |
| policy_loss             | -0.57765853   |
| qf1_loss                | 3.096804e-05  |
| qf2_loss                | 1.9181025e-05 |
| time_elapsed            | 1123          |
| total timesteps         | 214843        |
| value_loss              | 3.6116508e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008340854  |
| ent_coef_loss           | 1.7180729     |
| entropy                 | 1.2524174     |
| episodes                | 768           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 215493        |
| policy_loss             | -0.5566195    |
| qf1_loss                | 0.00029665566 |
| qf2_loss                | 0.00028675972 |
| time_elapsed            | 1127          |
| total timesteps         | 215593        |
| value_loss              | 2.5815036e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008552372  |
| ent_coef_loss           | -2.3934023    |
| entropy                 | 1.2592231     |
| episodes                | 772           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 216204        |
| policy_loss             | -0.5926925    |
| qf1_loss                | 2.0952879e-05 |
| qf2_loss                | 1.8445899e-05 |
| time_elapsed            | 1131          |
| total timesteps         | 216304        |
| value_loss              | 3.4286266e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0008088825   |
| ent_coef_loss           | -0.40886736    |
| entropy                 | 1.1678298      |
| episodes                | 776            |
| fps                     | 191            |
| mean 100 episode reward | 0.9            |
| n_updates               | 216831         |
| policy_loss             | -0.66667104    |
| qf1_loss                | 9.573208e-05   |
| qf2_loss                | 0.000113785994 |
| time_elapsed            | 1135           |
| total timesteps         | 216931         |
| value_loss              | 2.9109167e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009162244  |
| ent_coef_loss           | -1.3744371    |
| entropy                 | 1.2863426     |
| episodes                | 780           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 217483        |
| policy_loss             | -0.58151317   |
| qf1_loss                | 2.4622186e-05 |
| qf2_loss                | 3.3677345e-05 |
| time_elapsed            | 1138          |
| total timesteps         | 217583        |
| value_loss              | 5.5632914e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009387928  |
| ent_coef_loss           | -0.57607335   |
| entropy                 | 1.4024149     |
| episodes                | 784           |
| fps                     | 191           |
| mean 100 episode reward | 0.9           |
| n_updates               | 218279        |
| policy_loss             | -0.6099359    |
| qf1_loss                | 1.8881674e-05 |
| qf2_loss                | 2.9147322e-05 |
| time_elapsed            | 1142          |
| total timesteps         | 218379        |
| value_loss              | 4.270749e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0008187488   |
| ent_coef_loss           | -0.3852861     |
| entropy                 | 1.2975342      |
| episodes                | 788            |
| fps                     | 191            |
| mean 100 episode reward | 0.8            |
| n_updates               | 218946         |
| policy_loss             | -0.6289512     |
| qf1_loss                | 0.00011874613  |
| qf2_loss                | 0.000109816385 |
| time_elapsed            | 1146           |
| total timesteps         | 219046         |
| value_loss              | 7.919004e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00084810756 |
| ent_coef_loss           | 4.0778456     |
| entropy                 | 1.376087      |
| episodes                | 792           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 219596        |
| policy_loss             | -0.6142287    |
| qf1_loss                | 1.32191e-05   |
| qf2_loss                | 1.8204943e-05 |
| time_elapsed            | 1149          |
| total timesteps         | 219696        |
| value_loss              | 1.7442986e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000833042   |
| ent_coef_loss           | -0.71928114   |
| entropy                 | 1.3210198     |
| episodes                | 796           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 220223        |
| policy_loss             | -0.6124102    |
| qf1_loss                | 4.3786382e-05 |
| qf2_loss                | 5.939305e-05  |
| time_elapsed            | 1152          |
| total timesteps         | 220323        |
| value_loss              | 5.063625e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00082806306 |
| ent_coef_loss           | 0.5765171     |
| entropy                 | 1.4717532     |
| episodes                | 800           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 220854        |
| policy_loss             | -0.6074974    |
| qf1_loss                | 0.0001303804  |
| qf2_loss                | 0.00012151968 |
| time_elapsed            | 1155          |
| total timesteps         | 220954        |
| value_loss              | 4.5000783e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007813263  |
| ent_coef_loss           | 3.0839834     |
| entropy                 | 1.2797179     |
| episodes                | 804           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 221531        |
| policy_loss             | -0.58216834   |
| qf1_loss                | 4.65946e-05   |
| qf2_loss                | 0.00013223715 |
| time_elapsed            | 1159          |
| total timesteps         | 221631        |
| value_loss              | 3.331717e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00076650537 |
| ent_coef_loss           | -0.26097304   |
| entropy                 | 1.1922572     |
| episodes                | 808           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 222173        |
| policy_loss             | -0.5409722    |
| qf1_loss                | 0.00032394446 |
| qf2_loss                | 0.00014044961 |
| time_elapsed            | 1163          |
| total timesteps         | 222273        |
| value_loss              | 0.00016514037 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00073710235 |
| ent_coef_loss           | 1.2467141     |
| entropy                 | 1.3503877     |
| episodes                | 812           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 222838        |
| policy_loss             | -0.588207     |
| qf1_loss                | 2.7388101e-05 |
| qf2_loss                | 1.7632086e-05 |
| time_elapsed            | 1166          |
| total timesteps         | 222938        |
| value_loss              | 2.1921896e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007132304  |
| ent_coef_loss           | 2.11832       |
| entropy                 | 1.1641053     |
| episodes                | 816           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 223514        |
| policy_loss             | -0.61753654   |
| qf1_loss                | 0.00016256756 |
| qf2_loss                | 0.0001669499  |
| time_elapsed            | 1170          |
| total timesteps         | 223614        |
| value_loss              | 3.2114654e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006977054  |
| ent_coef_loss           | -3.5018795    |
| entropy                 | 1.1582272     |
| episodes                | 820           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 224174        |
| policy_loss             | -0.6058228    |
| qf1_loss                | 4.016164e-05  |
| qf2_loss                | 3.8855967e-05 |
| time_elapsed            | 1173          |
| total timesteps         | 224274        |
| value_loss              | 2.6406236e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007225322  |
| ent_coef_loss           | 1.8922472     |
| entropy                 | 1.3492036     |
| episodes                | 824           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 224845        |
| policy_loss             | -0.5866045    |
| qf1_loss                | 1.0936823e-05 |
| qf2_loss                | 1.9874573e-05 |
| time_elapsed            | 1177          |
| total timesteps         | 224945        |
| value_loss              | 2.9173494e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007538011  |
| ent_coef_loss           | 1.6076286     |
| entropy                 | 1.2642685     |
| episodes                | 828           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 225753        |
| policy_loss             | -0.6210096    |
| qf1_loss                | 3.8075115e-05 |
| qf2_loss                | 6.0032915e-05 |
| time_elapsed            | 1182          |
| total timesteps         | 225853        |
| value_loss              | 2.9603892e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007577104  |
| ent_coef_loss           | -0.417791     |
| entropy                 | 1.1890984     |
| episodes                | 832           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 226408        |
| policy_loss             | -0.5977788    |
| qf1_loss                | 0.00013124898 |
| qf2_loss                | 0.00011622797 |
| time_elapsed            | 1185          |
| total timesteps         | 226508        |
| value_loss              | 2.4055224e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000654965   |
| ent_coef_loss           | 1.6743718     |
| entropy                 | 1.1055639     |
| episodes                | 836           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 227065        |
| policy_loss             | -0.6157545    |
| qf1_loss                | 5.133966e-05  |
| qf2_loss                | 1.8643474e-05 |
| time_elapsed            | 1189          |
| total timesteps         | 227165        |
| value_loss              | 2.7069862e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00069112115 |
| ent_coef_loss           | -0.5253706    |
| entropy                 | 1.0958366     |
| episodes                | 840           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 227613        |
| policy_loss             | -0.571784     |
| qf1_loss                | 0.00012330293 |
| qf2_loss                | 7.7417564e-05 |
| time_elapsed            | 1192          |
| total timesteps         | 227713        |
| value_loss              | 5.9159207e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006890103  |
| ent_coef_loss           | 0.82484365    |
| entropy                 | 1.1230731     |
| episodes                | 844           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 228300        |
| policy_loss             | -0.5539925    |
| qf1_loss                | 3.2699587e-05 |
| qf2_loss                | 3.1801363e-05 |
| time_elapsed            | 1195          |
| total timesteps         | 228400        |
| value_loss              | 2.9723813e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0007074566   |
| ent_coef_loss           | -4.118076      |
| entropy                 | 1.1829271      |
| episodes                | 848            |
| fps                     | 191            |
| mean 100 episode reward | 0.8            |
| n_updates               | 228948         |
| policy_loss             | -0.6652538     |
| qf1_loss                | 1.09056145e-05 |
| qf2_loss                | 1.4522245e-05  |
| time_elapsed            | 1198           |
| total timesteps         | 229048         |
| value_loss              | 2.3612258e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00071125105 |
| ent_coef_loss           | 1.6214988     |
| entropy                 | 1.256719      |
| episodes                | 852           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 229628        |
| policy_loss             | -0.54658973   |
| qf1_loss                | 5.2630592e-05 |
| qf2_loss                | 7.413107e-05  |
| time_elapsed            | 1202          |
| total timesteps         | 229728        |
| value_loss              | 5.377703e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000678487   |
| ent_coef_loss           | -0.8668331    |
| entropy                 | 1.1962903     |
| episodes                | 856           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 230294        |
| policy_loss             | -0.58767396   |
| qf1_loss                | 2.2336037e-05 |
| qf2_loss                | 2.0416326e-05 |
| time_elapsed            | 1206          |
| total timesteps         | 230394        |
| value_loss              | 3.818844e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006928168  |
| ent_coef_loss           | 2.4134576     |
| entropy                 | 1.2171192     |
| episodes                | 860           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 230937        |
| policy_loss             | -0.6479976    |
| qf1_loss                | 6.501544e-05  |
| qf2_loss                | 4.667394e-05  |
| time_elapsed            | 1209          |
| total timesteps         | 231037        |
| value_loss              | 6.7983136e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00073168566 |
| ent_coef_loss           | 0.34231552    |
| entropy                 | 1.31597       |
| episodes                | 864           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 231620        |
| policy_loss             | -0.61066186   |
| qf1_loss                | 0.00012795311 |
| qf2_loss                | 6.9392234e-05 |
| time_elapsed            | 1212          |
| total timesteps         | 231720        |
| value_loss              | 4.7060366e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00073385413 |
| ent_coef_loss           | 0.82692254    |
| entropy                 | 1.3099927     |
| episodes                | 868           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 232256        |
| policy_loss             | -0.6161733    |
| qf1_loss                | 0.00010050072 |
| qf2_loss                | 9.7033866e-05 |
| time_elapsed            | 1216          |
| total timesteps         | 232356        |
| value_loss              | 6.120158e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007653173  |
| ent_coef_loss           | 0.9364662     |
| entropy                 | 1.246387      |
| episodes                | 872           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 232890        |
| policy_loss             | -0.62945807   |
| qf1_loss                | 2.5723519e-05 |
| qf2_loss                | 2.1028256e-05 |
| time_elapsed            | 1219          |
| total timesteps         | 232990        |
| value_loss              | 1.7419668e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00075625506 |
| ent_coef_loss           | 2.6596065     |
| entropy                 | 1.2418323     |
| episodes                | 876           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 233630        |
| policy_loss             | -0.62688386   |
| qf1_loss                | 4.1928248e-05 |
| qf2_loss                | 4.6186207e-05 |
| time_elapsed            | 1223          |
| total timesteps         | 233730        |
| value_loss              | 3.7827045e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007956189  |
| ent_coef_loss           | -1.3173919    |
| entropy                 | 1.2725068     |
| episodes                | 880           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 234313        |
| policy_loss             | -0.5791637    |
| qf1_loss                | 5.3906155e-05 |
| qf2_loss                | 5.8907415e-05 |
| time_elapsed            | 1227          |
| total timesteps         | 234413        |
| value_loss              | 3.6518133e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008052689  |
| ent_coef_loss           | -1.7866579    |
| entropy                 | 1.2979174     |
| episodes                | 884           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 235007        |
| policy_loss             | -0.6271684    |
| qf1_loss                | 1.367543e-05  |
| qf2_loss                | 1.8042843e-05 |
| time_elapsed            | 1230          |
| total timesteps         | 235107        |
| value_loss              | 2.3781071e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000778631   |
| ent_coef_loss           | 1.5080068     |
| entropy                 | 1.3404448     |
| episodes                | 888           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 235973        |
| policy_loss             | -0.57203627   |
| qf1_loss                | 3.465493e-05  |
| qf2_loss                | 6.7345856e-05 |
| time_elapsed            | 1235          |
| total timesteps         | 236073        |
| value_loss              | 2.7678856e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007820987  |
| ent_coef_loss           | -0.45527744   |
| entropy                 | 1.3421125     |
| episodes                | 892           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 236658        |
| policy_loss             | -0.5786643    |
| qf1_loss                | 3.395934e-05  |
| qf2_loss                | 3.0996925e-05 |
| time_elapsed            | 1239          |
| total timesteps         | 236758        |
| value_loss              | 3.9816543e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008758246  |
| ent_coef_loss           | -2.6849647    |
| entropy                 | 1.3483303     |
| episodes                | 896           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 237681        |
| policy_loss             | -0.6044663    |
| qf1_loss                | 6.1839455e-05 |
| qf2_loss                | 3.5874436e-05 |
| time_elapsed            | 1244          |
| total timesteps         | 237781        |
| value_loss              | 0.00010414634 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00084228395 |
| ent_coef_loss           | -0.083765104  |
| entropy                 | 1.2684584     |
| episodes                | 900           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 238377        |
| policy_loss             | -0.5849061    |
| qf1_loss                | 1.3979625e-05 |
| qf2_loss                | 3.1975702e-05 |
| time_elapsed            | 1248          |
| total timesteps         | 238477        |
| value_loss              | 1.247633e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085871795 |
| ent_coef_loss           | 0.7063757     |
| entropy                 | 1.3176548     |
| episodes                | 904           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 239047        |
| policy_loss             | -0.583537     |
| qf1_loss                | 2.6410813e-05 |
| qf2_loss                | 1.986937e-05  |
| time_elapsed            | 1252          |
| total timesteps         | 239147        |
| value_loss              | 1.9776133e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008292275  |
| ent_coef_loss           | 1.9033649     |
| entropy                 | 1.4063611     |
| episodes                | 908           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 239967        |
| policy_loss             | -0.6318611    |
| qf1_loss                | 4.275731e-05  |
| qf2_loss                | 4.7537265e-05 |
| time_elapsed            | 1256          |
| total timesteps         | 240067        |
| value_loss              | 5.1126342e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087333453 |
| ent_coef_loss           | -1.6819279    |
| entropy                 | 1.3063369     |
| episodes                | 912           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 240660        |
| policy_loss             | -0.592849     |
| qf1_loss                | 0.0001853726  |
| qf2_loss                | 0.00015830575 |
| time_elapsed            | 1260          |
| total timesteps         | 240760        |
| value_loss              | 5.6271383e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00084039837 |
| ent_coef_loss           | 0.99641085    |
| entropy                 | 1.3648627     |
| episodes                | 916           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 241337        |
| policy_loss             | -0.59290975   |
| qf1_loss                | 3.2777767e-05 |
| qf2_loss                | 2.3150918e-05 |
| time_elapsed            | 1264          |
| total timesteps         | 241437        |
| value_loss              | 6.800852e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008516344  |
| ent_coef_loss           | 0.40933853    |
| entropy                 | 1.2564404     |
| episodes                | 920           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 242084        |
| policy_loss             | -0.6267742    |
| qf1_loss                | 2.1230277e-05 |
| qf2_loss                | 2.4992612e-05 |
| time_elapsed            | 1268          |
| total timesteps         | 242184        |
| value_loss              | 3.7368707e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00076372275 |
| ent_coef_loss           | 2.471001      |
| entropy                 | 1.2669599     |
| episodes                | 924           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 242791        |
| policy_loss             | -0.6603696    |
| qf1_loss                | 1.6015578e-05 |
| qf2_loss                | 1.4898559e-05 |
| time_elapsed            | 1271          |
| total timesteps         | 242891        |
| value_loss              | 1.8000537e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00080892036 |
| ent_coef_loss           | -2.711623     |
| entropy                 | 1.2266946     |
| episodes                | 928           |
| fps                     | 191           |
| mean 100 episode reward | 0.8           |
| n_updates               | 243429        |
| policy_loss             | -0.63594127   |
| qf1_loss                | 2.1300544e-05 |
| qf2_loss                | 4.7239286e-05 |
| time_elapsed            | 1275          |
| total timesteps         | 243529        |
| value_loss              | 5.2618852e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007470628  |
| ent_coef_loss           | 0.2738772     |
| entropy                 | 1.160634      |
| episodes                | 932           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 244171        |
| policy_loss             | -0.5971724    |
| qf1_loss                | 2.1643285e-05 |
| qf2_loss                | 2.879658e-05  |
| time_elapsed            | 1279          |
| total timesteps         | 244271        |
| value_loss              | 5.2212294e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007748088  |
| ent_coef_loss           | -2.603768     |
| entropy                 | 1.2776037     |
| episodes                | 936           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 244848        |
| policy_loss             | -0.65394425   |
| qf1_loss                | 3.228367e-05  |
| qf2_loss                | 2.2595312e-05 |
| time_elapsed            | 1282          |
| total timesteps         | 244948        |
| value_loss              | 2.5773385e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00069450366 |
| ent_coef_loss           | -3.1145751    |
| entropy                 | 1.0515037     |
| episodes                | 940           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 245540        |
| policy_loss             | -0.62527907   |
| qf1_loss                | 3.1800195e-05 |
| qf2_loss                | 4.0224644e-05 |
| time_elapsed            | 1286          |
| total timesteps         | 245640        |
| value_loss              | 1.5968606e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00071386085 |
| ent_coef_loss           | -0.052271783  |
| entropy                 | 1.153712      |
| episodes                | 944           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 246276        |
| policy_loss             | -0.6360127    |
| qf1_loss                | 3.276934e-05  |
| qf2_loss                | 5.1503346e-05 |
| time_elapsed            | 1290          |
| total timesteps         | 246376        |
| value_loss              | 2.5048961e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007411653  |
| ent_coef_loss           | 0.05526066    |
| entropy                 | 1.069001      |
| episodes                | 948           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 246923        |
| policy_loss             | -0.56574106   |
| qf1_loss                | 3.0041163e-05 |
| qf2_loss                | 4.209788e-05  |
| time_elapsed            | 1293          |
| total timesteps         | 247023        |
| value_loss              | 3.281086e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007686337  |
| ent_coef_loss           | 1.3417645     |
| entropy                 | 1.2421609     |
| episodes                | 952           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 247574        |
| policy_loss             | -0.58074665   |
| qf1_loss                | 3.9707833e-05 |
| qf2_loss                | 2.5679627e-05 |
| time_elapsed            | 1296          |
| total timesteps         | 247674        |
| value_loss              | 2.3290422e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000816203   |
| ent_coef_loss           | -0.050962     |
| entropy                 | 1.2768128     |
| episodes                | 956           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 248215        |
| policy_loss             | -0.5853671    |
| qf1_loss                | 8.800412e-05  |
| qf2_loss                | 2.5288475e-05 |
| time_elapsed            | 1300          |
| total timesteps         | 248315        |
| value_loss              | 8.4219166e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007798018  |
| ent_coef_loss           | 0.68209124    |
| entropy                 | 1.3614177     |
| episodes                | 960           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 248841        |
| policy_loss             | -0.6419399    |
| qf1_loss                | 4.7792426e-05 |
| qf2_loss                | 1.44633e-05   |
| time_elapsed            | 1303          |
| total timesteps         | 248941        |
| value_loss              | 4.148838e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008003242  |
| ent_coef_loss           | 2.6046004     |
| entropy                 | 1.3666918     |
| episodes                | 964           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 249524        |
| policy_loss             | -0.5944107    |
| qf1_loss                | 0.00025169962 |
| qf2_loss                | 6.167825e-05  |
| time_elapsed            | 1307          |
| total timesteps         | 249624        |
| value_loss              | 5.364647e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00079886813 |
| ent_coef_loss           | 2.1498954     |
| entropy                 | 1.3878726     |
| episodes                | 968           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 250151        |
| policy_loss             | -0.5793133    |
| qf1_loss                | 4.344891e-05  |
| qf2_loss                | 3.8403134e-05 |
| time_elapsed            | 1310          |
| total timesteps         | 250251        |
| value_loss              | 4.068932e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00082692195 |
| ent_coef_loss           | 0.26518273    |
| entropy                 | 1.3865709     |
| episodes                | 972           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 250799        |
| policy_loss             | -0.5917623    |
| qf1_loss                | 2.718493e-05  |
| qf2_loss                | 2.9670646e-05 |
| time_elapsed            | 1314          |
| total timesteps         | 250899        |
| value_loss              | 2.574848e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00080449437 |
| ent_coef_loss           | -0.8872647    |
| entropy                 | 1.4632875     |
| episodes                | 976           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 251480        |
| policy_loss             | -0.60903335   |
| qf1_loss                | 3.2344687e-05 |
| qf2_loss                | 2.6930762e-05 |
| time_elapsed            | 1317          |
| total timesteps         | 251580        |
| value_loss              | 1.4852698e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007695366  |
| ent_coef_loss           | -0.4769463    |
| entropy                 | 1.3758373     |
| episodes                | 980           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 252151        |
| policy_loss             | -0.6249361    |
| qf1_loss                | 1.5582576e-05 |
| qf2_loss                | 4.77944e-05   |
| time_elapsed            | 1321          |
| total timesteps         | 252251        |
| value_loss              | 2.7854252e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007481715  |
| ent_coef_loss           | -2.4186974    |
| entropy                 | 1.2750804     |
| episodes                | 984           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 252897        |
| policy_loss             | -0.5825368    |
| qf1_loss                | 4.4547844e-05 |
| qf2_loss                | 5.3977812e-05 |
| time_elapsed            | 1324          |
| total timesteps         | 252997        |
| value_loss              | 5.4259144e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00077902916  |
| ent_coef_loss           | -1.3072518     |
| entropy                 | 1.3734038      |
| episodes                | 988            |
| fps                     | 190            |
| mean 100 episode reward | 0.9            |
| n_updates               | 253607         |
| policy_loss             | -0.6374935     |
| qf1_loss                | 1.5787087e-05  |
| qf2_loss                | 1.41472565e-05 |
| time_elapsed            | 1328           |
| total timesteps         | 253707         |
| value_loss              | 3.776301e-05   |
--------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00077799824  |
| ent_coef_loss           | 2.9818335      |
| entropy                 | 1.4418178      |
| episodes                | 992            |
| fps                     | 190            |
| mean 100 episode reward | 0.8            |
| n_updates               | 254525         |
| policy_loss             | -0.6027006     |
| qf1_loss                | 3.955066e-05   |
| qf2_loss                | 0.00012503074  |
| time_elapsed            | 1333           |
| total timesteps         | 254625         |
| value_loss              | 0.000109062064 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00081330707 |
| ent_coef_loss           | -0.792019     |
| entropy                 | 1.3971863     |
| episodes                | 996           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 255442        |
| policy_loss             | -0.5902892    |
| qf1_loss                | 3.0675597e-05 |
| qf2_loss                | 1.9054267e-05 |
| time_elapsed            | 1338          |
| total timesteps         | 255542        |
| value_loss              | 3.4838715e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007553202  |
| ent_coef_loss           | 1.0328801     |
| entropy                 | 1.3324194     |
| episodes                | 1000          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 256074        |
| policy_loss             | -0.6000955    |
| qf1_loss                | 4.204413e-05  |
| qf2_loss                | 3.039314e-05  |
| time_elapsed            | 1341          |
| total timesteps         | 256174        |
| value_loss              | 5.5201603e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00077344413 |
| ent_coef_loss           | 0.7301878     |
| entropy                 | 1.3256347     |
| episodes                | 1004          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 256740        |
| policy_loss             | -0.6214697    |
| qf1_loss                | 1.1873171e-05 |
| qf2_loss                | 2.0077525e-05 |
| time_elapsed            | 1345          |
| total timesteps         | 256840        |
| value_loss              | 3.0525516e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008071622  |
| ent_coef_loss           | 0.14942515    |
| entropy                 | 1.3313072     |
| episodes                | 1008          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 257372        |
| policy_loss             | -0.6200212    |
| qf1_loss                | 2.010802e-05  |
| qf2_loss                | 2.7577662e-05 |
| time_elapsed            | 1348          |
| total timesteps         | 257472        |
| value_loss              | 3.8010898e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00079287164 |
| ent_coef_loss           | 1.3036364     |
| entropy                 | 1.1716812     |
| episodes                | 1012          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 258069        |
| policy_loss             | -0.57363605   |
| qf1_loss                | 3.3665834e-05 |
| qf2_loss                | 3.9684797e-05 |
| time_elapsed            | 1352          |
| total timesteps         | 258169        |
| value_loss              | 5.1247065e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00080511376 |
| ent_coef_loss           | 0.57088447    |
| entropy                 | 1.342473      |
| episodes                | 1016          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 258973        |
| policy_loss             | -0.59324706   |
| qf1_loss                | 2.837309e-05  |
| qf2_loss                | 2.2348504e-05 |
| time_elapsed            | 1356          |
| total timesteps         | 259073        |
| value_loss              | 4.5893532e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007860678  |
| ent_coef_loss           | -0.09107417   |
| entropy                 | 1.3531473     |
| episodes                | 1020          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 259641        |
| policy_loss             | -0.58061653   |
| qf1_loss                | 3.9509003e-05 |
| qf2_loss                | 4.532335e-05  |
| time_elapsed            | 1360          |
| total timesteps         | 259741        |
| value_loss              | 6.448778e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00074485317 |
| ent_coef_loss           | 0.88494617    |
| entropy                 | 1.3245397     |
| episodes                | 1024          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 260460        |
| policy_loss             | -0.6153722    |
| qf1_loss                | 1.75342e-05   |
| qf2_loss                | 1.8977533e-05 |
| time_elapsed            | 1364          |
| total timesteps         | 260560        |
| value_loss              | 2.0584706e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008002193  |
| ent_coef_loss           | 2.0360422     |
| entropy                 | 1.3561859     |
| episodes                | 1028          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 261229        |
| policy_loss             | -0.5928585    |
| qf1_loss                | 2.9320334e-05 |
| qf2_loss                | 3.285079e-05  |
| time_elapsed            | 1368          |
| total timesteps         | 261329        |
| value_loss              | 2.4407225e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008905824  |
| ent_coef_loss           | 0.22254147    |
| entropy                 | 1.2355807     |
| episodes                | 1032          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 262140        |
| policy_loss             | -0.6057313    |
| qf1_loss                | 3.1921983e-05 |
| qf2_loss                | 4.5735353e-05 |
| time_elapsed            | 1373          |
| total timesteps         | 262240        |
| value_loss              | 8.133861e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00088848366 |
| ent_coef_loss           | 0.6620252     |
| entropy                 | 1.3323627     |
| episodes                | 1036          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 262809        |
| policy_loss             | -0.5684551    |
| qf1_loss                | 4.2283475e-05 |
| qf2_loss                | 2.1391861e-05 |
| time_elapsed            | 1377          |
| total timesteps         | 262909        |
| value_loss              | 4.6785357e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000988722   |
| ent_coef_loss           | -2.314155     |
| entropy                 | 1.4805459     |
| episodes                | 1040          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 263460        |
| policy_loss             | -0.6244818    |
| qf1_loss                | 2.3692322e-05 |
| qf2_loss                | 3.3102555e-05 |
| time_elapsed            | 1380          |
| total timesteps         | 263560        |
| value_loss              | 2.6375e-05    |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095095974 |
| ent_coef_loss           | -2.719024     |
| entropy                 | 1.5113904     |
| episodes                | 1044          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 264188        |
| policy_loss             | -0.6010741    |
| qf1_loss                | 1.3985318e-05 |
| qf2_loss                | 1.5808277e-05 |
| time_elapsed            | 1384          |
| total timesteps         | 264288        |
| value_loss              | 2.4754147e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009473422  |
| ent_coef_loss           | -0.8667551    |
| entropy                 | 1.3259106     |
| episodes                | 1048          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 264864        |
| policy_loss             | -0.5664155    |
| qf1_loss                | 0.00013323409 |
| qf2_loss                | 0.00027456396 |
| time_elapsed            | 1387          |
| total timesteps         | 264964        |
| value_loss              | 9.522183e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009807643  |
| ent_coef_loss           | 2.5298529     |
| entropy                 | 1.460396      |
| episodes                | 1052          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 265804        |
| policy_loss             | -0.6431019    |
| qf1_loss                | 2.7890803e-05 |
| qf2_loss                | 5.7050336e-05 |
| time_elapsed            | 1392          |
| total timesteps         | 265904        |
| value_loss              | 5.1808514e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009778294  |
| ent_coef_loss           | -2.057218     |
| entropy                 | 1.5122306     |
| episodes                | 1056          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 266469        |
| policy_loss             | -0.55342925   |
| qf1_loss                | 3.7843052e-05 |
| qf2_loss                | 9.0044996e-05 |
| time_elapsed            | 1396          |
| total timesteps         | 266569        |
| value_loss              | 3.355103e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094281905 |
| ent_coef_loss           | -1.3021482    |
| entropy                 | 1.354397      |
| episodes                | 1060          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 267125        |
| policy_loss             | -0.5998092    |
| qf1_loss                | 0.0002313758  |
| qf2_loss                | 0.00030711747 |
| time_elapsed            | 1399          |
| total timesteps         | 267225        |
| value_loss              | 2.7002772e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009379489  |
| ent_coef_loss           | -1.496526     |
| entropy                 | 1.3906131     |
| episodes                | 1064          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 267781        |
| policy_loss             | -0.55198646   |
| qf1_loss                | 6.252688e-05  |
| qf2_loss                | 5.1061863e-05 |
| time_elapsed            | 1403          |
| total timesteps         | 267881        |
| value_loss              | 6.224898e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008101139  |
| ent_coef_loss           | -0.67735565   |
| entropy                 | 1.5017177     |
| episodes                | 1068          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 268447        |
| policy_loss             | -0.5436785    |
| qf1_loss                | 0.00032818064 |
| qf2_loss                | 0.00021866    |
| time_elapsed            | 1406          |
| total timesteps         | 268547        |
| value_loss              | 7.64415e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090422796 |
| ent_coef_loss           | -1.0378885    |
| entropy                 | 1.5179899     |
| episodes                | 1072          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 269158        |
| policy_loss             | -0.5972696    |
| qf1_loss                | 3.440167e-05  |
| qf2_loss                | 3.2102394e-05 |
| time_elapsed            | 1410          |
| total timesteps         | 269258        |
| value_loss              | 2.7047987e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00094037433  |
| ent_coef_loss           | -0.81223345    |
| entropy                 | 1.4069707      |
| episodes                | 1076           |
| fps                     | 190            |
| mean 100 episode reward | 0.8            |
| n_updates               | 269945         |
| policy_loss             | -0.6222533     |
| qf1_loss                | 2.839365e-05   |
| qf2_loss                | 1.48881045e-05 |
| time_elapsed            | 1414           |
| total timesteps         | 270045         |
| value_loss              | 3.7433456e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008445973  |
| ent_coef_loss           | 3.7789938     |
| entropy                 | 1.2530904     |
| episodes                | 1080          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 270680        |
| policy_loss             | -0.53856117   |
| qf1_loss                | 4.3211978e-05 |
| qf2_loss                | 9.761827e-05  |
| time_elapsed            | 1418          |
| total timesteps         | 270780        |
| value_loss              | 0.00020217628 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008401035  |
| ent_coef_loss           | -1.4413582    |
| entropy                 | 1.3303379     |
| episodes                | 1084          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 271369        |
| policy_loss             | -0.6078173    |
| qf1_loss                | 5.1837662e-05 |
| qf2_loss                | 3.307756e-05  |
| time_elapsed            | 1422          |
| total timesteps         | 271469        |
| value_loss              | 5.6000805e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00083474786 |
| ent_coef_loss           | -0.9165852    |
| entropy                 | 1.3889782     |
| episodes                | 1088          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 272091        |
| policy_loss             | -0.574227     |
| qf1_loss                | 3.871575e-05  |
| qf2_loss                | 1.5678546e-05 |
| time_elapsed            | 1425          |
| total timesteps         | 272191        |
| value_loss              | 3.259143e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00079509785 |
| ent_coef_loss           | -1.6963515    |
| entropy                 | 1.5110034     |
| episodes                | 1092          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 272769        |
| policy_loss             | -0.5900564    |
| qf1_loss                | 2.8223696e-05 |
| qf2_loss                | 2.2938915e-05 |
| time_elapsed            | 1429          |
| total timesteps         | 272869        |
| value_loss              | 2.8442988e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007310126  |
| ent_coef_loss           | 0.6589104     |
| entropy                 | 1.1881438     |
| episodes                | 1096          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 273506        |
| policy_loss             | -0.54031956   |
| qf1_loss                | 3.8566246e-05 |
| qf2_loss                | 3.996307e-05  |
| time_elapsed            | 1433          |
| total timesteps         | 273606        |
| value_loss              | 9.688856e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008620723  |
| ent_coef_loss           | -0.79348314   |
| entropy                 | 1.4048862     |
| episodes                | 1100          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 274177        |
| policy_loss             | -0.5295713    |
| qf1_loss                | 4.799226e-05  |
| qf2_loss                | 2.0196469e-05 |
| time_elapsed            | 1436          |
| total timesteps         | 274277        |
| value_loss              | 1.8030403e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000913856   |
| ent_coef_loss           | -1.047981     |
| entropy                 | 1.4007603     |
| episodes                | 1104          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 274849        |
| policy_loss             | -0.5799805    |
| qf1_loss                | 6.0189224e-05 |
| qf2_loss                | 4.1990632e-05 |
| time_elapsed            | 1440          |
| total timesteps         | 274949        |
| value_loss              | 9.3582246e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086855114 |
| ent_coef_loss           | 1.9877197     |
| entropy                 | 1.3185351     |
| episodes                | 1108          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 275732        |
| policy_loss             | -0.5973342    |
| qf1_loss                | 0.00037139832 |
| qf2_loss                | 0.00037363404 |
| time_elapsed            | 1445          |
| total timesteps         | 275832        |
| value_loss              | 0.0003839175  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000824926   |
| ent_coef_loss           | 0.90116763    |
| entropy                 | 1.330972      |
| episodes                | 1112          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 276399        |
| policy_loss             | -0.6030847    |
| qf1_loss                | 4.759492e-05  |
| qf2_loss                | 4.0887306e-05 |
| time_elapsed            | 1448          |
| total timesteps         | 276499        |
| value_loss              | 5.5912467e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.000849237    |
| ent_coef_loss           | -1.1488475     |
| entropy                 | 1.4785593      |
| episodes                | 1116           |
| fps                     | 190            |
| mean 100 episode reward | 0.8            |
| n_updates               | 277105         |
| policy_loss             | -0.54139006    |
| qf1_loss                | 1.45542135e-05 |
| qf2_loss                | 3.4799363e-05  |
| time_elapsed            | 1452           |
| total timesteps         | 277205         |
| value_loss              | 2.8134105e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00074025267 |
| ent_coef_loss           | -1.064802     |
| entropy                 | 1.3405352     |
| episodes                | 1120          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 277774        |
| policy_loss             | -0.5873209    |
| qf1_loss                | 1.9662417e-05 |
| qf2_loss                | 2.6050977e-05 |
| time_elapsed            | 1455          |
| total timesteps         | 277874        |
| value_loss              | 5.904874e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007586265  |
| ent_coef_loss           | 1.1040215     |
| entropy                 | 1.2756114     |
| episodes                | 1124          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 278454        |
| policy_loss             | -0.5902577    |
| qf1_loss                | 4.1674226e-05 |
| qf2_loss                | 2.032079e-05  |
| time_elapsed            | 1459          |
| total timesteps         | 278554        |
| value_loss              | 4.2476895e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00078766956 |
| ent_coef_loss           | 3.1081662     |
| entropy                 | 1.2798747     |
| episodes                | 1128          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 279162        |
| policy_loss             | -0.53951156   |
| qf1_loss                | 4.183232e-05  |
| qf2_loss                | 8.482067e-05  |
| time_elapsed            | 1463          |
| total timesteps         | 279262        |
| value_loss              | 0.00012965252 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008186309  |
| ent_coef_loss           | 0.03205043    |
| entropy                 | 1.3843884     |
| episodes                | 1132          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 279872        |
| policy_loss             | -0.58521295   |
| qf1_loss                | 3.6834113e-05 |
| qf2_loss                | 2.003541e-05  |
| time_elapsed            | 1466          |
| total timesteps         | 279972        |
| value_loss              | 0.00012406986 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007876402  |
| ent_coef_loss           | -2.9989562    |
| entropy                 | 1.2765571     |
| episodes                | 1136          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 280631        |
| policy_loss             | -0.5495236    |
| qf1_loss                | 5.0613427e-05 |
| qf2_loss                | 0.00011903415 |
| time_elapsed            | 1470          |
| total timesteps         | 280731        |
| value_loss              | 3.465705e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00084090786 |
| ent_coef_loss           | -2.9384665    |
| entropy                 | 1.2927682     |
| episodes                | 1140          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 281276        |
| policy_loss             | -0.57112247   |
| qf1_loss                | 2.7826964e-05 |
| qf2_loss                | 3.981069e-05  |
| time_elapsed            | 1474          |
| total timesteps         | 281376        |
| value_loss              | 6.260814e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009911279  |
| ent_coef_loss           | 0.32377684    |
| entropy                 | 1.2944716     |
| episodes                | 1144          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 282025        |
| policy_loss             | -0.51516575   |
| qf1_loss                | 0.00034609623 |
| qf2_loss                | 0.00030170576 |
| time_elapsed            | 1478          |
| total timesteps         | 282125        |
| value_loss              | 0.00019002095 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010900463  |
| ent_coef_loss           | -0.3033538    |
| entropy                 | 1.4143361     |
| episodes                | 1148          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 282780        |
| policy_loss             | -0.58324355   |
| qf1_loss                | 5.2876596e-05 |
| qf2_loss                | 5.7512923e-05 |
| time_elapsed            | 1482          |
| total timesteps         | 282880        |
| value_loss              | 6.771548e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008970646  |
| ent_coef_loss           | 1.9364269     |
| entropy                 | 1.4121859     |
| episodes                | 1152          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 283474        |
| policy_loss             | -0.5645145    |
| qf1_loss                | 2.7075508e-05 |
| qf2_loss                | 2.543344e-05  |
| time_elapsed            | 1485          |
| total timesteps         | 283574        |
| value_loss              | 3.176921e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008847236  |
| ent_coef_loss           | 2.6823354     |
| entropy                 | 1.3610266     |
| episodes                | 1156          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 284136        |
| policy_loss             | -0.5951493    |
| qf1_loss                | 1.7616967e-05 |
| qf2_loss                | 2.774723e-05  |
| time_elapsed            | 1489          |
| total timesteps         | 284236        |
| value_loss              | 3.8620146e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086378364 |
| ent_coef_loss           | 0.22648409    |
| entropy                 | 1.312958      |
| episodes                | 1160          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 284888        |
| policy_loss             | -0.52093065   |
| qf1_loss                | 4.4870525e-05 |
| qf2_loss                | 2.9759252e-05 |
| time_elapsed            | 1493          |
| total timesteps         | 284988        |
| value_loss              | 5.5028344e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008840345  |
| ent_coef_loss           | -1.0045699    |
| entropy                 | 1.3376569     |
| episodes                | 1164          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 285590        |
| policy_loss             | -0.562906     |
| qf1_loss                | 3.0255806e-05 |
| qf2_loss                | 2.837557e-05  |
| time_elapsed            | 1497          |
| total timesteps         | 285690        |
| value_loss              | 2.517738e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009316234  |
| ent_coef_loss           | 0.5461196     |
| entropy                 | 1.2821155     |
| episodes                | 1168          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 286288        |
| policy_loss             | -0.51894665   |
| qf1_loss                | 0.00020643213 |
| qf2_loss                | 0.00011757447 |
| time_elapsed            | 1500          |
| total timesteps         | 286388        |
| value_loss              | 0.00011946143 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087675557 |
| ent_coef_loss           | -1.0615182    |
| entropy                 | 1.432537      |
| episodes                | 1172          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 287007        |
| policy_loss             | -0.5114398    |
| qf1_loss                | 0.00010214898 |
| qf2_loss                | 6.1085055e-05 |
| time_elapsed            | 1504          |
| total timesteps         | 287107        |
| value_loss              | 0.00010124968 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087416236 |
| ent_coef_loss           | -0.9274475    |
| entropy                 | 1.2301354     |
| episodes                | 1176          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 288066        |
| policy_loss             | -0.51401794   |
| qf1_loss                | 3.5192214e-05 |
| qf2_loss                | 5.612184e-05  |
| time_elapsed            | 1509          |
| total timesteps         | 288166        |
| value_loss              | 4.8142152e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087410945 |
| ent_coef_loss           | -4.278659     |
| entropy                 | 1.2817335     |
| episodes                | 1180          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 288839        |
| policy_loss             | -0.5763668    |
| qf1_loss                | 7.509844e-05  |
| qf2_loss                | 6.729338e-05  |
| time_elapsed            | 1513          |
| total timesteps         | 288939        |
| value_loss              | 0.00010853386 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086415315 |
| ent_coef_loss           | -0.0988763    |
| entropy                 | 1.1538389     |
| episodes                | 1184          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 289617        |
| policy_loss             | -0.5933264    |
| qf1_loss                | 0.0001221837  |
| qf2_loss                | 0.00016310117 |
| time_elapsed            | 1518          |
| total timesteps         | 289717        |
| value_loss              | 0.0002783601  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009989518  |
| ent_coef_loss           | -0.34082413   |
| entropy                 | 1.3801838     |
| episodes                | 1188          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 290236        |
| policy_loss             | -0.5507988    |
| qf1_loss                | 5.0866256e-05 |
| qf2_loss                | 6.611565e-05  |
| time_elapsed            | 1521          |
| total timesteps         | 290336        |
| value_loss              | 5.8837595e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009326599  |
| ent_coef_loss           | 3.8971233     |
| entropy                 | 1.1637394     |
| episodes                | 1192          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 290910        |
| policy_loss             | -0.5069853    |
| qf1_loss                | 0.00027673168 |
| qf2_loss                | 0.00019806919 |
| time_elapsed            | 1525          |
| total timesteps         | 291010        |
| value_loss              | 9.4106945e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086230086 |
| ent_coef_loss           | -1.7875257    |
| entropy                 | 1.2491728     |
| episodes                | 1196          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 292146        |
| policy_loss             | -0.57914174   |
| qf1_loss                | 2.8766866e-05 |
| qf2_loss                | 2.6590737e-05 |
| time_elapsed            | 1531          |
| total timesteps         | 292246        |
| value_loss              | 2.3570767e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008407399  |
| ent_coef_loss           | -1.3454093    |
| entropy                 | 1.4634213     |
| episodes                | 1200          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 292788        |
| policy_loss             | -0.5534667    |
| qf1_loss                | 2.6830447e-05 |
| qf2_loss                | 3.1437536e-05 |
| time_elapsed            | 1534          |
| total timesteps         | 292888        |
| value_loss              | 3.9972972e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008581383  |
| ent_coef_loss           | -0.92984545   |
| entropy                 | 1.4949125     |
| episodes                | 1204          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 293538        |
| policy_loss             | -0.5198557    |
| qf1_loss                | 2.1701282e-05 |
| qf2_loss                | 5.432553e-05  |
| time_elapsed            | 1538          |
| total timesteps         | 293638        |
| value_loss              | 5.7525605e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009381891   |
| ent_coef_loss           | -2.1189504     |
| entropy                 | 1.411346       |
| episodes                | 1208           |
| fps                     | 190            |
| mean 100 episode reward | 0.9            |
| n_updates               | 294310         |
| policy_loss             | -0.53573227    |
| qf1_loss                | 0.000117972624 |
| qf2_loss                | 8.700251e-05   |
| time_elapsed            | 1542           |
| total timesteps         | 294410         |
| value_loss              | 7.0012815e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001026519   |
| ent_coef_loss           | 3.4130259     |
| entropy                 | 1.4732492     |
| episodes                | 1212          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 295257        |
| policy_loss             | -0.5014001    |
| qf1_loss                | 3.2940523e-05 |
| qf2_loss                | 3.644504e-05  |
| time_elapsed            | 1547          |
| total timesteps         | 295357        |
| value_loss              | 0.00037471025 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009446091   |
| ent_coef_loss           | -2.9399266     |
| entropy                 | 1.4440056      |
| episodes                | 1216           |
| fps                     | 190            |
| mean 100 episode reward | 0.9            |
| n_updates               | 295947         |
| policy_loss             | -0.5082601     |
| qf1_loss                | 9.7809716e-05  |
| qf2_loss                | 7.068374e-05   |
| time_elapsed            | 1551           |
| total timesteps         | 296047         |
| value_loss              | 0.000119614444 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009759564  |
| ent_coef_loss           | -1.6799998    |
| entropy                 | 1.4716834     |
| episodes                | 1220          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 296621        |
| policy_loss             | -0.499269     |
| qf1_loss                | 3.129773e-05  |
| qf2_loss                | 3.1254178e-05 |
| time_elapsed            | 1554          |
| total timesteps         | 296721        |
| value_loss              | 4.342362e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097072986 |
| ent_coef_loss           | 2.9822578     |
| entropy                 | 1.4260745     |
| episodes                | 1224          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 297282        |
| policy_loss             | -0.50748885   |
| qf1_loss                | 4.906258e-05  |
| qf2_loss                | 4.4942786e-05 |
| time_elapsed            | 1558          |
| total timesteps         | 297382        |
| value_loss              | 9.6745614e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095028116 |
| ent_coef_loss           | 0.19972795    |
| entropy                 | 1.412427      |
| episodes                | 1228          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 298233        |
| policy_loss             | -0.5423062    |
| qf1_loss                | 7.558432e-05  |
| qf2_loss                | 6.819518e-05  |
| time_elapsed            | 1563          |
| total timesteps         | 298333        |
| value_loss              | 3.9752307e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095638714 |
| ent_coef_loss           | -0.89800954   |
| entropy                 | 1.3578879     |
| episodes                | 1232          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 298909        |
| policy_loss             | -0.50382406   |
| qf1_loss                | 0.0015090252  |
| qf2_loss                | 0.001586567   |
| time_elapsed            | 1567          |
| total timesteps         | 299009        |
| value_loss              | 4.7608293e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009128347  |
| ent_coef_loss           | -0.02681306   |
| entropy                 | 1.2524332     |
| episodes                | 1236          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 299552        |
| policy_loss             | -0.48549825   |
| qf1_loss                | 0.0001461265  |
| qf2_loss                | 0.00012181548 |
| time_elapsed            | 1570          |
| total timesteps         | 299652        |
| value_loss              | 0.0001379575  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008930331  |
| ent_coef_loss           | -0.060586274  |
| entropy                 | 1.5119014     |
| episodes                | 1240          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 300581        |
| policy_loss             | -0.5077852    |
| qf1_loss                | 5.224963e-05  |
| qf2_loss                | 5.7894238e-05 |
| time_elapsed            | 1575          |
| total timesteps         | 300681        |
| value_loss              | 5.9727736e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010049996  |
| ent_coef_loss           | -1.0048621    |
| entropy                 | 1.5162628     |
| episodes                | 1244          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 301202        |
| policy_loss             | -0.5449236    |
| qf1_loss                | 3.5242036e-05 |
| qf2_loss                | 6.3795494e-05 |
| time_elapsed            | 1579          |
| total timesteps         | 301302        |
| value_loss              | 2.9440806e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001051892   |
| ent_coef_loss           | 0.36709714    |
| entropy                 | 1.4162837     |
| episodes                | 1248          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 301924        |
| policy_loss             | -0.51603824   |
| qf1_loss                | 3.921587e-05  |
| qf2_loss                | 2.2287597e-05 |
| time_elapsed            | 1583          |
| total timesteps         | 302024        |
| value_loss              | 5.914901e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010264956 |
| ent_coef_loss           | -0.470186    |
| entropy                 | 1.3422104    |
| episodes                | 1252         |
| fps                     | 190          |
| mean 100 episode reward | 0.9          |
| n_updates               | 302699       |
| policy_loss             | -0.52194977  |
| qf1_loss                | 7.741462e-05 |
| qf2_loss                | 6.901198e-05 |
| time_elapsed            | 1587         |
| total timesteps         | 302799       |
| value_loss              | 6.405346e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092762854 |
| ent_coef_loss           | -0.4356079    |
| entropy                 | 1.3680351     |
| episodes                | 1256          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 303438        |
| policy_loss             | -0.510294     |
| qf1_loss                | 6.962501e-05  |
| qf2_loss                | 4.5467325e-05 |
| time_elapsed            | 1590          |
| total timesteps         | 303538        |
| value_loss              | 4.5828263e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000851267   |
| ent_coef_loss           | -1.7342596    |
| entropy                 | 1.2283183     |
| episodes                | 1260          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 304723        |
| policy_loss             | -0.4917124    |
| qf1_loss                | 5.1166804e-05 |
| qf2_loss                | 7.283546e-05  |
| time_elapsed            | 1597          |
| total timesteps         | 304823        |
| value_loss              | 8.571124e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009239046  |
| ent_coef_loss           | 0.019007653   |
| entropy                 | 1.4488763     |
| episodes                | 1264          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 305401        |
| policy_loss             | -0.51834965   |
| qf1_loss                | 3.371342e-05  |
| qf2_loss                | 4.7633697e-05 |
| time_elapsed            | 1601          |
| total timesteps         | 305501        |
| value_loss              | 5.4170116e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008738185  |
| ent_coef_loss           | -1.5995835    |
| entropy                 | 1.3533096     |
| episodes                | 1268          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 306095        |
| policy_loss             | -0.54390574   |
| qf1_loss                | 3.4875564e-05 |
| qf2_loss                | 3.9140123e-05 |
| time_elapsed            | 1604          |
| total timesteps         | 306195        |
| value_loss              | 0.00013515251 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008529813  |
| ent_coef_loss           | -1.8108604    |
| entropy                 | 1.4685435     |
| episodes                | 1272          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 306797        |
| policy_loss             | -0.5164715    |
| qf1_loss                | 2.9033909e-05 |
| qf2_loss                | 3.2602387e-05 |
| time_elapsed            | 1608          |
| total timesteps         | 306897        |
| value_loss              | 4.4107663e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00081839436 |
| ent_coef_loss           | -0.83713037   |
| entropy                 | 1.3315942     |
| episodes                | 1276          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 307505        |
| policy_loss             | -0.55631137   |
| qf1_loss                | 2.8743456e-05 |
| qf2_loss                | 3.5914913e-05 |
| time_elapsed            | 1612          |
| total timesteps         | 307605        |
| value_loss              | 3.0365074e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085644185 |
| ent_coef_loss           | 2.0181832     |
| entropy                 | 1.3528914     |
| episodes                | 1280          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 308251        |
| policy_loss             | -0.50246334   |
| qf1_loss                | 9.104361e-05  |
| qf2_loss                | 0.00011144264 |
| time_elapsed            | 1616          |
| total timesteps         | 308351        |
| value_loss              | 9.173878e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009305516   |
| ent_coef_loss           | 3.622421       |
| entropy                 | 1.5293553      |
| episodes                | 1284           |
| fps                     | 190            |
| mean 100 episode reward | 0.8            |
| n_updates               | 308948         |
| policy_loss             | -0.54270244    |
| qf1_loss                | 2.6269965e-05  |
| qf2_loss                | 3.2479613e-05  |
| time_elapsed            | 1619           |
| total timesteps         | 309048         |
| value_loss              | 0.000120995275 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089927623 |
| ent_coef_loss           | 1.4953375     |
| entropy                 | 1.4551007     |
| episodes                | 1288          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 309698        |
| policy_loss             | -0.50679886   |
| qf1_loss                | 6.5275075e-05 |
| qf2_loss                | 3.0062009e-05 |
| time_elapsed            | 1623          |
| total timesteps         | 309798        |
| value_loss              | 7.078343e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089698035 |
| ent_coef_loss           | 0.9694813     |
| entropy                 | 1.5820234     |
| episodes                | 1292          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 310453        |
| policy_loss             | -0.5655257    |
| qf1_loss                | 4.2748397e-05 |
| qf2_loss                | 3.46058e-05   |
| time_elapsed            | 1627          |
| total timesteps         | 310553        |
| value_loss              | 2.5255564e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000922137   |
| ent_coef_loss           | -1.7132118    |
| entropy                 | 1.507961      |
| episodes                | 1296          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 311191        |
| policy_loss             | -0.5667578    |
| qf1_loss                | 5.7469115e-05 |
| qf2_loss                | 2.9446006e-05 |
| time_elapsed            | 1631          |
| total timesteps         | 311291        |
| value_loss              | 6.050593e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087990426 |
| ent_coef_loss           | -2.431171     |
| entropy                 | 1.5001969     |
| episodes                | 1300          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 311878        |
| policy_loss             | -0.55876607   |
| qf1_loss                | 3.1883577e-05 |
| qf2_loss                | 3.3642547e-05 |
| time_elapsed            | 1635          |
| total timesteps         | 311978        |
| value_loss              | 3.4577697e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008165323  |
| ent_coef_loss           | 0.74542665    |
| entropy                 | 1.3823559     |
| episodes                | 1304          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 312566        |
| policy_loss             | -0.6123761    |
| qf1_loss                | 1.7928298e-05 |
| qf2_loss                | 2.1279651e-05 |
| time_elapsed            | 1639          |
| total timesteps         | 312666        |
| value_loss              | 4.1122657e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00077282405 |
| ent_coef_loss           | 4.065921      |
| entropy                 | 1.4613433     |
| episodes                | 1308          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 313257        |
| policy_loss             | -0.5600871    |
| qf1_loss                | 1.8180015e-05 |
| qf2_loss                | 2.4594687e-05 |
| time_elapsed            | 1642          |
| total timesteps         | 313357        |
| value_loss              | 4.6590307e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00078606553 |
| ent_coef_loss           | 0.5596049     |
| entropy                 | 1.479037      |
| episodes                | 1312          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 313969        |
| policy_loss             | -0.5979115    |
| qf1_loss                | 1.308671e-05  |
| qf2_loss                | 1.9048624e-05 |
| time_elapsed            | 1646          |
| total timesteps         | 314069        |
| value_loss              | 1.9320629e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00079123065 |
| ent_coef_loss           | 1.3189275     |
| entropy                 | 1.5024836     |
| episodes                | 1316          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 314965        |
| policy_loss             | -0.5714936    |
| qf1_loss                | 1.9038365e-05 |
| qf2_loss                | 2.2996079e-05 |
| time_elapsed            | 1651          |
| total timesteps         | 315065        |
| value_loss              | 3.765502e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000790585   |
| ent_coef_loss           | -0.39021146   |
| entropy                 | 1.5055047     |
| episodes                | 1320          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 315650        |
| policy_loss             | -0.55157876   |
| qf1_loss                | 4.1625088e-05 |
| qf2_loss                | 3.6298705e-05 |
| time_elapsed            | 1655          |
| total timesteps         | 315750        |
| value_loss              | 5.1901272e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008348219  |
| ent_coef_loss           | -0.3650115    |
| entropy                 | 1.5411618     |
| episodes                | 1324          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 316334        |
| policy_loss             | -0.56869507   |
| qf1_loss                | 1.2690381e-05 |
| qf2_loss                | 1.4688896e-05 |
| time_elapsed            | 1658          |
| total timesteps         | 316434        |
| value_loss              | 1.8050952e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008376035  |
| ent_coef_loss           | 0.507195      |
| entropy                 | 1.4859407     |
| episodes                | 1328          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 316979        |
| policy_loss             | -0.5625893    |
| qf1_loss                | 2.232108e-05  |
| qf2_loss                | 2.9423243e-05 |
| time_elapsed            | 1662          |
| total timesteps         | 317079        |
| value_loss              | 3.8174607e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008405639  |
| ent_coef_loss           | 1.471037      |
| entropy                 | 1.586642      |
| episodes                | 1332          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 317620        |
| policy_loss             | -0.59060717   |
| qf1_loss                | 7.3562405e-05 |
| qf2_loss                | 3.0008303e-05 |
| time_elapsed            | 1665          |
| total timesteps         | 317720        |
| value_loss              | 3.2099422e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0007728624 |
| ent_coef_loss           | 0.18368733   |
| entropy                 | 1.4532135    |
| episodes                | 1336         |
| fps                     | 190          |
| mean 100 episode reward | 0.8          |
| n_updates               | 318294       |
| policy_loss             | -0.5287227   |
| qf1_loss                | 6.934874e-05 |
| qf2_loss                | 5.727509e-05 |
| time_elapsed            | 1669         |
| total timesteps         | 318394       |
| value_loss              | 8.713745e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00076760666 |
| ent_coef_loss           | 0.645488      |
| entropy                 | 1.4513173     |
| episodes                | 1340          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 318981        |
| policy_loss             | -0.57933474   |
| qf1_loss                | 9.987378e-06  |
| qf2_loss                | 9.665897e-06  |
| time_elapsed            | 1672          |
| total timesteps         | 319081        |
| value_loss              | 1.6328322e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008087506  |
| ent_coef_loss           | 0.12745434    |
| entropy                 | 1.5192263     |
| episodes                | 1344          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 319746        |
| policy_loss             | -0.5847676    |
| qf1_loss                | 1.8657222e-05 |
| qf2_loss                | 1.7617589e-05 |
| time_elapsed            | 1676          |
| total timesteps         | 319846        |
| value_loss              | 1.2395445e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00082986    |
| ent_coef_loss           | 0.08733964    |
| entropy                 | 1.670238      |
| episodes                | 1348          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 320496        |
| policy_loss             | -0.5462605    |
| qf1_loss                | 1.4752547e-05 |
| qf2_loss                | 1.7637809e-05 |
| time_elapsed            | 1680          |
| total timesteps         | 320596        |
| value_loss              | 2.868921e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008141576  |
| ent_coef_loss           | 2.460846      |
| entropy                 | 1.4324169     |
| episodes                | 1352          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 321433        |
| policy_loss             | -0.55534697   |
| qf1_loss                | 1.5484991e-05 |
| qf2_loss                | 2.3119637e-05 |
| time_elapsed            | 1685          |
| total timesteps         | 321533        |
| value_loss              | 5.381136e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008939308  |
| ent_coef_loss           | 0.78729177    |
| entropy                 | 1.5285223     |
| episodes                | 1356          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 322093        |
| policy_loss             | -0.50066197   |
| qf1_loss                | 2.2002816e-05 |
| qf2_loss                | 1.4209074e-05 |
| time_elapsed            | 1688          |
| total timesteps         | 322193        |
| value_loss              | 7.691217e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085311267 |
| ent_coef_loss           | 1.0689064     |
| entropy                 | 1.5696349     |
| episodes                | 1360          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 322767        |
| policy_loss             | -0.59120965   |
| qf1_loss                | 1.8246841e-05 |
| qf2_loss                | 2.2954859e-05 |
| time_elapsed            | 1692          |
| total timesteps         | 322867        |
| value_loss              | 3.0231196e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008511002  |
| ent_coef_loss           | 0.49456823    |
| entropy                 | 1.4723377     |
| episodes                | 1364          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 323450        |
| policy_loss             | -0.5743514    |
| qf1_loss                | 3.1918516e-05 |
| qf2_loss                | 1.8821222e-05 |
| time_elapsed            | 1696          |
| total timesteps         | 323550        |
| value_loss              | 3.7028436e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000897956   |
| ent_coef_loss           | 0.40924692    |
| entropy                 | 1.5988598     |
| episodes                | 1368          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 324412        |
| policy_loss             | -0.60435486   |
| qf1_loss                | 2.5618328e-05 |
| qf2_loss                | 2.2307162e-05 |
| time_elapsed            | 1701          |
| total timesteps         | 324512        |
| value_loss              | 3.0864372e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001012217   |
| ent_coef_loss           | 0.94896793    |
| entropy                 | 1.5194495     |
| episodes                | 1372          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 325381        |
| policy_loss             | -0.5654688    |
| qf1_loss                | 8.164378e-05  |
| qf2_loss                | 5.430469e-05  |
| time_elapsed            | 1706          |
| total timesteps         | 325481        |
| value_loss              | 7.8139594e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009045359  |
| ent_coef_loss           | 2.515738      |
| entropy                 | 1.4901372     |
| episodes                | 1376          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 326131        |
| policy_loss             | -0.57046056   |
| qf1_loss                | 3.16914e-05   |
| qf2_loss                | 4.3614902e-05 |
| time_elapsed            | 1710          |
| total timesteps         | 326231        |
| value_loss              | 6.727526e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009377003  |
| ent_coef_loss           | 1.9028156     |
| entropy                 | 1.454694      |
| episodes                | 1380          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 326812        |
| policy_loss             | -0.5418886    |
| qf1_loss                | 4.2732183e-05 |
| qf2_loss                | 5.6399513e-05 |
| time_elapsed            | 1713          |
| total timesteps         | 326912        |
| value_loss              | 7.0403905e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009916413  |
| ent_coef_loss           | -0.39878315   |
| entropy                 | 1.4992144     |
| episodes                | 1384          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 327526        |
| policy_loss             | -0.5726345    |
| qf1_loss                | 4.2891945e-05 |
| qf2_loss                | 5.3881533e-05 |
| time_elapsed            | 1717          |
| total timesteps         | 327626        |
| value_loss              | 9.178826e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001036925   |
| ent_coef_loss           | 0.53571075    |
| entropy                 | 1.4397855     |
| episodes                | 1388          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 328197        |
| policy_loss             | -0.5355274    |
| qf1_loss                | 3.989325e-05  |
| qf2_loss                | 3.0901356e-05 |
| time_elapsed            | 1721          |
| total timesteps         | 328297        |
| value_loss              | 0.00019157308 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010637358  |
| ent_coef_loss           | 2.2689476     |
| entropy                 | 1.4717056     |
| episodes                | 1392          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 328957        |
| policy_loss             | -0.5686059    |
| qf1_loss                | 4.757548e-05  |
| qf2_loss                | 3.7594684e-05 |
| time_elapsed            | 1725          |
| total timesteps         | 329057        |
| value_loss              | 3.243183e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011309988  |
| ent_coef_loss           | 1.650443      |
| entropy                 | 1.2664216     |
| episodes                | 1396          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 330201        |
| policy_loss             | -0.55597365   |
| qf1_loss                | 2.191347e-05  |
| qf2_loss                | 2.8349948e-05 |
| time_elapsed            | 1731          |
| total timesteps         | 330301        |
| value_loss              | 3.7670183e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010888114  |
| ent_coef_loss           | 0.18205333    |
| entropy                 | 1.5262301     |
| episodes                | 1400          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 330874        |
| policy_loss             | -0.56638914   |
| qf1_loss                | 3.6682566e-05 |
| qf2_loss                | 4.4108572e-05 |
| time_elapsed            | 1735          |
| total timesteps         | 330974        |
| value_loss              | 5.3424475e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010548369  |
| ent_coef_loss           | -1.1240366    |
| entropy                 | 1.5381415     |
| episodes                | 1404          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 331786        |
| policy_loss             | -0.57494783   |
| qf1_loss                | 0.00017692999 |
| qf2_loss                | 0.00019143845 |
| time_elapsed            | 1740          |
| total timesteps         | 331886        |
| value_loss              | 8.09872e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011149057  |
| ent_coef_loss           | -2.430756     |
| entropy                 | 1.4996302     |
| episodes                | 1408          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 332622        |
| policy_loss             | -0.55991447   |
| qf1_loss                | 1.6730291e-05 |
| qf2_loss                | 1.6786043e-05 |
| time_elapsed            | 1744          |
| total timesteps         | 332722        |
| value_loss              | 1.7854152e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010441431  |
| ent_coef_loss           | 1.5351038     |
| entropy                 | 1.2734694     |
| episodes                | 1412          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 333382        |
| policy_loss             | -0.50601304   |
| qf1_loss                | 5.3256077e-05 |
| qf2_loss                | 2.5735824e-05 |
| time_elapsed            | 1748          |
| total timesteps         | 333482        |
| value_loss              | 7.3364085e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010888728  |
| ent_coef_loss           | -2.0764568    |
| entropy                 | 1.558507      |
| episodes                | 1416          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 334252        |
| policy_loss             | -0.5150414    |
| qf1_loss                | 9.627414e-05  |
| qf2_loss                | 4.0017905e-05 |
| time_elapsed            | 1753          |
| total timesteps         | 334352        |
| value_loss              | 3.9447867e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010011302  |
| ent_coef_loss           | -0.42182377   |
| entropy                 | 1.4230676     |
| episodes                | 1420          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 335466        |
| policy_loss             | -0.54112506   |
| qf1_loss                | 5.190661e-05  |
| qf2_loss                | 5.0876326e-05 |
| time_elapsed            | 1759          |
| total timesteps         | 335566        |
| value_loss              | 3.5325527e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00108788    |
| ent_coef_loss           | 1.3356817     |
| entropy                 | 1.5334988     |
| episodes                | 1424          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 336131        |
| policy_loss             | -0.53498745   |
| qf1_loss                | 0.00010586475 |
| qf2_loss                | 6.2401e-05    |
| time_elapsed            | 1763          |
| total timesteps         | 336231        |
| value_loss              | 0.0001816566  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011060036  |
| ent_coef_loss           | 4.3813286     |
| entropy                 | 1.347378      |
| episodes                | 1428          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 336772        |
| policy_loss             | -0.47388232   |
| qf1_loss                | 8.433735e-05  |
| qf2_loss                | 4.8687514e-05 |
| time_elapsed            | 1766          |
| total timesteps         | 336872        |
| value_loss              | 4.0436254e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001041671   |
| ent_coef_loss           | 0.37186998    |
| entropy                 | 1.3127067     |
| episodes                | 1432          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 337445        |
| policy_loss             | -0.47606334   |
| qf1_loss                | 0.00072245696 |
| qf2_loss                | 0.00031019712 |
| time_elapsed            | 1770          |
| total timesteps         | 337545        |
| value_loss              | 6.236391e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010771275  |
| ent_coef_loss           | 1.5147341     |
| entropy                 | 1.4342742     |
| episodes                | 1436          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 338173        |
| policy_loss             | -0.47919863   |
| qf1_loss                | 2.4405508e-05 |
| qf2_loss                | 2.903334e-05  |
| time_elapsed            | 1773          |
| total timesteps         | 338273        |
| value_loss              | 3.5113826e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009864314  |
| ent_coef_loss           | -1.8140948    |
| entropy                 | 1.2461183     |
| episodes                | 1440          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 339133        |
| policy_loss             | -0.5213516    |
| qf1_loss                | 4.387821e-05  |
| qf2_loss                | 4.8248672e-05 |
| time_elapsed            | 1778          |
| total timesteps         | 339233        |
| value_loss              | 6.201848e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010426585  |
| ent_coef_loss           | 2.14784       |
| entropy                 | 1.1801769     |
| episodes                | 1444          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 339848        |
| policy_loss             | -0.49871358   |
| qf1_loss                | 2.8388089e-05 |
| qf2_loss                | 2.9372333e-05 |
| time_elapsed            | 1782          |
| total timesteps         | 339948        |
| value_loss              | 9.3146366e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011594666  |
| ent_coef_loss           | 0.43147016    |
| entropy                 | 1.4319854     |
| episodes                | 1448          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 340516        |
| policy_loss             | -0.5139388    |
| qf1_loss                | 4.1141433e-05 |
| qf2_loss                | 4.3512555e-05 |
| time_elapsed            | 1786          |
| total timesteps         | 340616        |
| value_loss              | 2.6677026e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011771063  |
| ent_coef_loss           | -0.027978152  |
| entropy                 | 1.1913676     |
| episodes                | 1452          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 341285        |
| policy_loss             | -0.45595443   |
| qf1_loss                | 0.00015455695 |
| qf2_loss                | 0.00031553133 |
| time_elapsed            | 1790          |
| total timesteps         | 341385        |
| value_loss              | 0.00011706729 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001332993   |
| ent_coef_loss           | 1.6229247     |
| entropy                 | 1.557954      |
| episodes                | 1456          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 342236        |
| policy_loss             | -0.46093202   |
| qf1_loss                | 0.00052644336 |
| qf2_loss                | 0.0005830641  |
| time_elapsed            | 1795          |
| total timesteps         | 342336        |
| value_loss              | 7.712603e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013252174  |
| ent_coef_loss           | 0.95416486    |
| entropy                 | 1.3816        |
| episodes                | 1460          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 342956        |
| policy_loss             | -0.46027586   |
| qf1_loss                | 5.883485e-05  |
| qf2_loss                | 0.00021278061 |
| time_elapsed            | 1799          |
| total timesteps         | 343056        |
| value_loss              | 4.2812528e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012653884  |
| ent_coef_loss           | -2.2464027    |
| entropy                 | 1.3879603     |
| episodes                | 1464          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 343631        |
| policy_loss             | -0.5309989    |
| qf1_loss                | 3.873843e-05  |
| qf2_loss                | 5.644148e-05  |
| time_elapsed            | 1802          |
| total timesteps         | 343731        |
| value_loss              | 6.0712562e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011951039  |
| ent_coef_loss           | 1.5696449     |
| entropy                 | 1.381475      |
| episodes                | 1468          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 344289        |
| policy_loss             | -0.49403203   |
| qf1_loss                | 5.9136546e-05 |
| qf2_loss                | 7.5711054e-05 |
| time_elapsed            | 1806          |
| total timesteps         | 344389        |
| value_loss              | 3.5986377e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0011408117 |
| ent_coef_loss           | 0.94105834   |
| entropy                 | 1.457181     |
| episodes                | 1472         |
| fps                     | 190          |
| mean 100 episode reward | 0.8          |
| n_updates               | 345018       |
| policy_loss             | -0.5571971   |
| qf1_loss                | 0.0008333175 |
| qf2_loss                | 0.0008072188 |
| time_elapsed            | 1809         |
| total timesteps         | 345118       |
| value_loss              | 3.206628e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010569888  |
| ent_coef_loss           | 2.011201      |
| entropy                 | 1.2728462     |
| episodes                | 1476          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 345753        |
| policy_loss             | -0.49685246   |
| qf1_loss                | 0.00025382062 |
| qf2_loss                | 6.7439716e-05 |
| time_elapsed            | 1813          |
| total timesteps         | 345853        |
| value_loss              | 0.00025608926 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010584363  |
| ent_coef_loss           | 0.0032808185  |
| entropy                 | 1.446239      |
| episodes                | 1480          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 346427        |
| policy_loss             | -0.5070466    |
| qf1_loss                | 3.572758e-05  |
| qf2_loss                | 3.9339095e-05 |
| time_elapsed            | 1817          |
| total timesteps         | 346527        |
| value_loss              | 2.9781615e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010374977  |
| ent_coef_loss           | 0.94623405    |
| entropy                 | 1.3776165     |
| episodes                | 1484          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 347133        |
| policy_loss             | -0.46224618   |
| qf1_loss                | 3.6983976e-05 |
| qf2_loss                | 0.00011672189 |
| time_elapsed            | 1821          |
| total timesteps         | 347233        |
| value_loss              | 5.161702e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011131134  |
| ent_coef_loss           | 0.98966765    |
| entropy                 | 1.3485402     |
| episodes                | 1488          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 348150        |
| policy_loss             | -0.5034252    |
| qf1_loss                | 0.00063862343 |
| qf2_loss                | 0.00072786986 |
| time_elapsed            | 1826          |
| total timesteps         | 348250        |
| value_loss              | 0.00030911007 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010099333  |
| ent_coef_loss           | 0.7551532     |
| entropy                 | 1.1606963     |
| episodes                | 1492          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 348877        |
| policy_loss             | -0.49235666   |
| qf1_loss                | 5.0578776e-05 |
| qf2_loss                | 3.261559e-05  |
| time_elapsed            | 1830          |
| total timesteps         | 348977        |
| value_loss              | 0.0002516241  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008987421  |
| ent_coef_loss           | -0.8093377    |
| entropy                 | 1.2332401     |
| episodes                | 1496          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 349633        |
| policy_loss             | -0.5418384    |
| qf1_loss                | 4.5628785e-05 |
| qf2_loss                | 2.4597339e-05 |
| time_elapsed            | 1834          |
| total timesteps         | 349733        |
| value_loss              | 4.0082763e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00095318607 |
| ent_coef_loss           | 0.20334256    |
| entropy                 | 1.2463536     |
| episodes                | 1500          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 350350        |
| policy_loss             | -0.53001213   |
| qf1_loss                | 0.00049473863 |
| qf2_loss                | 0.00032074813 |
| time_elapsed            | 1838          |
| total timesteps         | 350450        |
| value_loss              | 0.0002838433  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010376135  |
| ent_coef_loss           | -0.2795285    |
| entropy                 | 1.3016659     |
| episodes                | 1504          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 351039        |
| policy_loss             | -0.5374481    |
| qf1_loss                | 6.153055e-05  |
| qf2_loss                | 4.071978e-05  |
| time_elapsed            | 1841          |
| total timesteps         | 351139        |
| value_loss              | 3.6994832e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009856096  |
| ent_coef_loss           | -0.4964436    |
| entropy                 | 1.3332065     |
| episodes                | 1508          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 351721        |
| policy_loss             | -0.50989443   |
| qf1_loss                | 2.6826876e-05 |
| qf2_loss                | 2.1248341e-05 |
| time_elapsed            | 1845          |
| total timesteps         | 351821        |
| value_loss              | 3.4225188e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009599802  |
| ent_coef_loss           | -2.287177     |
| entropy                 | 0.95137846    |
| episodes                | 1512          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 352357        |
| policy_loss             | -0.4897865    |
| qf1_loss                | 0.00021191104 |
| qf2_loss                | 0.00035589212 |
| time_elapsed            | 1848          |
| total timesteps         | 352457        |
| value_loss              | 0.0004421285  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009045398  |
| ent_coef_loss           | 1.8788409     |
| entropy                 | 1.257933      |
| episodes                | 1516          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 353046        |
| policy_loss             | -0.49908125   |
| qf1_loss                | 8.2064595e-05 |
| qf2_loss                | 7.014595e-05  |
| time_elapsed            | 1852          |
| total timesteps         | 353146        |
| value_loss              | 0.00010190275 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009649178  |
| ent_coef_loss           | -1.7117577    |
| entropy                 | 1.2485464     |
| episodes                | 1520          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 353750        |
| policy_loss             | -0.49951982   |
| qf1_loss                | 8.7047294e-05 |
| qf2_loss                | 0.00013778839 |
| time_elapsed            | 1855          |
| total timesteps         | 353850        |
| value_loss              | 5.5873345e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086930895 |
| ent_coef_loss           | 1.9094224     |
| entropy                 | 1.1204512     |
| episodes                | 1524          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 354510        |
| policy_loss             | -0.49536085   |
| qf1_loss                | 0.0010336032  |
| qf2_loss                | 0.0010922148  |
| time_elapsed            | 1859          |
| total timesteps         | 354610        |
| value_loss              | 4.4544817e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009252638  |
| ent_coef_loss           | -3.7152715    |
| entropy                 | 1.4534924     |
| episodes                | 1528          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 355248        |
| policy_loss             | -0.5924808    |
| qf1_loss                | 1.3655671e-05 |
| qf2_loss                | 1.2608502e-05 |
| time_elapsed            | 1863          |
| total timesteps         | 355348        |
| value_loss              | 2.6954021e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009889803  |
| ent_coef_loss           | 1.6036935     |
| entropy                 | 1.3800602     |
| episodes                | 1532          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 355927        |
| policy_loss             | -0.55530953   |
| qf1_loss                | 7.8286925e-05 |
| qf2_loss                | 6.583731e-05  |
| time_elapsed            | 1867          |
| total timesteps         | 356027        |
| value_loss              | 0.00019083399 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00092249986 |
| ent_coef_loss           | 0.08256158    |
| entropy                 | 1.3440349     |
| episodes                | 1536          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 356596        |
| policy_loss             | -0.50780296   |
| qf1_loss                | 3.3067558e-05 |
| qf2_loss                | 6.1108774e-05 |
| time_elapsed            | 1870          |
| total timesteps         | 356696        |
| value_loss              | 5.430731e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089504744 |
| ent_coef_loss           | 0.7588335     |
| entropy                 | 1.3473268     |
| episodes                | 1540          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 357337        |
| policy_loss             | -0.4996907    |
| qf1_loss                | 2.4778676e-05 |
| qf2_loss                | 2.4624629e-05 |
| time_elapsed            | 1874          |
| total timesteps         | 357437        |
| value_loss              | 3.6880894e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00080747594 |
| ent_coef_loss           | 3.4527748     |
| entropy                 | 1.1766541     |
| episodes                | 1544          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 358246        |
| policy_loss             | -0.53642964   |
| qf1_loss                | 8.856789e-05  |
| qf2_loss                | 8.249192e-05  |
| time_elapsed            | 1879          |
| total timesteps         | 358346        |
| value_loss              | 4.8348185e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008369304  |
| ent_coef_loss           | 1.8272325     |
| entropy                 | 1.2288688     |
| episodes                | 1548          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 358962        |
| policy_loss             | -0.52146345   |
| qf1_loss                | 4.4469194e-05 |
| qf2_loss                | 4.9711463e-05 |
| time_elapsed            | 1883          |
| total timesteps         | 359062        |
| value_loss              | 3.836533e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008113664  |
| ent_coef_loss           | 0.5391845     |
| entropy                 | 1.2356632     |
| episodes                | 1552          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 359729        |
| policy_loss             | -0.51264733   |
| qf1_loss                | 4.1988584e-05 |
| qf2_loss                | 3.2501604e-05 |
| time_elapsed            | 1887          |
| total timesteps         | 359829        |
| value_loss              | 4.403181e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00081712316 |
| ent_coef_loss           | 0.48202047    |
| entropy                 | 1.1015823     |
| episodes                | 1556          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 360876        |
| policy_loss             | -0.5205507    |
| qf1_loss                | 1.9893905e-05 |
| qf2_loss                | 4.1712803e-05 |
| time_elapsed            | 1893          |
| total timesteps         | 360976        |
| value_loss              | 4.4836557e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00080735853 |
| ent_coef_loss           | 2.2380328     |
| entropy                 | 1.242068      |
| episodes                | 1560          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 361587        |
| policy_loss             | -0.5447781    |
| qf1_loss                | 0.000572069   |
| qf2_loss                | 0.0005925219  |
| time_elapsed            | 1897          |
| total timesteps         | 361687        |
| value_loss              | 8.3083476e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00083422265 |
| ent_coef_loss           | -2.0616643    |
| entropy                 | 1.3790846     |
| episodes                | 1564          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 362296        |
| policy_loss             | -0.5461316    |
| qf1_loss                | 4.1759435e-05 |
| qf2_loss                | 4.550122e-05  |
| time_elapsed            | 1900          |
| total timesteps         | 362396        |
| value_loss              | 6.642642e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007259508  |
| ent_coef_loss           | 2.0421321     |
| entropy                 | 1.3269184     |
| episodes                | 1568          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 363049        |
| policy_loss             | -0.53072023   |
| qf1_loss                | 3.5292906e-05 |
| qf2_loss                | 1.1339802e-05 |
| time_elapsed            | 1904          |
| total timesteps         | 363149        |
| value_loss              | 2.3250885e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007768283  |
| ent_coef_loss           | 2.1185453     |
| entropy                 | 1.0454359     |
| episodes                | 1572          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 363740        |
| policy_loss             | -0.55049765   |
| qf1_loss                | 6.9926406e-05 |
| qf2_loss                | 4.0177703e-05 |
| time_elapsed            | 1908          |
| total timesteps         | 363840        |
| value_loss              | 4.4745673e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00082488824 |
| ent_coef_loss           | -2.1073134    |
| entropy                 | 1.2509478     |
| episodes                | 1576          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 364459        |
| policy_loss             | -0.53509927   |
| qf1_loss                | 2.3942841e-05 |
| qf2_loss                | 2.3211283e-05 |
| time_elapsed            | 1912          |
| total timesteps         | 364559        |
| value_loss              | 2.4626414e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007293751  |
| ent_coef_loss           | -0.40726495   |
| entropy                 | 1.1468687     |
| episodes                | 1580          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 365198        |
| policy_loss             | -0.56948155   |
| qf1_loss                | 7.240814e-05  |
| qf2_loss                | 3.6254358e-05 |
| time_elapsed            | 1916          |
| total timesteps         | 365298        |
| value_loss              | 3.472093e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007969361  |
| ent_coef_loss           | -1.6020273    |
| entropy                 | 1.1058095     |
| episodes                | 1584          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 365885        |
| policy_loss             | -0.6081667    |
| qf1_loss                | 3.4696634e-05 |
| qf2_loss                | 3.0861225e-05 |
| time_elapsed            | 1920          |
| total timesteps         | 365985        |
| value_loss              | 4.1559062e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00081653893 |
| ent_coef_loss           | -1.0711675    |
| entropy                 | 1.264756      |
| episodes                | 1588          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 366602        |
| policy_loss             | -0.5410209    |
| qf1_loss                | 1.9266241e-05 |
| qf2_loss                | 1.32881e-05   |
| time_elapsed            | 1923          |
| total timesteps         | 366702        |
| value_loss              | 1.663912e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090953655 |
| ent_coef_loss           | -1.4211689    |
| entropy                 | 1.4134538     |
| episodes                | 1592          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 367304        |
| policy_loss             | -0.5533253    |
| qf1_loss                | 3.352388e-05  |
| qf2_loss                | 6.4377135e-05 |
| time_elapsed            | 1927          |
| total timesteps         | 367404        |
| value_loss              | 5.689782e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009805479  |
| ent_coef_loss           | 1.8394036     |
| entropy                 | 1.1983678     |
| episodes                | 1596          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 368095        |
| policy_loss             | -0.5528986    |
| qf1_loss                | 8.392426e-05  |
| qf2_loss                | 5.854119e-05  |
| time_elapsed            | 1931          |
| total timesteps         | 368195        |
| value_loss              | 3.7872505e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008978576  |
| ent_coef_loss           | -0.08167869   |
| entropy                 | 1.2749739     |
| episodes                | 1600          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 368805        |
| policy_loss             | -0.5523344    |
| qf1_loss                | 0.00012922383 |
| qf2_loss                | 0.00017161778 |
| time_elapsed            | 1935          |
| total timesteps         | 368905        |
| value_loss              | 0.00022320484 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093860837 |
| ent_coef_loss           | 1.1348443     |
| entropy                 | 1.3191273     |
| episodes                | 1604          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 369515        |
| policy_loss             | -0.5523327    |
| qf1_loss                | 8.059546e-05  |
| qf2_loss                | 3.554091e-05  |
| time_elapsed            | 1939          |
| total timesteps         | 369615        |
| value_loss              | 2.4440727e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009520873  |
| ent_coef_loss           | -0.90270936   |
| entropy                 | 1.2495303     |
| episodes                | 1608          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 370225        |
| policy_loss             | -0.5114963    |
| qf1_loss                | 6.273393e-05  |
| qf2_loss                | 1.7426113e-05 |
| time_elapsed            | 1942          |
| total timesteps         | 370325        |
| value_loss              | 6.3445805e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000834937   |
| ent_coef_loss           | -3.053731     |
| entropy                 | 1.2829099     |
| episodes                | 1612          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 370923        |
| policy_loss             | -0.61271894   |
| qf1_loss                | 0.00010207872 |
| qf2_loss                | 4.5373614e-05 |
| time_elapsed            | 1946          |
| total timesteps         | 371023        |
| value_loss              | 3.0878557e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008415288  |
| ent_coef_loss           | -3.0290585    |
| entropy                 | 1.2282261     |
| episodes                | 1616          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 371644        |
| policy_loss             | -0.54712284   |
| qf1_loss                | 3.0006488e-05 |
| qf2_loss                | 4.6847163e-05 |
| time_elapsed            | 1950          |
| total timesteps         | 371744        |
| value_loss              | 7.846934e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0008629014 |
| ent_coef_loss           | 0.085900456  |
| entropy                 | 1.245719     |
| episodes                | 1620         |
| fps                     | 190          |
| mean 100 episode reward | 0.9          |
| n_updates               | 372343       |
| policy_loss             | -0.5486639   |
| qf1_loss                | 5.441879e-05 |
| qf2_loss                | 1.941211e-05 |
| time_elapsed            | 1954         |
| total timesteps         | 372443       |
| value_loss              | 4.333041e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089597533 |
| ent_coef_loss           | 2.5206795     |
| entropy                 | 1.0634525     |
| episodes                | 1624          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 373023        |
| policy_loss             | -0.51443046   |
| qf1_loss                | 5.4587978e-05 |
| qf2_loss                | 4.1918855e-05 |
| time_elapsed            | 1957          |
| total timesteps         | 373123        |
| value_loss              | 0.0002828167  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009428199   |
| ent_coef_loss           | 1.4434881      |
| entropy                 | 1.2932004      |
| episodes                | 1628           |
| fps                     | 190            |
| mean 100 episode reward | 0.9            |
| n_updates               | 373723         |
| policy_loss             | -0.5583364     |
| qf1_loss                | 3.4320423e-05  |
| qf2_loss                | 6.617434e-05   |
| time_elapsed            | 1961           |
| total timesteps         | 373823         |
| value_loss              | 0.000102530554 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009099174  |
| ent_coef_loss           | 0.20802695    |
| entropy                 | 1.1768036     |
| episodes                | 1632          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 374402        |
| policy_loss             | -0.5477903    |
| qf1_loss                | 3.727664e-05  |
| qf2_loss                | 7.782859e-05  |
| time_elapsed            | 1964          |
| total timesteps         | 374502        |
| value_loss              | 3.8237147e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00081429037 |
| ent_coef_loss           | -1.8845954    |
| entropy                 | 0.9889797     |
| episodes                | 1636          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 375066        |
| policy_loss             | -0.55965376   |
| qf1_loss                | 2.4424122e-05 |
| qf2_loss                | 2.4757852e-05 |
| time_elapsed            | 1968          |
| total timesteps         | 375166        |
| value_loss              | 2.0823489e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00087389187 |
| ent_coef_loss           | -1.3982575    |
| entropy                 | 1.1066475     |
| episodes                | 1640          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 375999        |
| policy_loss             | -0.61653113   |
| qf1_loss                | 5.9396792e-05 |
| qf2_loss                | 6.986748e-05  |
| time_elapsed            | 1973          |
| total timesteps         | 376099        |
| value_loss              | 6.0955652e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093909004 |
| ent_coef_loss           | 2.128007      |
| entropy                 | 1.2848095     |
| episodes                | 1644          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 377050        |
| policy_loss             | -0.54331267   |
| qf1_loss                | 0.00016576778 |
| qf2_loss                | 5.486422e-05  |
| time_elapsed            | 1978          |
| total timesteps         | 377150        |
| value_loss              | 0.0001245043  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090436207 |
| ent_coef_loss           | -0.54629564   |
| entropy                 | 1.3264849     |
| episodes                | 1648          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 378052        |
| policy_loss             | -0.5159966    |
| qf1_loss                | 3.423892e-05  |
| qf2_loss                | 2.5763973e-05 |
| time_elapsed            | 1984          |
| total timesteps         | 378152        |
| value_loss              | 7.770053e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009191707   |
| ent_coef_loss           | 1.834696       |
| entropy                 | 1.347184       |
| episodes                | 1652           |
| fps                     | 190            |
| mean 100 episode reward | 0.8            |
| n_updates               | 378786         |
| policy_loss             | -0.5068866     |
| qf1_loss                | 0.000117389834 |
| qf2_loss                | 0.000100596764 |
| time_elapsed            | 1987           |
| total timesteps         | 378886         |
| value_loss              | 8.667349e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009451881  |
| ent_coef_loss           | 0.6419742     |
| entropy                 | 1.35584       |
| episodes                | 1656          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 379498        |
| policy_loss             | -0.54749346   |
| qf1_loss                | 4.0248746e-05 |
| qf2_loss                | 4.553689e-05  |
| time_elapsed            | 1991          |
| total timesteps         | 379598        |
| value_loss              | 2.3280603e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093993184 |
| ent_coef_loss           | -0.4371475    |
| entropy                 | 1.3197104     |
| episodes                | 1660          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 380492        |
| policy_loss             | -0.52802503   |
| qf1_loss                | 6.168305e-05  |
| qf2_loss                | 3.9716313e-05 |
| time_elapsed            | 1996          |
| total timesteps         | 380592        |
| value_loss              | 6.134162e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090747664 |
| ent_coef_loss           | 0.95390004    |
| entropy                 | 1.2374349     |
| episodes                | 1664          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 381233        |
| policy_loss             | -0.5481349    |
| qf1_loss                | 3.4645913e-05 |
| qf2_loss                | 2.317795e-05  |
| time_elapsed            | 2000          |
| total timesteps         | 381333        |
| value_loss              | 4.482791e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009396715  |
| ent_coef_loss           | -1.3935406    |
| entropy                 | 1.3425614     |
| episodes                | 1668          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 381957        |
| policy_loss             | -0.53065455   |
| qf1_loss                | 3.77659e-05   |
| qf2_loss                | 3.778832e-05  |
| time_elapsed            | 2004          |
| total timesteps         | 382057        |
| value_loss              | 3.0333835e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00093574834 |
| ent_coef_loss           | 0.51046956    |
| entropy                 | 1.0870546     |
| episodes                | 1672          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 382718        |
| policy_loss             | -0.49623352   |
| qf1_loss                | 5.3694635e-05 |
| qf2_loss                | 8.130961e-05  |
| time_elapsed            | 2008          |
| total timesteps         | 382818        |
| value_loss              | 0.00011015253 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009377213   |
| ent_coef_loss           | 6.0628443      |
| entropy                 | 1.0304148      |
| episodes                | 1676           |
| fps                     | 190            |
| mean 100 episode reward | 0.8            |
| n_updates               | 383417         |
| policy_loss             | -0.48406595    |
| qf1_loss                | 5.3817028e-05  |
| qf2_loss                | 0.000119387005 |
| time_elapsed            | 2012           |
| total timesteps         | 383517         |
| value_loss              | 0.0001792353   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001005604   |
| ent_coef_loss           | 3.4115005     |
| entropy                 | 1.3691708     |
| episodes                | 1680          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 384096        |
| policy_loss             | -0.5468478    |
| qf1_loss                | 3.8753005e-05 |
| qf2_loss                | 6.2883395e-05 |
| time_elapsed            | 2015          |
| total timesteps         | 384196        |
| value_loss              | 0.0005279433  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010235833  |
| ent_coef_loss           | -2.1276205    |
| entropy                 | 1.4462965     |
| episodes                | 1684          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 384779        |
| policy_loss             | -0.5098601    |
| qf1_loss                | 4.9103914e-05 |
| qf2_loss                | 3.1023297e-05 |
| time_elapsed            | 2019          |
| total timesteps         | 384879        |
| value_loss              | 5.788746e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010469155  |
| ent_coef_loss           | 2.2500935     |
| entropy                 | 1.3748089     |
| episodes                | 1688          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 385453        |
| policy_loss             | -0.567171     |
| qf1_loss                | 5.7756402e-05 |
| qf2_loss                | 4.702047e-05  |
| time_elapsed            | 2022          |
| total timesteps         | 385553        |
| value_loss              | 6.713928e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010462553  |
| ent_coef_loss           | -0.70752096   |
| entropy                 | 1.3933831     |
| episodes                | 1692          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 386117        |
| policy_loss             | -0.529417     |
| qf1_loss                | 6.4677406e-05 |
| qf2_loss                | 6.741044e-05  |
| time_elapsed            | 2026          |
| total timesteps         | 386217        |
| value_loss              | 5.1923955e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010049843  |
| ent_coef_loss           | -0.6681626    |
| entropy                 | 1.2715397     |
| episodes                | 1696          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 387340        |
| policy_loss             | -0.51365453   |
| qf1_loss                | 3.9445044e-05 |
| qf2_loss                | 5.03357e-05   |
| time_elapsed            | 2032          |
| total timesteps         | 387440        |
| value_loss              | 5.4071177e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010117987  |
| ent_coef_loss           | -2.0807662    |
| entropy                 | 1.4894402     |
| episodes                | 1700          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 388009        |
| policy_loss             | -0.5868579    |
| qf1_loss                | 4.5103563e-05 |
| qf2_loss                | 3.1718162e-05 |
| time_elapsed            | 2036          |
| total timesteps         | 388109        |
| value_loss              | 2.6789956e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009888412  |
| ent_coef_loss           | -1.3459398    |
| entropy                 | 1.2079797     |
| episodes                | 1704          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 388747        |
| policy_loss             | -0.48650193   |
| qf1_loss                | 4.009047e-05  |
| qf2_loss                | 4.3167696e-05 |
| time_elapsed            | 2040          |
| total timesteps         | 388847        |
| value_loss              | 5.367014e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009905723  |
| ent_coef_loss           | 0.04144305    |
| entropy                 | 1.3008128     |
| episodes                | 1708          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 389456        |
| policy_loss             | -0.54700136   |
| qf1_loss                | 3.678064e-05  |
| qf2_loss                | 8.077873e-05  |
| time_elapsed            | 2043          |
| total timesteps         | 389556        |
| value_loss              | 4.7742116e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0009953962 |
| ent_coef_loss           | 0.29658526   |
| entropy                 | 1.2131674    |
| episodes                | 1712         |
| fps                     | 190          |
| mean 100 episode reward | 0.7          |
| n_updates               | 390201       |
| policy_loss             | -0.5205277   |
| qf1_loss                | 4.640641e-05 |
| qf2_loss                | 4.389971e-05 |
| time_elapsed            | 2047         |
| total timesteps         | 390301       |
| value_loss              | 8.699425e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009614122  |
| ent_coef_loss           | 1.8281928     |
| entropy                 | 1.3863286     |
| episodes                | 1716          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 390929        |
| policy_loss             | -0.5178817    |
| qf1_loss                | 3.7524667e-05 |
| qf2_loss                | 3.689374e-05  |
| time_elapsed            | 2051          |
| total timesteps         | 391029        |
| value_loss              | 4.0878287e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011564827  |
| ent_coef_loss           | -0.7726248    |
| entropy                 | 1.1555703     |
| episodes                | 1720          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 391641        |
| policy_loss             | -0.5820044    |
| qf1_loss                | 0.00015622421 |
| qf2_loss                | 5.8042984e-05 |
| time_elapsed            | 2055          |
| total timesteps         | 391741        |
| value_loss              | 5.368959e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011299826  |
| ent_coef_loss           | 1.4902502     |
| entropy                 | 1.3292452     |
| episodes                | 1724          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 392325        |
| policy_loss             | -0.54576784   |
| qf1_loss                | 6.358613e-05  |
| qf2_loss                | 7.508043e-05  |
| time_elapsed            | 2059          |
| total timesteps         | 392425        |
| value_loss              | 5.1332965e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012078538  |
| ent_coef_loss           | -0.2276094    |
| entropy                 | 1.4610826     |
| episodes                | 1728          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 393291        |
| policy_loss             | -0.5386244    |
| qf1_loss                | 5.6586294e-05 |
| qf2_loss                | 4.9895294e-05 |
| time_elapsed            | 2064          |
| total timesteps         | 393391        |
| value_loss              | 0.00014759228 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012144479  |
| ent_coef_loss           | 1.8175552     |
| entropy                 | 1.2496743     |
| episodes                | 1732          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 393975        |
| policy_loss             | -0.50967336   |
| qf1_loss                | 0.0012126165  |
| qf2_loss                | 0.00075001357 |
| time_elapsed            | 2067          |
| total timesteps         | 394075        |
| value_loss              | 0.0001511816  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012558411  |
| ent_coef_loss           | 0.44457874    |
| entropy                 | 1.6679928     |
| episodes                | 1736          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 394924        |
| policy_loss             | -0.54991317   |
| qf1_loss                | 3.63249e-05   |
| qf2_loss                | 2.1285132e-05 |
| time_elapsed            | 2072          |
| total timesteps         | 395024        |
| value_loss              | 5.58284e-05   |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0012242484 |
| ent_coef_loss           | -0.5010058   |
| entropy                 | 1.4445045    |
| episodes                | 1740         |
| fps                     | 190          |
| mean 100 episode reward | 0.7          |
| n_updates               | 395619       |
| policy_loss             | -0.46573997  |
| qf1_loss                | 0.0001385136 |
| qf2_loss                | 9.597449e-05 |
| time_elapsed            | 2076         |
| total timesteps         | 395719       |
| value_loss              | 8.412672e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012980303  |
| ent_coef_loss           | 0.12275338    |
| entropy                 | 1.5393784     |
| episodes                | 1744          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 396843        |
| policy_loss             | -0.5147675    |
| qf1_loss                | 4.102011e-05  |
| qf2_loss                | 7.6989156e-05 |
| time_elapsed            | 2082          |
| total timesteps         | 396943        |
| value_loss              | 3.467486e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0012493224 |
| ent_coef_loss           | 1.3556232    |
| entropy                 | 1.36952      |
| episodes                | 1748         |
| fps                     | 190          |
| mean 100 episode reward | 0.7          |
| n_updates               | 397918       |
| policy_loss             | -0.4856844   |
| qf1_loss                | 8.941187e-05 |
| qf2_loss                | 7.681457e-05 |
| time_elapsed            | 2088         |
| total timesteps         | 398018       |
| value_loss              | 8.913392e-05 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0011618752 |
| ent_coef_loss           | -1.3237811   |
| entropy                 | 1.4318635    |
| episodes                | 1752         |
| fps                     | 190          |
| mean 100 episode reward | 0.7          |
| n_updates               | 399134       |
| policy_loss             | -0.5303186   |
| qf1_loss                | 4.557749e-05 |
| qf2_loss                | 6.767192e-05 |
| time_elapsed            | 2094         |
| total timesteps         | 399234       |
| value_loss              | 5.475338e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012210204  |
| ent_coef_loss           | 1.6235427     |
| entropy                 | 1.5410852     |
| episodes                | 1756          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 399850        |
| policy_loss             | -0.46314454   |
| qf1_loss                | 7.170274e-05  |
| qf2_loss                | 7.3685886e-05 |
| time_elapsed            | 2098          |
| total timesteps         | 399950        |
| value_loss              | 0.00031388283 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011546175  |
| ent_coef_loss           | -0.15618813   |
| entropy                 | 1.5524005     |
| episodes                | 1760          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 400622        |
| policy_loss             | -0.4833241    |
| qf1_loss                | 8.040048e-05  |
| qf2_loss                | 6.255559e-05  |
| time_elapsed            | 2102          |
| total timesteps         | 400722        |
| value_loss              | 0.00011512103 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011907523  |
| ent_coef_loss           | -0.89094627   |
| entropy                 | 1.4630986     |
| episodes                | 1764          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 401317        |
| policy_loss             | -0.48033416   |
| qf1_loss                | 0.00015042408 |
| qf2_loss                | 0.00011370885 |
| time_elapsed            | 2106          |
| total timesteps         | 401417        |
| value_loss              | 6.751182e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012244306  |
| ent_coef_loss           | 1.4662654     |
| entropy                 | 1.380811      |
| episodes                | 1768          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 402058        |
| policy_loss             | -0.47214383   |
| qf1_loss                | 9.7277814e-05 |
| qf2_loss                | 7.662204e-05  |
| time_elapsed            | 2110          |
| total timesteps         | 402158        |
| value_loss              | 0.00010541368 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011079018  |
| ent_coef_loss           | 2.4413888     |
| entropy                 | 1.4460332     |
| episodes                | 1772          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 402853        |
| policy_loss             | -0.43316036   |
| qf1_loss                | 6.01365e-05   |
| qf2_loss                | 5.2716605e-05 |
| time_elapsed            | 2114          |
| total timesteps         | 402953        |
| value_loss              | 8.280675e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010618075  |
| ent_coef_loss           | -1.4070479    |
| entropy                 | 1.2518592     |
| episodes                | 1776          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 403675        |
| policy_loss             | -0.4787661    |
| qf1_loss                | 4.7530433e-05 |
| qf2_loss                | 9.009506e-05  |
| time_elapsed            | 2118          |
| total timesteps         | 403775        |
| value_loss              | 6.8110676e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001252823   |
| ent_coef_loss           | -0.2521902    |
| entropy                 | 1.5433534     |
| episodes                | 1780          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 405082        |
| policy_loss             | -0.47926974   |
| qf1_loss                | 4.221269e-05  |
| qf2_loss                | 2.9501545e-05 |
| time_elapsed            | 2126          |
| total timesteps         | 405182        |
| value_loss              | 4.7973204e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011671799  |
| ent_coef_loss           | -1.6228216    |
| entropy                 | 1.4493537     |
| episodes                | 1784          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 406213        |
| policy_loss             | -0.5022329    |
| qf1_loss                | 5.9956506e-05 |
| qf2_loss                | 5.7985064e-05 |
| time_elapsed            | 2132          |
| total timesteps         | 406313        |
| value_loss              | 0.00012889969 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011450549  |
| ent_coef_loss           | 3.7252078     |
| entropy                 | 1.3551402     |
| episodes                | 1788          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 406878        |
| policy_loss             | -0.49629682   |
| qf1_loss                | 0.00012594541 |
| qf2_loss                | 0.0002404775  |
| time_elapsed            | 2135          |
| total timesteps         | 406978        |
| value_loss              | 0.00013825417 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011843264  |
| ent_coef_loss           | -0.12386972   |
| entropy                 | 1.2934332     |
| episodes                | 1792          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 407862        |
| policy_loss             | -0.4051466    |
| qf1_loss                | 0.00013538754 |
| qf2_loss                | 7.577103e-05  |
| time_elapsed            | 2140          |
| total timesteps         | 407962        |
| value_loss              | 0.00025145162 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010651463 |
| ent_coef_loss           | -3.7123814   |
| entropy                 | 1.2197001    |
| episodes                | 1796         |
| fps                     | 190          |
| mean 100 episode reward | 0.7          |
| n_updates               | 408540       |
| policy_loss             | -0.41834214  |
| qf1_loss                | 0.0017480489 |
| qf2_loss                | 0.0007471444 |
| time_elapsed            | 2144         |
| total timesteps         | 408640       |
| value_loss              | 0.001527514  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010682805  |
| ent_coef_loss           | 0.58148944    |
| entropy                 | 1.4745955     |
| episodes                | 1800          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 409290        |
| policy_loss             | -0.49942985   |
| qf1_loss                | 7.141857e-05  |
| qf2_loss                | 4.0173265e-05 |
| time_elapsed            | 2148          |
| total timesteps         | 409390        |
| value_loss              | 7.188959e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010196716  |
| ent_coef_loss           | -0.5379994    |
| entropy                 | 1.2461492     |
| episodes                | 1804          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 410113        |
| policy_loss             | -0.45694783   |
| qf1_loss                | 5.286518e-05  |
| qf2_loss                | 6.257994e-05  |
| time_elapsed            | 2152          |
| total timesteps         | 410213        |
| value_loss              | 0.00013945447 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010198564 |
| ent_coef_loss           | 1.6885223    |
| entropy                 | 1.2143004    |
| episodes                | 1808         |
| fps                     | 190          |
| mean 100 episode reward | 0.7          |
| n_updates               | 410780       |
| policy_loss             | -0.45516428  |
| qf1_loss                | 0.0011628974 |
| qf2_loss                | 0.0010523224 |
| time_elapsed            | 2156         |
| total timesteps         | 410880       |
| value_loss              | 9.269211e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010787348  |
| ent_coef_loss           | 2.7899027     |
| entropy                 | 1.3390875     |
| episodes                | 1812          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 411453        |
| policy_loss             | -0.4842141    |
| qf1_loss                | 0.0002462662  |
| qf2_loss                | 0.00016576514 |
| time_elapsed            | 2159          |
| total timesteps         | 411553        |
| value_loss              | 0.00021178389 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010607069  |
| ent_coef_loss           | -0.5011342    |
| entropy                 | 1.1937839     |
| episodes                | 1816          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 412153        |
| policy_loss             | -0.4437611    |
| qf1_loss                | 0.0002157143  |
| qf2_loss                | 0.00011507195 |
| time_elapsed            | 2163          |
| total timesteps         | 412253        |
| value_loss              | 0.0001708008  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010442183  |
| ent_coef_loss           | 0.5912816     |
| entropy                 | 1.2575461     |
| episodes                | 1820          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 412785        |
| policy_loss             | -0.47089183   |
| qf1_loss                | 0.0011471708  |
| qf2_loss                | 0.0012678768  |
| time_elapsed            | 2166          |
| total timesteps         | 412885        |
| value_loss              | 5.7692137e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010856465  |
| ent_coef_loss           | -0.03818217   |
| entropy                 | 1.2349111     |
| episodes                | 1824          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 413498        |
| policy_loss             | -0.4846611    |
| qf1_loss                | 5.0690905e-05 |
| qf2_loss                | 4.2661766e-05 |
| time_elapsed            | 2170          |
| total timesteps         | 413598        |
| value_loss              | 6.421342e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010315249  |
| ent_coef_loss           | -1.9808019    |
| entropy                 | 1.2622085     |
| episodes                | 1828          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 414229        |
| policy_loss             | -0.52983224   |
| qf1_loss                | 0.00010790397 |
| qf2_loss                | 8.510571e-05  |
| time_elapsed            | 2174          |
| total timesteps         | 414329        |
| value_loss              | 5.1267583e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009871296  |
| ent_coef_loss           | -4.8844852    |
| entropy                 | 1.3818333     |
| episodes                | 1832          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 414950        |
| policy_loss             | -0.493102     |
| qf1_loss                | 8.78468e-05   |
| qf2_loss                | 6.133711e-05  |
| time_elapsed            | 2178          |
| total timesteps         | 415050        |
| value_loss              | 5.7892066e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010082751  |
| ent_coef_loss           | 1.934398      |
| entropy                 | 1.284926      |
| episodes                | 1836          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 415902        |
| policy_loss             | -0.5059802    |
| qf1_loss                | 4.600731e-05  |
| qf2_loss                | 5.6399313e-05 |
| time_elapsed            | 2183          |
| total timesteps         | 416002        |
| value_loss              | 8.248736e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010920279  |
| ent_coef_loss           | 1.6379585     |
| entropy                 | 1.4815668     |
| episodes                | 1840          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 416496        |
| policy_loss             | -0.5385939    |
| qf1_loss                | 7.034378e-05  |
| qf2_loss                | 6.0307793e-05 |
| time_elapsed            | 2186          |
| total timesteps         | 416596        |
| value_loss              | 9.066459e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010891339  |
| ent_coef_loss           | 0.12325728    |
| entropy                 | 1.2364929     |
| episodes                | 1844          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 417302        |
| policy_loss             | -0.5061283    |
| qf1_loss                | 4.3093052e-05 |
| qf2_loss                | 3.6050333e-05 |
| time_elapsed            | 2190          |
| total timesteps         | 417402        |
| value_loss              | 4.527799e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012728962  |
| ent_coef_loss           | 0.9095827     |
| entropy                 | 1.1492878     |
| episodes                | 1848          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 418058        |
| policy_loss             | -0.4613151    |
| qf1_loss                | 4.9744274e-05 |
| qf2_loss                | 6.034095e-05  |
| time_elapsed            | 2194          |
| total timesteps         | 418158        |
| value_loss              | 0.00016213974 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0012525907 |
| ent_coef_loss           | 0.36699587   |
| entropy                 | 1.3512855    |
| episodes                | 1852         |
| fps                     | 190          |
| mean 100 episode reward | 0.8          |
| n_updates               | 418817       |
| policy_loss             | -0.51969445  |
| qf1_loss                | 6.299783e-05 |
| qf2_loss                | 7.444728e-05 |
| time_elapsed            | 2198         |
| total timesteps         | 418917       |
| value_loss              | 6.94076e-05  |
------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0011779969   |
| ent_coef_loss           | -0.140984      |
| entropy                 | 1.4004507      |
| episodes                | 1856           |
| fps                     | 190            |
| mean 100 episode reward | 0.7            |
| n_updates               | 419910         |
| policy_loss             | -0.48468417    |
| qf1_loss                | 9.445289e-05   |
| qf2_loss                | 0.000109390174 |
| time_elapsed            | 2204           |
| total timesteps         | 420010         |
| value_loss              | 4.4196695e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011514847  |
| ent_coef_loss           | -3.5047414    |
| entropy                 | 1.4251027     |
| episodes                | 1860          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 420662        |
| policy_loss             | -0.504236     |
| qf1_loss                | 3.0310839e-05 |
| qf2_loss                | 3.3091543e-05 |
| time_elapsed            | 2208          |
| total timesteps         | 420762        |
| value_loss              | 0.00011042619 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011494817  |
| ent_coef_loss           | 0.2700138     |
| entropy                 | 1.3819004     |
| episodes                | 1864          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 421301        |
| policy_loss             | -0.46714532   |
| qf1_loss                | 3.1848507e-05 |
| qf2_loss                | 4.406281e-05  |
| time_elapsed            | 2211          |
| total timesteps         | 421401        |
| value_loss              | 5.3853903e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011872043  |
| ent_coef_loss           | 0.12535852    |
| entropy                 | 1.5516866     |
| episodes                | 1868          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 421992        |
| policy_loss             | -0.52304506   |
| qf1_loss                | 4.4635755e-05 |
| qf2_loss                | 6.135589e-05  |
| time_elapsed            | 2215          |
| total timesteps         | 422092        |
| value_loss              | 0.00010045196 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010765134  |
| ent_coef_loss           | 1.3119199     |
| entropy                 | 1.3159411     |
| episodes                | 1872          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 422676        |
| policy_loss             | -0.40837765   |
| qf1_loss                | 3.159685e-05  |
| qf2_loss                | 3.9809835e-05 |
| time_elapsed            | 2219          |
| total timesteps         | 422776        |
| value_loss              | 8.686654e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010818255  |
| ent_coef_loss           | -0.32870644   |
| entropy                 | 1.1728879     |
| episodes                | 1876          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 423418        |
| policy_loss             | -0.46518746   |
| qf1_loss                | 0.00037384394 |
| qf2_loss                | 5.309737e-05  |
| time_elapsed            | 2222          |
| total timesteps         | 423518        |
| value_loss              | 0.00045819554 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011341354  |
| ent_coef_loss           | -0.3523153    |
| entropy                 | 1.290902      |
| episodes                | 1880          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 424099        |
| policy_loss             | -0.45669705   |
| qf1_loss                | 6.0948514e-05 |
| qf2_loss                | 0.00016161535 |
| time_elapsed            | 2226          |
| total timesteps         | 424199        |
| value_loss              | 0.00025192817 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011662608  |
| ent_coef_loss           | 1.8865432     |
| entropy                 | 1.448877      |
| episodes                | 1884          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 424951        |
| policy_loss             | -0.4688195    |
| qf1_loss                | 3.5465157e-05 |
| qf2_loss                | 5.2695555e-05 |
| time_elapsed            | 2230          |
| total timesteps         | 425051        |
| value_loss              | 0.0001316012  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012395752  |
| ent_coef_loss           | 1.2745489     |
| entropy                 | 1.3318869     |
| episodes                | 1888          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 425880        |
| policy_loss             | -0.51852405   |
| qf1_loss                | 6.477646e-05  |
| qf2_loss                | 6.692297e-05  |
| time_elapsed            | 2235          |
| total timesteps         | 425980        |
| value_loss              | 0.00013201206 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012125564  |
| ent_coef_loss           | -1.996415     |
| entropy                 | 1.3468248     |
| episodes                | 1892          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 426857        |
| policy_loss             | -0.48182595   |
| qf1_loss                | 0.00010627685 |
| qf2_loss                | 5.7028003e-05 |
| time_elapsed            | 2241          |
| total timesteps         | 426957        |
| value_loss              | 0.00021552123 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0011762108   |
| ent_coef_loss           | -1.5811491     |
| entropy                 | 1.3326404      |
| episodes                | 1896           |
| fps                     | 190            |
| mean 100 episode reward | 0.7            |
| n_updates               | 428100         |
| policy_loss             | -0.47913307    |
| qf1_loss                | 0.00012245435  |
| qf2_loss                | 0.000111747846 |
| time_elapsed            | 2247           |
| total timesteps         | 428200         |
| value_loss              | 0.00015733315  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001263679   |
| ent_coef_loss           | -0.91225374   |
| entropy                 | 1.3727636     |
| episodes                | 1900          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 428858        |
| policy_loss             | -0.50323254   |
| qf1_loss                | 5.6987315e-05 |
| qf2_loss                | 6.986276e-05  |
| time_elapsed            | 2251          |
| total timesteps         | 428958        |
| value_loss              | 0.00011750954 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012927392  |
| ent_coef_loss           | 0.5633893     |
| entropy                 | 1.1690776     |
| episodes                | 1904          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 429568        |
| policy_loss             | -0.4687593    |
| qf1_loss                | 0.00012447571 |
| qf2_loss                | 0.0001152818  |
| time_elapsed            | 2255          |
| total timesteps         | 429668        |
| value_loss              | 0.00019821915 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012474199  |
| ent_coef_loss           | 1.5386956     |
| entropy                 | 1.1276824     |
| episodes                | 1908          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 430309        |
| policy_loss             | -0.44603404   |
| qf1_loss                | 8.489732e-05  |
| qf2_loss                | 9.076881e-05  |
| time_elapsed            | 2258          |
| total timesteps         | 430409        |
| value_loss              | 0.00021914419 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012743112  |
| ent_coef_loss           | -0.29994917   |
| entropy                 | 1.3115368     |
| episodes                | 1912          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 431109        |
| policy_loss             | -0.47474214   |
| qf1_loss                | 4.3790467e-05 |
| qf2_loss                | 4.3158787e-05 |
| time_elapsed            | 2263          |
| total timesteps         | 431209        |
| value_loss              | 4.9724084e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0012888038 |
| ent_coef_loss           | -4.708011    |
| entropy                 | 1.3190178    |
| episodes                | 1916         |
| fps                     | 190          |
| mean 100 episode reward | 0.7          |
| n_updates               | 432079       |
| policy_loss             | -0.44429263  |
| qf1_loss                | 8.802942e-05 |
| qf2_loss                | 5.108046e-05 |
| time_elapsed            | 2268         |
| total timesteps         | 432179       |
| value_loss              | 0.0001979717 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001209118   |
| ent_coef_loss           | 2.6209927     |
| entropy                 | 1.4913478     |
| episodes                | 1920          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 432864        |
| policy_loss             | -0.4531877    |
| qf1_loss                | 5.524893e-05  |
| qf2_loss                | 5.208108e-05  |
| time_elapsed            | 2272          |
| total timesteps         | 432964        |
| value_loss              | 0.00017014911 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011992333  |
| ent_coef_loss           | -1.226645     |
| entropy                 | 1.4701717     |
| episodes                | 1924          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 433631        |
| policy_loss             | -0.4823076    |
| qf1_loss                | 4.5243247e-05 |
| qf2_loss                | 4.975916e-05  |
| time_elapsed            | 2276          |
| total timesteps         | 433731        |
| value_loss              | 0.00021347277 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001256754   |
| ent_coef_loss           | -0.086544126  |
| entropy                 | 1.393753      |
| episodes                | 1928          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 434589        |
| policy_loss             | -0.45156384   |
| qf1_loss                | 6.817492e-05  |
| qf2_loss                | 4.0149953e-05 |
| time_elapsed            | 2281          |
| total timesteps         | 434689        |
| value_loss              | 0.0001088796  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012025466  |
| ent_coef_loss           | -1.7815778    |
| entropy                 | 1.3736305     |
| episodes                | 1932          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 435290        |
| policy_loss             | -0.42119515   |
| qf1_loss                | 7.3912845e-05 |
| qf2_loss                | 0.00011831951 |
| time_elapsed            | 2285          |
| total timesteps         | 435390        |
| value_loss              | 8.139569e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012087122  |
| ent_coef_loss           | 3.3607433     |
| entropy                 | 1.244881      |
| episodes                | 1936          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 436474        |
| policy_loss             | -0.44779706   |
| qf1_loss                | 0.00033622966 |
| qf2_loss                | 0.00033854265 |
| time_elapsed            | 2291          |
| total timesteps         | 436574        |
| value_loss              | 0.00019545793 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012376038  |
| ent_coef_loss           | -0.7327579    |
| entropy                 | 1.3835967     |
| episodes                | 1940          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 437280        |
| policy_loss             | -0.48743972   |
| qf1_loss                | 6.607434e-05  |
| qf2_loss                | 8.0594764e-05 |
| time_elapsed            | 2295          |
| total timesteps         | 437380        |
| value_loss              | 7.9894715e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011600052  |
| ent_coef_loss           | -1.5488125    |
| entropy                 | 1.308948      |
| episodes                | 1944          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 438065        |
| policy_loss             | -0.44935787   |
| qf1_loss                | 0.00021826918 |
| qf2_loss                | 0.0001878319  |
| time_elapsed            | 2299          |
| total timesteps         | 438165        |
| value_loss              | 0.00022125489 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011112223  |
| ent_coef_loss           | -1.2606709    |
| entropy                 | 1.314282      |
| episodes                | 1948          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 438767        |
| policy_loss             | -0.46826956   |
| qf1_loss                | 3.609158e-05  |
| qf2_loss                | 3.6911602e-05 |
| time_elapsed            | 2303          |
| total timesteps         | 438867        |
| value_loss              | 8.201816e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010808463  |
| ent_coef_loss           | -1.5489444    |
| entropy                 | 1.2765818     |
| episodes                | 1952          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 439491        |
| policy_loss             | -0.45460084   |
| qf1_loss                | 0.00012399908 |
| qf2_loss                | 0.00019982441 |
| time_elapsed            | 2307          |
| total timesteps         | 439591        |
| value_loss              | 0.00024790707 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010323398  |
| ent_coef_loss           | 1.2036154     |
| entropy                 | 1.1646471     |
| episodes                | 1956          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 440163        |
| policy_loss             | -0.421688     |
| qf1_loss                | 5.261539e-05  |
| qf2_loss                | 5.6112076e-05 |
| time_elapsed            | 2310          |
| total timesteps         | 440263        |
| value_loss              | 0.00010532138 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010501825  |
| ent_coef_loss           | -1.4481106    |
| entropy                 | 1.2750416     |
| episodes                | 1960          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 440947        |
| policy_loss             | -0.4728834    |
| qf1_loss                | 3.1688687e-05 |
| qf2_loss                | 0.00014264583 |
| time_elapsed            | 2314          |
| total timesteps         | 441047        |
| value_loss              | 0.00015512054 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011097841  |
| ent_coef_loss           | -1.3259397    |
| entropy                 | 1.3241656     |
| episodes                | 1964          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 441789        |
| policy_loss             | -0.46518278   |
| qf1_loss                | 4.1282263e-05 |
| qf2_loss                | 3.3942324e-05 |
| time_elapsed            | 2319          |
| total timesteps         | 441889        |
| value_loss              | 9.2463386e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012201049  |
| ent_coef_loss           | 2.691166      |
| entropy                 | 1.1873368     |
| episodes                | 1968          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 442473        |
| policy_loss             | -0.46127847   |
| qf1_loss                | 0.00022463116 |
| qf2_loss                | 7.697285e-05  |
| time_elapsed            | 2322          |
| total timesteps         | 442573        |
| value_loss              | 0.00010042669 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012728246  |
| ent_coef_loss           | 0.9832319     |
| entropy                 | 1.4442725     |
| episodes                | 1972          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 443184        |
| policy_loss             | -0.47160834   |
| qf1_loss                | 6.972111e-05  |
| qf2_loss                | 9.4342264e-05 |
| time_elapsed            | 2326          |
| total timesteps         | 443284        |
| value_loss              | 0.00017139221 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012689431  |
| ent_coef_loss           | -3.342627     |
| entropy                 | 1.3265376     |
| episodes                | 1976          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 444196        |
| policy_loss             | -0.4832325    |
| qf1_loss                | 9.135406e-05  |
| qf2_loss                | 5.2891373e-05 |
| time_elapsed            | 2331          |
| total timesteps         | 444296        |
| value_loss              | 7.6316814e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010284842  |
| ent_coef_loss           | 0.22855496    |
| entropy                 | 1.2304947     |
| episodes                | 1980          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 444923        |
| policy_loss             | -0.48536095   |
| qf1_loss                | 0.000250414   |
| qf2_loss                | 0.00030240676 |
| time_elapsed            | 2335          |
| total timesteps         | 445023        |
| value_loss              | 0.000137673   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009895563  |
| ent_coef_loss           | -1.9456735    |
| entropy                 | 1.2466135     |
| episodes                | 1984          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 445644        |
| policy_loss             | -0.47816825   |
| qf1_loss                | 5.8334306e-05 |
| qf2_loss                | 6.3134714e-05 |
| time_elapsed            | 2339          |
| total timesteps         | 445744        |
| value_loss              | 5.6489258e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010110367 |
| ent_coef_loss           | -2.9986079   |
| entropy                 | 1.2604251    |
| episodes                | 1988         |
| fps                     | 190          |
| mean 100 episode reward | 0.9          |
| n_updates               | 446407       |
| policy_loss             | -0.44492117  |
| qf1_loss                | 9.303208e-05 |
| qf2_loss                | 5.67911e-05  |
| time_elapsed            | 2343         |
| total timesteps         | 446507       |
| value_loss              | 5.824348e-05 |
------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0011423761   |
| ent_coef_loss           | 1.7209463      |
| entropy                 | 1.1947783      |
| episodes                | 1992           |
| fps                     | 190            |
| mean 100 episode reward | 0.9            |
| n_updates               | 447152         |
| policy_loss             | -0.44290966    |
| qf1_loss                | 0.0001403424   |
| qf2_loss                | 0.00013680517  |
| time_elapsed            | 2347           |
| total timesteps         | 447252         |
| value_loss              | 0.000102166625 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001138843   |
| ent_coef_loss           | -1.0923164    |
| entropy                 | 1.2825587     |
| episodes                | 1996          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 447969        |
| policy_loss             | -0.45275307   |
| qf1_loss                | 4.5957007e-05 |
| qf2_loss                | 4.8140984e-05 |
| time_elapsed            | 2351          |
| total timesteps         | 448069        |
| value_loss              | 4.4112112e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010648569  |
| ent_coef_loss           | -1.6553795    |
| entropy                 | 1.3447146     |
| episodes                | 2000          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 448788        |
| policy_loss             | -0.5093959    |
| qf1_loss                | 2.910643e-05  |
| qf2_loss                | 4.2995016e-05 |
| time_elapsed            | 2355          |
| total timesteps         | 448888        |
| value_loss              | 6.3260275e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010276552  |
| ent_coef_loss           | 0.28891128    |
| entropy                 | 1.0960107     |
| episodes                | 2004          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 449749        |
| policy_loss             | -0.4453716    |
| qf1_loss                | 8.8921624e-05 |
| qf2_loss                | 9.662926e-05  |
| time_elapsed            | 2361          |
| total timesteps         | 449849        |
| value_loss              | 0.00022163056 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010345301  |
| ent_coef_loss           | -0.004306078  |
| entropy                 | 1.2790966     |
| episodes                | 2008          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 450436        |
| policy_loss             | -0.49061045   |
| qf1_loss                | 5.3517804e-05 |
| qf2_loss                | 6.1221544e-05 |
| time_elapsed            | 2364          |
| total timesteps         | 450536        |
| value_loss              | 4.082051e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010206795  |
| ent_coef_loss           | -0.78098756   |
| entropy                 | 1.2465497     |
| episodes                | 2012          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 451245        |
| policy_loss             | -0.49264142   |
| qf1_loss                | 5.1485436e-05 |
| qf2_loss                | 8.356659e-05  |
| time_elapsed            | 2368          |
| total timesteps         | 451345        |
| value_loss              | 8.911048e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010370016  |
| ent_coef_loss           | -2.8789997    |
| entropy                 | 1.0486336     |
| episodes                | 2016          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 451969        |
| policy_loss             | -0.46637735   |
| qf1_loss                | 6.5286156e-05 |
| qf2_loss                | 3.2599208e-05 |
| time_elapsed            | 2372          |
| total timesteps         | 452069        |
| value_loss              | 5.688124e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010206513  |
| ent_coef_loss           | 1.3628135     |
| entropy                 | 1.1589911     |
| episodes                | 2020          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 452683        |
| policy_loss             | -0.4406517    |
| qf1_loss                | 0.00013997668 |
| qf2_loss                | 0.00012331975 |
| time_elapsed            | 2376          |
| total timesteps         | 452783        |
| value_loss              | 4.50054e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010631861  |
| ent_coef_loss           | -3.057644     |
| entropy                 | 1.091651      |
| episodes                | 2024          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 453437        |
| policy_loss             | -0.4763745    |
| qf1_loss                | 6.897601e-05  |
| qf2_loss                | 0.00013011618 |
| time_elapsed            | 2380          |
| total timesteps         | 453537        |
| value_loss              | 8.068506e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010697078  |
| ent_coef_loss           | -2.2074442    |
| entropy                 | 1.0688733     |
| episodes                | 2028          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 454204        |
| policy_loss             | -0.44825494   |
| qf1_loss                | 0.00022263406 |
| qf2_loss                | 0.00066555536 |
| time_elapsed            | 2384          |
| total timesteps         | 454304        |
| value_loss              | 0.00013772643 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011083815  |
| ent_coef_loss           | -0.68662524   |
| entropy                 | 1.1993531     |
| episodes                | 2032          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 454851        |
| policy_loss             | -0.49078304   |
| qf1_loss                | 0.00010292546 |
| qf2_loss                | 4.3683314e-05 |
| time_elapsed            | 2387          |
| total timesteps         | 454951        |
| value_loss              | 0.0001439538  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010960553  |
| ent_coef_loss           | -0.77005637   |
| entropy                 | 1.2390095     |
| episodes                | 2036          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 455739        |
| policy_loss             | -0.455623     |
| qf1_loss                | 3.792518e-05  |
| qf2_loss                | 4.0297666e-05 |
| time_elapsed            | 2392          |
| total timesteps         | 455839        |
| value_loss              | 4.7054462e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.001094999    |
| ent_coef_loss           | -1.2845864     |
| entropy                 | 0.9122558      |
| episodes                | 2040           |
| fps                     | 190            |
| mean 100 episode reward | 0.9            |
| n_updates               | 456475         |
| policy_loss             | -0.47721434    |
| qf1_loss                | 8.284372e-05   |
| qf2_loss                | 0.000104907405 |
| time_elapsed            | 2396           |
| total timesteps         | 456575         |
| value_loss              | 7.756507e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009774411  |
| ent_coef_loss           | -0.048814178  |
| entropy                 | 1.1004014     |
| episodes                | 2044          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 457157        |
| policy_loss             | -0.5147631    |
| qf1_loss                | 4.4534565e-05 |
| qf2_loss                | 7.8020414e-05 |
| time_elapsed            | 2399          |
| total timesteps         | 457257        |
| value_loss              | 6.379285e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000931114   |
| ent_coef_loss           | -4.167664     |
| entropy                 | 1.0970483     |
| episodes                | 2048          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 457881        |
| policy_loss             | -0.5296836    |
| qf1_loss                | 3.776673e-05  |
| qf2_loss                | 6.0607483e-05 |
| time_elapsed            | 2403          |
| total timesteps         | 457981        |
| value_loss              | 6.357794e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096348196 |
| ent_coef_loss           | -1.0916715    |
| entropy                 | 1.0256602     |
| episodes                | 2052          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 458598        |
| policy_loss             | -0.48733634   |
| qf1_loss                | 0.00017909158 |
| qf2_loss                | 0.00011175139 |
| time_elapsed            | 2407          |
| total timesteps         | 458698        |
| value_loss              | 6.229508e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010163847  |
| ent_coef_loss           | -2.9737694    |
| entropy                 | 1.1509953     |
| episodes                | 2056          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 459278        |
| policy_loss             | -0.52077985   |
| qf1_loss                | 6.750577e-05  |
| qf2_loss                | 4.7033653e-05 |
| time_elapsed            | 2410          |
| total timesteps         | 459378        |
| value_loss              | 4.504266e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010564018  |
| ent_coef_loss           | -0.49439883   |
| entropy                 | 1.1849989     |
| episodes                | 2060          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 460096        |
| policy_loss             | -0.50221854   |
| qf1_loss                | 2.7026339e-05 |
| qf2_loss                | 3.296473e-05  |
| time_elapsed            | 2415          |
| total timesteps         | 460196        |
| value_loss              | 5.7654288e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010212511 |
| ent_coef_loss           | 0.38615578   |
| entropy                 | 1.064846     |
| episodes                | 2064         |
| fps                     | 190          |
| mean 100 episode reward | 0.9          |
| n_updates               | 460805       |
| policy_loss             | -0.5246819   |
| qf1_loss                | 6.603945e-05 |
| qf2_loss                | 6.306106e-05 |
| time_elapsed            | 2419         |
| total timesteps         | 460905       |
| value_loss              | 0.0003299857 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010175433  |
| ent_coef_loss           | 2.8496287     |
| entropy                 | 1.274587      |
| episodes                | 2068          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 461525        |
| policy_loss             | -0.4885582    |
| qf1_loss                | 2.8332537e-05 |
| qf2_loss                | 2.7094758e-05 |
| time_elapsed            | 2423          |
| total timesteps         | 461625        |
| value_loss              | 3.8033548e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010173118  |
| ent_coef_loss           | 3.0097299     |
| entropy                 | 1.0794683     |
| episodes                | 2072          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 462275        |
| policy_loss             | -0.44024587   |
| qf1_loss                | 5.335659e-05  |
| qf2_loss                | 0.00023744209 |
| time_elapsed            | 2426          |
| total timesteps         | 462375        |
| value_loss              | 5.063457e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010261897  |
| ent_coef_loss           | -3.1450148    |
| entropy                 | 1.1756988     |
| episodes                | 2076          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 462948        |
| policy_loss             | -0.5506139    |
| qf1_loss                | 8.1779486e-05 |
| qf2_loss                | 4.01489e-05   |
| time_elapsed            | 2430          |
| total timesteps         | 463048        |
| value_loss              | 3.7269372e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010826987  |
| ent_coef_loss           | 0.17120335    |
| entropy                 | 1.3963938     |
| episodes                | 2080          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 463691        |
| policy_loss             | -0.5684662    |
| qf1_loss                | 4.2049058e-05 |
| qf2_loss                | 5.0367413e-05 |
| time_elapsed            | 2434          |
| total timesteps         | 463791        |
| value_loss              | 3.0567327e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0009613448 |
| ent_coef_loss           | 0.8087825    |
| entropy                 | 1.0793446    |
| episodes                | 2084         |
| fps                     | 190          |
| mean 100 episode reward | 0.9          |
| n_updates               | 464454       |
| policy_loss             | -0.46175408  |
| qf1_loss                | 8.835422e-05 |
| qf2_loss                | 3.843272e-05 |
| time_elapsed            | 2438         |
| total timesteps         | 464554       |
| value_loss              | 7.29857e-05  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094970135 |
| ent_coef_loss           | 2.2366483     |
| entropy                 | 1.0474843     |
| episodes                | 2088          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 465161        |
| policy_loss             | -0.46204036   |
| qf1_loss                | 0.00047615572 |
| qf2_loss                | 0.0001048587  |
| time_elapsed            | 2441          |
| total timesteps         | 465261        |
| value_loss              | 0.00011897027 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097129703 |
| ent_coef_loss           | 2.0568943     |
| entropy                 | 1.0930523     |
| episodes                | 2092          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 465915        |
| policy_loss             | -0.5075984    |
| qf1_loss                | 5.213789e-05  |
| qf2_loss                | 4.164588e-05  |
| time_elapsed            | 2445          |
| total timesteps         | 466015        |
| value_loss              | 3.8605016e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009852746  |
| ent_coef_loss           | -0.7374276    |
| entropy                 | 1.3133199     |
| episodes                | 2096          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 466754        |
| policy_loss             | -0.5422506    |
| qf1_loss                | 2.9011877e-05 |
| qf2_loss                | 3.369593e-05  |
| time_elapsed            | 2450          |
| total timesteps         | 466854        |
| value_loss              | 3.313595e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010648152  |
| ent_coef_loss           | 1.3694665     |
| entropy                 | 1.268525      |
| episodes                | 2100          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 467465        |
| policy_loss             | -0.5395782    |
| qf1_loss                | 2.29445e-05   |
| qf2_loss                | 2.3896519e-05 |
| time_elapsed            | 2454          |
| total timesteps         | 467565        |
| value_loss              | 3.0097708e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0010444265   |
| ent_coef_loss           | -2.0179055     |
| entropy                 | 1.2945516      |
| episodes                | 2104           |
| fps                     | 190            |
| mean 100 episode reward | 0.9            |
| n_updates               | 468203         |
| policy_loss             | -0.5435957     |
| qf1_loss                | 0.00011350556  |
| qf2_loss                | 0.000115135386 |
| time_elapsed            | 2457           |
| total timesteps         | 468303         |
| value_loss              | 4.183459e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010147949  |
| ent_coef_loss           | 0.36656666    |
| entropy                 | 1.3632886     |
| episodes                | 2108          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 468845        |
| policy_loss             | -0.51078176   |
| qf1_loss                | 7.08548e-05   |
| qf2_loss                | 5.9753922e-05 |
| time_elapsed            | 2461          |
| total timesteps         | 468945        |
| value_loss              | 5.8929916e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010261686  |
| ent_coef_loss           | -1.9036955    |
| entropy                 | 1.3521678     |
| episodes                | 2112          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 469503        |
| policy_loss             | -0.52883315   |
| qf1_loss                | 7.6966026e-05 |
| qf2_loss                | 9.314735e-05  |
| time_elapsed            | 2464          |
| total timesteps         | 469603        |
| value_loss              | 0.00013882894 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010917577  |
| ent_coef_loss           | -2.8311286    |
| entropy                 | 1.324065      |
| episodes                | 2116          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 470246        |
| policy_loss             | -0.5725074    |
| qf1_loss                | 6.9247806e-05 |
| qf2_loss                | 5.3329917e-05 |
| time_elapsed            | 2468          |
| total timesteps         | 470346        |
| value_loss              | 4.750005e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010831836  |
| ent_coef_loss           | -1.3463349    |
| entropy                 | 1.2696531     |
| episodes                | 2120          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 470966        |
| policy_loss             | -0.4863394    |
| qf1_loss                | 3.905472e-05  |
| qf2_loss                | 3.104893e-05  |
| time_elapsed            | 2472          |
| total timesteps         | 471066        |
| value_loss              | 4.4530385e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011081733  |
| ent_coef_loss           | -0.88158923   |
| entropy                 | 1.3907516     |
| episodes                | 2124          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 471667        |
| policy_loss             | -0.50570244   |
| qf1_loss                | 2.1114094e-05 |
| qf2_loss                | 1.91573e-05   |
| time_elapsed            | 2476          |
| total timesteps         | 471767        |
| value_loss              | 2.0269033e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010949234 |
| ent_coef_loss           | -1.2848362   |
| entropy                 | 1.3841023    |
| episodes                | 2128         |
| fps                     | 190          |
| mean 100 episode reward | 0.9          |
| n_updates               | 472500       |
| policy_loss             | -0.50589645  |
| qf1_loss                | 8.489481e-05 |
| qf2_loss                | 8.258021e-05 |
| time_elapsed            | 2480         |
| total timesteps         | 472600       |
| value_loss              | 0.0001218726 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010677795 |
| ent_coef_loss           | 2.0364819    |
| entropy                 | 1.438954     |
| episodes                | 2132         |
| fps                     | 190          |
| mean 100 episode reward | 0.9          |
| n_updates               | 473251       |
| policy_loss             | -0.5786209   |
| qf1_loss                | 4.522692e-05 |
| qf2_loss                | 8.165626e-05 |
| time_elapsed            | 2484         |
| total timesteps         | 473351       |
| value_loss              | 4.753865e-05 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0011287624 |
| ent_coef_loss           | -2.4463286   |
| entropy                 | 1.354853     |
| episodes                | 2136         |
| fps                     | 190          |
| mean 100 episode reward | 0.9          |
| n_updates               | 473995       |
| policy_loss             | -0.52978516  |
| qf1_loss                | 4.826273e-05 |
| qf2_loss                | 4.265334e-05 |
| time_elapsed            | 2488         |
| total timesteps         | 474095       |
| value_loss              | 6.390969e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011593467  |
| ent_coef_loss           | 3.0375116     |
| entropy                 | 1.4272845     |
| episodes                | 2140          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 474649        |
| policy_loss             | -0.4987598    |
| qf1_loss                | 0.00011471701 |
| qf2_loss                | 0.00017593763 |
| time_elapsed            | 2491          |
| total timesteps         | 474749        |
| value_loss              | 4.8640923e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011489656  |
| ent_coef_loss           | -1.2651197    |
| entropy                 | 1.4111371     |
| episodes                | 2144          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 475313        |
| policy_loss             | -0.57251716   |
| qf1_loss                | 3.6644924e-05 |
| qf2_loss                | 0.00010229708 |
| time_elapsed            | 2495          |
| total timesteps         | 475413        |
| value_loss              | 3.7391983e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0011735207 |
| ent_coef_loss           | 0.94866747   |
| entropy                 | 1.3472179    |
| episodes                | 2148         |
| fps                     | 190          |
| mean 100 episode reward | 0.9          |
| n_updates               | 476009       |
| policy_loss             | -0.5190677   |
| qf1_loss                | 8.485165e-05 |
| qf2_loss                | 7.281624e-05 |
| time_elapsed            | 2498         |
| total timesteps         | 476109       |
| value_loss              | 0.0001656459 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010913049  |
| ent_coef_loss           | 0.45638418    |
| entropy                 | 1.3003796     |
| episodes                | 2152          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 476774        |
| policy_loss             | -0.5594635    |
| qf1_loss                | 4.8108035e-05 |
| qf2_loss                | 5.6696663e-05 |
| time_elapsed            | 2502          |
| total timesteps         | 476874        |
| value_loss              | 2.7422535e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010554029  |
| ent_coef_loss           | -1.5769745    |
| entropy                 | 1.3206427     |
| episodes                | 2156          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 477540        |
| policy_loss             | -0.57680583   |
| qf1_loss                | 4.809433e-05  |
| qf2_loss                | 8.3415216e-05 |
| time_elapsed            | 2506          |
| total timesteps         | 477640        |
| value_loss              | 3.930006e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001052228   |
| ent_coef_loss           | 1.4665915     |
| entropy                 | 1.396017      |
| episodes                | 2160          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 478512        |
| policy_loss             | -0.4747616    |
| qf1_loss                | 7.172758e-05  |
| qf2_loss                | 3.991802e-05  |
| time_elapsed            | 2512          |
| total timesteps         | 478612        |
| value_loss              | 5.6196008e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0011044395 |
| ent_coef_loss           | -2.4823217   |
| entropy                 | 1.4193059    |
| episodes                | 2164         |
| fps                     | 190          |
| mean 100 episode reward | 0.9          |
| n_updates               | 479206       |
| policy_loss             | -0.5436423   |
| qf1_loss                | 1.373114e-05 |
| qf2_loss                | 1.935542e-05 |
| time_elapsed            | 2515         |
| total timesteps         | 479306       |
| value_loss              | 6.778282e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011363549  |
| ent_coef_loss           | 0.9427538     |
| entropy                 | 1.435241      |
| episodes                | 2168          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 479981        |
| policy_loss             | -0.5277304    |
| qf1_loss                | 2.1856185e-05 |
| qf2_loss                | 1.8965893e-05 |
| time_elapsed            | 2519          |
| total timesteps         | 480081        |
| value_loss              | 7.441838e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010787513  |
| ent_coef_loss           | -1.2243391    |
| entropy                 | 1.4498551     |
| episodes                | 2172          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 480732        |
| policy_loss             | -0.5495274    |
| qf1_loss                | 3.6560432e-05 |
| qf2_loss                | 2.9191793e-05 |
| time_elapsed            | 2523          |
| total timesteps         | 480832        |
| value_loss              | 1.862082e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010528293  |
| ent_coef_loss           | -1.587463     |
| entropy                 | 1.53829       |
| episodes                | 2176          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 481498        |
| policy_loss             | -0.5163127    |
| qf1_loss                | 2.8084209e-05 |
| qf2_loss                | 6.43907e-05   |
| time_elapsed            | 2527          |
| total timesteps         | 481598        |
| value_loss              | 7.821803e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010349881  |
| ent_coef_loss           | -2.4623594    |
| entropy                 | 1.377789      |
| episodes                | 2180          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 482224        |
| policy_loss             | -0.58741176   |
| qf1_loss                | 4.7424903e-05 |
| qf2_loss                | 3.5720386e-05 |
| time_elapsed            | 2531          |
| total timesteps         | 482324        |
| value_loss              | 3.111051e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009930462  |
| ent_coef_loss           | -5.476012     |
| entropy                 | 1.3886162     |
| episodes                | 2184          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 482915        |
| policy_loss             | -0.52323693   |
| qf1_loss                | 2.0675616e-05 |
| qf2_loss                | 2.2730736e-05 |
| time_elapsed            | 2535          |
| total timesteps         | 483015        |
| value_loss              | 2.4204e-05    |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010741287  |
| ent_coef_loss           | 0.4546727     |
| entropy                 | 1.356644      |
| episodes                | 2188          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 483595        |
| policy_loss             | -0.5496104    |
| qf1_loss                | 5.7202113e-05 |
| qf2_loss                | 5.5876782e-05 |
| time_elapsed            | 2539          |
| total timesteps         | 483695        |
| value_loss              | 5.0632225e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011877456  |
| ent_coef_loss           | -1.3794279    |
| entropy                 | 1.5646136     |
| episodes                | 2192          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 484255        |
| policy_loss             | -0.5799389    |
| qf1_loss                | 1.6947753e-05 |
| qf2_loss                | 2.4080406e-05 |
| time_elapsed            | 2542          |
| total timesteps         | 484355        |
| value_loss              | 4.239949e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001225558   |
| ent_coef_loss           | 1.0116131     |
| entropy                 | 1.47896       |
| episodes                | 2196          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 485007        |
| policy_loss             | -0.5364915    |
| qf1_loss                | 3.277482e-05  |
| qf2_loss                | 2.3523831e-05 |
| time_elapsed            | 2546          |
| total timesteps         | 485107        |
| value_loss              | 4.859943e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010747204  |
| ent_coef_loss           | 0.37897956    |
| entropy                 | 1.4066699     |
| episodes                | 2200          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 485761        |
| policy_loss             | -0.50189126   |
| qf1_loss                | 4.6820798e-05 |
| qf2_loss                | 4.347416e-05  |
| time_elapsed            | 2550          |
| total timesteps         | 485861        |
| value_loss              | 0.00013174693 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010069408  |
| ent_coef_loss           | 1.7244824     |
| entropy                 | 1.493867      |
| episodes                | 2204          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 486716        |
| policy_loss             | -0.53644824   |
| qf1_loss                | 0.0001294099  |
| qf2_loss                | 0.00012420859 |
| time_elapsed            | 2555          |
| total timesteps         | 486816        |
| value_loss              | 6.134425e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011220577  |
| ent_coef_loss           | -0.5144557    |
| entropy                 | 1.4360015     |
| episodes                | 2208          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 487719        |
| policy_loss             | -0.53143936   |
| qf1_loss                | 3.508378e-05  |
| qf2_loss                | 3.874274e-05  |
| time_elapsed            | 2560          |
| total timesteps         | 487819        |
| value_loss              | 4.0772375e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011973894  |
| ent_coef_loss           | 0.09713876    |
| entropy                 | 1.4274166     |
| episodes                | 2212          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 488406        |
| policy_loss             | -0.5544988    |
| qf1_loss                | 4.4091423e-05 |
| qf2_loss                | 4.622331e-05  |
| time_elapsed            | 2564          |
| total timesteps         | 488506        |
| value_loss              | 5.8998972e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011475283  |
| ent_coef_loss           | -0.5922494    |
| entropy                 | 1.5552545     |
| episodes                | 2216          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 489110        |
| policy_loss             | -0.55264175   |
| qf1_loss                | 2.8465485e-05 |
| qf2_loss                | 1.769965e-05  |
| time_elapsed            | 2567          |
| total timesteps         | 489210        |
| value_loss              | 2.7687198e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011551798  |
| ent_coef_loss           | 1.1572251     |
| entropy                 | 1.479659      |
| episodes                | 2220          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 489841        |
| policy_loss             | -0.5432646    |
| qf1_loss                | 6.709381e-05  |
| qf2_loss                | 2.4686482e-05 |
| time_elapsed            | 2572          |
| total timesteps         | 489941        |
| value_loss              | 5.4489465e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010961854  |
| ent_coef_loss           | -0.11485863   |
| entropy                 | 1.4144139     |
| episodes                | 2224          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 490491        |
| policy_loss             | -0.54225796   |
| qf1_loss                | 0.00021412452 |
| qf2_loss                | 0.00013820367 |
| time_elapsed            | 2575          |
| total timesteps         | 490591        |
| value_loss              | 4.9505026e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011081115  |
| ent_coef_loss           | 0.9666067     |
| entropy                 | 1.5025916     |
| episodes                | 2228          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 491453        |
| policy_loss             | -0.5927249    |
| qf1_loss                | 5.9614347e-05 |
| qf2_loss                | 7.266776e-05  |
| time_elapsed            | 2580          |
| total timesteps         | 491553        |
| value_loss              | 7.484217e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012020227  |
| ent_coef_loss           | -0.78666794   |
| entropy                 | 1.3281695     |
| episodes                | 2232          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 492107        |
| policy_loss             | -0.54674596   |
| qf1_loss                | 2.3282792e-05 |
| qf2_loss                | 3.3991208e-05 |
| time_elapsed            | 2583          |
| total timesteps         | 492207        |
| value_loss              | 4.164732e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011876052  |
| ent_coef_loss           | -1.304769     |
| entropy                 | 1.4492314     |
| episodes                | 2236          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 493048        |
| policy_loss             | -0.567739     |
| qf1_loss                | 5.3317253e-05 |
| qf2_loss                | 5.5612913e-05 |
| time_elapsed            | 2588          |
| total timesteps         | 493148        |
| value_loss              | 3.4343175e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010940601  |
| ent_coef_loss           | -1.0486623    |
| entropy                 | 1.3972614     |
| episodes                | 2240          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 493813        |
| policy_loss             | -0.56664616   |
| qf1_loss                | 2.5802514e-05 |
| qf2_loss                | 1.6745636e-05 |
| time_elapsed            | 2592          |
| total timesteps         | 493913        |
| value_loss              | 2.001549e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010169398  |
| ent_coef_loss           | -0.97654486   |
| entropy                 | 1.4237161     |
| episodes                | 2244          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 494650        |
| policy_loss             | -0.54050815   |
| qf1_loss                | 5.8813293e-05 |
| qf2_loss                | 5.6515182e-05 |
| time_elapsed            | 2597          |
| total timesteps         | 494750        |
| value_loss              | 4.9837563e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010941749  |
| ent_coef_loss           | 0.6330543     |
| entropy                 | 1.4116137     |
| episodes                | 2248          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 495421        |
| policy_loss             | -0.5454264    |
| qf1_loss                | 6.5008935e-05 |
| qf2_loss                | 5.4086697e-05 |
| time_elapsed            | 2601          |
| total timesteps         | 495521        |
| value_loss              | 8.9429974e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010423468  |
| ent_coef_loss           | -0.56420755   |
| entropy                 | 1.4525564     |
| episodes                | 2252          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 496292        |
| policy_loss             | -0.5215062    |
| qf1_loss                | 4.8110014e-05 |
| qf2_loss                | 3.34906e-05   |
| time_elapsed            | 2605          |
| total timesteps         | 496392        |
| value_loss              | 3.528906e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010645675  |
| ent_coef_loss           | -3.360148     |
| entropy                 | 1.3987561     |
| episodes                | 2256          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 496999        |
| policy_loss             | -0.5338576    |
| qf1_loss                | 2.099674e-05  |
| qf2_loss                | 2.8277806e-05 |
| time_elapsed            | 2609          |
| total timesteps         | 497099        |
| value_loss              | 0.00010520134 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010597853  |
| ent_coef_loss           | 3.4578109     |
| entropy                 | 1.5158931     |
| episodes                | 2260          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 497924        |
| policy_loss             | -0.56677794   |
| qf1_loss                | 9.0712056e-05 |
| qf2_loss                | 9.16164e-05   |
| time_elapsed            | 2614          |
| total timesteps         | 498024        |
| value_loss              | 9.1055765e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010877782  |
| ent_coef_loss           | -1.6534047    |
| entropy                 | 1.4826822     |
| episodes                | 2264          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 498654        |
| policy_loss             | -0.55386686   |
| qf1_loss                | 2.6936894e-05 |
| qf2_loss                | 3.4698503e-05 |
| time_elapsed            | 2618          |
| total timesteps         | 498754        |
| value_loss              | 3.9248174e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010982457  |
| ent_coef_loss           | 0.28609654    |
| entropy                 | 1.3581415     |
| episodes                | 2268          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 499570        |
| policy_loss             | -0.4620421    |
| qf1_loss                | 9.787173e-05  |
| qf2_loss                | 8.4757776e-05 |
| time_elapsed            | 2623          |
| total timesteps         | 499670        |
| value_loss              | 0.00011013435 |
-------------------------------------------
>>>>> End testing <<<<< decay:_0__nn_layers:_[512__256__128]
Final weights saved at:  /home/admin/tensorboard_logs/sac_decay:_0__nn_layers:_[512__256__128]/stable_baselines.pkl
TEST COMMAND: python3 py3_learning.py --test --weights  /home/admin/tensorboard_logs/sac_decay:_0__nn_layers:_[512__256__128]/stable_baselines.pkl
Starting test with params: {'nn_layers': [256, 128, 64]}
Namespace(draw_screen=False, env_config='configs/env.config', policy='multi_human_rl', policy_config='configs/policy.config', test=False, train_config='configs/train.config', weights=None)
Gym environment created.
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.54344976   |
| ent_coef_loss           | -2.0467336   |
| entropy                 | 2.5604289    |
| episodes                | 4            |
| fps                     | 183          |
| mean 100 episode reward | -0.1         |
| n_updates               | 1220         |
| policy_loss             | -5.325387    |
| qf1_loss                | 0.0011288472 |
| qf2_loss                | 0.0010913655 |
| time_elapsed            | 7            |
| total timesteps         | 1320         |
| value_loss              | 0.0073309066 |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0005      |
| ent_coef                | 0.22570935  |
| ent_coef_loss           | -4.943447   |
| entropy                 | 2.6390464   |
| episodes                | 8           |
| fps                     | 189         |
| mean 100 episode reward | -0.1        |
| n_updates               | 2980        |
| policy_loss             | -8.393043   |
| qf1_loss                | 0.007051414 |
| qf2_loss                | 0.007341477 |
| time_elapsed            | 16          |
| total timesteps         | 3080        |
| value_loss              | 0.012456853 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.09398562   |
| ent_coef_loss           | -7.722142    |
| entropy                 | 2.4562106    |
| episodes                | 12           |
| fps                     | 191          |
| mean 100 episode reward | -0.1         |
| n_updates               | 4740         |
| policy_loss             | -9.025309    |
| qf1_loss                | 0.0059900302 |
| qf2_loss                | 0.005340379  |
| time_elapsed            | 25           |
| total timesteps         | 4840         |
| value_loss              | 0.01690802   |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0005      |
| ent_coef                | 0.039358407 |
| ent_coef_loss           | -10.748964  |
| entropy                 | 2.569914    |
| episodes                | 16          |
| fps                     | 189         |
| mean 100 episode reward | -0.1        |
| n_updates               | 6500        |
| policy_loss             | -8.453232   |
| qf1_loss                | 0.00956554  |
| qf2_loss                | 0.009763184 |
| time_elapsed            | 34          |
| total timesteps         | 6600        |
| value_loss              | 0.02738053  |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.017374221  |
| ent_coef_loss           | -6.76544     |
| entropy                 | 3.4805331    |
| episodes                | 20           |
| fps                     | 189          |
| mean 100 episode reward | -0.1         |
| n_updates               | 8260         |
| policy_loss             | -7.963802    |
| qf1_loss                | 0.0051268423 |
| qf2_loss                | 0.0035217665 |
| time_elapsed            | 44           |
| total timesteps         | 8360         |
| value_loss              | 0.00658112   |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.010450203  |
| ent_coef_loss           | -2.6776874   |
| entropy                 | 2.2338037    |
| episodes                | 24           |
| fps                     | 190          |
| mean 100 episode reward | -0.2         |
| n_updates               | 9624         |
| policy_loss             | -7.347947    |
| qf1_loss                | 0.32912442   |
| qf2_loss                | 0.2347081    |
| time_elapsed            | 51           |
| total timesteps         | 9724         |
| value_loss              | 0.0031492868 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0068210755 |
| ent_coef_loss           | -5.1480675   |
| entropy                 | 2.1480796    |
| episodes                | 28           |
| fps                     | 190          |
| mean 100 episode reward | -0.3         |
| n_updates               | 11384        |
| policy_loss             | -6.904655    |
| qf1_loss                | 0.011489851  |
| qf2_loss                | 0.0046384907 |
| time_elapsed            | 60           |
| total timesteps         | 11484        |
| value_loss              | 0.009276902  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0039488333 |
| ent_coef_loss           | -4.319466    |
| entropy                 | 1.3160102    |
| episodes                | 32           |
| fps                     | 190          |
| mean 100 episode reward | -0.3         |
| n_updates               | 13144        |
| policy_loss             | -6.2777815   |
| qf1_loss                | 0.0014429551 |
| qf2_loss                | 0.0016296274 |
| time_elapsed            | 69           |
| total timesteps         | 13244        |
| value_loss              | 0.0048929183 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0032898346 |
| ent_coef_loss           | 2.5335257    |
| entropy                 | 0.8436591    |
| episodes                | 36           |
| fps                     | 190          |
| mean 100 episode reward | -0.3         |
| n_updates               | 14904        |
| policy_loss             | -5.9002943   |
| qf1_loss                | 0.2897661    |
| qf2_loss                | 0.29485363   |
| time_elapsed            | 78           |
| total timesteps         | 15004        |
| value_loss              | 0.0030036527 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0033402878 |
| ent_coef_loss           | 1.18413      |
| entropy                 | 0.1718732    |
| episodes                | 40           |
| fps                     | 190          |
| mean 100 episode reward | -0.2         |
| n_updates               | 16664        |
| policy_loss             | -5.169292    |
| qf1_loss                | 0.0034324587 |
| qf2_loss                | 0.004121315  |
| time_elapsed            | 87           |
| total timesteps         | 16764        |
| value_loss              | 0.024960518  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0032520108 |
| ent_coef_loss           | -0.009919703 |
| entropy                 | 1.1618427    |
| episodes                | 44           |
| fps                     | 190          |
| mean 100 episode reward | -0.2         |
| n_updates               | 18424        |
| policy_loss             | -4.7646294   |
| qf1_loss                | 0.21651106   |
| qf2_loss                | 0.21717301   |
| time_elapsed            | 97           |
| total timesteps         | 18524        |
| value_loss              | 0.0015922473 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0032882646 |
| ent_coef_loss           | -0.21591985  |
| entropy                 | 0.64948946   |
| episodes                | 48           |
| fps                     | 190          |
| mean 100 episode reward | -0.5         |
| n_updates               | 20184        |
| policy_loss             | -4.364356    |
| qf1_loss                | 0.0012817024 |
| qf2_loss                | 0.0011063169 |
| time_elapsed            | 106          |
| total timesteps         | 20284        |
| value_loss              | 0.0020516384 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0034720367 |
| ent_coef_loss           | -2.4746704   |
| entropy                 | 0.37589777   |
| episodes                | 52           |
| fps                     | 190          |
| mean 100 episode reward | -0.4         |
| n_updates               | 21944        |
| policy_loss             | -3.8490999   |
| qf1_loss                | 0.008146153  |
| qf2_loss                | 0.0080227805 |
| time_elapsed            | 115          |
| total timesteps         | 22044        |
| value_loss              | 0.0016649636 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0026460253 |
| ent_coef_loss           | -1.0407895   |
| entropy                 | -0.23709421  |
| episodes                | 56           |
| fps                     | 190          |
| mean 100 episode reward | -0.4         |
| n_updates               | 23704        |
| policy_loss             | -3.46039     |
| qf1_loss                | 0.0019411413 |
| qf2_loss                | 0.0019199143 |
| time_elapsed            | 125          |
| total timesteps         | 23804        |
| value_loss              | 0.0036930041 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0025371385 |
| ent_coef_loss           | -0.39367133  |
| entropy                 | -0.48235425  |
| episodes                | 60           |
| fps                     | 190          |
| mean 100 episode reward | -0.4         |
| n_updates               | 25464        |
| policy_loss             | -3.1253853   |
| qf1_loss                | 0.06952649   |
| qf2_loss                | 0.06818755   |
| time_elapsed            | 134          |
| total timesteps         | 25564        |
| value_loss              | 0.002450646  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.002254129   |
| ent_coef_loss           | -2.543324     |
| entropy                 | 0.07873561    |
| episodes                | 64            |
| fps                     | 190           |
| mean 100 episode reward | -0.3          |
| n_updates               | 27224         |
| policy_loss             | -2.860641     |
| qf1_loss                | 0.0003752609  |
| qf2_loss                | 0.00039084503 |
| time_elapsed            | 143           |
| total timesteps         | 27324         |
| value_loss              | 0.000587504   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0016688949  |
| ent_coef_loss           | 1.7678286     |
| entropy                 | -0.21408853   |
| episodes                | 68            |
| fps                     | 190           |
| mean 100 episode reward | -0.4          |
| n_updates               | 28984         |
| policy_loss             | -2.6099176    |
| qf1_loss                | 0.0014484087  |
| qf2_loss                | 0.0013058746  |
| time_elapsed            | 152           |
| total timesteps         | 29084         |
| value_loss              | 0.00024805148 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.001394253  |
| ent_coef_loss           | -2.7354097   |
| entropy                 | -0.7033486   |
| episodes                | 72           |
| fps                     | 190          |
| mean 100 episode reward | -0.4         |
| n_updates               | 30230        |
| policy_loss             | -2.391746    |
| qf1_loss                | 0.040373184  |
| qf2_loss                | 0.039947756  |
| time_elapsed            | 159          |
| total timesteps         | 30330        |
| value_loss              | 0.0003513995 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0015617915  |
| ent_coef_loss           | -3.3422785    |
| entropy                 | -0.37784344   |
| episodes                | 76            |
| fps                     | 190           |
| mean 100 episode reward | -0.6          |
| n_updates               | 31906         |
| policy_loss             | -2.1695786    |
| qf1_loss                | 0.0005261102  |
| qf2_loss                | 0.00064049894 |
| time_elapsed            | 167           |
| total timesteps         | 32006         |
| value_loss              | 0.00020840987 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001302995   |
| ent_coef_loss           | -2.3637643    |
| entropy                 | -0.055496894  |
| episodes                | 80            |
| fps                     | 190           |
| mean 100 episode reward | -0.6          |
| n_updates               | 32890         |
| policy_loss             | -2.0847206    |
| qf1_loss                | 0.001069407   |
| qf2_loss                | 0.00039475097 |
| time_elapsed            | 172           |
| total timesteps         | 32990         |
| value_loss              | 0.0006861263  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.001391559    |
| ent_coef_loss           | 1.5702139      |
| entropy                 | -0.1006959     |
| episodes                | 84             |
| fps                     | 190            |
| mean 100 episode reward | -0.6           |
| n_updates               | 34650          |
| policy_loss             | -1.8649282     |
| qf1_loss                | 0.000112574344 |
| qf2_loss                | 0.00014847037  |
| time_elapsed            | 182            |
| total timesteps         | 34750          |
| value_loss              | 0.00040039798  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010839333  |
| ent_coef_loss           | 0.47507882    |
| entropy                 | -0.58986974   |
| episodes                | 88            |
| fps                     | 190           |
| mean 100 episode reward | -0.6          |
| n_updates               | 36410         |
| policy_loss             | -1.7256997    |
| qf1_loss                | 0.00022888485 |
| qf2_loss                | 0.0002321235  |
| time_elapsed            | 191           |
| total timesteps         | 36510         |
| value_loss              | 0.00083317445 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010398244  |
| ent_coef_loss           | -2.8925405    |
| entropy                 | -0.3475864    |
| episodes                | 92            |
| fps                     | 190           |
| mean 100 episode reward | -0.6          |
| n_updates               | 38170         |
| policy_loss             | -1.5124075    |
| qf1_loss                | 0.00013248777 |
| qf2_loss                | 0.0001238178  |
| time_elapsed            | 200           |
| total timesteps         | 38270         |
| value_loss              | 0.00012507537 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010354969  |
| ent_coef_loss           | 0.85397387    |
| entropy                 | 0.4854408     |
| episodes                | 96            |
| fps                     | 190           |
| mean 100 episode reward | -0.6          |
| n_updates               | 39930         |
| policy_loss             | -1.3610146    |
| qf1_loss                | 0.00021158002 |
| qf2_loss                | 0.00017912143 |
| time_elapsed            | 209           |
| total timesteps         | 40030         |
| value_loss              | 0.00016483173 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011312744  |
| ent_coef_loss           | 3.5101664     |
| entropy                 | 0.5892029     |
| episodes                | 100           |
| fps                     | 190           |
| mean 100 episode reward | -0.6          |
| n_updates               | 41690         |
| policy_loss             | -1.2536851    |
| qf1_loss                | 0.0087309275  |
| qf2_loss                | 0.008902504   |
| time_elapsed            | 219           |
| total timesteps         | 41790         |
| value_loss              | 0.00013009032 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00082873774 |
| ent_coef_loss           | 0.99746335    |
| entropy                 | 0.30921268    |
| episodes                | 104           |
| fps                     | 190           |
| mean 100 episode reward | -0.6          |
| n_updates               | 43450         |
| policy_loss             | -1.12499      |
| qf1_loss                | 0.0108545935  |
| qf2_loss                | 0.009274265   |
| time_elapsed            | 228           |
| total timesteps         | 43550         |
| value_loss              | 0.00012983983 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00068023696  |
| ent_coef_loss           | -0.3511212     |
| entropy                 | -1.2350038     |
| episodes                | 108            |
| fps                     | 190            |
| mean 100 episode reward | -0.6           |
| n_updates               | 45210          |
| policy_loss             | -1.0219326     |
| qf1_loss                | 0.000115374176 |
| qf2_loss                | 6.395519e-05   |
| time_elapsed            | 237            |
| total timesteps         | 45310          |
| value_loss              | 0.00014696033  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000631941   |
| ent_coef_loss           | -1.1105374    |
| entropy                 | -0.65215826   |
| episodes                | 112           |
| fps                     | 190           |
| mean 100 episode reward | -0.6          |
| n_updates               | 46970         |
| policy_loss             | -0.92687106   |
| qf1_loss                | 0.00010495078 |
| qf2_loss                | 0.00012955943 |
| time_elapsed            | 246           |
| total timesteps         | 47070         |
| value_loss              | 6.150459e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00071280845 |
| ent_coef_loss           | 0.7801664     |
| entropy                 | 0.0037256926  |
| episodes                | 116           |
| fps                     | 190           |
| mean 100 episode reward | -0.6          |
| n_updates               | 48730         |
| policy_loss             | -0.816362     |
| qf1_loss                | 7.3055955e-05 |
| qf2_loss                | 5.867934e-05  |
| time_elapsed            | 256           |
| total timesteps         | 48830         |
| value_loss              | 2.3642213e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00063350203 |
| ent_coef_loss           | 0.6430019     |
| entropy                 | -0.5928115    |
| episodes                | 120           |
| fps                     | 190           |
| mean 100 episode reward | -0.6          |
| n_updates               | 50490         |
| policy_loss             | -0.7694466    |
| qf1_loss                | 0.0068157716  |
| qf2_loss                | 0.006662639   |
| time_elapsed            | 265           |
| total timesteps         | 50590         |
| value_loss              | 5.8961275e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0006214991 |
| ent_coef_loss           | -3.8526816   |
| entropy                 | -0.30827224  |
| episodes                | 124          |
| fps                     | 190          |
| mean 100 episode reward | -0.7         |
| n_updates               | 52250        |
| policy_loss             | -0.6624166   |
| qf1_loss                | 0.0024414987 |
| qf2_loss                | 0.0069633434 |
| time_elapsed            | 274          |
| total timesteps         | 52350        |
| value_loss              | 4.339399e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00068520475 |
| ent_coef_loss           | -1.4706209    |
| entropy                 | 0.6502462     |
| episodes                | 128           |
| fps                     | 190           |
| mean 100 episode reward | -0.7          |
| n_updates               | 54010         |
| policy_loss             | -0.60756946   |
| qf1_loss                | 0.0001322925  |
| qf2_loss                | 0.00010021849 |
| time_elapsed            | 283           |
| total timesteps         | 54110         |
| value_loss              | 0.0001811644  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007452624  |
| ent_coef_loss           | 5.5526624     |
| entropy                 | 0.6306549     |
| episodes                | 132           |
| fps                     | 190           |
| mean 100 episode reward | -0.7          |
| n_updates               | 55770         |
| policy_loss             | -0.5582021    |
| qf1_loss                | 8.51237e-05   |
| qf2_loss                | 7.5745455e-05 |
| time_elapsed            | 293           |
| total timesteps         | 55870         |
| value_loss              | 0.0003093634  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00081419956  |
| ent_coef_loss           | 0.7777265      |
| entropy                 | 0.28160685     |
| episodes                | 136            |
| fps                     | 190            |
| mean 100 episode reward | -0.7           |
| n_updates               | 57530          |
| policy_loss             | -0.4446055     |
| qf1_loss                | 0.00010251105  |
| qf2_loss                | 0.000110297624 |
| time_elapsed            | 302            |
| total timesteps         | 57630          |
| value_loss              | 0.00016575493  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006463881  |
| ent_coef_loss           | -1.0758376    |
| entropy                 | -0.13079406   |
| episodes                | 140           |
| fps                     | 190           |
| mean 100 episode reward | -0.7          |
| n_updates               | 59290         |
| policy_loss             | -0.39309263   |
| qf1_loss                | 3.0851777e-05 |
| qf2_loss                | 3.8444618e-05 |
| time_elapsed            | 311           |
| total timesteps         | 59390         |
| value_loss              | 5.1596202e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007956478  |
| ent_coef_loss           | 0.73890626    |
| entropy                 | 0.58990824    |
| episodes                | 144           |
| fps                     | 190           |
| mean 100 episode reward | -0.7          |
| n_updates               | 61050         |
| policy_loss             | -0.3278351    |
| qf1_loss                | 5.1475738e-05 |
| qf2_loss                | 5.1507363e-05 |
| time_elapsed            | 320           |
| total timesteps         | 61150         |
| value_loss              | 0.00013767739 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006087004  |
| ent_coef_loss           | -2.4185855    |
| entropy                 | 0.5108674     |
| episodes                | 148           |
| fps                     | 190           |
| mean 100 episode reward | -0.6          |
| n_updates               | 62810         |
| policy_loss             | -0.28865793   |
| qf1_loss                | 7.9012374e-05 |
| qf2_loss                | 4.283154e-05  |
| time_elapsed            | 330           |
| total timesteps         | 62910         |
| value_loss              | 9.7699216e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000550583   |
| ent_coef_loss           | 2.3478253     |
| entropy                 | -0.34367555   |
| episodes                | 152           |
| fps                     | 190           |
| mean 100 episode reward | -0.6          |
| n_updates               | 64570         |
| policy_loss             | -0.22266972   |
| qf1_loss                | 3.8911785e-05 |
| qf2_loss                | 5.2033938e-05 |
| time_elapsed            | 339           |
| total timesteps         | 64670         |
| value_loss              | 5.6963498e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0004544754  |
| ent_coef_loss           | 3.1657073     |
| entropy                 | -0.108862914  |
| episodes                | 156           |
| fps                     | 190           |
| mean 100 episode reward | -0.6          |
| n_updates               | 66330         |
| policy_loss             | -0.1950879    |
| qf1_loss                | 1.9469411e-05 |
| qf2_loss                | 1.2844988e-05 |
| time_elapsed            | 348           |
| total timesteps         | 66430         |
| value_loss              | 2.8972681e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00041680533 |
| ent_coef_loss           | -0.1308198    |
| entropy                 | 0.40289542    |
| episodes                | 160           |
| fps                     | 190           |
| mean 100 episode reward | -0.6          |
| n_updates               | 68090         |
| policy_loss             | -0.12410216   |
| qf1_loss                | 2.4760744e-05 |
| qf2_loss                | 2.8370037e-05 |
| time_elapsed            | 357           |
| total timesteps         | 68190         |
| value_loss              | 3.9431197e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00040554666 |
| ent_coef_loss           | -3.7000353    |
| entropy                 | 0.22083907    |
| episodes                | 164           |
| fps                     | 190           |
| mean 100 episode reward | -0.6          |
| n_updates               | 69850         |
| policy_loss             | -0.10764674   |
| qf1_loss                | 1.7424285e-05 |
| qf2_loss                | 1.4521681e-05 |
| time_elapsed            | 367           |
| total timesteps         | 69950         |
| value_loss              | 1.7268194e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00035045028 |
| ent_coef_loss           | -3.3043175    |
| entropy                 | 0.21120271    |
| episodes                | 168           |
| fps                     | 190           |
| mean 100 episode reward | -0.6          |
| n_updates               | 71610         |
| policy_loss             | -0.10323626   |
| qf1_loss                | 3.772848e-05  |
| qf2_loss                | 4.1499283e-05 |
| time_elapsed            | 376           |
| total timesteps         | 71710         |
| value_loss              | 9.4639516e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0002902852  |
| ent_coef_loss           | 2.42979       |
| entropy                 | -0.08957702   |
| episodes                | 172           |
| fps                     | 190           |
| mean 100 episode reward | -0.6          |
| n_updates               | 73370         |
| policy_loss             | -0.06520863   |
| qf1_loss                | 2.432082e-05  |
| qf2_loss                | 4.4222714e-05 |
| time_elapsed            | 385           |
| total timesteps         | 73470         |
| value_loss              | 7.582274e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0003397473  |
| ent_coef_loss           | -0.16145039   |
| entropy                 | 0.17597613    |
| episodes                | 176           |
| fps                     | 190           |
| mean 100 episode reward | -0.5          |
| n_updates               | 75130         |
| policy_loss             | -0.032527834  |
| qf1_loss                | 3.4093988e-05 |
| qf2_loss                | 3.2059048e-05 |
| time_elapsed            | 394           |
| total timesteps         | 75230         |
| value_loss              | 4.30907e-05   |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00029636902  |
| ent_coef_loss           | 3.1600742      |
| entropy                 | 0.41958255     |
| episodes                | 180            |
| fps                     | 190            |
| mean 100 episode reward | -0.4           |
| n_updates               | 76890          |
| policy_loss             | -0.035370402   |
| qf1_loss                | 1.08123595e-05 |
| qf2_loss                | 1.8252531e-05  |
| time_elapsed            | 403            |
| total timesteps         | 76990          |
| value_loss              | 7.3000256e-06  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00029224824 |
| ent_coef_loss           | 4.79944       |
| entropy                 | 0.5383377     |
| episodes                | 184           |
| fps                     | 190           |
| mean 100 episode reward | -0.3          |
| n_updates               | 78650         |
| policy_loss             | -0.040242843  |
| qf1_loss                | 3.2086245e-05 |
| qf2_loss                | 2.8949049e-05 |
| time_elapsed            | 413           |
| total timesteps         | 78750         |
| value_loss              | 1.1957257e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00019831085 |
| ent_coef_loss           | -3.935636     |
| entropy                 | -0.16231604   |
| episodes                | 188           |
| fps                     | 190           |
| mean 100 episode reward | -0.3          |
| n_updates               | 80410         |
| policy_loss             | -0.010274618  |
| qf1_loss                | 0.00080882147 |
| qf2_loss                | 0.000790014   |
| time_elapsed            | 422           |
| total timesteps         | 80510         |
| value_loss              | 1.2230048e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00017891289 |
| ent_coef_loss           | 6.093647      |
| entropy                 | -0.0853814    |
| episodes                | 192           |
| fps                     | 190           |
| mean 100 episode reward | -0.3          |
| n_updates               | 82170         |
| policy_loss             | -0.0048881043 |
| qf1_loss                | 1.1615849e-05 |
| qf2_loss                | 1.7214143e-05 |
| time_elapsed            | 431           |
| total timesteps         | 82270         |
| value_loss              | 1.0885338e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00023772668 |
| ent_coef_loss           | -3.6329412    |
| entropy                 | 0.4410786     |
| episodes                | 196           |
| fps                     | 190           |
| mean 100 episode reward | -0.3          |
| n_updates               | 83930         |
| policy_loss             | -0.012798002  |
| qf1_loss                | 1.0585833e-05 |
| qf2_loss                | 1.4350739e-05 |
| time_elapsed            | 441           |
| total timesteps         | 84030         |
| value_loss              | 1.7454913e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00023493422 |
| ent_coef_loss           | -2.1363742    |
| entropy                 | 0.49725398    |
| episodes                | 200           |
| fps                     | 190           |
| mean 100 episode reward | -0.3          |
| n_updates               | 85690         |
| policy_loss             | 0.012747357   |
| qf1_loss                | 4.174558e-05  |
| qf2_loss                | 2.8787166e-05 |
| time_elapsed            | 450           |
| total timesteps         | 85790         |
| value_loss              | 6.255413e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00022347439 |
| ent_coef_loss           | -1.3741789    |
| entropy                 | 0.38825113    |
| episodes                | 204           |
| fps                     | 190           |
| mean 100 episode reward | -0.3          |
| n_updates               | 87266         |
| policy_loss             | 0.0126320245  |
| qf1_loss                | 7.548848e-06  |
| qf2_loss                | 9.926041e-06  |
| time_elapsed            | 458           |
| total timesteps         | 87366         |
| value_loss              | 2.9848694e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00033406907 |
| ent_coef_loss           | 7.288842      |
| entropy                 | 1.0717955     |
| episodes                | 208           |
| fps                     | 190           |
| mean 100 episode reward | -0.3          |
| n_updates               | 89026         |
| policy_loss             | 0.01527839    |
| qf1_loss                | 1.812815e-05  |
| qf2_loss                | 1.4969803e-05 |
| time_elapsed            | 467           |
| total timesteps         | 89126         |
| value_loss              | 5.7794998e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00037920946 |
| ent_coef_loss           | 1.5707991     |
| entropy                 | 0.9497181     |
| episodes                | 212           |
| fps                     | 190           |
| mean 100 episode reward | -0.3          |
| n_updates               | 90786         |
| policy_loss             | -0.026931498  |
| qf1_loss                | 2.5360845e-05 |
| qf2_loss                | 2.5109042e-05 |
| time_elapsed            | 477           |
| total timesteps         | 90886         |
| value_loss              | 4.213002e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0004644045  |
| ent_coef_loss           | -1.89164      |
| entropy                 | 1.2949021     |
| episodes                | 216           |
| fps                     | 190           |
| mean 100 episode reward | -0.3          |
| n_updates               | 92422         |
| policy_loss             | -0.02023084   |
| qf1_loss                | 2.7382224e-05 |
| qf2_loss                | 2.668949e-05  |
| time_elapsed            | 485           |
| total timesteps         | 92522         |
| value_loss              | 3.3607826e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00038618068 |
| ent_coef_loss           | -5.671082     |
| entropy                 | 0.7768238     |
| episodes                | 220           |
| fps                     | 190           |
| mean 100 episode reward | -0.2          |
| n_updates               | 93533         |
| policy_loss             | -0.0020145294 |
| qf1_loss                | 2.0215684e-05 |
| qf2_loss                | 2.0836978e-05 |
| time_elapsed            | 491           |
| total timesteps         | 93633         |
| value_loss              | 2.256759e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00032751888 |
| ent_coef_loss           | 3.5021744     |
| entropy                 | 0.68113476    |
| episodes                | 224           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 95293         |
| policy_loss             | -0.0038383817 |
| qf1_loss                | 2.4356748e-05 |
| qf2_loss                | 2.2050473e-05 |
| time_elapsed            | 500           |
| total timesteps         | 95393         |
| value_loss              | 1.6166587e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00031559542 |
| ent_coef_loss           | -1.4767065    |
| entropy                 | 0.5022429     |
| episodes                | 228           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 96606         |
| policy_loss             | -0.0048308633 |
| qf1_loss                | 2.9346593e-05 |
| qf2_loss                | 3.8492562e-05 |
| time_elapsed            | 507           |
| total timesteps         | 96706         |
| value_loss              | 2.606072e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00026630904 |
| ent_coef_loss           | 0.6353383     |
| entropy                 | 0.26430085    |
| episodes                | 232           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 98366         |
| policy_loss             | 0.013963802   |
| qf1_loss                | 0.00012988839 |
| qf2_loss                | 0.00011971558 |
| time_elapsed            | 516           |
| total timesteps         | 98466         |
| value_loss              | 4.0785373e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00031057576 |
| ent_coef_loss           | -2.4421291    |
| entropy                 | 0.15716974    |
| episodes                | 236           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 99663         |
| policy_loss             | -0.004778358  |
| qf1_loss                | 0.00014998477 |
| qf2_loss                | 8.061221e-05  |
| time_elapsed            | 523           |
| total timesteps         | 99763         |
| value_loss              | 0.00013307901 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00035667897 |
| ent_coef_loss           | 1.4102231     |
| entropy                 | 0.3621985     |
| episodes                | 240           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 101207        |
| policy_loss             | -0.029473554  |
| qf1_loss                | 2.5274112e-05 |
| qf2_loss                | 2.5841215e-05 |
| time_elapsed            | 531           |
| total timesteps         | 101307        |
| value_loss              | 5.5615703e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00033601304 |
| ent_coef_loss           | -0.933003     |
| entropy                 | 0.1742697     |
| episodes                | 244           |
| fps                     | 190           |
| mean 100 episode reward | -0            |
| n_updates               | 102757        |
| policy_loss             | -0.027394293  |
| qf1_loss                | 2.4260962e-05 |
| qf2_loss                | 2.831111e-05  |
| time_elapsed            | 539           |
| total timesteps         | 102857        |
| value_loss              | 3.645383e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00036847964  |
| ent_coef_loss           | 0.34096035     |
| entropy                 | 0.6576664      |
| episodes                | 248            |
| fps                     | 190            |
| mean 100 episode reward | -0.1           |
| n_updates               | 104517         |
| policy_loss             | -0.027978728   |
| qf1_loss                | 9.662243e-05   |
| qf2_loss                | 0.000109519606 |
| time_elapsed            | 548            |
| total timesteps         | 104617         |
| value_loss              | 4.6628753e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0003669108  |
| ent_coef_loss           | -0.23757327   |
| entropy                 | 0.4881739     |
| episodes                | 252           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 106277        |
| policy_loss             | -0.02547564   |
| qf1_loss                | 5.2442483e-05 |
| qf2_loss                | 8.117179e-05  |
| time_elapsed            | 558           |
| total timesteps         | 106377        |
| value_loss              | 0.00011291947 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0003530546  |
| ent_coef_loss           | -2.305636     |
| entropy                 | 0.13034087    |
| episodes                | 256           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 107702        |
| policy_loss             | -0.044461407  |
| qf1_loss                | 0.0020230822  |
| qf2_loss                | 0.0020677543  |
| time_elapsed            | 565           |
| total timesteps         | 107802        |
| value_loss              | 8.8795765e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00034994114 |
| ent_coef_loss           | 0.6112672     |
| entropy                 | 0.4896263     |
| episodes                | 260           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 109462        |
| policy_loss             | -0.07890255   |
| qf1_loss                | 4.6170393e-05 |
| qf2_loss                | 1.9398452e-05 |
| time_elapsed            | 575           |
| total timesteps         | 109562        |
| value_loss              | 4.419055e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00039882085 |
| ent_coef_loss           | 1.1640171     |
| entropy                 | 0.46121466    |
| episodes                | 264           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 110530        |
| policy_loss             | -0.048676826  |
| qf1_loss                | 7.542718e-05  |
| qf2_loss                | 8.102072e-05  |
| time_elapsed            | 580           |
| total timesteps         | 110630        |
| value_loss              | 0.00013048132 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00042577498 |
| ent_coef_loss           | -0.29022276   |
| entropy                 | 0.32788783    |
| episodes                | 268           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 111812        |
| policy_loss             | -0.052883144  |
| qf1_loss                | 6.841043e-05  |
| qf2_loss                | 0.00011664799 |
| time_elapsed            | 587           |
| total timesteps         | 111912        |
| value_loss              | 5.981976e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00038120043  |
| ent_coef_loss           | -1.2115622     |
| entropy                 | 0.3469232      |
| episodes                | 272            |
| fps                     | 190            |
| mean 100 episode reward | -0.1           |
| n_updates               | 113205         |
| policy_loss             | -0.053648934   |
| qf1_loss                | 5.1384028e-05  |
| qf2_loss                | 0.000102542865 |
| time_elapsed            | 594            |
| total timesteps         | 113305         |
| value_loss              | 6.222635e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0003924887  |
| ent_coef_loss           | -2.8538394    |
| entropy                 | 0.3839573     |
| episodes                | 276           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 114965        |
| policy_loss             | -0.09085031   |
| qf1_loss                | 0.00010449326 |
| qf2_loss                | 0.00010093031 |
| time_elapsed            | 603           |
| total timesteps         | 115065        |
| value_loss              | 5.9985952e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0004166541  |
| ent_coef_loss           | -0.20054835   |
| entropy                 | 0.27227843    |
| episodes                | 280           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 116725        |
| policy_loss             | -0.07339396   |
| qf1_loss                | 3.094243e-05  |
| qf2_loss                | 5.6267025e-05 |
| time_elapsed            | 612           |
| total timesteps         | 116825        |
| value_loss              | 4.234827e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0004644745  |
| ent_coef_loss           | 1.7233888     |
| entropy                 | 0.2999544     |
| episodes                | 284           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 118485        |
| policy_loss             | -0.09779373   |
| qf1_loss                | 8.518831e-05  |
| qf2_loss                | 8.557949e-05  |
| time_elapsed            | 621           |
| total timesteps         | 118585        |
| value_loss              | 4.8029506e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0005368697  |
| ent_coef_loss           | 1.8928337     |
| entropy                 | 0.57584786    |
| episodes                | 288           |
| fps                     | 190           |
| mean 100 episode reward | -0.2          |
| n_updates               | 120245        |
| policy_loss             | -0.095911875  |
| qf1_loss                | 5.8541795e-05 |
| qf2_loss                | 6.284463e-05  |
| time_elapsed            | 631           |
| total timesteps         | 120345        |
| value_loss              | 8.737969e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006015489  |
| ent_coef_loss           | -2.355759     |
| entropy                 | 0.54176164    |
| episodes                | 292           |
| fps                     | 190           |
| mean 100 episode reward | -0.2          |
| n_updates               | 121194        |
| policy_loss             | -0.112515315  |
| qf1_loss                | 0.00015690306 |
| qf2_loss                | 0.0001378183  |
| time_elapsed            | 636           |
| total timesteps         | 121294        |
| value_loss              | 0.00025431393 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0005319077  |
| ent_coef_loss           | 2.7921975     |
| entropy                 | 0.6274        |
| episodes                | 296           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 122584        |
| policy_loss             | -0.11894706   |
| qf1_loss                | 7.344579e-05  |
| qf2_loss                | 0.00012505759 |
| time_elapsed            | 643           |
| total timesteps         | 122684        |
| value_loss              | 6.8668916e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007110306  |
| ent_coef_loss           | 1.7241883     |
| entropy                 | 1.1278611     |
| episodes                | 300           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 124138        |
| policy_loss             | -0.1428943    |
| qf1_loss                | 3.4599732e-05 |
| qf2_loss                | 3.402987e-05  |
| time_elapsed            | 651           |
| total timesteps         | 124238        |
| value_loss              | 9.581921e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007090016  |
| ent_coef_loss           | -2.962037     |
| entropy                 | 0.64611244    |
| episodes                | 304           |
| fps                     | 190           |
| mean 100 episode reward | -0.2          |
| n_updates               | 125898        |
| policy_loss             | -0.12796819   |
| qf1_loss                | 0.00018876279 |
| qf2_loss                | 6.7476205e-05 |
| time_elapsed            | 660           |
| total timesteps         | 125998        |
| value_loss              | 0.00015319258 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0005916297  |
| ent_coef_loss           | 2.1153996     |
| entropy                 | 0.50377536    |
| episodes                | 308           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 127029        |
| policy_loss             | -0.15936205   |
| qf1_loss                | 4.622415e-05  |
| qf2_loss                | 4.4012537e-05 |
| time_elapsed            | 667           |
| total timesteps         | 127129        |
| value_loss              | 0.00012857819 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00054835546 |
| ent_coef_loss           | -0.9614569    |
| entropy                 | 0.51782656    |
| episodes                | 312           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 128531        |
| policy_loss             | -0.16270229   |
| qf1_loss                | 3.0874762e-05 |
| qf2_loss                | 3.4969456e-05 |
| time_elapsed            | 674           |
| total timesteps         | 128631        |
| value_loss              | 3.223167e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0005653878 |
| ent_coef_loss           | 3.1963713    |
| entropy                 | 0.50948966   |
| episodes                | 316          |
| fps                     | 190          |
| mean 100 episode reward | -0.1         |
| n_updates               | 129441       |
| policy_loss             | -0.10731239  |
| qf1_loss                | 0.001711873  |
| qf2_loss                | 0.0020451425 |
| time_elapsed            | 679          |
| total timesteps         | 129541       |
| value_loss              | 0.00029788   |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00065555895 |
| ent_coef_loss           | 1.1855459     |
| entropy                 | 0.6492518     |
| episodes                | 320           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 130676        |
| policy_loss             | -0.1501807    |
| qf1_loss                | 3.18382e-05   |
| qf2_loss                | 5.9627535e-05 |
| time_elapsed            | 686           |
| total timesteps         | 130776        |
| value_loss              | 5.4378535e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0005463929  |
| ent_coef_loss           | 0.8641516     |
| entropy                 | 0.25354177    |
| episodes                | 324           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 132087        |
| policy_loss             | -0.12702055   |
| qf1_loss                | 5.2538075e-05 |
| qf2_loss                | 4.735685e-05  |
| time_elapsed            | 693           |
| total timesteps         | 132187        |
| value_loss              | 6.1897954e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00048644302 |
| ent_coef_loss           | -1.8854191    |
| entropy                 | -0.02119457   |
| episodes                | 328           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 133327        |
| policy_loss             | -0.10743738   |
| qf1_loss                | 7.0415816e-05 |
| qf2_loss                | 9.0947426e-05 |
| time_elapsed            | 700           |
| total timesteps         | 133427        |
| value_loss              | 2.5919551e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00049294555 |
| ent_coef_loss           | -0.570012     |
| entropy                 | -0.034056477  |
| episodes                | 332           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 134089        |
| policy_loss             | -0.13641268   |
| qf1_loss                | 9.517022e-05  |
| qf2_loss                | 0.00023323098 |
| time_elapsed            | 704           |
| total timesteps         | 134189        |
| value_loss              | 0.000395145   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00062893814 |
| ent_coef_loss           | -1.1643647    |
| entropy                 | 0.18515727    |
| episodes                | 336           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 135149        |
| policy_loss             | -0.1471528    |
| qf1_loss                | 5.544677e-05  |
| qf2_loss                | 4.2118063e-05 |
| time_elapsed            | 709           |
| total timesteps         | 135249        |
| value_loss              | 4.054418e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00062013615 |
| ent_coef_loss           | -0.15093207   |
| entropy                 | 0.53140974    |
| episodes                | 340           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 136007        |
| policy_loss             | -0.12272802   |
| qf1_loss                | 3.900607e-05  |
| qf2_loss                | 4.0843923e-05 |
| time_elapsed            | 714           |
| total timesteps         | 136107        |
| value_loss              | 7.751237e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006261762  |
| ent_coef_loss           | 0.9506894     |
| entropy                 | 0.3716007     |
| episodes                | 344           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 137215        |
| policy_loss             | -0.17617756   |
| qf1_loss                | 0.0021213414  |
| qf2_loss                | 0.0020940432  |
| time_elapsed            | 720           |
| total timesteps         | 137315        |
| value_loss              | 0.00011103645 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0005919057   |
| ent_coef_loss           | 3.5963635      |
| entropy                 | 0.46426383     |
| episodes                | 348            |
| fps                     | 190            |
| mean 100 episode reward | -0.1           |
| n_updates               | 138672         |
| policy_loss             | -0.14616905    |
| qf1_loss                | 0.000113968745 |
| qf2_loss                | 6.7214234e-05  |
| time_elapsed            | 728            |
| total timesteps         | 138772         |
| value_loss              | 0.0001028648   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00076847465 |
| ent_coef_loss           | 0.81899387    |
| entropy                 | 0.66685367    |
| episodes                | 352           |
| fps                     | 190           |
| mean 100 episode reward | -0.1          |
| n_updates               | 139990        |
| policy_loss             | -0.17805095   |
| qf1_loss                | 9.3467235e-05 |
| qf2_loss                | 8.2853774e-05 |
| time_elapsed            | 735           |
| total timesteps         | 140090        |
| value_loss              | 0.00012580752 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086422527 |
| ent_coef_loss           | -0.19873649   |
| entropy                 | 0.86199605    |
| episodes                | 356           |
| fps                     | 190           |
| mean 100 episode reward | -0            |
| n_updates               | 141521        |
| policy_loss             | -0.18490916   |
| qf1_loss                | 6.1262406e-05 |
| qf2_loss                | 9.649394e-05  |
| time_elapsed            | 743           |
| total timesteps         | 141621        |
| value_loss              | 0.00010834227 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00082594424 |
| ent_coef_loss           | -0.60511875   |
| entropy                 | 0.62370944    |
| episodes                | 360           |
| fps                     | 190           |
| mean 100 episode reward | 0.1           |
| n_updates               | 142498        |
| policy_loss             | -0.21458732   |
| qf1_loss                | 5.6596786e-05 |
| qf2_loss                | 5.7331126e-05 |
| time_elapsed            | 748           |
| total timesteps         | 142598        |
| value_loss              | 5.3604148e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094913365 |
| ent_coef_loss           | 1.2065804     |
| entropy                 | 0.83839655    |
| episodes                | 364           |
| fps                     | 190           |
| mean 100 episode reward | 0.1           |
| n_updates               | 143619        |
| policy_loss             | -0.18131116   |
| qf1_loss                | 7.400396e-05  |
| qf2_loss                | 7.079684e-05  |
| time_elapsed            | 754           |
| total timesteps         | 143719        |
| value_loss              | 0.0001785979  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009422932  |
| ent_coef_loss           | 2.6385682     |
| entropy                 | 0.8833177     |
| episodes                | 368           |
| fps                     | 190           |
| mean 100 episode reward | 0.1           |
| n_updates               | 144715        |
| policy_loss             | -0.17366475   |
| qf1_loss                | 0.0012565637  |
| qf2_loss                | 0.0003510672  |
| time_elapsed            | 760           |
| total timesteps         | 144815        |
| value_loss              | 0.00021830184 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00086702383  |
| ent_coef_loss           | 0.83850473     |
| entropy                 | 0.94215655     |
| episodes                | 372            |
| fps                     | 190            |
| mean 100 episode reward | 0.1            |
| n_updates               | 145502         |
| policy_loss             | -0.19677624    |
| qf1_loss                | 0.0005973571   |
| qf2_loss                | 0.0006282184   |
| time_elapsed            | 764            |
| total timesteps         | 145602         |
| value_loss              | 0.000115731884 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00090575946 |
| ent_coef_loss           | -0.8874648    |
| entropy                 | 0.92686653    |
| episodes                | 376           |
| fps                     | 190           |
| mean 100 episode reward | 0.1           |
| n_updates               | 146787        |
| policy_loss             | -0.24258873   |
| qf1_loss                | 0.00010269087 |
| qf2_loss                | 6.73953e-05   |
| time_elapsed            | 770           |
| total timesteps         | 146887        |
| value_loss              | 0.00017669058 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097128504 |
| ent_coef_loss           | -1.3544662    |
| entropy                 | 0.7864143     |
| episodes                | 380           |
| fps                     | 190           |
| mean 100 episode reward | 0.2           |
| n_updates               | 147658        |
| policy_loss             | -0.19143933   |
| qf1_loss                | 8.513406e-05  |
| qf2_loss                | 5.405549e-05  |
| time_elapsed            | 775           |
| total timesteps         | 147758        |
| value_loss              | 6.403543e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010232487  |
| ent_coef_loss           | 0.60910916    |
| entropy                 | 0.7435929     |
| episodes                | 384           |
| fps                     | 190           |
| mean 100 episode reward | 0.2           |
| n_updates               | 148584        |
| policy_loss             | -0.206643     |
| qf1_loss                | 0.00010112824 |
| qf2_loss                | 9.2730275e-05 |
| time_elapsed            | 780           |
| total timesteps         | 148684        |
| value_loss              | 6.27147e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011124767  |
| ent_coef_loss           | 0.92034084    |
| entropy                 | 0.82932174    |
| episodes                | 388           |
| fps                     | 190           |
| mean 100 episode reward | 0.3           |
| n_updates               | 149512        |
| policy_loss             | -0.19265455   |
| qf1_loss                | 8.4378255e-05 |
| qf2_loss                | 6.2733176e-05 |
| time_elapsed            | 785           |
| total timesteps         | 149612        |
| value_loss              | 8.7964436e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010800756  |
| ent_coef_loss           | -0.668677     |
| entropy                 | 0.97561085    |
| episodes                | 392           |
| fps                     | 190           |
| mean 100 episode reward | 0.3           |
| n_updates               | 150281        |
| policy_loss             | -0.21273156   |
| qf1_loss                | 9.031901e-05  |
| qf2_loss                | 8.981851e-05  |
| time_elapsed            | 789           |
| total timesteps         | 150381        |
| value_loss              | 4.0164392e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012016656  |
| ent_coef_loss           | 2.0326006     |
| entropy                 | 0.73620325    |
| episodes                | 396           |
| fps                     | 190           |
| mean 100 episode reward | 0.3           |
| n_updates               | 151192        |
| policy_loss             | -0.22384024   |
| qf1_loss                | 0.0014664052  |
| qf2_loss                | 0.0043641715  |
| time_elapsed            | 794           |
| total timesteps         | 151292        |
| value_loss              | 0.00027834755 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012132914  |
| ent_coef_loss           | 1.6176705     |
| entropy                 | 0.96867365    |
| episodes                | 400           |
| fps                     | 190           |
| mean 100 episode reward | 0.3           |
| n_updates               | 152185        |
| policy_loss             | -0.23641305   |
| qf1_loss                | 0.00011149517 |
| qf2_loss                | 9.7246986e-05 |
| time_elapsed            | 799           |
| total timesteps         | 152285        |
| value_loss              | 0.00016402265 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012101263  |
| ent_coef_loss           | -0.008934855  |
| entropy                 | 0.8458126     |
| episodes                | 404           |
| fps                     | 190           |
| mean 100 episode reward | 0.4           |
| n_updates               | 153089        |
| policy_loss             | -0.21459737   |
| qf1_loss                | 0.00013191938 |
| qf2_loss                | 0.00010866089 |
| time_elapsed            | 803           |
| total timesteps         | 153189        |
| value_loss              | 0.00013303608 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011505297  |
| ent_coef_loss           | 0.34687603    |
| entropy                 | 0.7754169     |
| episodes                | 408           |
| fps                     | 190           |
| mean 100 episode reward | 0.4           |
| n_updates               | 153907        |
| policy_loss             | -0.2155152    |
| qf1_loss                | 8.471035e-05  |
| qf2_loss                | 7.3558105e-05 |
| time_elapsed            | 808           |
| total timesteps         | 154007        |
| value_loss              | 0.00015602693 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012664285  |
| ent_coef_loss           | 0.17752588    |
| entropy                 | 0.9882291     |
| episodes                | 412           |
| fps                     | 190           |
| mean 100 episode reward | 0.5           |
| n_updates               | 155042        |
| policy_loss             | -0.22070833   |
| qf1_loss                | 7.822516e-05  |
| qf2_loss                | 0.00010007731 |
| time_elapsed            | 814           |
| total timesteps         | 155142        |
| value_loss              | 8.287428e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001289919   |
| ent_coef_loss           | -0.32310236   |
| entropy                 | 1.1430271     |
| episodes                | 416           |
| fps                     | 190           |
| mean 100 episode reward | 0.5           |
| n_updates               | 155804        |
| policy_loss             | -0.18194722   |
| qf1_loss                | 7.492395e-05  |
| qf2_loss                | 8.916661e-05  |
| time_elapsed            | 818           |
| total timesteps         | 155904        |
| value_loss              | 0.00010777606 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012043049  |
| ent_coef_loss           | -1.3950785    |
| entropy                 | 0.92741895    |
| episodes                | 420           |
| fps                     | 190           |
| mean 100 episode reward | 0.5           |
| n_updates               | 156883        |
| policy_loss             | -0.23889661   |
| qf1_loss                | 0.00014069435 |
| qf2_loss                | 0.00025053037 |
| time_elapsed            | 824           |
| total timesteps         | 156983        |
| value_loss              | 0.00018036558 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011946001  |
| ent_coef_loss           | -0.13091207   |
| entropy                 | 0.6506947     |
| episodes                | 424           |
| fps                     | 190           |
| mean 100 episode reward | 0.5           |
| n_updates               | 157663        |
| policy_loss             | -0.20923793   |
| qf1_loss                | 5.015037e-05  |
| qf2_loss                | 7.344413e-05  |
| time_elapsed            | 828           |
| total timesteps         | 157763        |
| value_loss              | 0.00010787495 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011319554  |
| ent_coef_loss           | -0.18541616   |
| entropy                 | 0.71308184    |
| episodes                | 428           |
| fps                     | 190           |
| mean 100 episode reward | 0.6           |
| n_updates               | 158390        |
| policy_loss             | -0.26785463   |
| qf1_loss                | 8.191557e-05  |
| qf2_loss                | 0.00010805573 |
| time_elapsed            | 831           |
| total timesteps         | 158490        |
| value_loss              | 9.993941e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011820144  |
| ent_coef_loss           | 0.9602667     |
| entropy                 | 0.947564      |
| episodes                | 432           |
| fps                     | 190           |
| mean 100 episode reward | 0.6           |
| n_updates               | 159329        |
| policy_loss             | -0.2853714    |
| qf1_loss                | 0.00019247031 |
| qf2_loss                | 9.068762e-05  |
| time_elapsed            | 836           |
| total timesteps         | 159429        |
| value_loss              | 0.00010123856 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012112255  |
| ent_coef_loss           | 2.3175848     |
| entropy                 | 0.94947654    |
| episodes                | 436           |
| fps                     | 190           |
| mean 100 episode reward | 0.6           |
| n_updates               | 160243        |
| policy_loss             | -0.33638772   |
| qf1_loss                | 6.6748005e-05 |
| qf2_loss                | 6.7766916e-05 |
| time_elapsed            | 841           |
| total timesteps         | 160343        |
| value_loss              | 0.0001317113  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011518806  |
| ent_coef_loss           | -2.5916617    |
| entropy                 | 0.6303376     |
| episodes                | 440           |
| fps                     | 190           |
| mean 100 episode reward | 0.6           |
| n_updates               | 160982        |
| policy_loss             | -0.3082928    |
| qf1_loss                | 9.6004274e-05 |
| qf2_loss                | 0.00025532674 |
| time_elapsed            | 845           |
| total timesteps         | 161082        |
| value_loss              | 0.0012391177  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011602265  |
| ent_coef_loss           | 0.7481872     |
| entropy                 | 0.8329334     |
| episodes                | 444           |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 161754        |
| policy_loss             | -0.2767652    |
| qf1_loss                | 0.00011306138 |
| qf2_loss                | 0.00013020601 |
| time_elapsed            | 849           |
| total timesteps         | 161854        |
| value_loss              | 0.0001574712  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0011371294   |
| ent_coef_loss           | -1.7502584     |
| entropy                 | 0.6925991      |
| episodes                | 448            |
| fps                     | 190            |
| mean 100 episode reward | 0.7            |
| n_updates               | 162414         |
| policy_loss             | -0.32316148    |
| qf1_loss                | 8.268175e-05   |
| qf2_loss                | 5.2621923e-05  |
| time_elapsed            | 853            |
| total timesteps         | 162514         |
| value_loss              | 0.000100431025 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011516088  |
| ent_coef_loss           | -2.6128879    |
| entropy                 | 0.6609645     |
| episodes                | 452           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 163161        |
| policy_loss             | -0.31854042   |
| qf1_loss                | 0.00039595406 |
| qf2_loss                | 0.0007883635  |
| time_elapsed            | 857           |
| total timesteps         | 163261        |
| value_loss              | 0.0022128553  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012291842  |
| ent_coef_loss           | -0.8069616    |
| entropy                 | 0.8160785     |
| episodes                | 456           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 163895        |
| policy_loss             | -0.3678742    |
| qf1_loss                | 8.3079445e-05 |
| qf2_loss                | 9.685043e-05  |
| time_elapsed            | 860           |
| total timesteps         | 163995        |
| value_loss              | 8.764607e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0012260092   |
| ent_coef_loss           | -2.162939      |
| entropy                 | 0.83654577     |
| episodes                | 460            |
| fps                     | 190            |
| mean 100 episode reward | 0.8            |
| n_updates               | 164624         |
| policy_loss             | -0.28632712    |
| qf1_loss                | 0.000120242985 |
| qf2_loss                | 0.00011751596  |
| time_elapsed            | 864            |
| total timesteps         | 164724         |
| value_loss              | 0.000111885274 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012039219  |
| ent_coef_loss           | 1.1644576     |
| entropy                 | 0.82142466    |
| episodes                | 464           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 165616        |
| policy_loss             | -0.32623416   |
| qf1_loss                | 0.0014991983  |
| qf2_loss                | 0.00019820208 |
| time_elapsed            | 869           |
| total timesteps         | 165716        |
| value_loss              | 0.00021620603 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012090397  |
| ent_coef_loss           | -1.2328043    |
| entropy                 | 0.88749826    |
| episodes                | 468           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 166499        |
| policy_loss             | -0.25398946   |
| qf1_loss                | 8.721698e-05  |
| qf2_loss                | 8.514209e-05  |
| time_elapsed            | 874           |
| total timesteps         | 166599        |
| value_loss              | 0.00011823193 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012677178  |
| ent_coef_loss           | -3.474874     |
| entropy                 | 0.761168      |
| episodes                | 472           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 167351        |
| policy_loss             | -0.36809143   |
| qf1_loss                | 6.3138286e-05 |
| qf2_loss                | 8.788606e-05  |
| time_elapsed            | 879           |
| total timesteps         | 167451        |
| value_loss              | 8.602755e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012994658  |
| ent_coef_loss           | -0.65782666   |
| entropy                 | 1.013509      |
| episodes                | 476           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 168241        |
| policy_loss             | -0.31174442   |
| qf1_loss                | 7.266503e-05  |
| qf2_loss                | 8.935967e-05  |
| time_elapsed            | 884           |
| total timesteps         | 168341        |
| value_loss              | 0.00011769855 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013407945  |
| ent_coef_loss           | -1.807018     |
| entropy                 | 0.8816222     |
| episodes                | 480           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 168931        |
| policy_loss             | -0.34809184   |
| qf1_loss                | 0.00012445278 |
| qf2_loss                | 0.00011172205 |
| time_elapsed            | 887           |
| total timesteps         | 169031        |
| value_loss              | 0.00013110979 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012846413  |
| ent_coef_loss           | -1.265065     |
| entropy                 | 1.0731282     |
| episodes                | 484           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 169774        |
| policy_loss             | -0.33773214   |
| qf1_loss                | 6.946265e-05  |
| qf2_loss                | 0.00012616352 |
| time_elapsed            | 892           |
| total timesteps         | 169874        |
| value_loss              | 0.00012888212 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013770557  |
| ent_coef_loss           | -0.93012226   |
| entropy                 | 1.1062903     |
| episodes                | 488           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 170593        |
| policy_loss             | -0.32311207   |
| qf1_loss                | 0.00044469343 |
| qf2_loss                | 0.0005530609  |
| time_elapsed            | 896           |
| total timesteps         | 170693        |
| value_loss              | 0.00021405029 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013225559  |
| ent_coef_loss           | 2.783891      |
| entropy                 | 0.90045726    |
| episodes                | 492           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 171390        |
| policy_loss             | -0.37747055   |
| qf1_loss                | 7.063759e-05  |
| qf2_loss                | 9.082578e-05  |
| time_elapsed            | 900           |
| total timesteps         | 171490        |
| value_loss              | 0.00012873566 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0014383844  |
| ent_coef_loss           | 0.2897672     |
| entropy                 | 1.0313642     |
| episodes                | 496           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 172133        |
| policy_loss             | -0.33896828   |
| qf1_loss                | 0.00040006044 |
| qf2_loss                | 0.00034667624 |
| time_elapsed            | 904           |
| total timesteps         | 172233        |
| value_loss              | 0.00016349743 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013607191  |
| ent_coef_loss           | 1.3669854     |
| entropy                 | 0.8478208     |
| episodes                | 500           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 172837        |
| policy_loss             | -0.3805827    |
| qf1_loss                | 0.0006256153  |
| qf2_loss                | 0.0005403993  |
| time_elapsed            | 908           |
| total timesteps         | 172937        |
| value_loss              | 0.00012104848 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0014125787  |
| ent_coef_loss           | -0.06925976   |
| entropy                 | 1.0857303     |
| episodes                | 504           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 173536        |
| policy_loss             | -0.33285213   |
| qf1_loss                | 0.0001313794  |
| qf2_loss                | 0.00024715695 |
| time_elapsed            | 912           |
| total timesteps         | 173636        |
| value_loss              | 0.00023970337 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013221228  |
| ent_coef_loss           | 1.6640618     |
| entropy                 | 1.0727847     |
| episodes                | 508           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 174235        |
| policy_loss             | -0.3493985    |
| qf1_loss                | 5.928171e-05  |
| qf2_loss                | 9.5396055e-05 |
| time_elapsed            | 915           |
| total timesteps         | 174335        |
| value_loss              | 7.125507e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0014150387  |
| ent_coef_loss           | -1.8998594    |
| entropy                 | 1.0760275     |
| episodes                | 512           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 175258        |
| policy_loss             | -0.37365222   |
| qf1_loss                | 4.8926115e-05 |
| qf2_loss                | 4.8369388e-05 |
| time_elapsed            | 920           |
| total timesteps         | 175358        |
| value_loss              | 6.371959e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00137068    |
| ent_coef_loss           | 2.3577616     |
| entropy                 | 1.0005531     |
| episodes                | 516           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 176137        |
| policy_loss             | -0.46535212   |
| qf1_loss                | 0.00023155476 |
| qf2_loss                | 0.00027877762 |
| time_elapsed            | 925           |
| total timesteps         | 176237        |
| value_loss              | 7.0271875e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0014078515  |
| ent_coef_loss           | 1.7810283     |
| entropy                 | 0.96981424    |
| episodes                | 520           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 176851        |
| policy_loss             | -0.4190266    |
| qf1_loss                | 6.2829116e-05 |
| qf2_loss                | 5.086587e-05  |
| time_elapsed            | 929           |
| total timesteps         | 176951        |
| value_loss              | 6.0595277e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013517449  |
| ent_coef_loss           | 0.65159786    |
| entropy                 | 1.1058972     |
| episodes                | 524           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 177424        |
| policy_loss             | -0.35563612   |
| qf1_loss                | 6.263212e-05  |
| qf2_loss                | 9.809012e-05  |
| time_elapsed            | 932           |
| total timesteps         | 177524        |
| value_loss              | 0.00015319703 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0014410707  |
| ent_coef_loss           | -2.675579     |
| entropy                 | 0.98326695    |
| episodes                | 528           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 178154        |
| policy_loss             | -0.44794655   |
| qf1_loss                | 5.9991766e-05 |
| qf2_loss                | 5.985081e-05  |
| time_elapsed            | 936           |
| total timesteps         | 178254        |
| value_loss              | 5.5944147e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001326769   |
| ent_coef_loss           | 1.1985283     |
| entropy                 | 0.8473958     |
| episodes                | 532           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 178985        |
| policy_loss             | -0.478122     |
| qf1_loss                | 0.0001573074  |
| qf2_loss                | 0.0001979449  |
| time_elapsed            | 940           |
| total timesteps         | 179085        |
| value_loss              | 0.00022549304 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0013644805 |
| ent_coef_loss           | -0.1741504   |
| entropy                 | 1.0085462    |
| episodes                | 536          |
| fps                     | 190          |
| mean 100 episode reward | 0.8          |
| n_updates               | 179743       |
| policy_loss             | -0.47882277  |
| qf1_loss                | 0.0023935349 |
| qf2_loss                | 0.001689307  |
| time_elapsed            | 944          |
| total timesteps         | 179843       |
| value_loss              | 7.20395e-05  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013849314  |
| ent_coef_loss           | -0.45750698   |
| entropy                 | 1.0969129     |
| episodes                | 540           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 180497        |
| policy_loss             | -0.42354032   |
| qf1_loss                | 7.4970914e-05 |
| qf2_loss                | 5.1040253e-05 |
| time_elapsed            | 948           |
| total timesteps         | 180597        |
| value_loss              | 7.711144e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0014171894  |
| ent_coef_loss           | -0.8620256    |
| entropy                 | 1.0845263     |
| episodes                | 544           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 181187        |
| policy_loss             | -0.43187457   |
| qf1_loss                | 0.00042956191 |
| qf2_loss                | 0.0005843063  |
| time_elapsed            | 952           |
| total timesteps         | 181287        |
| value_loss              | 6.248519e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0014417326   |
| ent_coef_loss           | 0.8853749      |
| entropy                 | 1.1748935      |
| episodes                | 548            |
| fps                     | 190            |
| mean 100 episode reward | 0.8            |
| n_updates               | 181923         |
| policy_loss             | -0.43997687    |
| qf1_loss                | 9.3728915e-05  |
| qf2_loss                | 0.000111842135 |
| time_elapsed            | 955            |
| total timesteps         | 182023         |
| value_loss              | 9.2386355e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0014064618  |
| ent_coef_loss           | 0.42363542    |
| entropy                 | 1.2503446     |
| episodes                | 552           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 182645        |
| policy_loss             | -0.38468182   |
| qf1_loss                | 0.00013395563 |
| qf2_loss                | 0.00011211233 |
| time_elapsed            | 959           |
| total timesteps         | 182745        |
| value_loss              | 8.4557105e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001409809   |
| ent_coef_loss           | 2.0826545     |
| entropy                 | 1.0524602     |
| episodes                | 556           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 183443        |
| policy_loss             | -0.4360825    |
| qf1_loss                | 7.109314e-05  |
| qf2_loss                | 6.0125705e-05 |
| time_elapsed            | 964           |
| total timesteps         | 183543        |
| value_loss              | 8.286965e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012895181  |
| ent_coef_loss           | -0.043331623  |
| entropy                 | 1.0112069     |
| episodes                | 560           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 184349        |
| policy_loss             | -0.41365874   |
| qf1_loss                | 6.2662744e-05 |
| qf2_loss                | 3.8229504e-05 |
| time_elapsed            | 968           |
| total timesteps         | 184449        |
| value_loss              | 7.787567e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012430492  |
| ent_coef_loss           | 0.10351664    |
| entropy                 | 1.0998465     |
| episodes                | 564           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 185111        |
| policy_loss             | -0.43128684   |
| qf1_loss                | 7.71946e-05   |
| qf2_loss                | 0.00012951597 |
| time_elapsed            | 972           |
| total timesteps         | 185211        |
| value_loss              | 0.00015252281 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012714652  |
| ent_coef_loss           | 1.4376338     |
| entropy                 | 1.0594791     |
| episodes                | 568           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 185839        |
| policy_loss             | -0.43610108   |
| qf1_loss                | 6.5257744e-05 |
| qf2_loss                | 6.747588e-05  |
| time_elapsed            | 976           |
| total timesteps         | 185939        |
| value_loss              | 7.3086114e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012927188  |
| ent_coef_loss           | 1.184423      |
| entropy                 | 1.1324244     |
| episodes                | 572           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 186581        |
| policy_loss             | -0.3618809    |
| qf1_loss                | 5.6196743e-05 |
| qf2_loss                | 4.8723716e-05 |
| time_elapsed            | 980           |
| total timesteps         | 186681        |
| value_loss              | 0.0003246576  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012457692  |
| ent_coef_loss           | -1.3110133    |
| entropy                 | 1.1547897     |
| episodes                | 576           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 187403        |
| policy_loss             | -0.39348096   |
| qf1_loss                | 0.00011913034 |
| qf2_loss                | 7.837721e-05  |
| time_elapsed            | 984           |
| total timesteps         | 187503        |
| value_loss              | 6.938125e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012177974  |
| ent_coef_loss           | -3.1173975    |
| entropy                 | 1.023213      |
| episodes                | 580           |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 188015        |
| policy_loss             | -0.44236523   |
| qf1_loss                | 3.8289494e-05 |
| qf2_loss                | 4.0070507e-05 |
| time_elapsed            | 987           |
| total timesteps         | 188115        |
| value_loss              | 5.698618e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0011757549 |
| ent_coef_loss           | 0.79213125   |
| entropy                 | 1.0381021    |
| episodes                | 584          |
| fps                     | 190          |
| mean 100 episode reward | 0.7          |
| n_updates               | 188762       |
| policy_loss             | -0.47687936  |
| qf1_loss                | 0.0006130333 |
| qf2_loss                | 0.0006084646 |
| time_elapsed            | 991          |
| total timesteps         | 188862       |
| value_loss              | 7.330912e-05 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0012476532 |
| ent_coef_loss           | 0.8104995    |
| entropy                 | 1.2624767    |
| episodes                | 588          |
| fps                     | 190          |
| mean 100 episode reward | 0.7          |
| n_updates               | 189506       |
| policy_loss             | -0.40341043  |
| qf1_loss                | 3.211602e-05 |
| qf2_loss                | 5.837846e-05 |
| time_elapsed            | 996          |
| total timesteps         | 189606       |
| value_loss              | 8.939115e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013321505  |
| ent_coef_loss           | -0.0071635246 |
| entropy                 | 0.98016864    |
| episodes                | 592           |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 190233        |
| policy_loss             | -0.43144816   |
| qf1_loss                | 9.958161e-05  |
| qf2_loss                | 9.962808e-05  |
| time_elapsed            | 999           |
| total timesteps         | 190333        |
| value_loss              | 0.00028207363 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013775895  |
| ent_coef_loss           | -0.39793736   |
| entropy                 | 0.90968525    |
| episodes                | 596           |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 191009        |
| policy_loss             | -0.4326743    |
| qf1_loss                | 0.00013793922 |
| qf2_loss                | 0.00011173034 |
| time_elapsed            | 1003          |
| total timesteps         | 191109        |
| value_loss              | 0.00014037914 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.001292672    |
| ent_coef_loss           | 0.6880462      |
| entropy                 | 1.2170253      |
| episodes                | 600            |
| fps                     | 190            |
| mean 100 episode reward | 0.7            |
| n_updates               | 191719         |
| policy_loss             | -0.4551491     |
| qf1_loss                | 7.8164565e-05  |
| qf2_loss                | 0.000108202206 |
| time_elapsed            | 1007           |
| total timesteps         | 191819         |
| value_loss              | 0.00013896669  |
--------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0014176619 |
| ent_coef_loss           | -1.4544405   |
| entropy                 | 1.2070149    |
| episodes                | 604          |
| fps                     | 190          |
| mean 100 episode reward | 0.7          |
| n_updates               | 192397       |
| policy_loss             | -0.42487782  |
| qf1_loss                | 5.645553e-05 |
| qf2_loss                | 6.979887e-05 |
| time_elapsed            | 1011         |
| total timesteps         | 192497       |
| value_loss              | 6.435035e-05 |
------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0013504596   |
| ent_coef_loss           | 0.22262436     |
| entropy                 | 1.051878       |
| episodes                | 608            |
| fps                     | 190            |
| mean 100 episode reward | 0.7            |
| n_updates               | 193189         |
| policy_loss             | -0.45136133    |
| qf1_loss                | 0.00013288477  |
| qf2_loss                | 0.000104385064 |
| time_elapsed            | 1015           |
| total timesteps         | 193289         |
| value_loss              | 0.00012055222  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012999634  |
| ent_coef_loss           | -0.61560094   |
| entropy                 | 0.9449418     |
| episodes                | 612           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 193865        |
| policy_loss             | -0.47067988   |
| qf1_loss                | 5.3365296e-05 |
| qf2_loss                | 1.9258116e-05 |
| time_elapsed            | 1018          |
| total timesteps         | 193965        |
| value_loss              | 2.8329736e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00135417    |
| ent_coef_loss           | 2.2831476     |
| entropy                 | 1.2699792     |
| episodes                | 616           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 194604        |
| policy_loss             | -0.40939575   |
| qf1_loss                | 0.00027744667 |
| qf2_loss                | 0.00020277547 |
| time_elapsed            | 1022          |
| total timesteps         | 194704        |
| value_loss              | 5.4142547e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0014141484  |
| ent_coef_loss           | -0.44063747   |
| entropy                 | 1.2015715     |
| episodes                | 620           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 195306        |
| policy_loss             | -0.46177343   |
| qf1_loss                | 3.1647258e-05 |
| qf2_loss                | 2.6119995e-05 |
| time_elapsed            | 1026          |
| total timesteps         | 195406        |
| value_loss              | 4.0645566e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001353514   |
| ent_coef_loss           | 0.014954686   |
| entropy                 | 1.0913626     |
| episodes                | 624           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 196348        |
| policy_loss             | -0.50464296   |
| qf1_loss                | 0.0001348608  |
| qf2_loss                | 0.00011975351 |
| time_elapsed            | 1032          |
| total timesteps         | 196448        |
| value_loss              | 6.4799766e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0015399394  |
| ent_coef_loss           | 0.5905258     |
| entropy                 | 1.084968      |
| episodes                | 628           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 197070        |
| policy_loss             | -0.5146026    |
| qf1_loss                | 4.0922238e-05 |
| qf2_loss                | 5.63753e-05   |
| time_elapsed            | 1035          |
| total timesteps         | 197170        |
| value_loss              | 6.225708e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0014014402  |
| ent_coef_loss           | 0.6515819     |
| entropy                 | 1.371285      |
| episodes                | 632           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 197824        |
| policy_loss             | -0.4625016    |
| qf1_loss                | 3.4563756e-05 |
| qf2_loss                | 3.339434e-05  |
| time_elapsed            | 1039          |
| total timesteps         | 197924        |
| value_loss              | 3.0828625e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0015054228 |
| ent_coef_loss           | -0.4278718   |
| entropy                 | 1.2828879    |
| episodes                | 636          |
| fps                     | 190          |
| mean 100 episode reward | 0.8          |
| n_updates               | 198502       |
| policy_loss             | -0.47538084  |
| qf1_loss                | 7.501875e-05 |
| qf2_loss                | 8.831779e-05 |
| time_elapsed            | 1043         |
| total timesteps         | 198602       |
| value_loss              | 8.8243e-05   |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0014482943  |
| ent_coef_loss           | 2.6519482     |
| entropy                 | 1.3529745     |
| episodes                | 640           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 199191        |
| policy_loss             | -0.44407424   |
| qf1_loss                | 7.9292455e-05 |
| qf2_loss                | 4.9990053e-05 |
| time_elapsed            | 1046          |
| total timesteps         | 199291        |
| value_loss              | 4.000256e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.001326124  |
| ent_coef_loss           | -2.2932792   |
| entropy                 | 1.2376341    |
| episodes                | 644          |
| fps                     | 190          |
| mean 100 episode reward | 0.8          |
| n_updates               | 199865       |
| policy_loss             | -0.45337003  |
| qf1_loss                | 7.022451e-05 |
| qf2_loss                | 6.966587e-05 |
| time_elapsed            | 1050         |
| total timesteps         | 199965       |
| value_loss              | 7.090974e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0014386731  |
| ent_coef_loss           | -0.4335605    |
| entropy                 | 1.171416      |
| episodes                | 648           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 200597        |
| policy_loss             | -0.49328256   |
| qf1_loss                | 3.8680715e-05 |
| qf2_loss                | 2.972222e-05  |
| time_elapsed            | 1054          |
| total timesteps         | 200697        |
| value_loss              | 3.983632e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001291903   |
| ent_coef_loss           | -1.7774723    |
| entropy                 | 1.2186302     |
| episodes                | 652           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 201562        |
| policy_loss             | -0.44544744   |
| qf1_loss                | 7.228136e-05  |
| qf2_loss                | 3.656106e-05  |
| time_elapsed            | 1059          |
| total timesteps         | 201662        |
| value_loss              | 3.4263125e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013000112  |
| ent_coef_loss           | 3.6672716     |
| entropy                 | 1.0823296     |
| episodes                | 656           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 202239        |
| policy_loss             | -0.51873654   |
| qf1_loss                | 2.990023e-05  |
| qf2_loss                | 5.622378e-05  |
| time_elapsed            | 1062          |
| total timesteps         | 202339        |
| value_loss              | 2.4989524e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001420741   |
| ent_coef_loss           | 1.1591189     |
| entropy                 | 1.2155285     |
| episodes                | 660           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 202911        |
| policy_loss             | -0.44916946   |
| qf1_loss                | 6.5596425e-05 |
| qf2_loss                | 4.2571155e-05 |
| time_elapsed            | 1066          |
| total timesteps         | 203011        |
| value_loss              | 4.5793975e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0014075816  |
| ent_coef_loss           | -0.33434474   |
| entropy                 | 1.2064167     |
| episodes                | 664           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 203610        |
| policy_loss             | -0.4819854    |
| qf1_loss                | 5.7391742e-05 |
| qf2_loss                | 3.113791e-05  |
| time_elapsed            | 1069          |
| total timesteps         | 203710        |
| value_loss              | 6.474362e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013662135  |
| ent_coef_loss           | 0.13576886    |
| entropy                 | 1.2092915     |
| episodes                | 668           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 204268        |
| policy_loss             | -0.50627774   |
| qf1_loss                | 5.5784716e-05 |
| qf2_loss                | 4.5476336e-05 |
| time_elapsed            | 1073          |
| total timesteps         | 204368        |
| value_loss              | 5.8326823e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012520723  |
| ent_coef_loss           | -0.610461     |
| entropy                 | 1.2061188     |
| episodes                | 672           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 205220        |
| policy_loss             | -0.49326476   |
| qf1_loss                | 0.0001380779  |
| qf2_loss                | 5.9605718e-05 |
| time_elapsed            | 1078          |
| total timesteps         | 205320        |
| value_loss              | 5.638303e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012285344  |
| ent_coef_loss           | -0.79215455   |
| entropy                 | 1.2492561     |
| episodes                | 676           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 206277        |
| policy_loss             | -0.41988242   |
| qf1_loss                | 3.0009382e-05 |
| qf2_loss                | 4.2037063e-05 |
| time_elapsed            | 1084          |
| total timesteps         | 206377        |
| value_loss              | 9.6864955e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012658972  |
| ent_coef_loss           | 1.4791642     |
| entropy                 | 1.3629061     |
| episodes                | 680           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 206988        |
| policy_loss             | -0.48963267   |
| qf1_loss                | 2.0459986e-05 |
| qf2_loss                | 3.0016996e-05 |
| time_elapsed            | 1087          |
| total timesteps         | 207088        |
| value_loss              | 5.8855785e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012656008  |
| ent_coef_loss           | -1.80304      |
| entropy                 | 1.3672165     |
| episodes                | 684           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 207731        |
| policy_loss             | -0.5394418    |
| qf1_loss                | 3.694478e-05  |
| qf2_loss                | 2.1228785e-05 |
| time_elapsed            | 1091          |
| total timesteps         | 207831        |
| value_loss              | 5.2789575e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013395548  |
| ent_coef_loss           | -0.26810122   |
| entropy                 | 1.307023      |
| episodes                | 688           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 208551        |
| policy_loss             | -0.47820333   |
| qf1_loss                | 4.0237e-05    |
| qf2_loss                | 2.7867625e-05 |
| time_elapsed            | 1095          |
| total timesteps         | 208651        |
| value_loss              | 6.3548665e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012953561  |
| ent_coef_loss           | 0.25223625    |
| entropy                 | 1.2918179     |
| episodes                | 692           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 209248        |
| policy_loss             | -0.4367528    |
| qf1_loss                | 6.5627e-05    |
| qf2_loss                | 7.451233e-05  |
| time_elapsed            | 1099          |
| total timesteps         | 209348        |
| value_loss              | 0.00014795187 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012595941  |
| ent_coef_loss           | 0.022352815   |
| entropy                 | 1.1513172     |
| episodes                | 696           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 209966        |
| policy_loss             | -0.4189787    |
| qf1_loss                | 2.9407813e-05 |
| qf2_loss                | 6.589485e-05  |
| time_elapsed            | 1103          |
| total timesteps         | 210066        |
| value_loss              | 4.4136166e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012555884  |
| ent_coef_loss           | -0.78576255   |
| entropy                 | 1.1181316     |
| episodes                | 700           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 210633        |
| policy_loss             | -0.47631      |
| qf1_loss                | 9.127178e-05  |
| qf2_loss                | 0.00032300124 |
| time_elapsed            | 1106          |
| total timesteps         | 210733        |
| value_loss              | 9.115385e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012582663  |
| ent_coef_loss           | 0.8152328     |
| entropy                 | 1.1946212     |
| episodes                | 704           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 211380        |
| policy_loss             | -0.47541672   |
| qf1_loss                | 0.00014092735 |
| qf2_loss                | 0.00017662207 |
| time_elapsed            | 1110          |
| total timesteps         | 211480        |
| value_loss              | 6.898273e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013073004  |
| ent_coef_loss           | 2.5165806     |
| entropy                 | 1.354806      |
| episodes                | 708           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 212177        |
| policy_loss             | -0.4562474    |
| qf1_loss                | 6.30867e-05   |
| qf2_loss                | 5.8204198e-05 |
| time_elapsed            | 1115          |
| total timesteps         | 212277        |
| value_loss              | 6.4672015e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0013071408   |
| ent_coef_loss           | -1.4425672     |
| entropy                 | 1.3940251      |
| episodes                | 712            |
| fps                     | 190            |
| mean 100 episode reward | 0.8            |
| n_updates               | 213021         |
| policy_loss             | -0.46728492    |
| qf1_loss                | 0.00012978664  |
| qf2_loss                | 0.00011831673  |
| time_elapsed            | 1119           |
| total timesteps         | 213121         |
| value_loss              | 0.000107714644 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012740985  |
| ent_coef_loss           | -1.074069     |
| entropy                 | 1.362745      |
| episodes                | 716           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 213775        |
| policy_loss             | -0.5195198    |
| qf1_loss                | 3.3867866e-05 |
| qf2_loss                | 3.5477566e-05 |
| time_elapsed            | 1123          |
| total timesteps         | 213875        |
| value_loss              | 2.5364865e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013036694  |
| ent_coef_loss           | 2.1118898     |
| entropy                 | 1.4053078     |
| episodes                | 720           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 214435        |
| policy_loss             | -0.5050889    |
| qf1_loss                | 3.0610143e-05 |
| qf2_loss                | 3.0934592e-05 |
| time_elapsed            | 1126          |
| total timesteps         | 214535        |
| value_loss              | 3.455007e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001270235   |
| ent_coef_loss           | 1.265166      |
| entropy                 | 1.3641807     |
| episodes                | 724           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 215236        |
| policy_loss             | -0.502216     |
| qf1_loss                | 3.2570242e-05 |
| qf2_loss                | 4.9093673e-05 |
| time_elapsed            | 1131          |
| total timesteps         | 215336        |
| value_loss              | 6.1245955e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0013440258  |
| ent_coef_loss           | -1.2892835    |
| entropy                 | 1.2282345     |
| episodes                | 728           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 215935        |
| policy_loss             | -0.5235471    |
| qf1_loss                | 7.829907e-05  |
| qf2_loss                | 5.5444645e-05 |
| time_elapsed            | 1134          |
| total timesteps         | 216035        |
| value_loss              | 5.400071e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012542222  |
| ent_coef_loss           | 0.8364779     |
| entropy                 | 1.4731929     |
| episodes                | 732           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 216670        |
| policy_loss             | -0.4843753    |
| qf1_loss                | 3.68397e-05   |
| qf2_loss                | 6.196524e-05  |
| time_elapsed            | 1138          |
| total timesteps         | 216770        |
| value_loss              | 7.3218005e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001262811   |
| ent_coef_loss           | 0.8531274     |
| entropy                 | 1.3955991     |
| episodes                | 736           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 217342        |
| policy_loss             | -0.5272266    |
| qf1_loss                | 8.0125654e-05 |
| qf2_loss                | 5.9975522e-05 |
| time_elapsed            | 1142          |
| total timesteps         | 217442        |
| value_loss              | 0.00017344224 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001209038   |
| ent_coef_loss           | 0.91000533    |
| entropy                 | 1.2091147     |
| episodes                | 740           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 218247        |
| policy_loss             | -0.4802773    |
| qf1_loss                | 0.00016015758 |
| qf2_loss                | 0.00016377623 |
| time_elapsed            | 1147          |
| total timesteps         | 218347        |
| value_loss              | 0.0003030334  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012545853  |
| ent_coef_loss           | -0.3320551    |
| entropy                 | 1.1475846     |
| episodes                | 744           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 218974        |
| policy_loss             | -0.55697995   |
| qf1_loss                | 4.1312196e-05 |
| qf2_loss                | 6.612751e-05  |
| time_elapsed            | 1150          |
| total timesteps         | 219074        |
| value_loss              | 8.657506e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0011989675 |
| ent_coef_loss           | 2.4517367    |
| entropy                 | 1.133113     |
| episodes                | 748          |
| fps                     | 190          |
| mean 100 episode reward | 0.8          |
| n_updates               | 219782       |
| policy_loss             | -0.5418019   |
| qf1_loss                | 4.152731e-05 |
| qf2_loss                | 6.035155e-05 |
| time_elapsed            | 1155         |
| total timesteps         | 219882       |
| value_loss              | 6.927051e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012175547  |
| ent_coef_loss           | -2.3162694    |
| entropy                 | 1.2487264     |
| episodes                | 752           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 220743        |
| policy_loss             | -0.56066453   |
| qf1_loss                | 5.653033e-05  |
| qf2_loss                | 4.0606315e-05 |
| time_elapsed            | 1160          |
| total timesteps         | 220843        |
| value_loss              | 3.8539718e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001208503   |
| ent_coef_loss           | -1.7248958    |
| entropy                 | 1.4397053     |
| episodes                | 756           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 221423        |
| policy_loss             | -0.51046526   |
| qf1_loss                | 6.38782e-05   |
| qf2_loss                | 7.2439405e-05 |
| time_elapsed            | 1163          |
| total timesteps         | 221523        |
| value_loss              | 0.00011069616 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001221297   |
| ent_coef_loss           | -1.6005678    |
| entropy                 | 1.3132609     |
| episodes                | 760           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 222128        |
| policy_loss             | -0.51457655   |
| qf1_loss                | 0.00019979113 |
| qf2_loss                | 0.0002144282  |
| time_elapsed            | 1167          |
| total timesteps         | 222228        |
| value_loss              | 8.120228e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012213483  |
| ent_coef_loss           | 1.5625077     |
| entropy                 | 1.4563456     |
| episodes                | 764           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 222787        |
| policy_loss             | -0.4633494    |
| qf1_loss                | 4.1889012e-05 |
| qf2_loss                | 5.077784e-05  |
| time_elapsed            | 1170          |
| total timesteps         | 222887        |
| value_loss              | 8.495985e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012619977  |
| ent_coef_loss           | -0.3405844    |
| entropy                 | 1.1821384     |
| episodes                | 768           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 223495        |
| policy_loss             | -0.5288503    |
| qf1_loss                | 6.8641195e-05 |
| qf2_loss                | 4.0316787e-05 |
| time_elapsed            | 1174          |
| total timesteps         | 223595        |
| value_loss              | 7.1428745e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0012217938 |
| ent_coef_loss           | -1.5136579   |
| entropy                 | 1.170652     |
| episodes                | 772          |
| fps                     | 190          |
| mean 100 episode reward | 0.8          |
| n_updates               | 224225       |
| policy_loss             | -0.4942504   |
| qf1_loss                | 6.95038e-05  |
| qf2_loss                | 6.225785e-05 |
| time_elapsed            | 1178         |
| total timesteps         | 224325       |
| value_loss              | 6.678631e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001212035   |
| ent_coef_loss           | -3.0030026    |
| entropy                 | 1.348513      |
| episodes                | 776           |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 224917        |
| policy_loss             | -0.5330548    |
| qf1_loss                | 8.266755e-05  |
| qf2_loss                | 8.570634e-05  |
| time_elapsed            | 1182          |
| total timesteps         | 225017        |
| value_loss              | 8.1085425e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012086045  |
| ent_coef_loss           | -0.04168427   |
| entropy                 | 1.3006897     |
| episodes                | 780           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 225586        |
| policy_loss             | -0.5180157    |
| qf1_loss                | 0.0005554878  |
| qf2_loss                | 0.00014293559 |
| time_elapsed            | 1185          |
| total timesteps         | 225686        |
| value_loss              | 0.00015671115 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011490269  |
| ent_coef_loss           | -1.4411285    |
| entropy                 | 1.2309712     |
| episodes                | 784           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 226258        |
| policy_loss             | -0.5466447    |
| qf1_loss                | 0.00010703448 |
| qf2_loss                | 0.00010355002 |
| time_elapsed            | 1189          |
| total timesteps         | 226358        |
| value_loss              | 2.4609408e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011017674  |
| ent_coef_loss           | -0.08831036   |
| entropy                 | 1.2979213     |
| episodes                | 788           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 226965        |
| policy_loss             | -0.55136156   |
| qf1_loss                | 0.0001257793  |
| qf2_loss                | 5.901914e-05  |
| time_elapsed            | 1192          |
| total timesteps         | 227065        |
| value_loss              | 0.00064018636 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011447908  |
| ent_coef_loss           | -0.5138372    |
| entropy                 | 1.3271657     |
| episodes                | 792           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 227658        |
| policy_loss             | -0.56112015   |
| qf1_loss                | 1.60853e-05   |
| qf2_loss                | 3.243132e-05  |
| time_elapsed            | 1196          |
| total timesteps         | 227758        |
| value_loss              | 3.0175217e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001066004   |
| ent_coef_loss           | -2.9388509    |
| entropy                 | 1.3106985     |
| episodes                | 796           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 228391        |
| policy_loss             | -0.50929326   |
| qf1_loss                | 3.6383164e-05 |
| qf2_loss                | 3.0373012e-05 |
| time_elapsed            | 1200          |
| total timesteps         | 228491        |
| value_loss              | 7.665774e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010762804 |
| ent_coef_loss           | 1.3346031    |
| entropy                 | 1.1188872    |
| episodes                | 800          |
| fps                     | 190          |
| mean 100 episode reward | 0.8          |
| n_updates               | 229172       |
| policy_loss             | -0.51903915  |
| qf1_loss                | 0.0027758882 |
| qf2_loss                | 0.0029173933 |
| time_elapsed            | 1204         |
| total timesteps         | 229272       |
| value_loss              | 7.020097e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001188218   |
| ent_coef_loss           | 1.198014      |
| entropy                 | 1.3176482     |
| episodes                | 804           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 229871        |
| policy_loss             | -0.49039948   |
| qf1_loss                | 6.11219e-05   |
| qf2_loss                | 4.5316403e-05 |
| time_elapsed            | 1208          |
| total timesteps         | 229971        |
| value_loss              | 0.0001024685  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011537551  |
| ent_coef_loss           | -1.3759812    |
| entropy                 | 1.2755017     |
| episodes                | 808           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 230578        |
| policy_loss             | -0.5263299    |
| qf1_loss                | 6.8480134e-05 |
| qf2_loss                | 5.9330403e-05 |
| time_elapsed            | 1211          |
| total timesteps         | 230678        |
| value_loss              | 6.853752e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011598072  |
| ent_coef_loss           | -3.2844543    |
| entropy                 | 1.2925354     |
| episodes                | 812           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 231318        |
| policy_loss             | -0.52918446   |
| qf1_loss                | 0.00021261768 |
| qf2_loss                | 0.0002706741  |
| time_elapsed            | 1215          |
| total timesteps         | 231418        |
| value_loss              | 6.0262213e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011517928  |
| ent_coef_loss           | 1.4890538     |
| entropy                 | 1.3093987     |
| episodes                | 816           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 232024        |
| policy_loss             | -0.54106057   |
| qf1_loss                | 4.3170607e-05 |
| qf2_loss                | 7.148627e-05  |
| time_elapsed            | 1219          |
| total timesteps         | 232124        |
| value_loss              | 5.7491576e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011352234  |
| ent_coef_loss           | 1.5057521     |
| entropy                 | 1.3839953     |
| episodes                | 820           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 232679        |
| policy_loss             | -0.49840164   |
| qf1_loss                | 4.8160324e-05 |
| qf2_loss                | 4.421518e-05  |
| time_elapsed            | 1222          |
| total timesteps         | 232779        |
| value_loss              | 6.445033e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012161708  |
| ent_coef_loss           | 0.658041      |
| entropy                 | 1.3160596     |
| episodes                | 824           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 233349        |
| policy_loss             | -0.48045492   |
| qf1_loss                | 7.0536305e-05 |
| qf2_loss                | 7.4669166e-05 |
| time_elapsed            | 1226          |
| total timesteps         | 233449        |
| value_loss              | 7.106364e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011706501  |
| ent_coef_loss           | -0.5990783    |
| entropy                 | 1.3089695     |
| episodes                | 828           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 234067        |
| policy_loss             | -0.5140325    |
| qf1_loss                | 3.207598e-05  |
| qf2_loss                | 3.3532713e-05 |
| time_elapsed            | 1229          |
| total timesteps         | 234167        |
| value_loss              | 4.2485433e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0011624239 |
| ent_coef_loss           | -0.2562885   |
| entropy                 | 1.3094923    |
| episodes                | 832          |
| fps                     | 190          |
| mean 100 episode reward | 0.8          |
| n_updates               | 234733       |
| policy_loss             | -0.4870876   |
| qf1_loss                | 9.289992e-05 |
| qf2_loss                | 5.56772e-05  |
| time_elapsed            | 1233         |
| total timesteps         | 234833       |
| value_loss              | 8.62483e-05  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012024273  |
| ent_coef_loss           | -1.3307909    |
| entropy                 | 1.4621177     |
| episodes                | 836           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 235402        |
| policy_loss             | -0.5397622    |
| qf1_loss                | 3.2036063e-05 |
| qf2_loss                | 2.0551364e-05 |
| time_elapsed            | 1237          |
| total timesteps         | 235502        |
| value_loss              | 7.38409e-05   |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0011578297   |
| ent_coef_loss           | 1.7070086      |
| entropy                 | 1.1808172      |
| episodes                | 840            |
| fps                     | 190            |
| mean 100 episode reward | 0.8            |
| n_updates               | 236099         |
| policy_loss             | -0.4935643     |
| qf1_loss                | 0.000100694306 |
| qf2_loss                | 0.00018102146  |
| time_elapsed            | 1240           |
| total timesteps         | 236199         |
| value_loss              | 5.2500065e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001188494   |
| ent_coef_loss           | 0.74368954    |
| entropy                 | 1.2688606     |
| episodes                | 844           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 236826        |
| policy_loss             | -0.5172125    |
| qf1_loss                | 9.921996e-05  |
| qf2_loss                | 3.1654756e-05 |
| time_elapsed            | 1244          |
| total timesteps         | 236926        |
| value_loss              | 3.8435148e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011743413  |
| ent_coef_loss           | -0.12843692   |
| entropy                 | 1.2374947     |
| episodes                | 848           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 237791        |
| policy_loss             | -0.561038     |
| qf1_loss                | 3.0217847e-05 |
| qf2_loss                | 2.6466621e-05 |
| time_elapsed            | 1249          |
| total timesteps         | 237891        |
| value_loss              | 7.1036644e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011857718  |
| ent_coef_loss           | -1.7474754    |
| entropy                 | 1.3004988     |
| episodes                | 852           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 238452        |
| policy_loss             | -0.5372134    |
| qf1_loss                | 3.910144e-05  |
| qf2_loss                | 3.3468255e-05 |
| time_elapsed            | 1253          |
| total timesteps         | 238552        |
| value_loss              | 5.889247e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011955022  |
| ent_coef_loss           | 0.9334748     |
| entropy                 | 1.384054      |
| episodes                | 856           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 239133        |
| policy_loss             | -0.532876     |
| qf1_loss                | 0.00018902702 |
| qf2_loss                | 0.00018506909 |
| time_elapsed            | 1256          |
| total timesteps         | 239233        |
| value_loss              | 6.844509e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010858821 |
| ent_coef_loss           | 1.9996916    |
| entropy                 | 1.1986935    |
| episodes                | 860          |
| fps                     | 190          |
| mean 100 episode reward | 0.8          |
| n_updates               | 239819       |
| policy_loss             | -0.52717865  |
| qf1_loss                | 5.53925e-05  |
| qf2_loss                | 6.233946e-05 |
| time_elapsed            | 1260         |
| total timesteps         | 239919       |
| value_loss              | 4.629109e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011052139  |
| ent_coef_loss           | -2.9564238    |
| entropy                 | 1.3783565     |
| episodes                | 864           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 240506        |
| policy_loss             | -0.51468265   |
| qf1_loss                | 2.9103085e-05 |
| qf2_loss                | 2.1328666e-05 |
| time_elapsed            | 1264          |
| total timesteps         | 240606        |
| value_loss              | 3.486188e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010704707  |
| ent_coef_loss           | -1.1421187    |
| entropy                 | 1.2779162     |
| episodes                | 868           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 241213        |
| policy_loss             | -0.481009     |
| qf1_loss                | 3.0977964e-05 |
| qf2_loss                | 5.0228227e-05 |
| time_elapsed            | 1267          |
| total timesteps         | 241313        |
| value_loss              | 5.287153e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011465438  |
| ent_coef_loss           | -0.048853755  |
| entropy                 | 1.4178774     |
| episodes                | 872           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 242137        |
| policy_loss             | -0.48463115   |
| qf1_loss                | 0.0012451615  |
| qf2_loss                | 0.0016069434  |
| time_elapsed            | 1272          |
| total timesteps         | 242237        |
| value_loss              | 0.00013561337 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010784607  |
| ent_coef_loss           | 1.5271294     |
| entropy                 | 1.1958444     |
| episodes                | 876           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 242921        |
| policy_loss             | -0.4993153    |
| qf1_loss                | 5.3757176e-05 |
| qf2_loss                | 3.6505648e-05 |
| time_elapsed            | 1276          |
| total timesteps         | 243021        |
| value_loss              | 8.05714e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011217052  |
| ent_coef_loss           | -0.03485197   |
| entropy                 | 1.3321673     |
| episodes                | 880           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 243584        |
| policy_loss             | -0.4928041    |
| qf1_loss                | 2.5794565e-05 |
| qf2_loss                | 2.9716908e-05 |
| time_elapsed            | 1280          |
| total timesteps         | 243684        |
| value_loss              | 2.8422015e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010939693  |
| ent_coef_loss           | 3.389894      |
| entropy                 | 1.3709171     |
| episodes                | 884           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 244401        |
| policy_loss             | -0.55898327   |
| qf1_loss                | 3.386318e-05  |
| qf2_loss                | 2.4588804e-05 |
| time_elapsed            | 1284          |
| total timesteps         | 244501        |
| value_loss              | 1.8746847e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010626757  |
| ent_coef_loss           | -0.6033585    |
| entropy                 | 1.5685663     |
| episodes                | 888           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 245383        |
| policy_loss             | -0.51629597   |
| qf1_loss                | 3.1972366e-05 |
| qf2_loss                | 5.622932e-05  |
| time_elapsed            | 1289          |
| total timesteps         | 245483        |
| value_loss              | 6.544826e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011112589  |
| ent_coef_loss           | -0.17025065   |
| entropy                 | 1.5165771     |
| episodes                | 892           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 246043        |
| policy_loss             | -0.5795826    |
| qf1_loss                | 9.122971e-05  |
| qf2_loss                | 6.4872846e-05 |
| time_elapsed            | 1293          |
| total timesteps         | 246143        |
| value_loss              | 9.392139e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010461954  |
| ent_coef_loss           | -1.5904559    |
| entropy                 | 1.1590382     |
| episodes                | 896           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 247080        |
| policy_loss             | -0.56010675   |
| qf1_loss                | 4.2067186e-05 |
| qf2_loss                | 3.3764398e-05 |
| time_elapsed            | 1298          |
| total timesteps         | 247180        |
| value_loss              | 9.267449e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010161774  |
| ent_coef_loss           | 3.753209      |
| entropy                 | 1.4212028     |
| episodes                | 900           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 247824        |
| policy_loss             | -0.57159287   |
| qf1_loss                | 9.343895e-05  |
| qf2_loss                | 8.204512e-05  |
| time_elapsed            | 1302          |
| total timesteps         | 247924        |
| value_loss              | 4.3427495e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010212734  |
| ent_coef_loss           | -0.9365742    |
| entropy                 | 1.3305902     |
| episodes                | 904           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 248745        |
| policy_loss             | -0.47617766   |
| qf1_loss                | 0.00013134451 |
| qf2_loss                | 0.00011954416 |
| time_elapsed            | 1307          |
| total timesteps         | 248845        |
| value_loss              | 7.360705e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011172835  |
| ent_coef_loss           | -0.19781655   |
| entropy                 | 1.2252108     |
| episodes                | 908           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 249424        |
| policy_loss             | -0.4787307    |
| qf1_loss                | 3.9387007e-05 |
| qf2_loss                | 5.2366944e-05 |
| time_elapsed            | 1310          |
| total timesteps         | 249524        |
| value_loss              | 4.4003493e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0010844198   |
| ent_coef_loss           | -0.9959097     |
| entropy                 | 1.1303022      |
| episodes                | 912            |
| fps                     | 190            |
| mean 100 episode reward | 0.8            |
| n_updates               | 250115         |
| policy_loss             | -0.5049731     |
| qf1_loss                | 0.000114827875 |
| qf2_loss                | 6.11285e-05    |
| time_elapsed            | 1314           |
| total timesteps         | 250215         |
| value_loss              | 6.517963e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010987822  |
| ent_coef_loss           | 1.9231695     |
| entropy                 | 1.3909347     |
| episodes                | 916           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 251066        |
| policy_loss             | -0.5576774    |
| qf1_loss                | 6.64728e-05   |
| qf2_loss                | 9.4724266e-05 |
| time_elapsed            | 1319          |
| total timesteps         | 251166        |
| value_loss              | 0.00021974923 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011133215  |
| ent_coef_loss           | -0.060043097  |
| entropy                 | 1.2175204     |
| episodes                | 920           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 251825        |
| policy_loss             | -0.5190597    |
| qf1_loss                | 8.190277e-05  |
| qf2_loss                | 3.9193394e-05 |
| time_elapsed            | 1323          |
| total timesteps         | 251925        |
| value_loss              | 3.950113e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001216031   |
| ent_coef_loss           | 2.077987      |
| entropy                 | 1.4366158     |
| episodes                | 924           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 252510        |
| policy_loss             | -0.53273785   |
| qf1_loss                | 5.6189318e-05 |
| qf2_loss                | 3.060692e-05  |
| time_elapsed            | 1327          |
| total timesteps         | 252610        |
| value_loss              | 7.7417724e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0012587121 |
| ent_coef_loss           | -1.1796699   |
| entropy                 | 1.2772486    |
| episodes                | 928          |
| fps                     | 190          |
| mean 100 episode reward | 0.8          |
| n_updates               | 253234       |
| policy_loss             | -0.5368902   |
| qf1_loss                | 3.433915e-05 |
| qf2_loss                | 4.087113e-05 |
| time_elapsed            | 1331         |
| total timesteps         | 253334       |
| value_loss              | 9.895167e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010969562  |
| ent_coef_loss           | -0.7813021    |
| entropy                 | 1.2398782     |
| episodes                | 932           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 254445        |
| policy_loss             | -0.55992466   |
| qf1_loss                | 7.022176e-05  |
| qf2_loss                | 4.0776486e-05 |
| time_elapsed            | 1337          |
| total timesteps         | 254545        |
| value_loss              | 8.763906e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010907862  |
| ent_coef_loss           | -3.2209086    |
| entropy                 | 1.2803512     |
| episodes                | 936           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 255189        |
| policy_loss             | -0.45934486   |
| qf1_loss                | 3.7001424e-05 |
| qf2_loss                | 5.1899286e-05 |
| time_elapsed            | 1341          |
| total timesteps         | 255289        |
| value_loss              | 0.00013546413 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009945232  |
| ent_coef_loss           | 2.0757203     |
| entropy                 | 1.23342       |
| episodes                | 940           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 255960        |
| policy_loss             | -0.50023985   |
| qf1_loss                | 5.0655057e-05 |
| qf2_loss                | 5.6266526e-05 |
| time_elapsed            | 1345          |
| total timesteps         | 256060        |
| value_loss              | 8.9331355e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097558554 |
| ent_coef_loss           | 0.31819105    |
| entropy                 | 1.3301839     |
| episodes                | 944           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 256715        |
| policy_loss             | -0.48315108   |
| qf1_loss                | 5.5275246e-05 |
| qf2_loss                | 4.4867455e-05 |
| time_elapsed            | 1349          |
| total timesteps         | 256815        |
| value_loss              | 4.708033e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010374897 |
| ent_coef_loss           | -1.1338317   |
| entropy                 | 1.2748991    |
| episodes                | 948          |
| fps                     | 190          |
| mean 100 episode reward | 0.8          |
| n_updates               | 257389       |
| policy_loss             | -0.51325107  |
| qf1_loss                | 0.0011859986 |
| qf2_loss                | 0.0011904286 |
| time_elapsed            | 1353         |
| total timesteps         | 257489       |
| value_loss              | 6.892848e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010403368  |
| ent_coef_loss           | 2.162698      |
| entropy                 | 1.235836      |
| episodes                | 952           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 258593        |
| policy_loss             | -0.50717205   |
| qf1_loss                | 3.7526363e-05 |
| qf2_loss                | 3.4813278e-05 |
| time_elapsed            | 1359          |
| total timesteps         | 258693        |
| value_loss              | 4.219205e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010047988  |
| ent_coef_loss           | -0.3830632    |
| entropy                 | 1.3006424     |
| episodes                | 956           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 259244        |
| policy_loss             | -0.5222258    |
| qf1_loss                | 7.2873896e-05 |
| qf2_loss                | 4.9141552e-05 |
| time_elapsed            | 1362          |
| total timesteps         | 259344        |
| value_loss              | 0.00013587667 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001031676   |
| ent_coef_loss           | 2.4006672     |
| entropy                 | 1.1737821     |
| episodes                | 960           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 259891        |
| policy_loss             | -0.5252081    |
| qf1_loss                | 0.00012262775 |
| qf2_loss                | 0.00015193259 |
| time_elapsed            | 1366          |
| total timesteps         | 259991        |
| value_loss              | 4.0520747e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009837634  |
| ent_coef_loss           | 0.408464      |
| entropy                 | 1.3310289     |
| episodes                | 964           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 260584        |
| policy_loss             | -0.4778541    |
| qf1_loss                | 3.1086565e-05 |
| qf2_loss                | 2.8936682e-05 |
| time_elapsed            | 1369          |
| total timesteps         | 260684        |
| value_loss              | 6.361178e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009822152  |
| ent_coef_loss           | -0.36501575   |
| entropy                 | 1.2470313     |
| episodes                | 968           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 261289        |
| policy_loss             | -0.4929269    |
| qf1_loss                | 2.3533194e-05 |
| qf2_loss                | 1.9767962e-05 |
| time_elapsed            | 1373          |
| total timesteps         | 261389        |
| value_loss              | 1.97433e-05   |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010376847 |
| ent_coef_loss           | -0.13582402  |
| entropy                 | 1.2880464    |
| episodes                | 972          |
| fps                     | 190          |
| mean 100 episode reward | 0.8          |
| n_updates               | 261942       |
| policy_loss             | -0.54708713  |
| qf1_loss                | 5.425184e-05 |
| qf2_loss                | 5.582664e-05 |
| time_elapsed            | 1376         |
| total timesteps         | 262042       |
| value_loss              | 5.388506e-05 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010156643 |
| ent_coef_loss           | -0.58218807  |
| entropy                 | 1.0328186    |
| episodes                | 976          |
| fps                     | 190          |
| mean 100 episode reward | 0.8          |
| n_updates               | 262941       |
| policy_loss             | -0.44365466  |
| qf1_loss                | 0.0006692873 |
| qf2_loss                | 0.0006265721 |
| time_elapsed            | 1382         |
| total timesteps         | 263041       |
| value_loss              | 7.52398e-05  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097450597 |
| ent_coef_loss           | -0.780057     |
| entropy                 | 1.051699      |
| episodes                | 980           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 263616        |
| policy_loss             | -0.5067727    |
| qf1_loss                | 4.506811e-05  |
| qf2_loss                | 3.5068762e-05 |
| time_elapsed            | 1385          |
| total timesteps         | 263716        |
| value_loss              | 3.9999002e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010148293  |
| ent_coef_loss           | 0.021578908   |
| entropy                 | 1.1634136     |
| episodes                | 984           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 264580        |
| policy_loss             | -0.5186098    |
| qf1_loss                | 8.48753e-05   |
| qf2_loss                | 9.131505e-05  |
| time_elapsed            | 1390          |
| total timesteps         | 264680        |
| value_loss              | 0.00012753901 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010199628  |
| ent_coef_loss           | 1.488041      |
| entropy                 | 1.1610197     |
| episodes                | 988           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 265267        |
| policy_loss             | -0.55141413   |
| qf1_loss                | 3.9187922e-05 |
| qf2_loss                | 3.1111707e-05 |
| time_elapsed            | 1394          |
| total timesteps         | 265367        |
| value_loss              | 9.1258014e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009312814  |
| ent_coef_loss           | 3.0864937     |
| entropy                 | 1.2146448     |
| episodes                | 992           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 265969        |
| policy_loss             | -0.5232616    |
| qf1_loss                | 5.2194075e-05 |
| qf2_loss                | 5.341479e-05  |
| time_elapsed            | 1398          |
| total timesteps         | 266069        |
| value_loss              | 3.0344376e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096653093 |
| ent_coef_loss           | -1.0194938    |
| entropy                 | 1.0976832     |
| episodes                | 996           |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 266948        |
| policy_loss             | -0.5270797    |
| qf1_loss                | 3.485923e-05  |
| qf2_loss                | 4.392753e-05  |
| time_elapsed            | 1403          |
| total timesteps         | 267048        |
| value_loss              | 0.00011428659 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009399655   |
| ent_coef_loss           | -1.2611649     |
| entropy                 | 1.133285       |
| episodes                | 1000           |
| fps                     | 190            |
| mean 100 episode reward | 0.8            |
| n_updates               | 267655         |
| policy_loss             | -0.50540745    |
| qf1_loss                | 2.1664759e-05  |
| qf2_loss                | 1.41535365e-05 |
| time_elapsed            | 1406           |
| total timesteps         | 267755         |
| value_loss              | 2.9227645e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010166145  |
| ent_coef_loss           | 0.22378713    |
| entropy                 | 1.1441257     |
| episodes                | 1004          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 268414        |
| policy_loss             | -0.53869945   |
| qf1_loss                | 1.8157827e-05 |
| qf2_loss                | 3.2571763e-05 |
| time_elapsed            | 1410          |
| total timesteps         | 268514        |
| value_loss              | 3.6711754e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009973707  |
| ent_coef_loss           | -1.6768191    |
| entropy                 | 1.1672766     |
| episodes                | 1008          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 269153        |
| policy_loss             | -0.48675287   |
| qf1_loss                | 1.7543767e-05 |
| qf2_loss                | 2.2516784e-05 |
| time_elapsed            | 1414          |
| total timesteps         | 269253        |
| value_loss              | 5.3590746e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010252579  |
| ent_coef_loss           | -5.020448     |
| entropy                 | 1.2546659     |
| episodes                | 1012          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 269925        |
| policy_loss             | -0.5246487    |
| qf1_loss                | 9.327242e-05  |
| qf2_loss                | 8.973523e-05  |
| time_elapsed            | 1418          |
| total timesteps         | 270025        |
| value_loss              | 4.2266543e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096470484 |
| ent_coef_loss           | 2.557595      |
| entropy                 | 1.1906598     |
| episodes                | 1016          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 270593        |
| policy_loss             | -0.5577242    |
| qf1_loss                | 1.7572758e-05 |
| qf2_loss                | 4.3101445e-05 |
| time_elapsed            | 1422          |
| total timesteps         | 270693        |
| value_loss              | 3.665753e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009826799  |
| ent_coef_loss           | -0.26935363   |
| entropy                 | 1.341881      |
| episodes                | 1020          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 271335        |
| policy_loss             | -0.51238936   |
| qf1_loss                | 2.5476727e-05 |
| qf2_loss                | 4.1947795e-05 |
| time_elapsed            | 1426          |
| total timesteps         | 271435        |
| value_loss              | 2.3320292e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010200563  |
| ent_coef_loss           | -0.11411083   |
| entropy                 | 1.1075233     |
| episodes                | 1024          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 272053        |
| policy_loss             | -0.5077083    |
| qf1_loss                | 5.3421958e-05 |
| qf2_loss                | 0.0001138892  |
| time_elapsed            | 1429          |
| total timesteps         | 272153        |
| value_loss              | 0.00020261596 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009874555  |
| ent_coef_loss           | 1.400069      |
| entropy                 | 1.0814883     |
| episodes                | 1028          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 272842        |
| policy_loss             | -0.5286801    |
| qf1_loss                | 4.5695648e-05 |
| qf2_loss                | 3.2908323e-05 |
| time_elapsed            | 1434          |
| total timesteps         | 272942        |
| value_loss              | 9.637467e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010076023 |
| ent_coef_loss           | 0.54189694   |
| entropy                 | 1.1144437    |
| episodes                | 1032         |
| fps                     | 190          |
| mean 100 episode reward | 0.8          |
| n_updates               | 273504       |
| policy_loss             | -0.55441475  |
| qf1_loss                | 4.51792e-05  |
| qf2_loss                | 3.344594e-05 |
| time_elapsed            | 1437         |
| total timesteps         | 273604       |
| value_loss              | 3.552207e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097502285 |
| ent_coef_loss           | -1.0193955    |
| entropy                 | 1.3125509     |
| episodes                | 1036          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 274213        |
| policy_loss             | -0.6057775    |
| qf1_loss                | 0.000260306   |
| qf2_loss                | 0.00022307543 |
| time_elapsed            | 1441          |
| total timesteps         | 274313        |
| value_loss              | 2.5912268e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096357754 |
| ent_coef_loss           | -2.7262757    |
| entropy                 | 1.1210465     |
| episodes                | 1040          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 274931        |
| policy_loss             | -0.5070343    |
| qf1_loss                | 7.224904e-05  |
| qf2_loss                | 8.069341e-05  |
| time_elapsed            | 1445          |
| total timesteps         | 275031        |
| value_loss              | 8.410429e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009797963  |
| ent_coef_loss           | 1.5055127     |
| entropy                 | 1.23401       |
| episodes                | 1044          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 275636        |
| policy_loss             | -0.5416542    |
| qf1_loss                | 3.8152983e-05 |
| qf2_loss                | 3.4287033e-05 |
| time_elapsed            | 1448          |
| total timesteps         | 275736        |
| value_loss              | 8.1435435e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010675774  |
| ent_coef_loss           | -1.9786766    |
| entropy                 | 1.2663817     |
| episodes                | 1048          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 276332        |
| policy_loss             | -0.6234141    |
| qf1_loss                | 7.926575e-05  |
| qf2_loss                | 7.7172685e-05 |
| time_elapsed            | 1452          |
| total timesteps         | 276432        |
| value_loss              | 1.8407567e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010167725  |
| ent_coef_loss           | 1.1954675     |
| entropy                 | 1.195281      |
| episodes                | 1052          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 276993        |
| policy_loss             | -0.5318587    |
| qf1_loss                | 6.9373404e-05 |
| qf2_loss                | 8.213566e-05  |
| time_elapsed            | 1455          |
| total timesteps         | 277093        |
| value_loss              | 0.00010881557 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010181213  |
| ent_coef_loss           | 0.8522797     |
| entropy                 | 1.0981212     |
| episodes                | 1056          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 277842        |
| policy_loss             | -0.5400401    |
| qf1_loss                | 3.1251777e-05 |
| qf2_loss                | 3.807703e-05  |
| time_elapsed            | 1460          |
| total timesteps         | 277942        |
| value_loss              | 5.2335025e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010044941  |
| ent_coef_loss           | 1.2936063     |
| entropy                 | 0.99025834    |
| episodes                | 1060          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 278509        |
| policy_loss             | -0.5242992    |
| qf1_loss                | 0.00011684047 |
| qf2_loss                | 7.8768004e-05 |
| time_elapsed            | 1463          |
| total timesteps         | 278609        |
| value_loss              | 0.00012387498 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010335889  |
| ent_coef_loss           | 0.14624509    |
| entropy                 | 1.2769749     |
| episodes                | 1064          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 279254        |
| policy_loss             | -0.56674916   |
| qf1_loss                | 4.3871183e-05 |
| qf2_loss                | 4.4105975e-05 |
| time_elapsed            | 1467          |
| total timesteps         | 279354        |
| value_loss              | 6.9903224e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010166819  |
| ent_coef_loss           | 4.9946136     |
| entropy                 | 0.9972943     |
| episodes                | 1068          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 279949        |
| policy_loss             | -0.53139997   |
| qf1_loss                | 5.6574398e-05 |
| qf2_loss                | 5.5907964e-05 |
| time_elapsed            | 1471          |
| total timesteps         | 280049        |
| value_loss              | 0.00010011786 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010241038  |
| ent_coef_loss           | -2.3692658    |
| entropy                 | 1.2327719     |
| episodes                | 1072          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 280675        |
| policy_loss             | -0.5852152    |
| qf1_loss                | 3.40344e-05   |
| qf2_loss                | 3.1158714e-05 |
| time_elapsed            | 1475          |
| total timesteps         | 280775        |
| value_loss              | 5.6426266e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009613416  |
| ent_coef_loss           | 2.629775      |
| entropy                 | 1.2338905     |
| episodes                | 1076          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 281431        |
| policy_loss             | -0.6105899    |
| qf1_loss                | 8.225285e-05  |
| qf2_loss                | 9.368523e-05  |
| time_elapsed            | 1479          |
| total timesteps         | 281531        |
| value_loss              | 3.8527854e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010330395  |
| ent_coef_loss           | -2.5623398    |
| entropy                 | 1.2911646     |
| episodes                | 1080          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 282101        |
| policy_loss             | -0.5333172    |
| qf1_loss                | 5.2242078e-05 |
| qf2_loss                | 3.697611e-05  |
| time_elapsed            | 1483          |
| total timesteps         | 282201        |
| value_loss              | 6.008385e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001032105   |
| ent_coef_loss           | 0.023880363   |
| entropy                 | 1.2474725     |
| episodes                | 1084          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 282921        |
| policy_loss             | -0.5746924    |
| qf1_loss                | 4.4220695e-05 |
| qf2_loss                | 4.0604788e-05 |
| time_elapsed            | 1487          |
| total timesteps         | 283021        |
| value_loss              | 0.00012056499 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001015737   |
| ent_coef_loss           | -2.4775734    |
| entropy                 | 1.194708      |
| episodes                | 1088          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 283646        |
| policy_loss             | -0.55050075   |
| qf1_loss                | 6.0625338e-05 |
| qf2_loss                | 4.6519337e-05 |
| time_elapsed            | 1491          |
| total timesteps         | 283746        |
| value_loss              | 8.705147e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011360531  |
| ent_coef_loss           | -2.6232867    |
| entropy                 | 1.293746      |
| episodes                | 1092          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 284475        |
| policy_loss             | -0.53738564   |
| qf1_loss                | 4.3042586e-05 |
| qf2_loss                | 4.9048667e-05 |
| time_elapsed            | 1495          |
| total timesteps         | 284575        |
| value_loss              | 8.1284416e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010615129  |
| ent_coef_loss           | 1.632164      |
| entropy                 | 1.1507589     |
| episodes                | 1096          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 285445        |
| policy_loss             | -0.52721465   |
| qf1_loss                | 4.1037973e-05 |
| qf2_loss                | 0.00011158535 |
| time_elapsed            | 1500          |
| total timesteps         | 285545        |
| value_loss              | 4.8106616e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010602073  |
| ent_coef_loss           | -0.038488448  |
| entropy                 | 1.2533734     |
| episodes                | 1100          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 286214        |
| policy_loss             | -0.5349437    |
| qf1_loss                | 1.9260264e-05 |
| qf2_loss                | 2.6173831e-05 |
| time_elapsed            | 1504          |
| total timesteps         | 286314        |
| value_loss              | 6.5426284e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010722204  |
| ent_coef_loss           | -2.4304514    |
| entropy                 | 1.2106792     |
| episodes                | 1104          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 287233        |
| policy_loss             | -0.58027834   |
| qf1_loss                | 7.1680006e-05 |
| qf2_loss                | 8.22671e-05   |
| time_elapsed            | 1509          |
| total timesteps         | 287333        |
| value_loss              | 7.1510935e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010833116 |
| ent_coef_loss           | 0.34522942   |
| entropy                 | 1.1767399    |
| episodes                | 1108         |
| fps                     | 190          |
| mean 100 episode reward | 0.7          |
| n_updates               | 287898       |
| policy_loss             | -0.55576575  |
| qf1_loss                | 6.405571e-05 |
| qf2_loss                | 5.72783e-05  |
| time_elapsed            | 1513         |
| total timesteps         | 287998       |
| value_loss              | 0.0001532285 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010618592 |
| ent_coef_loss           | 0.086201906  |
| entropy                 | 1.0973034    |
| episodes                | 1112         |
| fps                     | 190          |
| mean 100 episode reward | 0.7          |
| n_updates               | 288612       |
| policy_loss             | -0.56743914  |
| qf1_loss                | 5.543028e-05 |
| qf2_loss                | 9.826152e-05 |
| time_elapsed            | 1517         |
| total timesteps         | 288712       |
| value_loss              | 4.108491e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010166795  |
| ent_coef_loss           | -2.3111334    |
| entropy                 | 1.0299505     |
| episodes                | 1116          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 289363        |
| policy_loss             | -0.5844288    |
| qf1_loss                | 5.6838217e-05 |
| qf2_loss                | 4.874278e-05  |
| time_elapsed            | 1520          |
| total timesteps         | 289463        |
| value_loss              | 0.00013858282 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010930344  |
| ent_coef_loss           | 0.11299962    |
| entropy                 | 1.1168516     |
| episodes                | 1120          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 290056        |
| policy_loss             | -0.5310395    |
| qf1_loss                | 3.3311295e-05 |
| qf2_loss                | 4.2230968e-05 |
| time_elapsed            | 1524          |
| total timesteps         | 290156        |
| value_loss              | 2.5999965e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010127187  |
| ent_coef_loss           | -0.92306566   |
| entropy                 | 1.140177      |
| episodes                | 1124          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 290773        |
| policy_loss             | -0.5637413    |
| qf1_loss                | 5.0389666e-05 |
| qf2_loss                | 6.114622e-05  |
| time_elapsed            | 1528          |
| total timesteps         | 290873        |
| value_loss              | 4.8955335e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010327843  |
| ent_coef_loss           | 0.59336174    |
| entropy                 | 1.2674617     |
| episodes                | 1128          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 291805        |
| policy_loss             | -0.51018703   |
| qf1_loss                | 4.277633e-05  |
| qf2_loss                | 2.0378047e-05 |
| time_elapsed            | 1534          |
| total timesteps         | 291905        |
| value_loss              | 6.019878e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010937185  |
| ent_coef_loss           | -1.5132344    |
| entropy                 | 1.1419146     |
| episodes                | 1132          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 292505        |
| policy_loss             | -0.6032129    |
| qf1_loss                | 3.3747696e-05 |
| qf2_loss                | 3.4271958e-05 |
| time_elapsed            | 1537          |
| total timesteps         | 292605        |
| value_loss              | 7.301741e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011775385  |
| ent_coef_loss           | 2.2240958     |
| entropy                 | 1.4379716     |
| episodes                | 1136          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 293253        |
| policy_loss             | -0.5241771    |
| qf1_loss                | 8.462489e-05  |
| qf2_loss                | 7.699078e-05  |
| time_elapsed            | 1541          |
| total timesteps         | 293353        |
| value_loss              | 0.00041972907 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012431387  |
| ent_coef_loss           | 1.9875953     |
| entropy                 | 1.2575945     |
| episodes                | 1140          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 294174        |
| policy_loss             | -0.4887369    |
| qf1_loss                | 6.702485e-05  |
| qf2_loss                | 4.2591902e-05 |
| time_elapsed            | 1546          |
| total timesteps         | 294274        |
| value_loss              | 0.00010631885 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012297101  |
| ent_coef_loss           | 1.0880668     |
| entropy                 | 1.1386132     |
| episodes                | 1144          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 294876        |
| policy_loss             | -0.50613344   |
| qf1_loss                | 5.805996e-05  |
| qf2_loss                | 5.7925274e-05 |
| time_elapsed            | 1550          |
| total timesteps         | 294976        |
| value_loss              | 5.3833406e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012833147  |
| ent_coef_loss           | 3.521559      |
| entropy                 | 1.3956745     |
| episodes                | 1148          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 295551        |
| policy_loss             | -0.50319856   |
| qf1_loss                | 0.0008009634  |
| qf2_loss                | 0.00025818316 |
| time_elapsed            | 1553          |
| total timesteps         | 295651        |
| value_loss              | 0.00010136153 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001263106   |
| ent_coef_loss           | -2.5335352    |
| entropy                 | 1.3930746     |
| episodes                | 1152          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 296218        |
| policy_loss             | -0.5491934    |
| qf1_loss                | 4.270952e-05  |
| qf2_loss                | 4.3043397e-05 |
| time_elapsed            | 1557          |
| total timesteps         | 296318        |
| value_loss              | 3.8760732e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011937614  |
| ent_coef_loss           | -0.77944267   |
| entropy                 | 1.2089275     |
| episodes                | 1156          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 296883        |
| policy_loss             | -0.49905795   |
| qf1_loss                | 4.3933065e-05 |
| qf2_loss                | 5.8281446e-05 |
| time_elapsed            | 1560          |
| total timesteps         | 296983        |
| value_loss              | 9.7234464e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.001269627   |
| ent_coef_loss           | 1.3529665     |
| entropy                 | 1.1696771     |
| episodes                | 1160          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 297635        |
| policy_loss             | -0.49284744   |
| qf1_loss                | 4.8144393e-05 |
| qf2_loss                | 4.890047e-05  |
| time_elapsed            | 1564          |
| total timesteps         | 297735        |
| value_loss              | 6.842257e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0012645241  |
| ent_coef_loss           | 1.0539932     |
| entropy                 | 1.2276299     |
| episodes                | 1164          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 298368        |
| policy_loss             | -0.44968513   |
| qf1_loss                | 6.0048573e-05 |
| qf2_loss                | 6.064461e-05  |
| time_elapsed            | 1568          |
| total timesteps         | 298468        |
| value_loss              | 0.00012189874 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011398123  |
| ent_coef_loss           | -0.68070155   |
| entropy                 | 1.1180261     |
| episodes                | 1168          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 299065        |
| policy_loss             | -0.54643273   |
| qf1_loss                | 8.4274136e-05 |
| qf2_loss                | 8.254726e-05  |
| time_elapsed            | 1572          |
| total timesteps         | 299165        |
| value_loss              | 4.9417915e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011207551  |
| ent_coef_loss           | -0.09046149   |
| entropy                 | 1.080879      |
| episodes                | 1172          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 299798        |
| policy_loss             | -0.50432616   |
| qf1_loss                | 7.2401905e-05 |
| qf2_loss                | 6.3014224e-05 |
| time_elapsed            | 1575          |
| total timesteps         | 299898        |
| value_loss              | 6.6510314e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011687482  |
| ent_coef_loss           | -2.1215835    |
| entropy                 | 1.2398714     |
| episodes                | 1176          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 300532        |
| policy_loss             | -0.54819345   |
| qf1_loss                | 6.781249e-05  |
| qf2_loss                | 4.7189875e-05 |
| time_elapsed            | 1579          |
| total timesteps         | 300632        |
| value_loss              | 8.257928e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011491366  |
| ent_coef_loss           | -1.5052462    |
| entropy                 | 1.1655282     |
| episodes                | 1180          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 301207        |
| policy_loss             | -0.5132693    |
| qf1_loss                | 3.062126e-05  |
| qf2_loss                | 4.5243978e-05 |
| time_elapsed            | 1583          |
| total timesteps         | 301307        |
| value_loss              | 5.1880266e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011310673  |
| ent_coef_loss           | 2.5451782     |
| entropy                 | 1.1689515     |
| episodes                | 1184          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 301920        |
| policy_loss             | -0.48852876   |
| qf1_loss                | 9.387352e-05  |
| qf2_loss                | 5.7381527e-05 |
| time_elapsed            | 1587          |
| total timesteps         | 302020        |
| value_loss              | 5.7887315e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011482536  |
| ent_coef_loss           | -0.013173148  |
| entropy                 | 1.3540082     |
| episodes                | 1188          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 302597        |
| policy_loss             | -0.4971276    |
| qf1_loss                | 3.7136393e-05 |
| qf2_loss                | 3.8257996e-05 |
| time_elapsed            | 1590          |
| total timesteps         | 302697        |
| value_loss              | 2.9692594e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010909303  |
| ent_coef_loss           | -1.8506341    |
| entropy                 | 1.1444409     |
| episodes                | 1192          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 303300        |
| policy_loss             | -0.4960301    |
| qf1_loss                | 0.00036428988 |
| qf2_loss                | 0.0004776058  |
| time_elapsed            | 1594          |
| total timesteps         | 303400        |
| value_loss              | 0.00014078271 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010362419  |
| ent_coef_loss           | -0.6693555    |
| entropy                 | 1.3368211     |
| episodes                | 1196          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 304112        |
| policy_loss             | -0.50666517   |
| qf1_loss                | 0.00014390524 |
| qf2_loss                | 6.881358e-05  |
| time_elapsed            | 1598          |
| total timesteps         | 304212        |
| value_loss              | 3.9082162e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010833205  |
| ent_coef_loss           | -2.9009764    |
| entropy                 | 1.4293265     |
| episodes                | 1200          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 304781        |
| policy_loss             | -0.5346493    |
| qf1_loss                | 7.7257675e-05 |
| qf2_loss                | 2.7466667e-05 |
| time_elapsed            | 1602          |
| total timesteps         | 304881        |
| value_loss              | 7.526117e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010308768  |
| ent_coef_loss           | -1.820341     |
| entropy                 | 1.2540125     |
| episodes                | 1204          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 305520        |
| policy_loss             | -0.47343767   |
| qf1_loss                | 4.9256785e-05 |
| qf2_loss                | 3.262655e-05  |
| time_elapsed            | 1606          |
| total timesteps         | 305620        |
| value_loss              | 3.936491e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009990386  |
| ent_coef_loss           | -1.7694753    |
| entropy                 | 1.1277562     |
| episodes                | 1208          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 306293        |
| policy_loss             | -0.5162066    |
| qf1_loss                | 5.1288036e-05 |
| qf2_loss                | 5.0148148e-05 |
| time_elapsed            | 1610          |
| total timesteps         | 306393        |
| value_loss              | 0.00010370554 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094118714 |
| ent_coef_loss           | -3.796014     |
| entropy                 | 1.2612143     |
| episodes                | 1212          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 306987        |
| policy_loss             | -0.5596042    |
| qf1_loss                | 3.6093053e-05 |
| qf2_loss                | 4.385671e-05  |
| time_elapsed            | 1613          |
| total timesteps         | 307087        |
| value_loss              | 3.25688e-05   |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0008704077   |
| ent_coef_loss           | -0.9979287     |
| entropy                 | 1.2329534      |
| episodes                | 1216           |
| fps                     | 190            |
| mean 100 episode reward | 0.9            |
| n_updates               | 307666         |
| policy_loss             | -0.48026577    |
| qf1_loss                | 4.5856596e-05  |
| qf2_loss                | 3.2904118e-05  |
| time_elapsed            | 1617           |
| total timesteps         | 307766         |
| value_loss              | 0.000108977154 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085828727 |
| ent_coef_loss           | 1.2079564     |
| entropy                 | 1.2568412     |
| episodes                | 1220          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 308338        |
| policy_loss             | -0.47398186   |
| qf1_loss                | 2.5645699e-05 |
| qf2_loss                | 3.2024633e-05 |
| time_elapsed            | 1620          |
| total timesteps         | 308438        |
| value_loss              | 6.292846e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094259786 |
| ent_coef_loss           | -0.9377504    |
| entropy                 | 1.2827036     |
| episodes                | 1224          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 309489        |
| policy_loss             | -0.5304254    |
| qf1_loss                | 0.00020420592 |
| qf2_loss                | 0.00028561405 |
| time_elapsed            | 1627          |
| total timesteps         | 309589        |
| value_loss              | 9.275084e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0010059101   |
| ent_coef_loss           | -4.266427      |
| entropy                 | 1.2936296      |
| episodes                | 1228           |
| fps                     | 190            |
| mean 100 episode reward | 0.8            |
| n_updates               | 310216         |
| policy_loss             | -0.5264803     |
| qf1_loss                | 0.00011185648  |
| qf2_loss                | 7.168697e-05   |
| time_elapsed            | 1630           |
| total timesteps         | 310316         |
| value_loss              | 0.000103891405 |
--------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.00094033126  |
| ent_coef_loss           | -4.045482      |
| entropy                 | 1.0278478      |
| episodes                | 1232           |
| fps                     | 190            |
| mean 100 episode reward | 0.8            |
| n_updates               | 310938         |
| policy_loss             | -0.5247294     |
| qf1_loss                | 0.000102131744 |
| qf2_loss                | 6.694665e-05   |
| time_elapsed            | 1634           |
| total timesteps         | 311038         |
| value_loss              | 3.1263593e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00094768737 |
| ent_coef_loss           | -1.6029569    |
| entropy                 | 1.2627609     |
| episodes                | 1236          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 311599        |
| policy_loss             | -0.5159459    |
| qf1_loss                | 3.914058e-05  |
| qf2_loss                | 3.9293744e-05 |
| time_elapsed            | 1638          |
| total timesteps         | 311699        |
| value_loss              | 4.2147574e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009904056  |
| ent_coef_loss           | 2.5602803     |
| entropy                 | 1.3000827     |
| episodes                | 1240          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 312623        |
| policy_loss             | -0.49684995   |
| qf1_loss                | 0.00020264831 |
| qf2_loss                | 7.6858254e-05 |
| time_elapsed            | 1643          |
| total timesteps         | 312723        |
| value_loss              | 5.9960435e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009857181  |
| ent_coef_loss           | -1.4566758    |
| entropy                 | 1.0785996     |
| episodes                | 1244          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 313369        |
| policy_loss             | -0.4836777    |
| qf1_loss                | 7.3741685e-05 |
| qf2_loss                | 4.9100156e-05 |
| time_elapsed            | 1647          |
| total timesteps         | 313469        |
| value_loss              | 5.135103e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000887313   |
| ent_coef_loss           | 0.6188499     |
| entropy                 | 1.3746774     |
| episodes                | 1248          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 314271        |
| policy_loss             | -0.54885244   |
| qf1_loss                | 0.00015475006 |
| qf2_loss                | 0.00017366334 |
| time_elapsed            | 1652          |
| total timesteps         | 314371        |
| value_loss              | 4.0779523e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0009526    |
| ent_coef_loss           | 1.4256397    |
| entropy                 | 1.0914147    |
| episodes                | 1252         |
| fps                     | 190          |
| mean 100 episode reward | 0.8          |
| n_updates               | 314985       |
| policy_loss             | -0.4945602   |
| qf1_loss                | 0.005218697  |
| qf2_loss                | 0.004763532  |
| time_elapsed            | 1656         |
| total timesteps         | 315085       |
| value_loss              | 0.0001320776 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010148645  |
| ent_coef_loss           | -0.24565583   |
| entropy                 | 1.3130653     |
| episodes                | 1256          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 315777        |
| policy_loss             | -0.47902417   |
| qf1_loss                | 0.00014504042 |
| qf2_loss                | 0.00014000126 |
| time_elapsed            | 1660          |
| total timesteps         | 315877        |
| value_loss              | 6.975778e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009641677   |
| ent_coef_loss           | 2.21004        |
| entropy                 | 1.1777432      |
| episodes                | 1260           |
| fps                     | 190            |
| mean 100 episode reward | 0.8            |
| n_updates               | 316546         |
| policy_loss             | -0.511428      |
| qf1_loss                | 0.000116439776 |
| qf2_loss                | 0.00010095291  |
| time_elapsed            | 1664           |
| total timesteps         | 316646         |
| value_loss              | 9.970022e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009457819  |
| ent_coef_loss           | -1.5224968    |
| entropy                 | 1.1511443     |
| episodes                | 1264          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 317283        |
| policy_loss             | -0.55339223   |
| qf1_loss                | 5.7719873e-05 |
| qf2_loss                | 4.9754377e-05 |
| time_elapsed            | 1668          |
| total timesteps         | 317383        |
| value_loss              | 8.606601e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00096545357 |
| ent_coef_loss           | -0.5630336    |
| entropy                 | 1.1204325     |
| episodes                | 1268          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 317985        |
| policy_loss             | -0.5608532    |
| qf1_loss                | 5.860797e-05  |
| qf2_loss                | 6.6539935e-05 |
| time_elapsed            | 1671          |
| total timesteps         | 318085        |
| value_loss              | 0.00012221705 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008386614  |
| ent_coef_loss           | -0.71665204   |
| entropy                 | 0.95322967    |
| episodes                | 1272          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 318816        |
| policy_loss             | -0.49569613   |
| qf1_loss                | 2.2217862e-05 |
| qf2_loss                | 3.7743303e-05 |
| time_elapsed            | 1676          |
| total timesteps         | 318916        |
| value_loss              | 5.5603352e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00085576624 |
| ent_coef_loss           | 3.5938075     |
| entropy                 | 1.0787947     |
| episodes                | 1276          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 319476        |
| policy_loss             | -0.5403638    |
| qf1_loss                | 3.931879e-05  |
| qf2_loss                | 4.7420937e-05 |
| time_elapsed            | 1679          |
| total timesteps         | 319576        |
| value_loss              | 3.176641e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008553448  |
| ent_coef_loss           | -1.9060009    |
| entropy                 | 1.0673838     |
| episodes                | 1280          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 320168        |
| policy_loss             | -0.5412803    |
| qf1_loss                | 0.00015850221 |
| qf2_loss                | 0.00012526159 |
| time_elapsed            | 1683          |
| total timesteps         | 320268        |
| value_loss              | 0.00020677992 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009209831  |
| ent_coef_loss           | 0.65947175    |
| entropy                 | 1.1519506     |
| episodes                | 1284          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 321119        |
| policy_loss             | -0.5389547    |
| qf1_loss                | 0.00021322556 |
| qf2_loss                | 0.0002745074  |
| time_elapsed            | 1688          |
| total timesteps         | 321219        |
| value_loss              | 3.244071e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00091835187 |
| ent_coef_loss           | -0.46901757   |
| entropy                 | 0.9335531     |
| episodes                | 1288          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 321881        |
| policy_loss             | -0.5379441    |
| qf1_loss                | 4.485667e-05  |
| qf2_loss                | 8.5595675e-05 |
| time_elapsed            | 1692          |
| total timesteps         | 321981        |
| value_loss              | 7.08888e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00097013847 |
| ent_coef_loss           | -1.3114188    |
| entropy                 | 1.1243765     |
| episodes                | 1292          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 322842        |
| policy_loss             | -0.48927584   |
| qf1_loss                | 7.433194e-05  |
| qf2_loss                | 8.622209e-05  |
| time_elapsed            | 1697          |
| total timesteps         | 322942        |
| value_loss              | 0.0006394439  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009822091  |
| ent_coef_loss           | 0.61601436    |
| entropy                 | 1.1301049     |
| episodes                | 1296          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 323785        |
| policy_loss             | -0.5432869    |
| qf1_loss                | 5.2525575e-05 |
| qf2_loss                | 4.0079645e-05 |
| time_elapsed            | 1702          |
| total timesteps         | 323885        |
| value_loss              | 4.7249712e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010841452  |
| ent_coef_loss           | 2.9232497     |
| entropy                 | 1.1695778     |
| episodes                | 1300          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 324522        |
| policy_loss             | -0.55566055   |
| qf1_loss                | 0.00017419756 |
| qf2_loss                | 0.00019159302 |
| time_elapsed            | 1705          |
| total timesteps         | 324622        |
| value_loss              | 4.7900867e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010992229  |
| ent_coef_loss           | -1.459492     |
| entropy                 | 1.4525565     |
| episodes                | 1304          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 325482        |
| policy_loss             | -0.53780353   |
| qf1_loss                | 3.05762e-05   |
| qf2_loss                | 3.8300197e-05 |
| time_elapsed            | 1710          |
| total timesteps         | 325582        |
| value_loss              | 5.541083e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011756154  |
| ent_coef_loss           | -1.7489371    |
| entropy                 | 1.3006833     |
| episodes                | 1308          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 326146        |
| policy_loss             | -0.5005405    |
| qf1_loss                | 6.6513996e-05 |
| qf2_loss                | 5.7198253e-05 |
| time_elapsed            | 1714          |
| total timesteps         | 326246        |
| value_loss              | 6.3187035e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011372291  |
| ent_coef_loss           | 1.947511      |
| entropy                 | 1.2820932     |
| episodes                | 1312          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 326845        |
| policy_loss             | -0.5291869    |
| qf1_loss                | 9.0668975e-05 |
| qf2_loss                | 4.6389458e-05 |
| time_elapsed            | 1718          |
| total timesteps         | 326945        |
| value_loss              | 9.659442e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011956008  |
| ent_coef_loss           | -1.4338077    |
| entropy                 | 1.2642974     |
| episodes                | 1316          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 327545        |
| policy_loss             | -0.5083269    |
| qf1_loss                | 4.1253028e-05 |
| qf2_loss                | 6.064935e-05  |
| time_elapsed            | 1721          |
| total timesteps         | 327645        |
| value_loss              | 4.703787e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010553596  |
| ent_coef_loss           | -1.1484666    |
| entropy                 | 1.2427776     |
| episodes                | 1320          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 328338        |
| policy_loss             | -0.5230354    |
| qf1_loss                | 8.2269034e-05 |
| qf2_loss                | 9.9251665e-05 |
| time_elapsed            | 1726          |
| total timesteps         | 328438        |
| value_loss              | 4.0185e-05    |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010266703  |
| ent_coef_loss           | 2.2679513     |
| entropy                 | 1.3195293     |
| episodes                | 1324          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 329029        |
| policy_loss             | -0.5368547    |
| qf1_loss                | 2.8303883e-05 |
| qf2_loss                | 2.2953995e-05 |
| time_elapsed            | 1729          |
| total timesteps         | 329129        |
| value_loss              | 3.7250626e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0011012827  |
| ent_coef_loss           | -0.35164544   |
| entropy                 | 1.2654572     |
| episodes                | 1328          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 329710        |
| policy_loss             | -0.47869104   |
| qf1_loss                | 3.5583947e-05 |
| qf2_loss                | 4.825331e-05  |
| time_elapsed            | 1733          |
| total timesteps         | 329810        |
| value_loss              | 3.3376222e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010965838  |
| ent_coef_loss           | -0.5306747    |
| entropy                 | 1.3393185     |
| episodes                | 1332          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 330438        |
| policy_loss             | -0.52965647   |
| qf1_loss                | 2.5256677e-05 |
| qf2_loss                | 2.3226274e-05 |
| time_elapsed            | 1736          |
| total timesteps         | 330538        |
| value_loss              | 5.3989494e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010488718  |
| ent_coef_loss           | -2.2978828    |
| entropy                 | 1.2917607     |
| episodes                | 1336          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 331141        |
| policy_loss             | -0.45468026   |
| qf1_loss                | 5.8376565e-05 |
| qf2_loss                | 3.2857042e-05 |
| time_elapsed            | 1740          |
| total timesteps         | 331241        |
| value_loss              | 6.205711e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010957934  |
| ent_coef_loss           | -1.3674436    |
| entropy                 | 1.3207617     |
| episodes                | 1340          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 331856        |
| policy_loss             | -0.51326954   |
| qf1_loss                | 6.0496794e-05 |
| qf2_loss                | 3.8036094e-05 |
| time_elapsed            | 1744          |
| total timesteps         | 331956        |
| value_loss              | 4.1237225e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010339161 |
| ent_coef_loss           | -0.63507414  |
| entropy                 | 1.2619835    |
| episodes                | 1344         |
| fps                     | 190          |
| mean 100 episode reward | 0.9          |
| n_updates               | 332569       |
| policy_loss             | -0.49204814  |
| qf1_loss                | 4.050589e-05 |
| qf2_loss                | 3.322091e-05 |
| time_elapsed            | 1748         |
| total timesteps         | 332669       |
| value_loss              | 4.289125e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009821693  |
| ent_coef_loss           | 0.043652773   |
| entropy                 | 1.1391983     |
| episodes                | 1348          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 333330        |
| policy_loss             | -0.5415851    |
| qf1_loss                | 0.00012220655 |
| qf2_loss                | 0.00017953276 |
| time_elapsed            | 1752          |
| total timesteps         | 333430        |
| value_loss              | 3.227278e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000855415   |
| ent_coef_loss           | -0.33112568   |
| entropy                 | 1.0390272     |
| episodes                | 1352          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 333982        |
| policy_loss             | -0.5264099    |
| qf1_loss                | 2.4821522e-05 |
| qf2_loss                | 2.21749e-05   |
| time_elapsed            | 1755          |
| total timesteps         | 334082        |
| value_loss              | 2.0790025e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086208957 |
| ent_coef_loss           | -1.6851923    |
| entropy                 | 1.1658893     |
| episodes                | 1356          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 334732        |
| policy_loss             | -0.5065212    |
| qf1_loss                | 2.89189e-05   |
| qf2_loss                | 2.1852262e-05 |
| time_elapsed            | 1759          |
| total timesteps         | 334832        |
| value_loss              | 2.464628e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00086312817 |
| ent_coef_loss           | 2.2535338     |
| entropy                 | 1.2928462     |
| episodes                | 1360          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 335468        |
| policy_loss             | -0.49370822   |
| qf1_loss                | 6.8155125e-05 |
| qf2_loss                | 2.4991914e-05 |
| time_elapsed            | 1763          |
| total timesteps         | 335568        |
| value_loss              | 5.86042e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089065376 |
| ent_coef_loss           | 0.7284268     |
| entropy                 | 1.1578615     |
| episodes                | 1364          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 336312        |
| policy_loss             | -0.51496613   |
| qf1_loss                | 9.891264e-05  |
| qf2_loss                | 3.4578516e-05 |
| time_elapsed            | 1767          |
| total timesteps         | 336412        |
| value_loss              | 3.987174e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089027756 |
| ent_coef_loss           | -0.6449781    |
| entropy                 | 1.0879397     |
| episodes                | 1368          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 336976        |
| policy_loss             | -0.5096811    |
| qf1_loss                | 0.00013292403 |
| qf2_loss                | 4.5044013e-05 |
| time_elapsed            | 1770          |
| total timesteps         | 337076        |
| value_loss              | 5.373241e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00088877435 |
| ent_coef_loss           | 2.3472207     |
| entropy                 | 1.0735017     |
| episodes                | 1372          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 337789        |
| policy_loss             | -0.4941377    |
| qf1_loss                | 9.663067e-05  |
| qf2_loss                | 5.1558804e-05 |
| time_elapsed            | 1775          |
| total timesteps         | 337889        |
| value_loss              | 0.0002213139  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0008995061 |
| ent_coef_loss           | -1.3166168   |
| entropy                 | 1.2760595    |
| episodes                | 1376         |
| fps                     | 190          |
| mean 100 episode reward | 0.9          |
| n_updates               | 338698       |
| policy_loss             | -0.49366343  |
| qf1_loss                | 0.0001080512 |
| qf2_loss                | 9.657853e-05 |
| time_elapsed            | 1780         |
| total timesteps         | 338798       |
| value_loss              | 6.864389e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008406753  |
| ent_coef_loss           | 6.1025333     |
| entropy                 | 1.2445521     |
| episodes                | 1380          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 339374        |
| policy_loss             | -0.46821335   |
| qf1_loss                | 2.8423558e-05 |
| qf2_loss                | 5.0379273e-05 |
| time_elapsed            | 1783          |
| total timesteps         | 339474        |
| value_loss              | 3.7364556e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00088551495 |
| ent_coef_loss           | 2.719403      |
| entropy                 | 1.0981302     |
| episodes                | 1384          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 340353        |
| policy_loss             | -0.45919177   |
| qf1_loss                | 2.3014898e-05 |
| qf2_loss                | 3.5028417e-05 |
| time_elapsed            | 1788          |
| total timesteps         | 340453        |
| value_loss              | 4.8988735e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009934648   |
| ent_coef_loss           | 1.6735325      |
| entropy                 | 1.2807777      |
| episodes                | 1388           |
| fps                     | 190            |
| mean 100 episode reward | 0.9            |
| n_updates               | 341094         |
| policy_loss             | -0.54369116    |
| qf1_loss                | 0.00011471601  |
| qf2_loss                | 0.000104070445 |
| time_elapsed            | 1792           |
| total timesteps         | 341194         |
| value_loss              | 4.3684508e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010084622  |
| ent_coef_loss           | -2.290419     |
| entropy                 | 1.1600064     |
| episodes                | 1392          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 341801        |
| policy_loss             | -0.57613075   |
| qf1_loss                | 2.0583486e-05 |
| qf2_loss                | 1.9898805e-05 |
| time_elapsed            | 1796          |
| total timesteps         | 341901        |
| value_loss              | 3.4942605e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010449421 |
| ent_coef_loss           | 1.552889     |
| entropy                 | 1.1819577    |
| episodes                | 1396         |
| fps                     | 190          |
| mean 100 episode reward | 0.9          |
| n_updates               | 342562       |
| policy_loss             | -0.50166357  |
| qf1_loss                | 3.600165e-05 |
| qf2_loss                | 3.176674e-05 |
| time_elapsed            | 1800         |
| total timesteps         | 342662       |
| value_loss              | 3.078304e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010529956  |
| ent_coef_loss           | 0.22542775    |
| entropy                 | 1.4209424     |
| episodes                | 1400          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 343273        |
| policy_loss             | -0.59793794   |
| qf1_loss                | 2.7104867e-05 |
| qf2_loss                | 1.4193838e-05 |
| time_elapsed            | 1804          |
| total timesteps         | 343373        |
| value_loss              | 1.8256445e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009457237  |
| ent_coef_loss           | 0.11508143    |
| entropy                 | 1.108321      |
| episodes                | 1404          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 343955        |
| policy_loss             | -0.5106494    |
| qf1_loss                | 4.800709e-05  |
| qf2_loss                | 3.8027018e-05 |
| time_elapsed            | 1807          |
| total timesteps         | 344055        |
| value_loss              | 3.0615414e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010610361  |
| ent_coef_loss           | 2.3859353     |
| entropy                 | 1.4503639     |
| episodes                | 1408          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 344623        |
| policy_loss             | -0.582366     |
| qf1_loss                | 7.373898e-05  |
| qf2_loss                | 4.4472858e-05 |
| time_elapsed            | 1811          |
| total timesteps         | 344723        |
| value_loss              | 8.345486e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010629038  |
| ent_coef_loss           | -3.6943321    |
| entropy                 | 1.2977637     |
| episodes                | 1412          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 345341        |
| policy_loss             | -0.4829059    |
| qf1_loss                | 2.9909872e-05 |
| qf2_loss                | 3.5335506e-05 |
| time_elapsed            | 1815          |
| total timesteps         | 345441        |
| value_loss              | 5.288763e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0010042939 |
| ent_coef_loss           | 1.7715787    |
| entropy                 | 1.4104534    |
| episodes                | 1416         |
| fps                     | 190          |
| mean 100 episode reward | 0.9          |
| n_updates               | 346119       |
| policy_loss             | -0.5527626   |
| qf1_loss                | 4.430615e-05 |
| qf2_loss                | 3.618015e-05 |
| time_elapsed            | 1819         |
| total timesteps         | 346219       |
| value_loss              | 4.158156e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009293304  |
| ent_coef_loss           | 0.30219382    |
| entropy                 | 1.2542143     |
| episodes                | 1420          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 346785        |
| policy_loss             | -0.48049444   |
| qf1_loss                | 2.98548e-05   |
| qf2_loss                | 2.046158e-05  |
| time_elapsed            | 1822          |
| total timesteps         | 346885        |
| value_loss              | 2.6813852e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0010133032  |
| ent_coef_loss           | -1.3195947    |
| entropy                 | 1.2793167     |
| episodes                | 1424          |
| fps                     | 190           |
| mean 100 episode reward | 0.9           |
| n_updates               | 347694        |
| policy_loss             | -0.52255726   |
| qf1_loss                | 0.00010117146 |
| qf2_loss                | 8.797759e-05  |
| time_elapsed            | 1827          |
| total timesteps         | 347794        |
| value_loss              | 5.2316336e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008814954  |
| ent_coef_loss           | -0.16282868   |
| entropy                 | 1.1426893     |
| episodes                | 1428          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 348657        |
| policy_loss             | -0.50373703   |
| qf1_loss                | 8.356213e-05  |
| qf2_loss                | 7.973574e-05  |
| time_elapsed            | 1832          |
| total timesteps         | 348757        |
| value_loss              | 2.0677508e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008328947  |
| ent_coef_loss           | -2.372272     |
| entropy                 | 1.274277      |
| episodes                | 1432          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 349327        |
| policy_loss             | -0.5876614    |
| qf1_loss                | 8.697284e-05  |
| qf2_loss                | 0.00010067864 |
| time_elapsed            | 1836          |
| total timesteps         | 349427        |
| value_loss              | 0.00022232938 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007611513  |
| ent_coef_loss           | -0.96503246   |
| entropy                 | 0.9697629     |
| episodes                | 1436          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 350064        |
| policy_loss             | -0.5297563    |
| qf1_loss                | 4.5865672e-05 |
| qf2_loss                | 2.7236187e-05 |
| time_elapsed            | 1839          |
| total timesteps         | 350164        |
| value_loss              | 3.380428e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0005       |
| ent_coef                | 0.0007785772 |
| ent_coef_loss           | 0.9468652    |
| entropy                 | 1.1520748    |
| episodes                | 1440         |
| fps                     | 190          |
| mean 100 episode reward | 0.8          |
| n_updates               | 351028       |
| policy_loss             | -0.54258853  |
| qf1_loss                | 9.132667e-05 |
| qf2_loss                | 3.26834e-05  |
| time_elapsed            | 1844         |
| total timesteps         | 351128       |
| value_loss              | 0.0001179642 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008140047  |
| ent_coef_loss           | 0.14170581    |
| entropy                 | 1.1340252     |
| episodes                | 1444          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 351867        |
| policy_loss             | -0.5005038    |
| qf1_loss                | 7.8372206e-05 |
| qf2_loss                | 6.2497966e-05 |
| time_elapsed            | 1849          |
| total timesteps         | 351967        |
| value_loss              | 7.9906036e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00065363554 |
| ent_coef_loss           | -2.4224498    |
| entropy                 | 0.94807005    |
| episodes                | 1448          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 352646        |
| policy_loss             | -0.54037935   |
| qf1_loss                | 3.594017e-05  |
| qf2_loss                | 1.5691043e-05 |
| time_elapsed            | 1853          |
| total timesteps         | 352746        |
| value_loss              | 9.852949e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00078582345 |
| ent_coef_loss           | -0.9701632    |
| entropy                 | 0.95313925    |
| episodes                | 1452          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 353398        |
| policy_loss             | -0.58149016   |
| qf1_loss                | 4.011445e-05  |
| qf2_loss                | 2.9383784e-05 |
| time_elapsed            | 1857          |
| total timesteps         | 353498        |
| value_loss              | 7.589519e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00081907486 |
| ent_coef_loss           | 2.404984      |
| entropy                 | 0.9962471     |
| episodes                | 1456          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 354119        |
| policy_loss             | -0.5105791    |
| qf1_loss                | 5.7904843e-05 |
| qf2_loss                | 6.239144e-05  |
| time_elapsed            | 1860          |
| total timesteps         | 354219        |
| value_loss              | 0.00012850613 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007925553  |
| ent_coef_loss           | 3.8189814     |
| entropy                 | 1.0549262     |
| episodes                | 1460          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 354760        |
| policy_loss             | -0.53545785   |
| qf1_loss                | 0.00063553115 |
| qf2_loss                | 0.0006928628  |
| time_elapsed            | 1864          |
| total timesteps         | 354860        |
| value_loss              | 5.7046927e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00067730004 |
| ent_coef_loss           | 2.1934013     |
| entropy                 | 0.94720995    |
| episodes                | 1464          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 355475        |
| policy_loss             | -0.549392     |
| qf1_loss                | 4.500606e-05  |
| qf2_loss                | 3.0562303e-05 |
| time_elapsed            | 1868          |
| total timesteps         | 355575        |
| value_loss              | 3.761044e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00066818815 |
| ent_coef_loss           | -0.63724285   |
| entropy                 | 0.9770143     |
| episodes                | 1468          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 356130        |
| policy_loss             | -0.54072833   |
| qf1_loss                | 3.5130695e-05 |
| qf2_loss                | 2.9358627e-05 |
| time_elapsed            | 1871          |
| total timesteps         | 356230        |
| value_loss              | 4.90659e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00075067114 |
| ent_coef_loss           | 0.87823343    |
| entropy                 | 1.251221      |
| episodes                | 1472          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 357111        |
| policy_loss             | -0.5641558    |
| qf1_loss                | 6.734007e-05  |
| qf2_loss                | 5.9924238e-05 |
| time_elapsed            | 1876          |
| total timesteps         | 357211        |
| value_loss              | 2.181948e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.000699888   |
| ent_coef_loss           | 0.23946592    |
| entropy                 | 0.82162285    |
| episodes                | 1476          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 357833        |
| policy_loss             | -0.5035836    |
| qf1_loss                | 0.00021726455 |
| qf2_loss                | 5.9322374e-05 |
| time_elapsed            | 1880          |
| total timesteps         | 357933        |
| value_loss              | 0.00019509942 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006531411  |
| ent_coef_loss           | 3.2301228     |
| entropy                 | 1.0917338     |
| episodes                | 1480          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 358553        |
| policy_loss             | -0.5567211    |
| qf1_loss                | 2.1692733e-05 |
| qf2_loss                | 5.2733878e-05 |
| time_elapsed            | 1884          |
| total timesteps         | 358653        |
| value_loss              | 3.98887e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00072917936 |
| ent_coef_loss           | 3.2159686     |
| entropy                 | 1.2844133     |
| episodes                | 1484          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 359368        |
| policy_loss             | -0.6230406    |
| qf1_loss                | 5.7882127e-05 |
| qf2_loss                | 5.4600587e-05 |
| time_elapsed            | 1888          |
| total timesteps         | 359468        |
| value_loss              | 5.5456323e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008327696  |
| ent_coef_loss           | -0.3958978    |
| entropy                 | 1.2423687     |
| episodes                | 1488          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 360198        |
| policy_loss             | -0.5498533    |
| qf1_loss                | 0.00010940138 |
| qf2_loss                | 5.3731837e-05 |
| time_elapsed            | 1892          |
| total timesteps         | 360298        |
| value_loss              | 4.3056996e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006990505  |
| ent_coef_loss           | 2.8569465     |
| entropy                 | 1.1265533     |
| episodes                | 1492          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 360946        |
| policy_loss             | -0.56647885   |
| qf1_loss                | 1.5585614e-05 |
| qf2_loss                | 2.2391432e-05 |
| time_elapsed            | 1896          |
| total timesteps         | 361046        |
| value_loss              | 0.00013688116 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007364359  |
| ent_coef_loss           | 1.4355445     |
| entropy                 | 1.2878628     |
| episodes                | 1496          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 361693        |
| policy_loss             | -0.6229214    |
| qf1_loss                | 0.00014221904 |
| qf2_loss                | 0.00016274267 |
| time_elapsed            | 1900          |
| total timesteps         | 361793        |
| value_loss              | 9.072446e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00071121    |
| ent_coef_loss           | -2.0209024    |
| entropy                 | 1.062308      |
| episodes                | 1500          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 362363        |
| policy_loss             | -0.54356843   |
| qf1_loss                | 8.985311e-05  |
| qf2_loss                | 0.00011482234 |
| time_elapsed            | 1904          |
| total timesteps         | 362463        |
| value_loss              | 7.394218e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007198499  |
| ent_coef_loss           | -2.0384939    |
| entropy                 | 1.1936677     |
| episodes                | 1504          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 363054        |
| policy_loss             | -0.5703719    |
| qf1_loss                | 2.2667022e-05 |
| qf2_loss                | 2.0407853e-05 |
| time_elapsed            | 1907          |
| total timesteps         | 363154        |
| value_loss              | 3.5127636e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006987102  |
| ent_coef_loss           | 1.4763274     |
| entropy                 | 1.2248484     |
| episodes                | 1508          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 363755        |
| policy_loss             | -0.5806436    |
| qf1_loss                | 0.00045435294 |
| qf2_loss                | 0.00021591655 |
| time_elapsed            | 1911          |
| total timesteps         | 363855        |
| value_loss              | 4.5104745e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007139422  |
| ent_coef_loss           | -2.4264224    |
| entropy                 | 1.081507      |
| episodes                | 1512          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 364399        |
| policy_loss             | -0.57546633   |
| qf1_loss                | 3.4934998e-05 |
| qf2_loss                | 2.1919997e-05 |
| time_elapsed            | 1914          |
| total timesteps         | 364499        |
| value_loss              | 3.008953e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00069913385 |
| ent_coef_loss           | 0.69240093    |
| entropy                 | 1.1132596     |
| episodes                | 1516          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 365138        |
| policy_loss             | -0.57018805   |
| qf1_loss                | 8.3948966e-05 |
| qf2_loss                | 7.8813486e-05 |
| time_elapsed            | 1918          |
| total timesteps         | 365238        |
| value_loss              | 3.3257602e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00071657693 |
| ent_coef_loss           | -2.1975784    |
| entropy                 | 1.005053      |
| episodes                | 1520          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 365888        |
| policy_loss             | -0.57196933   |
| qf1_loss                | 2.245876e-05  |
| qf2_loss                | 1.8691864e-05 |
| time_elapsed            | 1922          |
| total timesteps         | 365988        |
| value_loss              | 7.1840695e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00072692765 |
| ent_coef_loss           | 0.2821558     |
| entropy                 | 1.0496634     |
| episodes                | 1524          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 366779        |
| policy_loss             | -0.597648     |
| qf1_loss                | 3.983479e-05  |
| qf2_loss                | 2.0855205e-05 |
| time_elapsed            | 1927          |
| total timesteps         | 366879        |
| value_loss              | 2.101058e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0007899591   |
| ent_coef_loss           | 0.8518697      |
| entropy                 | 1.0828764      |
| episodes                | 1528           |
| fps                     | 190            |
| mean 100 episode reward | 0.8            |
| n_updates               | 367553         |
| policy_loss             | -0.57166994    |
| qf1_loss                | 0.000115963434 |
| qf2_loss                | 1.8942445e-05  |
| time_elapsed            | 1931           |
| total timesteps         | 367653         |
| value_loss              | 7.16168e-05    |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00076360296 |
| ent_coef_loss           | -1.2965376    |
| entropy                 | 1.13191       |
| episodes                | 1532          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 368230        |
| policy_loss             | -0.55311865   |
| qf1_loss                | 3.721106e-05  |
| qf2_loss                | 2.592156e-05  |
| time_elapsed            | 1934          |
| total timesteps         | 368330        |
| value_loss              | 6.0013306e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007632961  |
| ent_coef_loss           | -0.6192764    |
| entropy                 | 1.0273198     |
| episodes                | 1536          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 368953        |
| policy_loss             | -0.5446232    |
| qf1_loss                | 8.352822e-05  |
| qf2_loss                | 3.536421e-05  |
| time_elapsed            | 1938          |
| total timesteps         | 369053        |
| value_loss              | 0.00023675617 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00078485877 |
| ent_coef_loss           | 2.6658394     |
| entropy                 | 1.0772786     |
| episodes                | 1540          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 369662        |
| policy_loss             | -0.5741546    |
| qf1_loss                | 5.2069532e-05 |
| qf2_loss                | 7.022571e-05  |
| time_elapsed            | 1942          |
| total timesteps         | 369762        |
| value_loss              | 3.9580016e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0006943172  |
| ent_coef_loss           | 1.550317      |
| entropy                 | 1.1191146     |
| episodes                | 1544          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 370374        |
| policy_loss             | -0.6066936    |
| qf1_loss                | 2.666935e-05  |
| qf2_loss                | 2.651077e-05  |
| time_elapsed            | 1945          |
| total timesteps         | 370474        |
| value_loss              | 1.4984887e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00072276895 |
| ent_coef_loss           | 1.0794314     |
| entropy                 | 1.0284338     |
| episodes                | 1548          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 371132        |
| policy_loss             | -0.5802269    |
| qf1_loss                | 1.3495808e-05 |
| qf2_loss                | 3.3849785e-05 |
| time_elapsed            | 1949          |
| total timesteps         | 371232        |
| value_loss              | 2.2653978e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00070421613 |
| ent_coef_loss           | -1.2152874    |
| entropy                 | 0.8700896     |
| episodes                | 1552          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 371820        |
| policy_loss             | -0.57534206   |
| qf1_loss                | 7.955845e-05  |
| qf2_loss                | 5.5225162e-05 |
| time_elapsed            | 1953          |
| total timesteps         | 371920        |
| value_loss              | 3.4352393e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008032624  |
| ent_coef_loss           | -0.46316797   |
| entropy                 | 1.0650482     |
| episodes                | 1556          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 372800        |
| policy_loss             | -0.586398     |
| qf1_loss                | 6.2996085e-05 |
| qf2_loss                | 4.4496854e-05 |
| time_elapsed            | 1958          |
| total timesteps         | 372900        |
| value_loss              | 5.2127027e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007841241  |
| ent_coef_loss           | 0.50558746    |
| entropy                 | 1.1739233     |
| episodes                | 1560          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 373438        |
| policy_loss             | -0.5876367    |
| qf1_loss                | 4.6828372e-05 |
| qf2_loss                | 5.2255953e-05 |
| time_elapsed            | 1962          |
| total timesteps         | 373538        |
| value_loss              | 4.150761e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007661524  |
| ent_coef_loss           | -0.40042663   |
| entropy                 | 0.9194267     |
| episodes                | 1564          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 374194        |
| policy_loss             | -0.5833867    |
| qf1_loss                | 3.9498038e-05 |
| qf2_loss                | 5.217298e-05  |
| time_elapsed            | 1965          |
| total timesteps         | 374294        |
| value_loss              | 3.7413352e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00068554335 |
| ent_coef_loss           | -0.8286408    |
| entropy                 | 0.97884715    |
| episodes                | 1568          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 374895        |
| policy_loss             | -0.58237505   |
| qf1_loss                | 3.576643e-05  |
| qf2_loss                | 4.212694e-05  |
| time_elapsed            | 1969          |
| total timesteps         | 374995        |
| value_loss              | 2.1424607e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0007144772  |
| ent_coef_loss           | 4.964751      |
| entropy                 | 1.064801      |
| episodes                | 1572          |
| fps                     | 190           |
| mean 100 episode reward | 0.8           |
| n_updates               | 375668        |
| policy_loss             | -0.571102     |
| qf1_loss                | 3.0786305e-05 |
| qf2_loss                | 3.679285e-05  |
| time_elapsed            | 1973          |
| total timesteps         | 375768        |
| value_loss              | 5.9922197e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00076097494 |
| ent_coef_loss           | -3.1904013    |
| entropy                 | 1.0539926     |
| episodes                | 1576          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 376608        |
| policy_loss             | -0.57916474   |
| qf1_loss                | 5.624908e-05  |
| qf2_loss                | 4.4418997e-05 |
| time_elapsed            | 1978          |
| total timesteps         | 376708        |
| value_loss              | 6.249572e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00075243326 |
| ent_coef_loss           | -0.6571546    |
| entropy                 | 0.9334163     |
| episodes                | 1580          |
| fps                     | 190           |
| mean 100 episode reward | 0.6           |
| n_updates               | 377126        |
| policy_loss             | -0.5572395    |
| qf1_loss                | 0.00013835664 |
| qf2_loss                | 0.00014256465 |
| time_elapsed            | 1981          |
| total timesteps         | 377226        |
| value_loss              | 0.0003476824  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008415906  |
| ent_coef_loss           | 1.9652972     |
| entropy                 | 0.9196894     |
| episodes                | 1584          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 377848        |
| policy_loss             | -0.5865985    |
| qf1_loss                | 0.00014442473 |
| qf2_loss                | 0.0001028841  |
| time_elapsed            | 1985          |
| total timesteps         | 377948        |
| value_loss              | 0.00015935261 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089829863 |
| ent_coef_loss           | -0.89973164   |
| entropy                 | 1.078907      |
| episodes                | 1588          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 378547        |
| policy_loss             | -0.5638714    |
| qf1_loss                | 0.00014989478 |
| qf2_loss                | 0.00014518351 |
| time_elapsed            | 1988          |
| total timesteps         | 378647        |
| value_loss              | 0.00010696174 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008092618  |
| ent_coef_loss           | 0.5240398     |
| entropy                 | 0.9086647     |
| episodes                | 1592          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 379269        |
| policy_loss             | -0.6247961    |
| qf1_loss                | 7.159272e-05  |
| qf2_loss                | 7.616878e-05  |
| time_elapsed            | 1992          |
| total timesteps         | 379369        |
| value_loss              | 9.7523705e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008079647  |
| ent_coef_loss           | 0.8762851     |
| entropy                 | 0.8483583     |
| episodes                | 1596          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 380199        |
| policy_loss             | -0.5475709    |
| qf1_loss                | 0.00016912993 |
| qf2_loss                | 6.439731e-05  |
| time_elapsed            | 1997          |
| total timesteps         | 380299        |
| value_loss              | 5.8376216e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009405999  |
| ent_coef_loss           | -1.0380876    |
| entropy                 | 0.88653064    |
| episodes                | 1600          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 380942        |
| policy_loss             | -0.60981107   |
| qf1_loss                | 5.733165e-05  |
| qf2_loss                | 7.348686e-05  |
| time_elapsed            | 2001          |
| total timesteps         | 381042        |
| value_loss              | 9.9337965e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009449092  |
| ent_coef_loss           | -0.1003288    |
| entropy                 | 0.8936417     |
| episodes                | 1604          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 381887        |
| policy_loss             | -0.56814194   |
| qf1_loss                | 5.1913856e-05 |
| qf2_loss                | 5.538505e-05  |
| time_elapsed            | 2006          |
| total timesteps         | 381987        |
| value_loss              | 6.246763e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0005         |
| ent_coef                | 0.0009776304   |
| ent_coef_loss           | -1.4071254     |
| entropy                 | 0.8206876      |
| episodes                | 1608           |
| fps                     | 190            |
| mean 100 episode reward | 0.7            |
| n_updates               | 382556         |
| policy_loss             | -0.53482914    |
| qf1_loss                | 0.000105174644 |
| qf2_loss                | 8.1438586e-05  |
| time_elapsed            | 2009           |
| total timesteps         | 382656         |
| value_loss              | 0.00010556829  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0009865208  |
| ent_coef_loss           | -0.08145589   |
| entropy                 | 1.0562667     |
| episodes                | 1612          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 383488        |
| policy_loss             | -0.6201924    |
| qf1_loss                | 4.1681564e-05 |
| qf2_loss                | 2.782461e-05  |
| time_elapsed            | 2014          |
| total timesteps         | 383588        |
| value_loss              | 0.00013088484 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.00089260907 |
| ent_coef_loss           | 0.013600469   |
| entropy                 | 0.87628025    |
| episodes                | 1616          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 384473        |
| policy_loss             | -0.5281223    |
| qf1_loss                | 3.932364e-05  |
| qf2_loss                | 4.9689563e-05 |
| time_elapsed            | 2020          |
| total timesteps         | 384573        |
| value_loss              | 3.1316067e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0005        |
| ent_coef                | 0.0008866143  |
| ent_coef_loss           | 0.4556961     |
| entropy                 | 0.9243524     |
| episodes                | 1620          |
| fps                     | 190           |
| mean 100 episode reward | 0.7           |
| n_updates               | 385329        |
| policy_loss             | -0.5526393    |
| qf1_loss                | 2.5000258e-05 |
| qf2_loss                | 3.6367856e-05 |
| time_elapsed            | 2024          |
| total timesteps         | 385429        |
| value_loss              | 6.218916e-05  |
-------------------------------------------
